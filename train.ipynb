{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This is the training section of the Spectrogram U-Net for Music Source Separation. Before running this, make sure the Spectrograms directory (along with the data points for testing and training, of course) is generated by running the preprocessor.py file once.\n",
    "\n",
    "The training process utilizes the architecture of U-Net implemented in the UNet.py file and the loss functions implemented in the loss_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from architectures.UNet.UNet import SpectrogramUNet\n",
    "from architectures.UNet.loss_functions import VocalLoss, InstrumentLoss\n",
    "from dataset import DSDDataset\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializations and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECTROGRAMS_PATH = './Spectrograms'\n",
    "VOCAL_ONLY = True\n",
    "MODEL_PATH = \"./models/vocal-accompaniment-separation/\" if VOCAL_ONLY else \"./models/all-separation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_CHANNELS = 1\n",
    "OUT_CHANNELS = 2 if VOCAL_ONLY else 4\n",
    "FEATURES = [32, 64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-6\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAL_ALPHA = 0.651 #as per my calculations that hinge on borderline delusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA1 = 0.297\n",
    "ALPHA2 = 0.262\n",
    "ALPHA3 = 0.232\n",
    "ALPHA4 = 0.209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpectrogramUNet(in_channel=IN_CHANNELS, out_channel=OUT_CHANNELS, features=FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "├─ModuleList: 1-1                             --\n",
      "|    └─DoubleConv: 2-1                        --\n",
      "|    |    └─Sequential: 3-1                   9,696\n",
      "|    └─DoubleConv: 2-2                        --\n",
      "|    |    └─Sequential: 3-2                   55,680\n",
      "|    └─DoubleConv: 2-3                        --\n",
      "|    |    └─Sequential: 3-3                   221,952\n",
      "|    └─DoubleConv: 2-4                        --\n",
      "|    |    └─Sequential: 3-4                   886,272\n",
      "|    └─DoubleConv: 2-5                        --\n",
      "|    |    └─Sequential: 3-5                   3,542,016\n",
      "├─ModuleList: 1-2                             --\n",
      "|    └─UpSampling: 2-6                        --\n",
      "|    |    └─Sequential: 3-6                   3,277,568\n",
      "|    └─DoubleDeConv: 2-7                      --\n",
      "|    |    └─Sequential: 3-7                   1,771,008\n",
      "|    └─UpSampling: 2-8                        --\n",
      "|    |    └─Sequential: 3-8                   819,584\n",
      "|    └─DoubleDeConv: 2-9                      --\n",
      "|    |    └─Sequential: 3-9                   443,136\n",
      "|    └─UpSampling: 2-10                       --\n",
      "|    |    └─Sequential: 3-10                  204,992\n",
      "|    └─DoubleDeConv: 2-11                     --\n",
      "|    |    └─Sequential: 3-11                  110,976\n",
      "|    └─UpSampling: 2-12                       --\n",
      "|    |    └─Sequential: 3-12                  51,296\n",
      "|    └─DoubleDeConv: 2-13                     --\n",
      "|    |    └─Sequential: 3-13                  27,840\n",
      "├─MaxPool2d: 1-3                              --\n",
      "├─Conv2d: 1-4                                 66\n",
      "======================================================================\n",
      "Total params: 11,422,082\n",
      "Trainable params: 11,422,082\n",
      "Non-trainable params: 0\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "├─ModuleList: 1-1                             --\n",
       "|    └─DoubleConv: 2-1                        --\n",
       "|    |    └─Sequential: 3-1                   9,696\n",
       "|    └─DoubleConv: 2-2                        --\n",
       "|    |    └─Sequential: 3-2                   55,680\n",
       "|    └─DoubleConv: 2-3                        --\n",
       "|    |    └─Sequential: 3-3                   221,952\n",
       "|    └─DoubleConv: 2-4                        --\n",
       "|    |    └─Sequential: 3-4                   886,272\n",
       "|    └─DoubleConv: 2-5                        --\n",
       "|    |    └─Sequential: 3-5                   3,542,016\n",
       "├─ModuleList: 1-2                             --\n",
       "|    └─UpSampling: 2-6                        --\n",
       "|    |    └─Sequential: 3-6                   3,277,568\n",
       "|    └─DoubleDeConv: 2-7                      --\n",
       "|    |    └─Sequential: 3-7                   1,771,008\n",
       "|    └─UpSampling: 2-8                        --\n",
       "|    |    └─Sequential: 3-8                   819,584\n",
       "|    └─DoubleDeConv: 2-9                      --\n",
       "|    |    └─Sequential: 3-9                   443,136\n",
       "|    └─UpSampling: 2-10                       --\n",
       "|    |    └─Sequential: 3-10                  204,992\n",
       "|    └─DoubleDeConv: 2-11                     --\n",
       "|    |    └─Sequential: 3-11                  110,976\n",
       "|    └─UpSampling: 2-12                       --\n",
       "|    |    └─Sequential: 3-12                  51,296\n",
       "|    └─DoubleDeConv: 2-13                     --\n",
       "|    |    └─Sequential: 3-13                  27,840\n",
       "├─MaxPool2d: 1-3                              --\n",
       "├─Conv2d: 1-4                                 66\n",
       "======================================================================\n",
       "Total params: 11,422,082\n",
       "Trainable params: 11,422,082\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = DSDDataset(spectrograms_path=SPECTROGRAMS_PATH, vocal_only=VOCAL_ONLY, train=True)\n",
    "val_set = DSDDataset(spectrograms_path=SPECTROGRAMS_PATH, vocal_only=VOCAL_ONLY, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: torch.Size([8, 1, 1025, 173])\n",
      "\n",
      "Targets: dict_keys(['vocals', 'accompaniment'])\n",
      "\n",
      "Vocal target shape: torch.Size([8, 1, 1025, 173])\n",
      "\n",
      "Accompaniment target shape: torch.Size([8, 1, 1025, 173])\n"
     ]
    }
   ],
   "source": [
    "for feature, target in train_loader:\n",
    "    print(f\"Feature shape: {feature.shape}\\n\")\n",
    "    print(f\"Targets: {target.keys()}\\n\")\n",
    "    print(f\"Vocal target shape: {target['vocals'].shape}\\n\")\n",
    "    print(f\"Accompaniment target shape: {target['accompaniment'].shape}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(model, dataloader, loss_fn, optimizer, device):\n",
    "    \n",
    "    model = model.to(device)\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "         \n",
    "        feature, target = data\n",
    "\n",
    "        feature = feature.to(device)\n",
    "        target['accompaniment'] = target['accompaniment'].to(device)\n",
    "        target['vocals'] = target['vocals'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(feature)\n",
    "\n",
    "        vocal_channel_output = outputs[:, 0, :, :].unsqueeze(1)\n",
    "        accompaniment_channel_output = outputs[:, 1, :, :].unsqueeze(1)\n",
    "\n",
    "        loss = loss_fn(vocal_channel_output ,target['vocals'],  accompaniment_channel_output ,target['accompaniment'])\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "\n",
    "        if (i+1)%5==0:\n",
    "         last_loss = running_loss/5\n",
    "         print(f'Batch {i+1},  loss: {last_loss}')\n",
    "         running_loss=0\n",
    "    return last_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_fn, optimizer, device, epochs):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f'EPOCH {epoch+1}:')\n",
    "\n",
    "        model.train(True)\n",
    "        avg_loss = train_one(model, train_loader, loss_fn, optimizer, device)\n",
    "\n",
    "        running_val_loss = 0.0\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for i, vdata in enumerate(val_loader):\n",
    "                vfeature, vtarget = vdata\n",
    "                vfeature = vfeature.to(device)\n",
    "                vtarget['accompaniment'] = vtarget['accompaniment'].to(device)\n",
    "                vtarget['vocals'] = vtarget['vocals'].to(device)\n",
    "                voutput = model(vfeature)\n",
    "\n",
    "                vocal_channel_output = voutput[:, 0, :, :].unsqueeze(1)\n",
    "                accompaniment_channel_output = voutput[:, 1, :, :].unsqueeze(1)\n",
    "                vloss = loss_fn(vocal_channel_output, vtarget['vocals'], accompaniment_channel_output, vtarget['accompaniment'])\n",
    "                running_val_loss += vloss.item()\n",
    "            avg_vloss = running_val_loss / (i + 1)\n",
    "            print(f'LOSS train {avg_loss}. Validation loss: {avg_vloss} \\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lr=LEARNING_RATE, params=model.parameters(), weight_decay=WEIGHT_DECAY)\n",
    "loss_fn = VocalLoss(alpha=VOCAL_ALPHA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "Batch 5,  loss: 0.5277842581272125\n",
      "Batch 10,  loss: 0.5417925000190735\n",
      "Batch 15,  loss: 0.4697329461574554\n",
      "Batch 20,  loss: 0.4361927568912506\n",
      "Batch 25,  loss: 0.46901829838752745\n",
      "Batch 30,  loss: 0.47267635464668273\n",
      "Batch 35,  loss: 0.4088644742965698\n",
      "Batch 40,  loss: 0.3632271021604538\n",
      "Batch 45,  loss: 0.45297521352767944\n",
      "Batch 50,  loss: 0.4435111105442047\n",
      "Batch 55,  loss: 0.38349348306655884\n",
      "Batch 60,  loss: 0.45731995105743406\n",
      "Batch 65,  loss: 0.402921199798584\n",
      "Batch 70,  loss: 0.3789593309164047\n",
      "Batch 75,  loss: 0.3728358387947083\n",
      "Batch 80,  loss: 0.43539483547210694\n",
      "Batch 85,  loss: 0.42598719000816343\n",
      "Batch 90,  loss: 0.3862423896789551\n",
      "Batch 95,  loss: 0.3646151602268219\n",
      "Batch 100,  loss: 0.4233479738235474\n",
      "Batch 105,  loss: 0.37043683528900145\n",
      "Batch 110,  loss: 0.36508663892745974\n",
      "Batch 115,  loss: 0.3448273539543152\n",
      "Batch 120,  loss: 0.3769064098596573\n",
      "Batch 125,  loss: 0.4326876699924469\n",
      "Batch 130,  loss: 0.3790858328342438\n",
      "Batch 135,  loss: 0.3994510114192963\n",
      "Batch 140,  loss: 0.36508655548095703\n",
      "Batch 145,  loss: 0.412154084444046\n",
      "Batch 150,  loss: 0.3868043661117554\n",
      "Batch 155,  loss: 0.3472862333059311\n",
      "Batch 160,  loss: 0.3526044309139252\n",
      "Batch 165,  loss: 0.3808549106121063\n",
      "Batch 170,  loss: 0.3781320333480835\n",
      "Batch 175,  loss: 0.3751114785671234\n",
      "Batch 180,  loss: 0.35963515639305116\n",
      "Batch 185,  loss: 0.38251838088035583\n",
      "Batch 190,  loss: 0.3122812628746033\n",
      "Batch 195,  loss: 0.3428284525871277\n",
      "Batch 200,  loss: 0.40924790501594543\n",
      "Batch 205,  loss: 0.3371244013309479\n",
      "Batch 210,  loss: 0.35782855153083803\n",
      "Batch 215,  loss: 0.3521371126174927\n",
      "Batch 220,  loss: 0.32016425132751464\n",
      "Batch 225,  loss: 0.32707823216915133\n",
      "Batch 230,  loss: 0.365787410736084\n",
      "Batch 235,  loss: 0.31837473511695863\n",
      "Batch 240,  loss: 0.31427901387214663\n",
      "Batch 245,  loss: 0.36258100867271426\n",
      "Batch 250,  loss: 0.38284451961517335\n",
      "Batch 255,  loss: 0.3871928632259369\n",
      "Batch 260,  loss: 0.416255259513855\n",
      "Batch 265,  loss: 0.3669788360595703\n",
      "Batch 270,  loss: 0.34339656233787536\n",
      "Batch 275,  loss: 0.3321817874908447\n",
      "Batch 280,  loss: 0.3043928980827332\n",
      "Batch 285,  loss: 0.3446000933647156\n",
      "Batch 290,  loss: 0.3958449184894562\n",
      "Batch 295,  loss: 0.3294406235218048\n",
      "Batch 300,  loss: 0.31617521643638613\n",
      "Batch 305,  loss: 0.34671390652656553\n",
      "Batch 310,  loss: 0.38322819471359254\n",
      "Batch 315,  loss: 0.3106840193271637\n",
      "Batch 320,  loss: 0.33523699045181277\n",
      "Batch 325,  loss: 0.4292794644832611\n",
      "Batch 330,  loss: 0.46802343130111695\n",
      "Batch 335,  loss: 0.28797149658203125\n",
      "Batch 340,  loss: 0.4179149031639099\n",
      "Batch 345,  loss: 0.38408883810043337\n",
      "Batch 350,  loss: 0.34526175260543823\n",
      "Batch 355,  loss: 0.3303211510181427\n",
      "Batch 360,  loss: 0.3543245792388916\n",
      "Batch 365,  loss: 0.3151010096073151\n",
      "Batch 370,  loss: 0.31687227487564085\n",
      "Batch 375,  loss: 0.4492840111255646\n",
      "Batch 380,  loss: 0.4257389008998871\n",
      "Batch 385,  loss: 0.34302051067352296\n",
      "Batch 390,  loss: 0.2831042319536209\n",
      "Batch 395,  loss: 0.36034985184669494\n",
      "Batch 400,  loss: 0.31812961101531984\n",
      "Batch 405,  loss: 0.38722015619277955\n",
      "Batch 410,  loss: 0.25803974866867063\n",
      "Batch 415,  loss: 0.3226012229919434\n",
      "Batch 420,  loss: 0.3728673100471497\n",
      "Batch 425,  loss: 0.36564840078353883\n",
      "Batch 430,  loss: 0.28091593980789187\n",
      "Batch 435,  loss: 0.3686992347240448\n",
      "Batch 440,  loss: 0.32992081344127655\n",
      "Batch 445,  loss: 0.321748948097229\n",
      "Batch 450,  loss: 0.25921958684921265\n",
      "Batch 455,  loss: 0.3187249004840851\n",
      "Batch 460,  loss: 0.30523261725902556\n",
      "Batch 465,  loss: 0.3369579643011093\n",
      "Batch 470,  loss: 0.35261930227279664\n",
      "Batch 475,  loss: 0.3657365083694458\n",
      "Batch 480,  loss: 0.32957770824432375\n",
      "Batch 485,  loss: 0.3278039753437042\n",
      "Batch 490,  loss: 0.3304205358028412\n",
      "Batch 495,  loss: 0.3477275550365448\n",
      "Batch 500,  loss: 0.2966440826654434\n",
      "Batch 505,  loss: 0.32527785897254946\n",
      "Batch 510,  loss: 0.2873452603816986\n",
      "Batch 515,  loss: 0.3768227338790894\n",
      "Batch 520,  loss: 0.3718563973903656\n",
      "Batch 525,  loss: 0.35156087279319764\n",
      "Batch 530,  loss: 0.31825755834579467\n",
      "Batch 535,  loss: 0.38455620408058167\n",
      "Batch 540,  loss: 0.30345308780670166\n",
      "Batch 545,  loss: 0.35488681197166444\n",
      "Batch 550,  loss: 0.33132373690605166\n",
      "Batch 555,  loss: 0.3089525789022446\n",
      "Batch 560,  loss: 0.33957406878471375\n",
      "Batch 565,  loss: 0.34316856861114503\n",
      "Batch 570,  loss: 0.35545344948768615\n",
      "Batch 575,  loss: 0.27630890905857086\n",
      "Batch 580,  loss: 0.35196166634559634\n",
      "Batch 585,  loss: 0.2790533274412155\n",
      "Batch 590,  loss: 0.34437660574913026\n",
      "Batch 595,  loss: 0.2622443974018097\n",
      "Batch 600,  loss: 0.29742295742034913\n",
      "Batch 605,  loss: 0.3199381113052368\n",
      "Batch 610,  loss: 0.3725289136171341\n",
      "Batch 615,  loss: 0.29478038251399996\n",
      "Batch 620,  loss: 0.30693461298942565\n",
      "Batch 625,  loss: 0.3129689633846283\n",
      "Batch 630,  loss: 0.30669569969177246\n",
      "Batch 635,  loss: 0.3394334316253662\n",
      "Batch 640,  loss: 0.28304705023765564\n",
      "Batch 645,  loss: 0.35743007659912107\n",
      "Batch 650,  loss: 0.31355823278427125\n",
      "Batch 655,  loss: 0.368800550699234\n",
      "Batch 660,  loss: 0.34836806654930114\n",
      "Batch 665,  loss: 0.2733970910310745\n",
      "Batch 670,  loss: 0.30162513256073\n",
      "Batch 675,  loss: 0.288840526342392\n",
      "Batch 680,  loss: 0.3070934057235718\n",
      "Batch 685,  loss: 0.2757603466510773\n",
      "Batch 690,  loss: 0.3596875429153442\n",
      "Batch 695,  loss: 0.30946989059448243\n",
      "Batch 700,  loss: 0.33769422173500063\n",
      "Batch 705,  loss: 0.359957754611969\n",
      "Batch 710,  loss: 0.33469086289405825\n",
      "Batch 715,  loss: 0.3560568630695343\n",
      "Batch 720,  loss: 0.3019704699516296\n",
      "Batch 725,  loss: 0.2938792914152145\n",
      "Batch 730,  loss: 0.35958101153373717\n",
      "Batch 735,  loss: 0.33544001579284666\n",
      "Batch 740,  loss: 0.275093811750412\n",
      "Batch 745,  loss: 0.3698927700519562\n",
      "Batch 750,  loss: 0.3571006000041962\n",
      "Batch 755,  loss: 0.30650598406791685\n",
      "Batch 760,  loss: 0.31752332448959353\n",
      "Batch 765,  loss: 0.3016566216945648\n",
      "Batch 770,  loss: 0.33166685700416565\n",
      "Batch 775,  loss: 0.29681065380573274\n",
      "Batch 780,  loss: 0.3420881360769272\n",
      "Batch 785,  loss: 0.2770609468221664\n",
      "Batch 790,  loss: 0.3392327904701233\n",
      "Batch 795,  loss: 0.2922353148460388\n",
      "Batch 800,  loss: 0.37805246710777285\n",
      "Batch 805,  loss: 0.25118176341056825\n",
      "Batch 810,  loss: 0.29221625328063966\n",
      "Batch 815,  loss: 0.3083688497543335\n",
      "Batch 820,  loss: 0.3328569412231445\n",
      "Batch 825,  loss: 0.2988471031188965\n",
      "Batch 830,  loss: 0.3122012734413147\n",
      "Batch 835,  loss: 0.30785030126571655\n",
      "Batch 840,  loss: 0.25677770376205444\n",
      "Batch 845,  loss: 0.3817669689655304\n",
      "Batch 850,  loss: 0.34965293407440184\n",
      "Batch 855,  loss: 0.3166939616203308\n",
      "Batch 860,  loss: 0.3890660166740417\n",
      "Batch 865,  loss: 0.2851104557514191\n",
      "Batch 870,  loss: 0.305500453710556\n",
      "Batch 875,  loss: 0.37019863724708557\n",
      "Batch 880,  loss: 0.28071117103099824\n",
      "Batch 885,  loss: 0.31981833577156066\n",
      "Batch 890,  loss: 0.357376366853714\n",
      "Batch 895,  loss: 0.3787968307733536\n",
      "Batch 900,  loss: 0.3200793623924255\n",
      "Batch 905,  loss: 0.3113870322704315\n",
      "Batch 910,  loss: 0.3342340111732483\n",
      "Batch 915,  loss: 0.3139582633972168\n",
      "Batch 920,  loss: 0.33279470205307005\n",
      "Batch 925,  loss: 0.2976987898349762\n",
      "Batch 930,  loss: 0.2983315706253052\n",
      "Batch 935,  loss: 0.27476893961429594\n",
      "Batch 940,  loss: 0.33289151787757876\n",
      "Batch 945,  loss: 0.2986381769180298\n",
      "Batch 950,  loss: 0.29887411594390867\n",
      "Batch 955,  loss: 0.3607961475849152\n",
      "Batch 960,  loss: 0.35580371618270873\n",
      "Batch 965,  loss: 0.27583531141281126\n",
      "Batch 970,  loss: 0.24467416405677794\n",
      "Batch 975,  loss: 0.3834490716457367\n",
      "Batch 980,  loss: 0.2743851184844971\n",
      "Batch 985,  loss: 0.3218245983123779\n",
      "Batch 990,  loss: 0.28352050185203553\n",
      "Batch 995,  loss: 0.3204016089439392\n",
      "Batch 1000,  loss: 0.2956180274486542\n",
      "Batch 1005,  loss: 0.29723540544509885\n",
      "Batch 1010,  loss: 0.25810423493385315\n",
      "Batch 1015,  loss: 0.3188523054122925\n",
      "Batch 1020,  loss: 0.363212651014328\n",
      "Batch 1025,  loss: 0.32875266671180725\n",
      "Batch 1030,  loss: 0.2830712527036667\n",
      "Batch 1035,  loss: 0.26006301045417785\n",
      "Batch 1040,  loss: 0.31049518287181854\n",
      "Batch 1045,  loss: 0.32574477791786194\n",
      "Batch 1050,  loss: 0.27318344712257386\n",
      "Batch 1055,  loss: 0.25103040039539337\n",
      "Batch 1060,  loss: 0.2982201397418976\n",
      "Batch 1065,  loss: 0.3093501806259155\n",
      "Batch 1070,  loss: 0.2875928521156311\n",
      "Batch 1075,  loss: 0.3430355191230774\n",
      "Batch 1080,  loss: 0.30719161331653594\n",
      "Batch 1085,  loss: 0.34438394010066986\n",
      "Batch 1090,  loss: 0.30543524622917173\n",
      "Batch 1095,  loss: 0.31642635464668273\n",
      "Batch 1100,  loss: 0.2616525381803513\n",
      "Batch 1105,  loss: 0.30519508719444277\n",
      "Batch 1110,  loss: 0.3027722865343094\n",
      "Batch 1115,  loss: 0.34486266374588015\n",
      "Batch 1120,  loss: 0.2544120818376541\n",
      "Batch 1125,  loss: 0.29617666602134707\n",
      "Batch 1130,  loss: 0.27304318845272063\n",
      "Batch 1135,  loss: 0.3166881173849106\n",
      "Batch 1140,  loss: 0.3862462878227234\n",
      "Batch 1145,  loss: 0.30367915630340575\n",
      "Batch 1150,  loss: 0.3096776843070984\n",
      "Batch 1155,  loss: 0.3089240074157715\n",
      "Batch 1160,  loss: 0.28338648080825807\n",
      "Batch 1165,  loss: 0.2937684118747711\n",
      "Batch 1170,  loss: 0.255523157119751\n",
      "Batch 1175,  loss: 0.2842663645744324\n",
      "Batch 1180,  loss: 0.341483536362648\n",
      "Batch 1185,  loss: 0.3207392394542694\n",
      "Batch 1190,  loss: 0.3135666370391846\n",
      "Batch 1195,  loss: 0.3628041982650757\n",
      "Batch 1200,  loss: 0.25285168290138244\n",
      "Batch 1205,  loss: 0.2890903502702713\n",
      "Batch 1210,  loss: 0.3052903562784195\n",
      "Batch 1215,  loss: 0.25180512070655825\n",
      "Batch 1220,  loss: 0.30194170475006105\n",
      "Batch 1225,  loss: 0.2853092133998871\n",
      "Batch 1230,  loss: 0.304691082239151\n",
      "Batch 1235,  loss: 0.29687082171440127\n",
      "Batch 1240,  loss: 0.36915449500083924\n",
      "Batch 1245,  loss: 0.32171398401260376\n",
      "Batch 1250,  loss: 0.2512815952301025\n",
      "Batch 1255,  loss: 0.2827736407518387\n",
      "Batch 1260,  loss: 0.3081683337688446\n",
      "Batch 1265,  loss: 0.35125817358493805\n",
      "Batch 1270,  loss: 0.294084358215332\n",
      "Batch 1275,  loss: 0.31712931394577026\n",
      "Batch 1280,  loss: 0.33525999188423156\n",
      "Batch 1285,  loss: 0.2835590422153473\n",
      "Batch 1290,  loss: 0.29129649698734283\n",
      "Batch 1295,  loss: 0.2907665461301804\n",
      "Batch 1300,  loss: 0.33063417077064516\n",
      "Batch 1305,  loss: 0.2739928185939789\n",
      "Batch 1310,  loss: 0.33260194957256317\n",
      "Batch 1315,  loss: 0.2621590793132782\n",
      "Batch 1320,  loss: 0.24298766851425171\n",
      "Batch 1325,  loss: 0.2661713272333145\n",
      "Batch 1330,  loss: 0.2619384527206421\n",
      "Batch 1335,  loss: 0.21703461706638336\n",
      "Batch 1340,  loss: 0.27105998396873476\n",
      "Batch 1345,  loss: 0.31777127385139464\n",
      "Batch 1350,  loss: 0.3293307900428772\n",
      "Batch 1355,  loss: 0.30798194408416746\n",
      "Batch 1360,  loss: 0.2754907995462418\n",
      "Batch 1365,  loss: 0.28850739598274233\n",
      "Batch 1370,  loss: 0.2888524651527405\n",
      "Batch 1375,  loss: 0.30414952635765075\n",
      "Batch 1380,  loss: 0.3131330728530884\n",
      "Batch 1385,  loss: 0.31182992458343506\n",
      "Batch 1390,  loss: 0.2691482752561569\n",
      "Batch 1395,  loss: 0.2997643053531647\n",
      "Batch 1400,  loss: 0.299640554189682\n",
      "Batch 1405,  loss: 0.34130279123783114\n",
      "Batch 1410,  loss: 0.24249668419361115\n",
      "Batch 1415,  loss: 0.3222025543451309\n",
      "Batch 1420,  loss: 0.30696249604225156\n",
      "Batch 1425,  loss: 0.24405869841575623\n",
      "Batch 1430,  loss: 0.2324380874633789\n",
      "Batch 1435,  loss: 0.3563093483448029\n",
      "Batch 1440,  loss: 0.3150653213262558\n",
      "Batch 1445,  loss: 0.29847821295261384\n",
      "Batch 1450,  loss: 0.27971538007259367\n",
      "Batch 1455,  loss: 0.32699432373046877\n",
      "Batch 1460,  loss: 0.29014855325222016\n",
      "Batch 1465,  loss: 0.294699165225029\n",
      "Batch 1470,  loss: 0.28816327154636384\n",
      "Batch 1475,  loss: 0.2992843508720398\n",
      "Batch 1480,  loss: 0.31786258816719054\n",
      "Batch 1485,  loss: 0.2702220529317856\n",
      "Batch 1490,  loss: 0.20523203015327454\n",
      "Batch 1495,  loss: 0.2808109223842621\n",
      "Batch 1500,  loss: 0.2751598536968231\n",
      "Batch 1505,  loss: 0.28207932114601136\n",
      "Batch 1510,  loss: 0.306339955329895\n",
      "Batch 1515,  loss: 0.3429711937904358\n",
      "Batch 1520,  loss: 0.36589057743549347\n",
      "Batch 1525,  loss: 0.2784135341644287\n",
      "Batch 1530,  loss: 0.2917125463485718\n",
      "Batch 1535,  loss: 0.2746056318283081\n",
      "Batch 1540,  loss: 0.3107184052467346\n",
      "Batch 1545,  loss: 0.316684490442276\n",
      "Batch 1550,  loss: 0.32655545473098757\n",
      "Batch 1555,  loss: 0.31546675562858584\n",
      "Batch 1560,  loss: 0.2480068176984787\n",
      "Batch 1565,  loss: 0.3285703480243683\n",
      "Batch 1570,  loss: 0.2577973961830139\n",
      "Batch 1575,  loss: 0.2744264632463455\n",
      "Batch 1580,  loss: 0.29188836812973024\n",
      "Batch 1585,  loss: 0.30200599431991576\n",
      "Batch 1590,  loss: 0.2720765620470047\n",
      "Batch 1595,  loss: 0.26124770045280454\n",
      "Batch 1600,  loss: 0.3207391321659088\n",
      "Batch 1605,  loss: 0.29363601207733153\n",
      "Batch 1610,  loss: 0.2654261589050293\n",
      "Batch 1615,  loss: 0.2928165793418884\n",
      "Batch 1620,  loss: 0.264813494682312\n",
      "Batch 1625,  loss: 0.34885379672050476\n",
      "Batch 1630,  loss: 0.33844574093818663\n",
      "Batch 1635,  loss: 0.3439737856388092\n",
      "Batch 1640,  loss: 0.22729903757572173\n",
      "Batch 1645,  loss: 0.3169442117214203\n",
      "Batch 1650,  loss: 0.2909147560596466\n",
      "Batch 1655,  loss: 0.23751063644886017\n",
      "Batch 1660,  loss: 0.3363358020782471\n",
      "Batch 1665,  loss: 0.2748824954032898\n",
      "Batch 1670,  loss: 0.27350854873657227\n",
      "Batch 1675,  loss: 0.2718033164739609\n",
      "Batch 1680,  loss: 0.3726228058338165\n",
      "Batch 1685,  loss: 0.2733550310134888\n",
      "Batch 1690,  loss: 0.3536055326461792\n",
      "Batch 1695,  loss: 0.33169694542884826\n",
      "Batch 1700,  loss: 0.2990314602851868\n",
      "Batch 1705,  loss: 0.21954011023044587\n",
      "Batch 1710,  loss: 0.23043778538703918\n",
      "Batch 1715,  loss: 0.317476162314415\n",
      "Batch 1720,  loss: 0.28736690878868104\n",
      "Batch 1725,  loss: 0.3084635198116302\n",
      "Batch 1730,  loss: 0.2888650357723236\n",
      "Batch 1735,  loss: 0.25263831913471224\n",
      "Batch 1740,  loss: 0.34004184007644656\n",
      "Batch 1745,  loss: 0.292460161447525\n",
      "Batch 1750,  loss: 0.2861288249492645\n",
      "Batch 1755,  loss: 0.27826552391052245\n",
      "Batch 1760,  loss: 0.246721950173378\n",
      "Batch 1765,  loss: 0.26974389553070066\n",
      "Batch 1770,  loss: 0.26933409571647643\n",
      "Batch 1775,  loss: 0.33878484964370725\n",
      "Batch 1780,  loss: 0.2915951102972031\n",
      "Batch 1785,  loss: 0.3009281873703003\n",
      "Batch 1790,  loss: 0.29118120670318604\n",
      "Batch 1795,  loss: 0.34438747763633726\n",
      "Batch 1800,  loss: 0.27135654389858244\n",
      "Batch 1805,  loss: 0.2927163243293762\n",
      "Batch 1810,  loss: 0.23497590124607087\n",
      "Batch 1815,  loss: 0.2765196979045868\n",
      "Batch 1820,  loss: 0.29805301427841185\n",
      "Batch 1825,  loss: 0.29011245965957644\n",
      "Batch 1830,  loss: 0.2842001885175705\n",
      "Batch 1835,  loss: 0.24640342891216277\n",
      "Batch 1840,  loss: 0.2504564464092255\n",
      "Batch 1845,  loss: 0.2824980437755585\n",
      "Batch 1850,  loss: 0.28179881870746615\n",
      "Batch 1855,  loss: 0.2705237865447998\n",
      "Batch 1860,  loss: 0.28515766859054564\n",
      "Batch 1865,  loss: 0.29878783226013184\n",
      "Batch 1870,  loss: 0.2766841471195221\n",
      "Batch 1875,  loss: 0.2780725538730621\n",
      "Batch 1880,  loss: 0.2897668719291687\n",
      "Batch 1885,  loss: 0.3091330170631409\n",
      "Batch 1890,  loss: 0.2586574196815491\n",
      "Batch 1895,  loss: 0.30832738280296323\n",
      "Batch 1900,  loss: 0.22570163905620574\n",
      "Batch 1905,  loss: 0.30667738914489745\n",
      "Batch 1910,  loss: 0.2840537965297699\n",
      "Batch 1915,  loss: 0.2857820808887482\n",
      "Batch 1920,  loss: 0.26061873137950897\n",
      "Batch 1925,  loss: 0.2996090233325958\n",
      "Batch 1930,  loss: 0.30477564930915835\n",
      "Batch 1935,  loss: 0.26147600710392\n",
      "Batch 1940,  loss: 0.2807100236415863\n",
      "Batch 1945,  loss: 0.3083594560623169\n",
      "Batch 1950,  loss: 0.2747059851884842\n",
      "Batch 1955,  loss: 0.25240174531936643\n",
      "Batch 1960,  loss: 0.2504757046699524\n",
      "Batch 1965,  loss: 0.24096475541591644\n",
      "Batch 1970,  loss: 0.2688554376363754\n",
      "Batch 1975,  loss: 0.26186357736587523\n",
      "Batch 1980,  loss: 0.29198052883148196\n",
      "Batch 1985,  loss: 0.25022744536399844\n",
      "Batch 1990,  loss: 0.27978616058826444\n",
      "Batch 1995,  loss: 0.29366756677627565\n",
      "Batch 2000,  loss: 0.22430651485919953\n",
      "Batch 2005,  loss: 0.28639020323753356\n",
      "Batch 2010,  loss: 0.31702737510204315\n",
      "Batch 2015,  loss: 0.2927742004394531\n",
      "Batch 2020,  loss: 0.2946658104658127\n",
      "Batch 2025,  loss: 0.30473113656044004\n",
      "Batch 2030,  loss: 0.2565662920475006\n",
      "Batch 2035,  loss: 0.2731827437877655\n",
      "Batch 2040,  loss: 0.2658898442983627\n",
      "Batch 2045,  loss: 0.27288960218429564\n",
      "Batch 2050,  loss: 0.2526369333267212\n",
      "Batch 2055,  loss: 0.3239004731178284\n",
      "Batch 2060,  loss: 0.2809242606163025\n",
      "Batch 2065,  loss: 0.27146620452404024\n",
      "Batch 2070,  loss: 0.26362565755844114\n",
      "Batch 2075,  loss: 0.2685562163591385\n",
      "Batch 2080,  loss: 0.27249912917613983\n",
      "Batch 2085,  loss: 0.2633410215377808\n",
      "Batch 2090,  loss: 0.23699325919151307\n",
      "Batch 2095,  loss: 0.29145925045013427\n",
      "Batch 2100,  loss: 0.245658740401268\n",
      "Batch 2105,  loss: 0.2934377372264862\n",
      "Batch 2110,  loss: 0.2621208935976028\n",
      "Batch 2115,  loss: 0.2418577641248703\n",
      "Batch 2120,  loss: 0.27738647162914276\n",
      "Batch 2125,  loss: 0.24221546947956085\n",
      "Batch 2130,  loss: 0.25343276262283326\n",
      "Batch 2135,  loss: 0.2660828948020935\n",
      "Batch 2140,  loss: 0.26582216620445254\n",
      "Batch 2145,  loss: 0.28935854136943817\n",
      "Batch 2150,  loss: 0.3027980327606201\n",
      "Batch 2155,  loss: 0.24603182971477508\n",
      "Batch 2160,  loss: 0.2387743979692459\n",
      "Batch 2165,  loss: 0.2979243040084839\n",
      "Batch 2170,  loss: 0.27136485278606415\n",
      "Batch 2175,  loss: 0.26288408041000366\n",
      "Batch 2180,  loss: 0.2752962827682495\n",
      "Batch 2185,  loss: 0.270704910159111\n",
      "Batch 2190,  loss: 0.2704363465309143\n",
      "Batch 2195,  loss: 0.27300979793071745\n",
      "Batch 2200,  loss: 0.2981380820274353\n",
      "Batch 2205,  loss: 0.2867555797100067\n",
      "Batch 2210,  loss: 0.2485392212867737\n",
      "Batch 2215,  loss: 0.3210923194885254\n",
      "Batch 2220,  loss: 0.2645730823278427\n",
      "Batch 2225,  loss: 0.24276575148105622\n",
      "Batch 2230,  loss: 0.223444801568985\n",
      "Batch 2235,  loss: 0.29410526156425476\n",
      "Batch 2240,  loss: 0.2840948700904846\n",
      "Batch 2245,  loss: 0.2758369237184525\n",
      "Batch 2250,  loss: 0.22637768387794494\n",
      "Batch 2255,  loss: 0.25727849900722505\n",
      "Batch 2260,  loss: 0.24161930084228517\n",
      "Batch 2265,  loss: 0.2840588569641113\n",
      "Batch 2270,  loss: 0.25690079629421236\n",
      "Batch 2275,  loss: 0.25250605642795565\n",
      "Batch 2280,  loss: 0.25287647247314454\n",
      "Batch 2285,  loss: 0.26149131655693053\n",
      "Batch 2290,  loss: 0.27511235475540163\n",
      "Batch 2295,  loss: 0.2542315721511841\n",
      "Batch 2300,  loss: 0.29605627357959746\n",
      "Batch 2305,  loss: 0.2503084659576416\n",
      "Batch 2310,  loss: 0.24223732054233552\n",
      "Batch 2315,  loss: 0.24911570250988008\n",
      "Batch 2320,  loss: 0.25276851654052734\n",
      "Batch 2325,  loss: 0.27308388352394103\n",
      "Batch 2330,  loss: 0.2602508693933487\n",
      "Batch 2335,  loss: 0.2223791629076004\n",
      "Batch 2340,  loss: 0.2582936197519302\n",
      "Batch 2345,  loss: 0.2591709017753601\n",
      "Batch 2350,  loss: 0.27664263248443605\n",
      "Batch 2355,  loss: 0.2682315170764923\n",
      "Batch 2360,  loss: 0.3456290066242218\n",
      "Batch 2365,  loss: 0.26991255581378937\n",
      "Batch 2370,  loss: 0.26637897491455076\n",
      "Batch 2375,  loss: 0.27858791649341585\n",
      "Batch 2380,  loss: 0.24186217784881592\n",
      "Batch 2385,  loss: 0.20638175308704376\n",
      "Batch 2390,  loss: 0.28384656012058257\n",
      "Batch 2395,  loss: 0.23061709702014924\n",
      "Batch 2400,  loss: 0.24705499410629272\n",
      "Batch 2405,  loss: 0.23688575327396394\n",
      "Batch 2410,  loss: 0.23326495587825774\n",
      "Batch 2415,  loss: 0.2568384945392609\n",
      "Batch 2420,  loss: 0.32572019696235655\n",
      "Batch 2425,  loss: 0.26018072962760924\n",
      "Batch 2430,  loss: 0.2959021508693695\n",
      "Batch 2435,  loss: 0.32517921924591064\n",
      "Batch 2440,  loss: 0.23784327507019043\n",
      "Batch 2445,  loss: 0.21094213128089906\n",
      "Batch 2450,  loss: 0.260782915353775\n",
      "Batch 2455,  loss: 0.2809314548969269\n",
      "Batch 2460,  loss: 0.28520016074180604\n",
      "Batch 2465,  loss: 0.238761967420578\n",
      "Batch 2470,  loss: 0.26077401638031006\n",
      "Batch 2475,  loss: 0.24474471509456636\n",
      "Batch 2480,  loss: 0.26654627323150637\n",
      "Batch 2485,  loss: 0.28427211940288544\n",
      "Batch 2490,  loss: 0.25382244884967803\n",
      "Batch 2495,  loss: 0.25716230273246765\n",
      "Batch 2500,  loss: 0.2821883767843246\n",
      "Batch 2505,  loss: 0.26343672573566435\n",
      "Batch 2510,  loss: 0.28555486500263216\n",
      "Batch 2515,  loss: 0.27807773649692535\n",
      "Batch 2520,  loss: 0.29038057923316957\n",
      "Batch 2525,  loss: 0.25247618854045867\n",
      "Batch 2530,  loss: 0.20224414467811586\n",
      "Batch 2535,  loss: 0.27468145191669463\n",
      "Batch 2540,  loss: 0.2764411062002182\n",
      "Batch 2545,  loss: 0.23812061548233032\n",
      "Batch 2550,  loss: 0.2910295367240906\n",
      "Batch 2555,  loss: 0.26098464131355287\n",
      "Batch 2560,  loss: 0.22001030147075654\n",
      "Batch 2565,  loss: 0.2566318780183792\n",
      "Batch 2570,  loss: 0.24240036606788634\n",
      "Batch 2575,  loss: 0.2391118586063385\n",
      "Batch 2580,  loss: 0.25908989906311036\n",
      "Batch 2585,  loss: 0.2983802556991577\n",
      "Batch 2590,  loss: 0.2326434522867203\n",
      "Batch 2595,  loss: 0.2638632506132126\n",
      "Batch 2600,  loss: 0.24897059798240662\n",
      "Batch 2605,  loss: 0.25714983344078063\n",
      "Batch 2610,  loss: 0.2699347913265228\n",
      "Batch 2615,  loss: 0.26303157210350037\n",
      "Batch 2620,  loss: 0.24939932227134703\n",
      "Batch 2625,  loss: 0.2593575924634933\n",
      "Batch 2630,  loss: 0.2785365402698517\n",
      "Batch 2635,  loss: 0.30971630811691286\n",
      "Batch 2640,  loss: 0.30948787927627563\n",
      "Batch 2645,  loss: 0.3013775050640106\n",
      "Batch 2650,  loss: 0.2963230848312378\n",
      "Batch 2655,  loss: 0.2893682062625885\n",
      "Batch 2660,  loss: 0.22631195485591887\n",
      "Batch 2665,  loss: 0.24407195746898652\n",
      "Batch 2670,  loss: 0.22129860520362854\n",
      "Batch 2675,  loss: 0.26821562051773074\n",
      "Batch 2680,  loss: 0.31170758306980134\n",
      "Batch 2685,  loss: 0.26671687364578245\n",
      "Batch 2690,  loss: 0.2940000623464584\n",
      "Batch 2695,  loss: 0.25326815247535706\n",
      "Batch 2700,  loss: 0.2378741353750229\n",
      "Batch 2705,  loss: 0.2460446298122406\n",
      "Batch 2710,  loss: 0.26389744877815247\n",
      "Batch 2715,  loss: 0.2717535972595215\n",
      "Batch 2720,  loss: 0.2523283511400223\n",
      "Batch 2725,  loss: 0.2572888046503067\n",
      "Batch 2730,  loss: 0.2206391930580139\n",
      "Batch 2735,  loss: 0.2489405870437622\n",
      "Batch 2740,  loss: 0.2419820547103882\n",
      "Batch 2745,  loss: 0.26777262091636655\n",
      "Batch 2750,  loss: 0.2384200543165207\n",
      "Batch 2755,  loss: 0.31328313052654266\n",
      "Batch 2760,  loss: 0.215448996424675\n",
      "Batch 2765,  loss: 0.26799566149711607\n",
      "Batch 2770,  loss: 0.3327095001935959\n",
      "LOSS train 0.3327095001935959. Validation loss: 0.23362949229431926 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 2:\n",
      "Batch 5,  loss: 0.2354193776845932\n",
      "Batch 10,  loss: 0.2818483352661133\n",
      "Batch 15,  loss: 0.24647943377494813\n",
      "Batch 20,  loss: 0.23669523894786834\n",
      "Batch 25,  loss: 0.25572592318058013\n",
      "Batch 30,  loss: 0.2501023471355438\n",
      "Batch 35,  loss: 0.2580922722816467\n",
      "Batch 40,  loss: 0.24490603506565095\n",
      "Batch 45,  loss: 0.29066688418388364\n",
      "Batch 50,  loss: 0.2394566595554352\n",
      "Batch 55,  loss: 0.2392578423023224\n",
      "Batch 60,  loss: 0.3231355547904968\n",
      "Batch 65,  loss: 0.2634500086307526\n",
      "Batch 70,  loss: 0.29749985933303835\n",
      "Batch 75,  loss: 0.2715142101049423\n",
      "Batch 80,  loss: 0.21663423180580138\n",
      "Batch 85,  loss: 0.19969358444213867\n",
      "Batch 90,  loss: 0.330684494972229\n",
      "Batch 95,  loss: 0.23992456197738649\n",
      "Batch 100,  loss: 0.29188762307167054\n",
      "Batch 105,  loss: 0.2758811801671982\n",
      "Batch 110,  loss: 0.28856025338172914\n",
      "Batch 115,  loss: 0.257916122674942\n",
      "Batch 120,  loss: 0.2530125379562378\n",
      "Batch 125,  loss: 0.3033022880554199\n",
      "Batch 130,  loss: 0.26354268193244934\n",
      "Batch 135,  loss: 0.27013447880744934\n",
      "Batch 140,  loss: 0.274847811460495\n",
      "Batch 145,  loss: 0.25922794342041017\n",
      "Batch 150,  loss: 0.31138481497764586\n",
      "Batch 155,  loss: 0.2662728577852249\n",
      "Batch 160,  loss: 0.2985720247030258\n",
      "Batch 165,  loss: 0.3101807951927185\n",
      "Batch 170,  loss: 0.22988118827342988\n",
      "Batch 175,  loss: 0.24435041546821595\n",
      "Batch 180,  loss: 0.3003619313240051\n",
      "Batch 185,  loss: 0.2675292372703552\n",
      "Batch 190,  loss: 0.23249683976173402\n",
      "Batch 195,  loss: 0.2577086418867111\n",
      "Batch 200,  loss: 0.2857500523328781\n",
      "Batch 205,  loss: 0.291006064414978\n",
      "Batch 210,  loss: 0.2484961688518524\n",
      "Batch 215,  loss: 0.25884687900543213\n",
      "Batch 220,  loss: 0.22340021133422852\n",
      "Batch 225,  loss: 0.21613484025001525\n",
      "Batch 230,  loss: 0.27426321506500245\n",
      "Batch 235,  loss: 0.27096099555492403\n",
      "Batch 240,  loss: 0.2744382470846176\n",
      "Batch 245,  loss: 0.2692474365234375\n",
      "Batch 250,  loss: 0.26077992618083956\n",
      "Batch 255,  loss: 0.26361295878887175\n",
      "Batch 260,  loss: 0.26152315735816956\n",
      "Batch 265,  loss: 0.27330955266952517\n",
      "Batch 270,  loss: 0.29682259261608124\n",
      "Batch 275,  loss: 0.27504211068153384\n",
      "Batch 280,  loss: 0.2570070058107376\n",
      "Batch 285,  loss: 0.25225902795791627\n",
      "Batch 290,  loss: 0.231406632065773\n",
      "Batch 295,  loss: 0.29902453124523165\n",
      "Batch 300,  loss: 0.24894595742225648\n",
      "Batch 305,  loss: 0.2628053784370422\n",
      "Batch 310,  loss: 0.2576518476009369\n",
      "Batch 315,  loss: 0.24739167988300323\n",
      "Batch 320,  loss: 0.3360261023044586\n",
      "Batch 325,  loss: 0.23621411621570587\n",
      "Batch 330,  loss: 0.2322987675666809\n",
      "Batch 335,  loss: 0.26077801585197447\n",
      "Batch 340,  loss: 0.2395729809999466\n",
      "Batch 345,  loss: 0.2818491369485855\n",
      "Batch 350,  loss: 0.22200130820274352\n",
      "Batch 355,  loss: 0.2535505622625351\n",
      "Batch 360,  loss: 0.23670035898685454\n",
      "Batch 365,  loss: 0.2344524383544922\n",
      "Batch 370,  loss: 0.26512478590011596\n",
      "Batch 375,  loss: 0.26677378714084626\n",
      "Batch 380,  loss: 0.27280691266059875\n",
      "Batch 385,  loss: 0.23876751065254212\n",
      "Batch 390,  loss: 0.2717085599899292\n",
      "Batch 395,  loss: 0.31042357683181765\n",
      "Batch 400,  loss: 0.2542148917913437\n",
      "Batch 405,  loss: 0.24590044617652893\n",
      "Batch 410,  loss: 0.34741923213005066\n",
      "Batch 415,  loss: 0.2701930820941925\n",
      "Batch 420,  loss: 0.22914129495620728\n",
      "Batch 425,  loss: 0.2323024719953537\n",
      "Batch 430,  loss: 0.27297528386116027\n",
      "Batch 435,  loss: 0.26225208938121797\n",
      "Batch 440,  loss: 0.2695329189300537\n",
      "Batch 445,  loss: 0.24175661504268647\n",
      "Batch 450,  loss: 0.29028422832489015\n",
      "Batch 455,  loss: 0.2909718632698059\n",
      "Batch 460,  loss: 0.21322166323661804\n",
      "Batch 465,  loss: 0.261750328540802\n",
      "Batch 470,  loss: 0.21419388353824614\n",
      "Batch 475,  loss: 0.31592259705066683\n",
      "Batch 480,  loss: 0.26357520222663877\n",
      "Batch 485,  loss: 0.27864368855953214\n",
      "Batch 490,  loss: 0.25447994768619536\n",
      "Batch 495,  loss: 0.23970601558685303\n",
      "Batch 500,  loss: 0.25975383520126344\n",
      "Batch 505,  loss: 0.26090108454227445\n",
      "Batch 510,  loss: 0.20044084787368774\n",
      "Batch 515,  loss: 0.2328278511762619\n",
      "Batch 520,  loss: 0.2696268200874329\n",
      "Batch 525,  loss: 0.2301263302564621\n",
      "Batch 530,  loss: 0.24018543660640718\n",
      "Batch 535,  loss: 0.2520566940307617\n",
      "Batch 540,  loss: 0.27281283140182494\n",
      "Batch 545,  loss: 0.281843775510788\n",
      "Batch 550,  loss: 0.25209684669971466\n",
      "Batch 555,  loss: 0.23385191559791565\n",
      "Batch 560,  loss: 0.24397261142730714\n",
      "Batch 565,  loss: 0.25718367993831637\n",
      "Batch 570,  loss: 0.2960526466369629\n",
      "Batch 575,  loss: 0.2647863388061523\n",
      "Batch 580,  loss: 0.2359575480222702\n",
      "Batch 585,  loss: 0.2507012516260147\n",
      "Batch 590,  loss: 0.2581672966480255\n",
      "Batch 595,  loss: 0.3153741270303726\n",
      "Batch 600,  loss: 0.22161889374256133\n",
      "Batch 605,  loss: 0.2629450857639313\n",
      "Batch 610,  loss: 0.2209058701992035\n",
      "Batch 615,  loss: 0.22947022318840027\n",
      "Batch 620,  loss: 0.2589038580656052\n",
      "Batch 625,  loss: 0.2657466530799866\n",
      "Batch 630,  loss: 0.33423533141613004\n",
      "Batch 635,  loss: 0.31234298944473265\n",
      "Batch 640,  loss: 0.2343068778514862\n",
      "Batch 645,  loss: 0.24708985090255736\n",
      "Batch 650,  loss: 0.24257712364196776\n",
      "Batch 655,  loss: 0.30535413324832916\n",
      "Batch 660,  loss: 0.2345894306898117\n",
      "Batch 665,  loss: 0.21702346801757813\n",
      "Batch 670,  loss: 0.24835701882839203\n",
      "Batch 675,  loss: 0.2348414897918701\n",
      "Batch 680,  loss: 0.2286352127790451\n",
      "Batch 685,  loss: 0.28296302556991576\n",
      "Batch 690,  loss: 0.24558275640010835\n",
      "Batch 695,  loss: 0.2678560733795166\n",
      "Batch 700,  loss: 0.23566322326660155\n",
      "Batch 705,  loss: 0.2379926174879074\n",
      "Batch 710,  loss: 0.2983212798833847\n",
      "Batch 715,  loss: 0.19392173886299133\n",
      "Batch 720,  loss: 0.2422507643699646\n",
      "Batch 725,  loss: 0.2460995137691498\n",
      "Batch 730,  loss: 0.22980404198169707\n",
      "Batch 735,  loss: 0.29010080099105834\n",
      "Batch 740,  loss: 0.25687786340713503\n",
      "Batch 745,  loss: 0.256887948513031\n",
      "Batch 750,  loss: 0.24876826107501984\n",
      "Batch 755,  loss: 0.2115100145339966\n",
      "Batch 760,  loss: 0.21598732173442842\n",
      "Batch 765,  loss: 0.25883153080940247\n",
      "Batch 770,  loss: 0.2081813782453537\n",
      "Batch 775,  loss: 0.21584156155586243\n",
      "Batch 780,  loss: 0.33845244646072387\n",
      "Batch 785,  loss: 0.2559145361185074\n",
      "Batch 790,  loss: 0.23449210524559022\n",
      "Batch 795,  loss: 0.2639964997768402\n",
      "Batch 800,  loss: 0.23598347008228301\n",
      "Batch 805,  loss: 0.22754513025283812\n",
      "Batch 810,  loss: 0.24949175119400024\n",
      "Batch 815,  loss: 0.2458903819322586\n",
      "Batch 820,  loss: 0.2159199297428131\n",
      "Batch 825,  loss: 0.23265818357467652\n",
      "Batch 830,  loss: 0.2738328665494919\n",
      "Batch 835,  loss: 0.20475021600723267\n",
      "Batch 840,  loss: 0.24706648290157318\n",
      "Batch 845,  loss: 0.21635298132896424\n",
      "Batch 850,  loss: 0.27014808654785155\n",
      "Batch 855,  loss: 0.2979289621114731\n",
      "Batch 860,  loss: 0.24815846085548401\n",
      "Batch 865,  loss: 0.2905000776052475\n",
      "Batch 870,  loss: 0.2536415308713913\n",
      "Batch 875,  loss: 0.31733421683311464\n",
      "Batch 880,  loss: 0.25020611584186553\n",
      "Batch 885,  loss: 0.2290456622838974\n",
      "Batch 890,  loss: 0.27478422224521637\n",
      "Batch 895,  loss: 0.26574801206588744\n",
      "Batch 900,  loss: 0.23562079668045044\n",
      "Batch 905,  loss: 0.23350001871585846\n",
      "Batch 910,  loss: 0.19099193215370178\n",
      "Batch 915,  loss: 0.2426898419857025\n",
      "Batch 920,  loss: 0.21331300139427184\n",
      "Batch 925,  loss: 0.22299768030643463\n",
      "Batch 930,  loss: 0.25885569155216215\n",
      "Batch 935,  loss: 0.26348879337310793\n",
      "Batch 940,  loss: 0.2579506367444992\n",
      "Batch 945,  loss: 0.22174012660980225\n",
      "Batch 950,  loss: 0.23691856861114502\n",
      "Batch 955,  loss: 0.2923328161239624\n",
      "Batch 960,  loss: 0.26234211325645446\n",
      "Batch 965,  loss: 0.28606473803520205\n",
      "Batch 970,  loss: 0.2647072523832321\n",
      "Batch 975,  loss: 0.2609275639057159\n",
      "Batch 980,  loss: 0.21965426504611968\n",
      "Batch 985,  loss: 0.21627073884010314\n",
      "Batch 990,  loss: 0.2773021996021271\n",
      "Batch 995,  loss: 0.2365208387374878\n",
      "Batch 1000,  loss: 0.230744069814682\n",
      "Batch 1005,  loss: 0.278927680850029\n",
      "Batch 1010,  loss: 0.2911789059638977\n",
      "Batch 1015,  loss: 0.2666128039360046\n",
      "Batch 1020,  loss: 0.2487650454044342\n",
      "Batch 1025,  loss: 0.2525566786527634\n",
      "Batch 1030,  loss: 0.27421370446681975\n",
      "Batch 1035,  loss: 0.23949985206127167\n",
      "Batch 1040,  loss: 0.20337772667407988\n",
      "Batch 1045,  loss: 0.28712438344955443\n",
      "Batch 1050,  loss: 0.25075781941413877\n",
      "Batch 1055,  loss: 0.2377531945705414\n",
      "Batch 1060,  loss: 0.290905100107193\n",
      "Batch 1065,  loss: 0.27155098915100095\n",
      "Batch 1070,  loss: 0.25912049412727356\n",
      "Batch 1075,  loss: 0.25735985338687895\n",
      "Batch 1080,  loss: 0.2591187536716461\n",
      "Batch 1085,  loss: 0.27202420830726626\n",
      "Batch 1090,  loss: 0.23909545838832855\n",
      "Batch 1095,  loss: 0.2618571311235428\n",
      "Batch 1100,  loss: 0.18388035297393798\n",
      "Batch 1105,  loss: 0.2165793240070343\n",
      "Batch 1110,  loss: 0.21641409397125244\n",
      "Batch 1115,  loss: 0.33898499608039856\n",
      "Batch 1120,  loss: 0.28322395384311677\n",
      "Batch 1125,  loss: 0.25837781429290774\n",
      "Batch 1130,  loss: 0.2633087307214737\n",
      "Batch 1135,  loss: 0.2269183337688446\n",
      "Batch 1140,  loss: 0.23020192682743074\n",
      "Batch 1145,  loss: 0.2914754331111908\n",
      "Batch 1150,  loss: 0.18868471682071686\n",
      "Batch 1155,  loss: 0.2590731680393219\n",
      "Batch 1160,  loss: 0.23884138464927673\n",
      "Batch 1165,  loss: 0.20870908200740815\n",
      "Batch 1170,  loss: 0.23756445050239564\n",
      "Batch 1175,  loss: 0.26731005907058714\n",
      "Batch 1180,  loss: 0.21622798442840577\n",
      "Batch 1185,  loss: 0.27591472268104555\n",
      "Batch 1190,  loss: 0.30528528690338136\n",
      "Batch 1195,  loss: 0.25786167979240415\n",
      "Batch 1200,  loss: 0.20408613681793214\n",
      "Batch 1205,  loss: 0.2219984859228134\n",
      "Batch 1210,  loss: 0.2314814120531082\n",
      "Batch 1215,  loss: 0.2248409867286682\n",
      "Batch 1220,  loss: 0.24411360323429107\n",
      "Batch 1225,  loss: 0.2837303102016449\n",
      "Batch 1230,  loss: 0.2660725057125092\n",
      "Batch 1235,  loss: 0.29591278433799745\n",
      "Batch 1240,  loss: 0.27882662117481233\n",
      "Batch 1245,  loss: 0.2597792327404022\n",
      "Batch 1250,  loss: 0.251649934053421\n",
      "Batch 1255,  loss: 0.21972065567970275\n",
      "Batch 1260,  loss: 0.24409908056259155\n",
      "Batch 1265,  loss: 0.2590928733348846\n",
      "Batch 1270,  loss: 0.20223023891448974\n",
      "Batch 1275,  loss: 0.24570010900497435\n",
      "Batch 1280,  loss: 0.24536079168319702\n",
      "Batch 1285,  loss: 0.25881012380123136\n",
      "Batch 1290,  loss: 0.30554351806640623\n",
      "Batch 1295,  loss: 0.2627023935317993\n",
      "Batch 1300,  loss: 0.2817538619041443\n",
      "Batch 1305,  loss: 0.31252864599227903\n",
      "Batch 1310,  loss: 0.23591878712177278\n",
      "Batch 1315,  loss: 0.22429957389831542\n",
      "Batch 1320,  loss: 0.21962845623493193\n",
      "Batch 1325,  loss: 0.27151223421096804\n",
      "Batch 1330,  loss: 0.23444034159183502\n",
      "Batch 1335,  loss: 0.22887508273124696\n",
      "Batch 1340,  loss: 0.23929133713245393\n",
      "Batch 1345,  loss: 0.25305363833904265\n",
      "Batch 1350,  loss: 0.2409278392791748\n",
      "Batch 1355,  loss: 0.27246817052364347\n",
      "Batch 1360,  loss: 0.2734664976596832\n",
      "Batch 1365,  loss: 0.2579303175210953\n",
      "Batch 1370,  loss: 0.26802878379821776\n",
      "Batch 1375,  loss: 0.22802894413471222\n",
      "Batch 1380,  loss: 0.23165296614170075\n",
      "Batch 1385,  loss: 0.22644706070423126\n",
      "Batch 1390,  loss: 0.25519773960113523\n",
      "Batch 1395,  loss: 0.2590984612703323\n",
      "Batch 1400,  loss: 0.3174731135368347\n",
      "Batch 1405,  loss: 0.2533828169107437\n",
      "Batch 1410,  loss: 0.22241680026054383\n",
      "Batch 1415,  loss: 0.24767885804176332\n",
      "Batch 1420,  loss: 0.2703876107931137\n",
      "Batch 1425,  loss: 0.2973687589168549\n",
      "Batch 1430,  loss: 0.23302658498287201\n",
      "Batch 1435,  loss: 0.25203212201595304\n",
      "Batch 1440,  loss: 0.23863063454627992\n",
      "Batch 1445,  loss: 0.2498313844203949\n",
      "Batch 1450,  loss: 0.25581101775169374\n",
      "Batch 1455,  loss: 0.24039371609687804\n",
      "Batch 1460,  loss: 0.22423672080039977\n",
      "Batch 1465,  loss: 0.3025711953639984\n",
      "Batch 1470,  loss: 0.262864425778389\n",
      "Batch 1475,  loss: 0.2527162730693817\n",
      "Batch 1480,  loss: 0.2938292592763901\n",
      "Batch 1485,  loss: 0.29983902275562285\n",
      "Batch 1490,  loss: 0.23296072483062744\n",
      "Batch 1495,  loss: 0.265682715177536\n",
      "Batch 1500,  loss: 0.24190033674240113\n",
      "Batch 1505,  loss: 0.28768294453620913\n",
      "Batch 1510,  loss: 0.27460844814777374\n",
      "Batch 1515,  loss: 0.21370337009429932\n",
      "Batch 1520,  loss: 0.25853225886821746\n",
      "Batch 1525,  loss: 0.22706227302551268\n",
      "Batch 1530,  loss: 0.30803475975990297\n",
      "Batch 1535,  loss: 0.21150763630867003\n",
      "Batch 1540,  loss: 0.2823976218700409\n",
      "Batch 1545,  loss: 0.23215181529521942\n",
      "Batch 1550,  loss: 0.26859173774719236\n",
      "Batch 1555,  loss: 0.24918822348117828\n",
      "Batch 1560,  loss: 0.21410999000072478\n",
      "Batch 1565,  loss: 0.26725361347198484\n",
      "Batch 1570,  loss: 0.2513103008270264\n",
      "Batch 1575,  loss: 0.25795296132564544\n",
      "Batch 1580,  loss: 0.21651022136211395\n",
      "Batch 1585,  loss: 0.20636578202247619\n",
      "Batch 1590,  loss: 0.2508420795202255\n",
      "Batch 1595,  loss: 0.2294800400733948\n",
      "Batch 1600,  loss: 0.34574357271194456\n",
      "Batch 1605,  loss: 0.24607883095741273\n",
      "Batch 1610,  loss: 0.25672106742858886\n",
      "Batch 1615,  loss: 0.2278026282787323\n",
      "Batch 1620,  loss: 0.2928455889225006\n",
      "Batch 1625,  loss: 0.2526141345500946\n",
      "Batch 1630,  loss: 0.2477206587791443\n",
      "Batch 1635,  loss: 0.23963410556316375\n",
      "Batch 1640,  loss: 0.22378612458705902\n",
      "Batch 1645,  loss: 0.2374754250049591\n",
      "Batch 1650,  loss: 0.25438897907733915\n",
      "Batch 1655,  loss: 0.2820554614067078\n",
      "Batch 1660,  loss: 0.23502110242843627\n",
      "Batch 1665,  loss: 0.2468011349439621\n",
      "Batch 1670,  loss: 0.21462986171245574\n",
      "Batch 1675,  loss: 0.23329077959060668\n",
      "Batch 1680,  loss: 0.18695056736469268\n",
      "Batch 1685,  loss: 0.2064516216516495\n",
      "Batch 1690,  loss: 0.2037152737379074\n",
      "Batch 1695,  loss: 0.27149962186813353\n",
      "Batch 1700,  loss: 0.2226274788379669\n",
      "Batch 1705,  loss: 0.24516453742980956\n",
      "Batch 1710,  loss: 0.21369749009609224\n",
      "Batch 1715,  loss: 0.22557872533798218\n",
      "Batch 1720,  loss: 0.19888134598731994\n",
      "Batch 1725,  loss: 0.21136657297611236\n",
      "Batch 1730,  loss: 0.27079598903656005\n",
      "Batch 1735,  loss: 0.2807955414056778\n",
      "Batch 1740,  loss: 0.21856081783771514\n",
      "Batch 1745,  loss: 0.3000796973705292\n",
      "Batch 1750,  loss: 0.24976933300495147\n",
      "Batch 1755,  loss: 0.21464875042438508\n",
      "Batch 1760,  loss: 0.24834711253643035\n",
      "Batch 1765,  loss: 0.24858823120594026\n",
      "Batch 1770,  loss: 0.21383619904518128\n",
      "Batch 1775,  loss: 0.24009265899658203\n",
      "Batch 1780,  loss: 0.26797554194927214\n",
      "Batch 1785,  loss: 0.2693629711866379\n",
      "Batch 1790,  loss: 0.20344039797782898\n",
      "Batch 1795,  loss: 0.23162053823471068\n",
      "Batch 1800,  loss: 0.24122304618358612\n",
      "Batch 1805,  loss: 0.23894432485103606\n",
      "Batch 1810,  loss: 0.24450356364250184\n",
      "Batch 1815,  loss: 0.2625026434659958\n",
      "Batch 1820,  loss: 0.24338547885417938\n",
      "Batch 1825,  loss: 0.24742525815963745\n",
      "Batch 1830,  loss: 0.31517693102359773\n",
      "Batch 1835,  loss: 0.29740801453590393\n",
      "Batch 1840,  loss: 0.28824318051338194\n",
      "Batch 1845,  loss: 0.2112654685974121\n",
      "Batch 1850,  loss: 0.2925065070390701\n",
      "Batch 1855,  loss: 0.23647897839546203\n",
      "Batch 1860,  loss: 0.29019010066986084\n",
      "Batch 1865,  loss: 0.31834169030189513\n",
      "Batch 1870,  loss: 0.27049354612827303\n",
      "Batch 1875,  loss: 0.28800475001335146\n",
      "Batch 1880,  loss: 0.2296518713235855\n",
      "Batch 1885,  loss: 0.2798013299703598\n",
      "Batch 1890,  loss: 0.23713814914226533\n",
      "Batch 1895,  loss: 0.2591588914394379\n",
      "Batch 1900,  loss: 0.22221148312091826\n",
      "Batch 1905,  loss: 0.2254094213247299\n",
      "Batch 1910,  loss: 0.22585704028606415\n",
      "Batch 1915,  loss: 0.20030232071876525\n",
      "Batch 1920,  loss: 0.24750880599021913\n",
      "Batch 1925,  loss: 0.24839507341384887\n",
      "Batch 1930,  loss: 0.21391460597515105\n",
      "Batch 1935,  loss: 0.22569329738616944\n",
      "Batch 1940,  loss: 0.25122964680194854\n",
      "Batch 1945,  loss: 0.2319854289293289\n",
      "Batch 1950,  loss: 0.29462469220161436\n",
      "Batch 1955,  loss: 0.2340105414390564\n",
      "Batch 1960,  loss: 0.25548370480537413\n",
      "Batch 1965,  loss: 0.20157468020915986\n",
      "Batch 1970,  loss: 0.3161275804042816\n",
      "Batch 1975,  loss: 0.22582687437534332\n",
      "Batch 1980,  loss: 0.24680652022361754\n",
      "Batch 1985,  loss: 0.26367758214473724\n",
      "Batch 1990,  loss: 0.22088269293308258\n",
      "Batch 1995,  loss: 0.23250523209571838\n",
      "Batch 2000,  loss: 0.23826218545436859\n",
      "Batch 2005,  loss: 0.2644566744565964\n",
      "Batch 2010,  loss: 0.26505600214004515\n",
      "Batch 2015,  loss: 0.2870319217443466\n",
      "Batch 2020,  loss: 0.2618578851222992\n",
      "Batch 2025,  loss: 0.2731685370206833\n",
      "Batch 2030,  loss: 0.2127983808517456\n",
      "Batch 2035,  loss: 0.2388530045747757\n",
      "Batch 2040,  loss: 0.27470924854278567\n",
      "Batch 2045,  loss: 0.23471688330173493\n",
      "Batch 2050,  loss: 0.24906135499477386\n",
      "Batch 2055,  loss: 0.21065984964370726\n",
      "Batch 2060,  loss: 0.2954289555549622\n",
      "Batch 2065,  loss: 0.2485547035932541\n",
      "Batch 2070,  loss: 0.2090806096792221\n",
      "Batch 2075,  loss: 0.23435478508472443\n",
      "Batch 2080,  loss: 0.21519575119018555\n",
      "Batch 2085,  loss: 0.22932544350624084\n",
      "Batch 2090,  loss: 0.23365498185157776\n",
      "Batch 2095,  loss: 0.23209252655506135\n",
      "Batch 2100,  loss: 0.22657682597637177\n",
      "Batch 2105,  loss: 0.2237572431564331\n",
      "Batch 2110,  loss: 0.2507835149765015\n",
      "Batch 2115,  loss: 0.284968176484108\n",
      "Batch 2120,  loss: 0.26830647736787794\n",
      "Batch 2125,  loss: 0.22253220081329345\n",
      "Batch 2130,  loss: 0.20995218753814698\n",
      "Batch 2135,  loss: 0.2079916149377823\n",
      "Batch 2140,  loss: 0.2891911119222641\n",
      "Batch 2145,  loss: 0.24820992946624756\n",
      "Batch 2150,  loss: 0.2119639903306961\n",
      "Batch 2155,  loss: 0.24209150671958923\n",
      "Batch 2160,  loss: 0.2513669401407242\n",
      "Batch 2165,  loss: 0.2869692429900169\n",
      "Batch 2170,  loss: 0.30432549118995667\n",
      "Batch 2175,  loss: 0.23743240237236024\n",
      "Batch 2180,  loss: 0.3359727442264557\n",
      "Batch 2185,  loss: 0.21786672472953797\n",
      "Batch 2190,  loss: 0.28621076345443724\n",
      "Batch 2195,  loss: 0.25869840681552886\n",
      "Batch 2200,  loss: 0.2604448854923248\n",
      "Batch 2205,  loss: 0.2899375855922699\n",
      "Batch 2210,  loss: 0.30222943127155305\n",
      "Batch 2215,  loss: 0.27270248234272004\n",
      "Batch 2220,  loss: 0.23819419443607331\n",
      "Batch 2225,  loss: 0.30467185378074646\n",
      "Batch 2230,  loss: 0.2671813279390335\n",
      "Batch 2235,  loss: 0.20977013409137726\n",
      "Batch 2240,  loss: 0.25769045054912565\n",
      "Batch 2245,  loss: 0.19852142333984374\n",
      "Batch 2250,  loss: 0.18110069930553435\n",
      "Batch 2255,  loss: 0.26299731731414794\n",
      "Batch 2260,  loss: 0.2700272977352142\n",
      "Batch 2265,  loss: 0.2197400599718094\n",
      "Batch 2270,  loss: 0.24532919526100158\n",
      "Batch 2275,  loss: 0.2202578753232956\n",
      "Batch 2280,  loss: 0.2427212804555893\n",
      "Batch 2285,  loss: 0.2732430398464203\n",
      "Batch 2290,  loss: 0.31267134845256805\n",
      "Batch 2295,  loss: 0.2396576702594757\n",
      "Batch 2300,  loss: 0.27959023118019105\n",
      "Batch 2305,  loss: 0.23059152960777282\n",
      "Batch 2310,  loss: 0.2282426565885544\n",
      "Batch 2315,  loss: 0.2200636386871338\n",
      "Batch 2320,  loss: 0.21144953072071077\n",
      "Batch 2325,  loss: 0.23802854716777802\n",
      "Batch 2330,  loss: 0.30158513486385347\n",
      "Batch 2335,  loss: 0.20855513215065002\n",
      "Batch 2340,  loss: 0.2422974407672882\n",
      "Batch 2345,  loss: 0.23410072028636933\n",
      "Batch 2350,  loss: 0.2397716760635376\n",
      "Batch 2355,  loss: 0.23922103643417358\n",
      "Batch 2360,  loss: 0.23011375069618226\n",
      "Batch 2365,  loss: 0.2303997278213501\n",
      "Batch 2370,  loss: 0.23002209067344664\n",
      "Batch 2375,  loss: 0.2748968780040741\n",
      "Batch 2380,  loss: 0.26696213483810427\n",
      "Batch 2385,  loss: 0.23013331592082978\n",
      "Batch 2390,  loss: 0.2531021535396576\n",
      "Batch 2395,  loss: 0.25949073433876035\n",
      "Batch 2400,  loss: 0.27966724932193754\n",
      "Batch 2405,  loss: 0.21989333927631377\n",
      "Batch 2410,  loss: 0.23466442227363588\n",
      "Batch 2415,  loss: 0.2802064746618271\n",
      "Batch 2420,  loss: 0.2159763306379318\n",
      "Batch 2425,  loss: 0.24049218297004699\n",
      "Batch 2430,  loss: 0.25532529652118685\n",
      "Batch 2435,  loss: 0.25542065501213074\n",
      "Batch 2440,  loss: 0.2585743755102158\n",
      "Batch 2445,  loss: 0.2800816774368286\n",
      "Batch 2450,  loss: 0.27909048795700075\n",
      "Batch 2455,  loss: 0.24985281527042388\n",
      "Batch 2460,  loss: 0.22106191217899324\n",
      "Batch 2465,  loss: 0.25099150836467743\n",
      "Batch 2470,  loss: 0.25121175646781924\n",
      "Batch 2475,  loss: 0.23163954317569732\n",
      "Batch 2480,  loss: 0.3332329273223877\n",
      "Batch 2485,  loss: 0.2394065260887146\n",
      "Batch 2490,  loss: 0.2774089515209198\n",
      "Batch 2495,  loss: 0.24624109268188477\n",
      "Batch 2500,  loss: 0.2601099759340286\n",
      "Batch 2505,  loss: 0.29532286524772644\n",
      "Batch 2510,  loss: 0.23017988204956055\n",
      "Batch 2515,  loss: 0.22176506817340852\n",
      "Batch 2520,  loss: 0.23680710196495056\n",
      "Batch 2525,  loss: 0.2389434039592743\n",
      "Batch 2530,  loss: 0.28130186796188356\n",
      "Batch 2535,  loss: 0.25177406072616576\n",
      "Batch 2540,  loss: 0.22433772981166838\n",
      "Batch 2545,  loss: 0.2476971298456192\n",
      "Batch 2550,  loss: 0.2567473858594894\n",
      "Batch 2555,  loss: 0.23249464631080627\n",
      "Batch 2560,  loss: 0.2358255445957184\n",
      "Batch 2565,  loss: 0.23236547112464906\n",
      "Batch 2570,  loss: 0.2912375330924988\n",
      "Batch 2575,  loss: 0.23252064883708953\n",
      "Batch 2580,  loss: 0.18685384094715118\n",
      "Batch 2585,  loss: 0.2336584746837616\n",
      "Batch 2590,  loss: 0.27303892374038696\n",
      "Batch 2595,  loss: 0.2477281391620636\n",
      "Batch 2600,  loss: 0.27109822630882263\n",
      "Batch 2605,  loss: 0.2587185323238373\n",
      "Batch 2610,  loss: 0.2133732408285141\n",
      "Batch 2615,  loss: 0.2694795697927475\n",
      "Batch 2620,  loss: 0.24534195065498351\n",
      "Batch 2625,  loss: 0.23707271218299866\n",
      "Batch 2630,  loss: 0.22902598679065705\n",
      "Batch 2635,  loss: 0.25706865191459655\n",
      "Batch 2640,  loss: 0.25925877690315247\n",
      "Batch 2645,  loss: 0.24059851169586183\n",
      "Batch 2650,  loss: 0.2619982898235321\n",
      "Batch 2655,  loss: 0.2349320739507675\n",
      "Batch 2660,  loss: 0.2856618851423264\n",
      "Batch 2665,  loss: 0.24692720770835877\n",
      "Batch 2670,  loss: 0.26649110615253446\n",
      "Batch 2675,  loss: 0.20980460047721863\n",
      "Batch 2680,  loss: 0.2245699644088745\n",
      "Batch 2685,  loss: 0.3032056510448456\n",
      "Batch 2690,  loss: 0.2587846666574478\n",
      "Batch 2695,  loss: 0.23543197512626649\n",
      "Batch 2700,  loss: 0.259191620349884\n",
      "Batch 2705,  loss: 0.22327670454978943\n",
      "Batch 2710,  loss: 0.26757744550704954\n",
      "Batch 2715,  loss: 0.26094512045383456\n",
      "Batch 2720,  loss: 0.25552611947059634\n",
      "Batch 2725,  loss: 0.22632318139076232\n",
      "Batch 2730,  loss: 0.2306135594844818\n",
      "Batch 2735,  loss: 0.2675321280956268\n",
      "Batch 2740,  loss: 0.17633947730064392\n",
      "Batch 2745,  loss: 0.20460568517446517\n",
      "Batch 2750,  loss: 0.27075650691986086\n",
      "Batch 2755,  loss: 0.2596754014492035\n",
      "Batch 2760,  loss: 0.27719886004924776\n",
      "Batch 2765,  loss: 0.2696146935224533\n",
      "Batch 2770,  loss: 0.18796058893203735\n",
      "LOSS train 0.18796058893203735. Validation loss: 0.21200432346668094 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 3:\n",
      "Batch 5,  loss: 0.24485509991645812\n",
      "Batch 10,  loss: 0.2162425309419632\n",
      "Batch 15,  loss: 0.2292659640312195\n",
      "Batch 20,  loss: 0.27759196162223815\n",
      "Batch 25,  loss: 0.24355306029319762\n",
      "Batch 30,  loss: 0.25238817632198335\n",
      "Batch 35,  loss: 0.23332032859325408\n",
      "Batch 40,  loss: 0.2108402132987976\n",
      "Batch 45,  loss: 0.27304004728794096\n",
      "Batch 50,  loss: 0.2197733700275421\n",
      "Batch 55,  loss: 0.2724252760410309\n",
      "Batch 60,  loss: 0.2693206548690796\n",
      "Batch 65,  loss: 0.24766989052295685\n",
      "Batch 70,  loss: 0.21130965948104857\n",
      "Batch 75,  loss: 0.19898803532123566\n",
      "Batch 80,  loss: 0.26043393909931184\n",
      "Batch 85,  loss: 0.26694957315921786\n",
      "Batch 90,  loss: 0.27294526994228363\n",
      "Batch 95,  loss: 0.2660371780395508\n",
      "Batch 100,  loss: 0.23157260119915007\n",
      "Batch 105,  loss: 0.22323150634765626\n",
      "Batch 110,  loss: 0.22894819974899291\n",
      "Batch 115,  loss: 0.23776370882987977\n",
      "Batch 120,  loss: 0.2358970135450363\n",
      "Batch 125,  loss: 0.27290030717849734\n",
      "Batch 130,  loss: 0.25019247829914093\n",
      "Batch 135,  loss: 0.2215709775686264\n",
      "Batch 140,  loss: 0.2650201082229614\n",
      "Batch 145,  loss: 0.24196349382400512\n",
      "Batch 150,  loss: 0.24647752940654755\n",
      "Batch 155,  loss: 0.2609535813331604\n",
      "Batch 160,  loss: 0.20214016139507293\n",
      "Batch 165,  loss: 0.20564550161361694\n",
      "Batch 170,  loss: 0.25058132112026216\n",
      "Batch 175,  loss: 0.2533592015504837\n",
      "Batch 180,  loss: 0.24770936071872712\n",
      "Batch 185,  loss: 0.266385355591774\n",
      "Batch 190,  loss: 0.20853860378265382\n",
      "Batch 195,  loss: 0.20405817031860352\n",
      "Batch 200,  loss: 0.268308487534523\n",
      "Batch 205,  loss: 0.22245970368385315\n",
      "Batch 210,  loss: 0.25645708441734316\n",
      "Batch 215,  loss: 0.27323164641857145\n",
      "Batch 220,  loss: 0.2492401570081711\n",
      "Batch 225,  loss: 0.3091139793395996\n",
      "Batch 230,  loss: 0.2556999266147614\n",
      "Batch 235,  loss: 0.2467135339975357\n",
      "Batch 240,  loss: 0.2361745536327362\n",
      "Batch 245,  loss: 0.20237186253070832\n",
      "Batch 250,  loss: 0.2183622121810913\n",
      "Batch 255,  loss: 0.24992183446884156\n",
      "Batch 260,  loss: 0.30085319876670835\n",
      "Batch 265,  loss: 0.25052817463874816\n",
      "Batch 270,  loss: 0.2249421715736389\n",
      "Batch 275,  loss: 0.2638463467359543\n",
      "Batch 280,  loss: 0.24327928721904754\n",
      "Batch 285,  loss: 0.18707165122032166\n",
      "Batch 290,  loss: 0.2520394116640091\n",
      "Batch 295,  loss: 0.22060864567756652\n",
      "Batch 300,  loss: 0.2162914365530014\n",
      "Batch 305,  loss: 0.22506997287273406\n",
      "Batch 310,  loss: 0.19795651137828826\n",
      "Batch 315,  loss: 0.22652918696403504\n",
      "Batch 320,  loss: 0.22394146919250488\n",
      "Batch 325,  loss: 0.2655391454696655\n",
      "Batch 330,  loss: 0.26197765171527865\n",
      "Batch 335,  loss: 0.21482015252113343\n",
      "Batch 340,  loss: 0.2381577283143997\n",
      "Batch 345,  loss: 0.22868480086326598\n",
      "Batch 350,  loss: 0.3358341157436371\n",
      "Batch 355,  loss: 0.20714879035949707\n",
      "Batch 360,  loss: 0.24985141754150392\n",
      "Batch 365,  loss: 0.26799149811267853\n",
      "Batch 370,  loss: 0.2872619152069092\n",
      "Batch 375,  loss: 0.2079593539237976\n",
      "Batch 380,  loss: 0.2650667279958725\n",
      "Batch 385,  loss: 0.23760881125926972\n",
      "Batch 390,  loss: 0.221245276927948\n",
      "Batch 395,  loss: 0.2356238156557083\n",
      "Batch 400,  loss: 0.23695833683013917\n",
      "Batch 405,  loss: 0.25560023486614225\n",
      "Batch 410,  loss: 0.23630233407020568\n",
      "Batch 415,  loss: 0.18688827753067017\n",
      "Batch 420,  loss: 0.2666165292263031\n",
      "Batch 425,  loss: 0.238140869140625\n",
      "Batch 430,  loss: 0.26097714304924013\n",
      "Batch 435,  loss: 0.2357206642627716\n",
      "Batch 440,  loss: 0.2918103814125061\n",
      "Batch 445,  loss: 0.2928865611553192\n",
      "Batch 450,  loss: 0.22107846438884735\n",
      "Batch 455,  loss: 0.25497809052467346\n",
      "Batch 460,  loss: 0.22113284468650818\n",
      "Batch 465,  loss: 0.29538640975952146\n",
      "Batch 470,  loss: 0.24606576263904573\n",
      "Batch 475,  loss: 0.1820715069770813\n",
      "Batch 480,  loss: 0.20009679794311525\n",
      "Batch 485,  loss: 0.2532307028770447\n",
      "Batch 490,  loss: 0.19778284132480622\n",
      "Batch 495,  loss: 0.23793493807315827\n",
      "Batch 500,  loss: 0.23407818078994752\n",
      "Batch 505,  loss: 0.24598236680030822\n",
      "Batch 510,  loss: 0.2512984603643417\n",
      "Batch 515,  loss: 0.2244483768939972\n",
      "Batch 520,  loss: 0.19703639149665833\n",
      "Batch 525,  loss: 0.2606095016002655\n",
      "Batch 530,  loss: 0.22676582634449005\n",
      "Batch 535,  loss: 0.26204111576080324\n",
      "Batch 540,  loss: 0.21013168394565582\n",
      "Batch 545,  loss: 0.25136275589466095\n",
      "Batch 550,  loss: 0.23834823369979857\n",
      "Batch 555,  loss: 0.2630380213260651\n",
      "Batch 560,  loss: 0.19876296520233155\n",
      "Batch 565,  loss: 0.24512785971164702\n",
      "Batch 570,  loss: 0.2988506883382797\n",
      "Batch 575,  loss: 0.20898695588111876\n",
      "Batch 580,  loss: 0.18198312073946\n",
      "Batch 585,  loss: 0.2333614081144333\n",
      "Batch 590,  loss: 0.2755729019641876\n",
      "Batch 595,  loss: 0.25030731558799746\n",
      "Batch 600,  loss: 0.22536303102970123\n",
      "Batch 605,  loss: 0.19280083775520324\n",
      "Batch 610,  loss: 0.20162105560302734\n",
      "Batch 615,  loss: 0.22578363716602326\n",
      "Batch 620,  loss: 0.23534116744995118\n",
      "Batch 625,  loss: 0.2496428519487381\n",
      "Batch 630,  loss: 0.22805487215518952\n",
      "Batch 635,  loss: 0.25055848360061644\n",
      "Batch 640,  loss: 0.23991183042526246\n",
      "Batch 645,  loss: 0.21741328835487367\n",
      "Batch 650,  loss: 0.2223972499370575\n",
      "Batch 655,  loss: 0.26418815851211547\n",
      "Batch 660,  loss: 0.24090574979782103\n",
      "Batch 665,  loss: 0.2594729870557785\n",
      "Batch 670,  loss: 0.2702960789203644\n",
      "Batch 675,  loss: 0.24309557676315308\n",
      "Batch 680,  loss: 0.2766091853380203\n",
      "Batch 685,  loss: 0.22565915882587434\n",
      "Batch 690,  loss: 0.24566186666488649\n",
      "Batch 695,  loss: 0.24067752361297606\n",
      "Batch 700,  loss: 0.2580662667751312\n",
      "Batch 705,  loss: 0.27050096094608306\n",
      "Batch 710,  loss: 0.26843641698360443\n",
      "Batch 715,  loss: 0.1983484923839569\n",
      "Batch 720,  loss: 0.27193962037563324\n",
      "Batch 725,  loss: 0.2859321922063828\n",
      "Batch 730,  loss: 0.24575773179531096\n",
      "Batch 735,  loss: 0.22167015671730042\n",
      "Batch 740,  loss: 0.2425193667411804\n",
      "Batch 745,  loss: 0.22412947118282317\n",
      "Batch 750,  loss: 0.2578700751066208\n",
      "Batch 755,  loss: 0.21991706788539886\n",
      "Batch 760,  loss: 0.235180327296257\n",
      "Batch 765,  loss: 0.2682661235332489\n",
      "Batch 770,  loss: 0.23494063019752504\n",
      "Batch 775,  loss: 0.1882990449666977\n",
      "Batch 780,  loss: 0.27539379596710206\n",
      "Batch 785,  loss: 0.2609904408454895\n",
      "Batch 790,  loss: 0.22130769789218901\n",
      "Batch 795,  loss: 0.26886971294879913\n",
      "Batch 800,  loss: 0.2593736171722412\n",
      "Batch 805,  loss: 0.26004343926906587\n",
      "Batch 810,  loss: 0.25849578678607943\n",
      "Batch 815,  loss: 0.2865831032395363\n",
      "Batch 820,  loss: 0.2391985237598419\n",
      "Batch 825,  loss: 0.2078656882047653\n",
      "Batch 830,  loss: 0.2691880464553833\n",
      "Batch 835,  loss: 0.24724196195602416\n",
      "Batch 840,  loss: 0.2355031132698059\n",
      "Batch 845,  loss: 0.2460813581943512\n",
      "Batch 850,  loss: 0.28501280546188357\n",
      "Batch 855,  loss: 0.24295445084571837\n",
      "Batch 860,  loss: 0.20918114483356476\n",
      "Batch 865,  loss: 0.310400128364563\n",
      "Batch 870,  loss: 0.261823970079422\n",
      "Batch 875,  loss: 0.22395703196525574\n",
      "Batch 880,  loss: 0.21608287394046782\n",
      "Batch 885,  loss: 0.3093488186597824\n",
      "Batch 890,  loss: 0.27163194715976713\n",
      "Batch 895,  loss: 0.23313680589199065\n",
      "Batch 900,  loss: 0.22022615671157836\n",
      "Batch 905,  loss: 0.2459468960762024\n",
      "Batch 910,  loss: 0.26868011951446535\n",
      "Batch 915,  loss: 0.28601576685905455\n",
      "Batch 920,  loss: 0.18782432973384858\n",
      "Batch 925,  loss: 0.26013249456882476\n",
      "Batch 930,  loss: 0.22649540305137633\n",
      "Batch 935,  loss: 0.23481496870517732\n",
      "Batch 940,  loss: 0.2502659440040588\n",
      "Batch 945,  loss: 0.24901601672172546\n",
      "Batch 950,  loss: 0.2756173014640808\n",
      "Batch 955,  loss: 0.263213512301445\n",
      "Batch 960,  loss: 0.19261323511600495\n",
      "Batch 965,  loss: 0.2729082256555557\n",
      "Batch 970,  loss: 0.2418260842561722\n",
      "Batch 975,  loss: 0.29572929739952086\n",
      "Batch 980,  loss: 0.2808926612138748\n",
      "Batch 985,  loss: 0.2633300244808197\n",
      "Batch 990,  loss: 0.23784948885440826\n",
      "Batch 995,  loss: 0.2178880125284195\n",
      "Batch 1000,  loss: 0.2141621232032776\n",
      "Batch 1005,  loss: 0.21780530214309693\n",
      "Batch 1010,  loss: 0.23271896243095397\n",
      "Batch 1015,  loss: 0.19923723936080934\n",
      "Batch 1020,  loss: 0.21432178914546968\n",
      "Batch 1025,  loss: 0.2633501261472702\n",
      "Batch 1030,  loss: 0.21823063492774963\n",
      "Batch 1035,  loss: 0.23406612277030944\n",
      "Batch 1040,  loss: 0.2151660740375519\n",
      "Batch 1045,  loss: 0.2140199661254883\n",
      "Batch 1050,  loss: 0.26260713338851926\n",
      "Batch 1055,  loss: 0.23269307613372803\n",
      "Batch 1060,  loss: 0.20525565147399902\n",
      "Batch 1065,  loss: 0.23820050358772277\n",
      "Batch 1070,  loss: 0.3162450581789017\n",
      "Batch 1075,  loss: 0.235773766040802\n",
      "Batch 1080,  loss: 0.24345068037509918\n",
      "Batch 1085,  loss: 0.21319128572940826\n",
      "Batch 1090,  loss: 0.21656455248594284\n",
      "Batch 1095,  loss: 0.2417889952659607\n",
      "Batch 1100,  loss: 0.25450722575187684\n",
      "Batch 1105,  loss: 0.2676347464323044\n",
      "Batch 1110,  loss: 0.2531279146671295\n",
      "Batch 1115,  loss: 0.24734837114810942\n",
      "Batch 1120,  loss: 0.22243508398532869\n",
      "Batch 1125,  loss: 0.22224321961402893\n",
      "Batch 1130,  loss: 0.2627362012863159\n",
      "Batch 1135,  loss: 0.21740613579750062\n",
      "Batch 1140,  loss: 0.2456260710954666\n",
      "Batch 1145,  loss: 0.2718086302280426\n",
      "Batch 1150,  loss: 0.28892460763454436\n",
      "Batch 1155,  loss: 0.27224734127521516\n",
      "Batch 1160,  loss: 0.28815621733665464\n",
      "Batch 1165,  loss: 0.24069757163524627\n",
      "Batch 1170,  loss: 0.22089526653289795\n",
      "Batch 1175,  loss: 0.20327439308166503\n",
      "Batch 1180,  loss: 0.24797216653823853\n",
      "Batch 1185,  loss: 0.17844973802566527\n",
      "Batch 1190,  loss: 0.20808299779891967\n",
      "Batch 1195,  loss: 0.2945336580276489\n",
      "Batch 1200,  loss: 0.20684816241264342\n",
      "Batch 1205,  loss: 0.2083258420228958\n",
      "Batch 1210,  loss: 0.24806252419948577\n",
      "Batch 1215,  loss: 0.24713867008686066\n",
      "Batch 1220,  loss: 0.22607991397380828\n",
      "Batch 1225,  loss: 0.2022282749414444\n",
      "Batch 1230,  loss: 0.2968562662601471\n",
      "Batch 1235,  loss: 0.2387858361005783\n",
      "Batch 1240,  loss: 0.24613067209720613\n",
      "Batch 1245,  loss: 0.26796925365924834\n",
      "Batch 1250,  loss: 0.2556830942630768\n",
      "Batch 1255,  loss: 0.21429399251937867\n",
      "Batch 1260,  loss: 0.19309695065021515\n",
      "Batch 1265,  loss: 0.24093748331069947\n",
      "Batch 1270,  loss: 0.22495997548103333\n",
      "Batch 1275,  loss: 0.25242981910705564\n",
      "Batch 1280,  loss: 0.2904627501964569\n",
      "Batch 1285,  loss: 0.2651330977678299\n",
      "Batch 1290,  loss: 0.23989734947681426\n",
      "Batch 1295,  loss: 0.22909597158432007\n",
      "Batch 1300,  loss: 0.24988920390605926\n",
      "Batch 1305,  loss: 0.32935795485973357\n",
      "Batch 1310,  loss: 0.24707479476928712\n",
      "Batch 1315,  loss: 0.2170797049999237\n",
      "Batch 1320,  loss: 0.24698469638824463\n",
      "Batch 1325,  loss: 0.24302247166633606\n",
      "Batch 1330,  loss: 0.27057325541973115\n",
      "Batch 1335,  loss: 0.23873495757579805\n",
      "Batch 1340,  loss: 0.2653484731912613\n",
      "Batch 1345,  loss: 0.2470499247312546\n",
      "Batch 1350,  loss: 0.2964965462684631\n",
      "Batch 1355,  loss: 0.22422067523002626\n",
      "Batch 1360,  loss: 0.2153247892856598\n",
      "Batch 1365,  loss: 0.23537744283676149\n",
      "Batch 1370,  loss: 0.21663748621940612\n",
      "Batch 1375,  loss: 0.23645139932632447\n",
      "Batch 1380,  loss: 0.23631415963172914\n",
      "Batch 1385,  loss: 0.22225019633769988\n",
      "Batch 1390,  loss: 0.256677919626236\n",
      "Batch 1395,  loss: 0.25059216618537905\n",
      "Batch 1400,  loss: 0.18722136914730073\n",
      "Batch 1405,  loss: 0.2928694784641266\n",
      "Batch 1410,  loss: 0.26622517704963683\n",
      "Batch 1415,  loss: 0.1905597448348999\n",
      "Batch 1420,  loss: 0.2151186138391495\n",
      "Batch 1425,  loss: 0.20211353600025178\n",
      "Batch 1430,  loss: 0.2524089515209198\n",
      "Batch 1435,  loss: 0.21894843578338624\n",
      "Batch 1440,  loss: 0.258588445186615\n",
      "Batch 1445,  loss: 0.2255033552646637\n",
      "Batch 1450,  loss: 0.2272097051143646\n",
      "Batch 1455,  loss: 0.25921628177165984\n",
      "Batch 1460,  loss: 0.22654446661472322\n",
      "Batch 1465,  loss: 0.2125180572271347\n",
      "Batch 1470,  loss: 0.23800402879714966\n",
      "Batch 1475,  loss: 0.24125208258628844\n",
      "Batch 1480,  loss: 0.25479403138160706\n",
      "Batch 1485,  loss: 0.22280041873455048\n",
      "Batch 1490,  loss: 0.2852797627449036\n",
      "Batch 1495,  loss: 0.29230816662311554\n",
      "Batch 1500,  loss: 0.21710062623023987\n",
      "Batch 1505,  loss: 0.21105238199234008\n",
      "Batch 1510,  loss: 0.20651884973049164\n",
      "Batch 1515,  loss: 0.21381587386131287\n",
      "Batch 1520,  loss: 0.25367942452430725\n",
      "Batch 1525,  loss: 0.23555469810962676\n",
      "Batch 1530,  loss: 0.217578661441803\n",
      "Batch 1535,  loss: 0.24658863842487336\n",
      "Batch 1540,  loss: 0.28451767563819885\n",
      "Batch 1545,  loss: 0.23669851422309876\n",
      "Batch 1550,  loss: 0.2139589637517929\n",
      "Batch 1555,  loss: 0.1867002233862877\n",
      "Batch 1560,  loss: 0.2264024406671524\n",
      "Batch 1565,  loss: 0.258299320936203\n",
      "Batch 1570,  loss: 0.21844615042209625\n",
      "Batch 1575,  loss: 0.264358389377594\n",
      "Batch 1580,  loss: 0.17025501430034637\n",
      "Batch 1585,  loss: 0.21199811697006227\n",
      "Batch 1590,  loss: 0.27128841280937194\n",
      "Batch 1595,  loss: 0.28716938495635985\n",
      "Batch 1600,  loss: 0.23008995354175568\n",
      "Batch 1605,  loss: 0.25719091594219207\n",
      "Batch 1610,  loss: 0.2432596802711487\n",
      "Batch 1615,  loss: 0.19445662796497346\n",
      "Batch 1620,  loss: 0.2295859456062317\n",
      "Batch 1625,  loss: 0.22630169987678528\n",
      "Batch 1630,  loss: 0.24039292633533477\n",
      "Batch 1635,  loss: 0.2326020985841751\n",
      "Batch 1640,  loss: 0.2248110294342041\n",
      "Batch 1645,  loss: 0.18842211067676545\n",
      "Batch 1650,  loss: 0.25416911840438844\n",
      "Batch 1655,  loss: 0.23287549912929534\n",
      "Batch 1660,  loss: 0.21339167654514313\n",
      "Batch 1665,  loss: 0.2390074372291565\n",
      "Batch 1670,  loss: 0.23317356109619142\n",
      "Batch 1675,  loss: 0.21390298306941985\n",
      "Batch 1680,  loss: 0.218762668967247\n",
      "Batch 1685,  loss: 0.2643167734146118\n",
      "Batch 1690,  loss: 0.24309177100658416\n",
      "Batch 1695,  loss: 0.21138348281383515\n",
      "Batch 1700,  loss: 0.22572459280490875\n",
      "Batch 1705,  loss: 0.22494864761829375\n",
      "Batch 1710,  loss: 0.22139959335327147\n",
      "Batch 1715,  loss: 0.22578598260879518\n",
      "Batch 1720,  loss: 0.205377933382988\n",
      "Batch 1725,  loss: 0.2615618497133255\n",
      "Batch 1730,  loss: 0.24022579193115234\n",
      "Batch 1735,  loss: 0.21614099740982057\n",
      "Batch 1740,  loss: 0.23707224428653717\n",
      "Batch 1745,  loss: 0.22478646039962769\n",
      "Batch 1750,  loss: 0.22552040517330169\n",
      "Batch 1755,  loss: 0.21686697602272034\n",
      "Batch 1760,  loss: 0.24126471281051637\n",
      "Batch 1765,  loss: 0.22008419036865234\n",
      "Batch 1770,  loss: 0.22047640085220338\n",
      "Batch 1775,  loss: 0.17490397095680238\n",
      "Batch 1780,  loss: 0.25329850018024447\n",
      "Batch 1785,  loss: 0.20172300040721894\n",
      "Batch 1790,  loss: 0.24987374246120453\n",
      "Batch 1795,  loss: 0.23023703396320344\n",
      "Batch 1800,  loss: 0.23196466863155366\n",
      "Batch 1805,  loss: 0.23159000873565674\n",
      "Batch 1810,  loss: 0.2065087229013443\n",
      "Batch 1815,  loss: 0.2750614732503891\n",
      "Batch 1820,  loss: 0.20824380815029145\n",
      "Batch 1825,  loss: 0.2266426682472229\n",
      "Batch 1830,  loss: 0.19789243638515472\n",
      "Batch 1835,  loss: 0.22084521353244782\n",
      "Batch 1840,  loss: 0.2543592035770416\n",
      "Batch 1845,  loss: 0.21890925765037536\n",
      "Batch 1850,  loss: 0.2278996080160141\n",
      "Batch 1855,  loss: 0.26439937949180603\n",
      "Batch 1860,  loss: 0.24542085230350494\n",
      "Batch 1865,  loss: 0.19991324841976166\n",
      "Batch 1870,  loss: 0.2832567423582077\n",
      "Batch 1875,  loss: 0.2173812597990036\n",
      "Batch 1880,  loss: 0.20189314782619477\n",
      "Batch 1885,  loss: 0.2328146755695343\n",
      "Batch 1890,  loss: 0.2196057289838791\n",
      "Batch 1895,  loss: 0.23970988988876343\n",
      "Batch 1900,  loss: 0.1999440759420395\n",
      "Batch 1905,  loss: 0.18795064091682434\n",
      "Batch 1910,  loss: 0.24846462309360504\n",
      "Batch 1915,  loss: 0.2504996955394745\n",
      "Batch 1920,  loss: 0.2155778795480728\n",
      "Batch 1925,  loss: 0.24036642909049988\n",
      "Batch 1930,  loss: 0.24268272519111633\n",
      "Batch 1935,  loss: 0.2392115116119385\n",
      "Batch 1940,  loss: 0.22858825623989104\n",
      "Batch 1945,  loss: 0.27107122391462324\n",
      "Batch 1950,  loss: 0.21680472493171693\n",
      "Batch 1955,  loss: 0.18546003997325897\n",
      "Batch 1960,  loss: 0.21286015212535858\n",
      "Batch 1965,  loss: 0.25920563042163847\n",
      "Batch 1970,  loss: 0.21821533739566804\n",
      "Batch 1975,  loss: 0.2431420862674713\n",
      "Batch 1980,  loss: 0.2509433478116989\n",
      "Batch 1985,  loss: 0.1965199440717697\n",
      "Batch 1990,  loss: 0.26746585965156555\n",
      "Batch 1995,  loss: 0.24058808386325836\n",
      "Batch 2000,  loss: 0.21713399589061738\n",
      "Batch 2005,  loss: 0.2303760379552841\n",
      "Batch 2010,  loss: 0.24285050332546235\n",
      "Batch 2015,  loss: 0.2747875601053238\n",
      "Batch 2020,  loss: 0.26593601107597353\n",
      "Batch 2025,  loss: 0.250456964969635\n",
      "Batch 2030,  loss: 0.2600974917411804\n",
      "Batch 2035,  loss: 0.23768073916435242\n",
      "Batch 2040,  loss: 0.20854080468416214\n",
      "Batch 2045,  loss: 0.23288664519786834\n",
      "Batch 2050,  loss: 0.22964513003826142\n",
      "Batch 2055,  loss: 0.24877274334430693\n",
      "Batch 2060,  loss: 0.21323335468769072\n",
      "Batch 2065,  loss: 0.2089879721403122\n",
      "Batch 2070,  loss: 0.1839861661195755\n",
      "Batch 2075,  loss: 0.2649404764175415\n",
      "Batch 2080,  loss: 0.2299257129430771\n",
      "Batch 2085,  loss: 0.2558058530092239\n",
      "Batch 2090,  loss: 0.2442804217338562\n",
      "Batch 2095,  loss: 0.2572572559118271\n",
      "Batch 2100,  loss: 0.2576755553483963\n",
      "Batch 2105,  loss: 0.17855965495109558\n",
      "Batch 2110,  loss: 0.24357696175575255\n",
      "Batch 2115,  loss: 0.2407474100589752\n",
      "Batch 2120,  loss: 0.21459135711193084\n",
      "Batch 2125,  loss: 0.24796246886253356\n",
      "Batch 2130,  loss: 0.257119682431221\n",
      "Batch 2135,  loss: 0.24042726457118987\n",
      "Batch 2140,  loss: 0.2406088411808014\n",
      "Batch 2145,  loss: 0.2044990360736847\n",
      "Batch 2150,  loss: 0.22337001264095308\n",
      "Batch 2155,  loss: 0.19930942058563234\n",
      "Batch 2160,  loss: 0.27829891741275786\n",
      "Batch 2165,  loss: 0.30557321310043334\n",
      "Batch 2170,  loss: 0.2108470767736435\n",
      "Batch 2175,  loss: 0.2126523345708847\n",
      "Batch 2180,  loss: 0.2351183831691742\n",
      "Batch 2185,  loss: 0.2441621392965317\n",
      "Batch 2190,  loss: 0.2667037099599838\n",
      "Batch 2195,  loss: 0.25012348890304564\n",
      "Batch 2200,  loss: 0.25167292952537534\n",
      "Batch 2205,  loss: 0.2201413929462433\n",
      "Batch 2210,  loss: 0.2785079061985016\n",
      "Batch 2215,  loss: 0.18222065269947052\n",
      "Batch 2220,  loss: 0.24666935801506043\n",
      "Batch 2225,  loss: 0.26170432567596436\n",
      "Batch 2230,  loss: 0.22469889223575593\n",
      "Batch 2235,  loss: 0.25216004550457\n",
      "Batch 2240,  loss: 0.2783702492713928\n",
      "Batch 2245,  loss: 0.28890875577926634\n",
      "Batch 2250,  loss: 0.27603948712348936\n",
      "Batch 2255,  loss: 0.26413953900337217\n",
      "Batch 2260,  loss: 0.26278730630874636\n",
      "Batch 2265,  loss: 0.23024051189422606\n",
      "Batch 2270,  loss: 0.24743445813655854\n",
      "Batch 2275,  loss: 0.26638736128807067\n",
      "Batch 2280,  loss: 0.26019455790519713\n",
      "Batch 2285,  loss: 0.28391059637069704\n",
      "Batch 2290,  loss: 0.24660569429397583\n",
      "Batch 2295,  loss: 0.2003106653690338\n",
      "Batch 2300,  loss: 0.21907815039157869\n",
      "Batch 2305,  loss: 0.23493357598781586\n",
      "Batch 2310,  loss: 0.24822133779525757\n",
      "Batch 2315,  loss: 0.3285221576690674\n",
      "Batch 2320,  loss: 0.2448212057352066\n",
      "Batch 2325,  loss: 0.16112700700759888\n",
      "Batch 2330,  loss: 0.202817639708519\n",
      "Batch 2335,  loss: 0.23599381744861603\n",
      "Batch 2340,  loss: 0.24391432702541352\n",
      "Batch 2345,  loss: 0.20686458051204681\n",
      "Batch 2350,  loss: 0.25681903660297395\n",
      "Batch 2355,  loss: 0.19929371178150176\n",
      "Batch 2360,  loss: 0.23697807490825654\n",
      "Batch 2365,  loss: 0.21160460412502288\n",
      "Batch 2370,  loss: 0.18820914924144744\n",
      "Batch 2375,  loss: 0.23299110531806946\n",
      "Batch 2380,  loss: 0.23280377686023712\n",
      "Batch 2385,  loss: 0.22728090584278107\n",
      "Batch 2390,  loss: 0.20633949041366578\n",
      "Batch 2395,  loss: 0.19211726486682892\n",
      "Batch 2400,  loss: 0.23200427889823913\n",
      "Batch 2405,  loss: 0.25391642153263094\n",
      "Batch 2410,  loss: 0.24030793011188506\n",
      "Batch 2415,  loss: 0.28906758427619933\n",
      "Batch 2420,  loss: 0.22527493834495543\n",
      "Batch 2425,  loss: 0.22812938392162324\n",
      "Batch 2430,  loss: 0.24478287994861603\n",
      "Batch 2435,  loss: 0.2172750860452652\n",
      "Batch 2440,  loss: 0.20986984968185424\n",
      "Batch 2445,  loss: 0.23296907246112825\n",
      "Batch 2450,  loss: 0.23532335460186005\n",
      "Batch 2455,  loss: 0.3167340159416199\n",
      "Batch 2460,  loss: 0.2870901048183441\n",
      "Batch 2465,  loss: 0.3229477286338806\n",
      "Batch 2470,  loss: 0.22073186039924622\n",
      "Batch 2475,  loss: 0.2309303104877472\n",
      "Batch 2480,  loss: 0.23639368116855622\n",
      "Batch 2485,  loss: 0.20757324397563934\n",
      "Batch 2490,  loss: 0.2843454897403717\n",
      "Batch 2495,  loss: 0.22809893488883973\n",
      "Batch 2500,  loss: 0.23244260847568513\n",
      "Batch 2505,  loss: 0.2194878041744232\n",
      "Batch 2510,  loss: 0.23953403830528258\n",
      "Batch 2515,  loss: 0.22553942799568177\n",
      "Batch 2520,  loss: 0.20767741203308104\n",
      "Batch 2525,  loss: 0.22319377064704896\n",
      "Batch 2530,  loss: 0.1614237666130066\n",
      "Batch 2535,  loss: 0.23924774825572967\n",
      "Batch 2540,  loss: 0.24378955960273743\n",
      "Batch 2545,  loss: 0.24211303889751434\n",
      "Batch 2550,  loss: 0.20437297821044922\n",
      "Batch 2555,  loss: 0.30670177936553955\n",
      "Batch 2560,  loss: 0.23119182586669923\n",
      "Batch 2565,  loss: 0.22284963428974153\n",
      "Batch 2570,  loss: 0.35311020016670225\n",
      "Batch 2575,  loss: 0.22862488925457\n",
      "Batch 2580,  loss: 0.23381003737449646\n",
      "Batch 2585,  loss: 0.25851852297782896\n",
      "Batch 2590,  loss: 0.2445330500602722\n",
      "Batch 2595,  loss: 0.20036307573318482\n",
      "Batch 2600,  loss: 0.24922987818717957\n",
      "Batch 2605,  loss: 0.22449661195278167\n",
      "Batch 2610,  loss: 0.23328051567077637\n",
      "Batch 2615,  loss: 0.28935694992542266\n",
      "Batch 2620,  loss: 0.24930890798568725\n",
      "Batch 2625,  loss: 0.2919130355119705\n",
      "Batch 2630,  loss: 0.24023430049419403\n",
      "Batch 2635,  loss: 0.22850967943668365\n",
      "Batch 2640,  loss: 0.21531091630458832\n",
      "Batch 2645,  loss: 0.19071584045886994\n",
      "Batch 2650,  loss: 0.23014141917228698\n",
      "Batch 2655,  loss: 0.22829751968383788\n",
      "Batch 2660,  loss: 0.2346666395664215\n",
      "Batch 2665,  loss: 0.2531033128499985\n",
      "Batch 2670,  loss: 0.23166695833206177\n",
      "Batch 2675,  loss: 0.2592352330684662\n",
      "Batch 2680,  loss: 0.22348760664463044\n",
      "Batch 2685,  loss: 0.26211938858032224\n",
      "Batch 2690,  loss: 0.23031148314476013\n",
      "Batch 2695,  loss: 0.22937299609184264\n",
      "Batch 2700,  loss: 0.21186351478099824\n",
      "Batch 2705,  loss: 0.2290357992053032\n",
      "Batch 2710,  loss: 0.19074586033821106\n",
      "Batch 2715,  loss: 0.22675376534461975\n",
      "Batch 2720,  loss: 0.2459706962108612\n",
      "Batch 2725,  loss: 0.2224947988986969\n",
      "Batch 2730,  loss: 0.2270876944065094\n",
      "Batch 2735,  loss: 0.18184497058391572\n",
      "Batch 2740,  loss: 0.21617376804351807\n",
      "Batch 2745,  loss: 0.2794368892908096\n",
      "Batch 2750,  loss: 0.20649459660053254\n",
      "Batch 2755,  loss: 0.2286867767572403\n",
      "Batch 2760,  loss: 0.2376999318599701\n",
      "Batch 2765,  loss: 0.2361906200647354\n",
      "Batch 2770,  loss: 0.19587407112121583\n",
      "LOSS train 0.19587407112121583. Validation loss: 0.2006220946894717 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 4:\n",
      "Batch 5,  loss: 0.20721287429332733\n",
      "Batch 10,  loss: 0.24118224084377288\n",
      "Batch 15,  loss: 0.23878272473812104\n",
      "Batch 20,  loss: 0.23822519481182097\n",
      "Batch 25,  loss: 0.209660542011261\n",
      "Batch 30,  loss: 0.17515031695365907\n",
      "Batch 35,  loss: 0.24494541585445403\n",
      "Batch 40,  loss: 0.2401394158601761\n",
      "Batch 45,  loss: 0.2585008472204208\n",
      "Batch 50,  loss: 0.20457426011562346\n",
      "Batch 55,  loss: 0.2592479318380356\n",
      "Batch 60,  loss: 0.2503576725721359\n",
      "Batch 65,  loss: 0.2911252111196518\n",
      "Batch 70,  loss: 0.2298006922006607\n",
      "Batch 75,  loss: 0.25534023642539977\n",
      "Batch 80,  loss: 0.22127118408679963\n",
      "Batch 85,  loss: 0.2021043598651886\n",
      "Batch 90,  loss: 0.23851781189441681\n",
      "Batch 95,  loss: 0.19911110103130342\n",
      "Batch 100,  loss: 0.2372568964958191\n",
      "Batch 105,  loss: 0.28686933815479276\n",
      "Batch 110,  loss: 0.23052876591682434\n",
      "Batch 115,  loss: 0.25007203221321106\n",
      "Batch 120,  loss: 0.2143012911081314\n",
      "Batch 125,  loss: 0.2513581544160843\n",
      "Batch 130,  loss: 0.2607328176498413\n",
      "Batch 135,  loss: 0.27487741112709047\n",
      "Batch 140,  loss: 0.1890462189912796\n",
      "Batch 145,  loss: 0.24321974515914918\n",
      "Batch 150,  loss: 0.2683282673358917\n",
      "Batch 155,  loss: 0.309832963347435\n",
      "Batch 160,  loss: 0.24690597057342528\n",
      "Batch 165,  loss: 0.2401542603969574\n",
      "Batch 170,  loss: 0.20022769868373871\n",
      "Batch 175,  loss: 0.19785613417625428\n",
      "Batch 180,  loss: 0.24705279469490052\n",
      "Batch 185,  loss: 0.21613747775554656\n",
      "Batch 190,  loss: 0.25931250751018525\n",
      "Batch 195,  loss: 0.20231741964817046\n",
      "Batch 200,  loss: 0.2381069004535675\n",
      "Batch 205,  loss: 0.17956686913967132\n",
      "Batch 210,  loss: 0.22390906810760497\n",
      "Batch 215,  loss: 0.2927001953125\n",
      "Batch 220,  loss: 0.24298507273197173\n",
      "Batch 225,  loss: 0.24187147617340088\n",
      "Batch 230,  loss: 0.23144512474536896\n",
      "Batch 235,  loss: 0.27112679481506347\n",
      "Batch 240,  loss: 0.18924373090267183\n",
      "Batch 245,  loss: 0.20331962108612062\n",
      "Batch 250,  loss: 0.21709102094173433\n",
      "Batch 255,  loss: 0.24518969655036926\n",
      "Batch 260,  loss: 0.23760246634483337\n",
      "Batch 265,  loss: 0.23042197227478028\n",
      "Batch 270,  loss: 0.21808436512947083\n",
      "Batch 275,  loss: 0.2295856297016144\n",
      "Batch 280,  loss: 0.2637426435947418\n",
      "Batch 285,  loss: 0.24517410397529601\n",
      "Batch 290,  loss: 0.2582420498132706\n",
      "Batch 295,  loss: 0.22802909910678865\n",
      "Batch 300,  loss: 0.2503300756216049\n",
      "Batch 305,  loss: 0.20881326496601105\n",
      "Batch 310,  loss: 0.22579192817211152\n",
      "Batch 315,  loss: 0.24564388394355774\n",
      "Batch 320,  loss: 0.24617387652397155\n",
      "Batch 325,  loss: 0.20853606462478638\n",
      "Batch 330,  loss: 0.22923917174339295\n",
      "Batch 335,  loss: 0.20631177127361297\n",
      "Batch 340,  loss: 0.18430845439434052\n",
      "Batch 345,  loss: 0.2185879170894623\n",
      "Batch 350,  loss: 0.210691699385643\n",
      "Batch 355,  loss: 0.20466119349002837\n",
      "Batch 360,  loss: 0.20460572540760041\n",
      "Batch 365,  loss: 0.23463138937950134\n",
      "Batch 370,  loss: 0.24545938372612\n",
      "Batch 375,  loss: 0.1941617548465729\n",
      "Batch 380,  loss: 0.23643573522567748\n",
      "Batch 385,  loss: 0.22671393752098085\n",
      "Batch 390,  loss: 0.2088663697242737\n",
      "Batch 395,  loss: 0.2437019467353821\n",
      "Batch 400,  loss: 0.25069512128829957\n",
      "Batch 405,  loss: 0.24988148212432862\n",
      "Batch 410,  loss: 0.22331780791282654\n",
      "Batch 415,  loss: 0.221036496758461\n",
      "Batch 420,  loss: 0.28022940158843995\n",
      "Batch 425,  loss: 0.22596656680107116\n",
      "Batch 430,  loss: 0.21265606284141542\n",
      "Batch 435,  loss: 0.2184729367494583\n",
      "Batch 440,  loss: 0.2636537253856659\n",
      "Batch 445,  loss: 0.21168533265590667\n",
      "Batch 450,  loss: 0.2560326635837555\n",
      "Batch 455,  loss: 0.22560574114322662\n",
      "Batch 460,  loss: 0.21426651179790496\n",
      "Batch 465,  loss: 0.2276633381843567\n",
      "Batch 470,  loss: 0.19268848598003388\n",
      "Batch 475,  loss: 0.2219027042388916\n",
      "Batch 480,  loss: 0.2581190764904022\n",
      "Batch 485,  loss: 0.2224068820476532\n",
      "Batch 490,  loss: 0.2196196049451828\n",
      "Batch 495,  loss: 0.228000146150589\n",
      "Batch 500,  loss: 0.29932043254375457\n",
      "Batch 505,  loss: 0.21495208740234376\n",
      "Batch 510,  loss: 0.31090896725654604\n",
      "Batch 515,  loss: 0.21811742782592775\n",
      "Batch 520,  loss: 0.21523523330688477\n",
      "Batch 525,  loss: 0.23267680704593657\n",
      "Batch 530,  loss: 0.23467887341976165\n",
      "Batch 535,  loss: 0.24814534187316895\n",
      "Batch 540,  loss: 0.20591639280319213\n",
      "Batch 545,  loss: 0.2493206351995468\n",
      "Batch 550,  loss: 0.23807204365730286\n",
      "Batch 555,  loss: 0.28588164150714873\n",
      "Batch 560,  loss: 0.23144284784793853\n",
      "Batch 565,  loss: 0.24420028626918794\n",
      "Batch 570,  loss: 0.21027658879756927\n",
      "Batch 575,  loss: 0.25167647898197176\n",
      "Batch 580,  loss: 0.2743339627981186\n",
      "Batch 585,  loss: 0.1764415055513382\n",
      "Batch 590,  loss: 0.24631808400154115\n",
      "Batch 595,  loss: 0.23365139365196227\n",
      "Batch 600,  loss: 0.26066074669361117\n",
      "Batch 605,  loss: 0.22519088685512542\n",
      "Batch 610,  loss: 0.21855266988277436\n",
      "Batch 615,  loss: 0.26347784101963045\n",
      "Batch 620,  loss: 0.20328551083803176\n",
      "Batch 625,  loss: 0.24688776433467866\n",
      "Batch 630,  loss: 0.25004094243049624\n",
      "Batch 635,  loss: 0.24492896795272828\n",
      "Batch 640,  loss: 0.2944593757390976\n",
      "Batch 645,  loss: 0.23792671263217927\n",
      "Batch 650,  loss: 0.24238646924495696\n",
      "Batch 655,  loss: 0.25716357827186587\n",
      "Batch 660,  loss: 0.22014637887477875\n",
      "Batch 665,  loss: 0.1883627027273178\n",
      "Batch 670,  loss: 0.22070587277412415\n",
      "Batch 675,  loss: 0.2475426733493805\n",
      "Batch 680,  loss: 0.21641224026679992\n",
      "Batch 685,  loss: 0.22109257578849792\n",
      "Batch 690,  loss: 0.22763020396232606\n",
      "Batch 695,  loss: 0.207663094997406\n",
      "Batch 700,  loss: 0.24348477721214296\n",
      "Batch 705,  loss: 0.19617000222206116\n",
      "Batch 710,  loss: 0.21497225463390351\n",
      "Batch 715,  loss: 0.25684250593185426\n",
      "Batch 720,  loss: 0.22791119217872619\n",
      "Batch 725,  loss: 0.23001583516597748\n",
      "Batch 730,  loss: 0.2252075493335724\n",
      "Batch 735,  loss: 0.18160176873207093\n",
      "Batch 740,  loss: 0.27390183210372926\n",
      "Batch 745,  loss: 0.3346547544002533\n",
      "Batch 750,  loss: 0.21583267748355867\n",
      "Batch 755,  loss: 0.196855565905571\n",
      "Batch 760,  loss: 0.20416500568389892\n",
      "Batch 765,  loss: 0.1992317706346512\n",
      "Batch 770,  loss: 0.22659420371055602\n",
      "Batch 775,  loss: 0.2328077495098114\n",
      "Batch 780,  loss: 0.24956229627132415\n",
      "Batch 785,  loss: 0.22663049399852753\n",
      "Batch 790,  loss: 0.20928663313388823\n",
      "Batch 795,  loss: 0.23018122613430023\n",
      "Batch 800,  loss: 0.24890513420104982\n",
      "Batch 805,  loss: 0.22016439139842986\n",
      "Batch 810,  loss: 0.16920284926891327\n",
      "Batch 815,  loss: 0.25196641981601714\n",
      "Batch 820,  loss: 0.2616658121347427\n",
      "Batch 825,  loss: 0.2727298468351364\n",
      "Batch 830,  loss: 0.2426844507455826\n",
      "Batch 835,  loss: 0.29665152728557587\n",
      "Batch 840,  loss: 0.27076672315597533\n",
      "Batch 845,  loss: 0.2622895449399948\n",
      "Batch 850,  loss: 0.18641195595264434\n",
      "Batch 855,  loss: 0.25196286141872404\n",
      "Batch 860,  loss: 0.2664145678281784\n",
      "Batch 865,  loss: 0.23532272577285768\n",
      "Batch 870,  loss: 0.26939027905464175\n",
      "Batch 875,  loss: 0.3017920732498169\n",
      "Batch 880,  loss: 0.2821341872215271\n",
      "Batch 885,  loss: 0.23655202686786653\n",
      "Batch 890,  loss: 0.2611295610666275\n",
      "Batch 895,  loss: 0.23311751782894136\n",
      "Batch 900,  loss: 0.28658961653709414\n",
      "Batch 905,  loss: 0.22728049755096436\n",
      "Batch 910,  loss: 0.2248971164226532\n",
      "Batch 915,  loss: 0.19727205932140351\n",
      "Batch 920,  loss: 0.21400370597839355\n",
      "Batch 925,  loss: 0.2864275336265564\n",
      "Batch 930,  loss: 0.2438356578350067\n",
      "Batch 935,  loss: 0.24961584210395812\n",
      "Batch 940,  loss: 0.2265172392129898\n",
      "Batch 945,  loss: 0.24303724467754365\n",
      "Batch 950,  loss: 0.19568877816200256\n",
      "Batch 955,  loss: 0.21913576424121856\n",
      "Batch 960,  loss: 0.19265978932380676\n",
      "Batch 965,  loss: 0.22100276947021485\n",
      "Batch 970,  loss: 0.22435517311096193\n",
      "Batch 975,  loss: 0.24184279441833495\n",
      "Batch 980,  loss: 0.23784525096416473\n",
      "Batch 985,  loss: 0.2487269163131714\n",
      "Batch 990,  loss: 0.2336897999048233\n",
      "Batch 995,  loss: 0.17457861602306365\n",
      "Batch 1000,  loss: 0.19992423355579375\n",
      "Batch 1005,  loss: 0.1900639772415161\n",
      "Batch 1010,  loss: 0.1758502721786499\n",
      "Batch 1015,  loss: 0.23209484219551085\n",
      "Batch 1020,  loss: 0.19227428436279298\n",
      "Batch 1025,  loss: 0.21861259937286376\n",
      "Batch 1030,  loss: 0.2522314190864563\n",
      "Batch 1035,  loss: 0.23049747943878174\n",
      "Batch 1040,  loss: 0.21641736924648286\n",
      "Batch 1045,  loss: 0.2643390715122223\n",
      "Batch 1050,  loss: 0.22129811644554137\n",
      "Batch 1055,  loss: 0.2031187206506729\n",
      "Batch 1060,  loss: 0.23138475120067598\n",
      "Batch 1065,  loss: 0.2514821231365204\n",
      "Batch 1070,  loss: 0.21358895897865296\n",
      "Batch 1075,  loss: 0.2414238601922989\n",
      "Batch 1080,  loss: 0.18273734748363496\n",
      "Batch 1085,  loss: 0.21818259060382844\n",
      "Batch 1090,  loss: 0.23300498127937316\n",
      "Batch 1095,  loss: 0.2175190955400467\n",
      "Batch 1100,  loss: 0.23460040390491485\n",
      "Batch 1105,  loss: 0.24513787925243377\n",
      "Batch 1110,  loss: 0.17685190737247466\n",
      "Batch 1115,  loss: 0.22847805619239808\n",
      "Batch 1120,  loss: 0.2575246125459671\n",
      "Batch 1125,  loss: 0.1854754328727722\n",
      "Batch 1130,  loss: 0.1842593267560005\n",
      "Batch 1135,  loss: 0.188175767660141\n",
      "Batch 1140,  loss: 0.258836618065834\n",
      "Batch 1145,  loss: 0.20838117301464082\n",
      "Batch 1150,  loss: 0.23895533680915831\n",
      "Batch 1155,  loss: 0.2310165584087372\n",
      "Batch 1160,  loss: 0.20105769038200377\n",
      "Batch 1165,  loss: 0.21506959348917007\n",
      "Batch 1170,  loss: 0.20027029812335967\n",
      "Batch 1175,  loss: 0.2298860341310501\n",
      "Batch 1180,  loss: 0.2198701560497284\n",
      "Batch 1185,  loss: 0.19552797079086304\n",
      "Batch 1190,  loss: 0.2509233683347702\n",
      "Batch 1195,  loss: 0.18577249199151993\n",
      "Batch 1200,  loss: 0.2066354900598526\n",
      "Batch 1205,  loss: 0.2424749493598938\n",
      "Batch 1210,  loss: 0.248750302195549\n",
      "Batch 1215,  loss: 0.253415247797966\n",
      "Batch 1220,  loss: 0.3086299240589142\n",
      "Batch 1225,  loss: 0.21569722294807434\n",
      "Batch 1230,  loss: 0.22131550312042236\n",
      "Batch 1235,  loss: 0.2316728413105011\n",
      "Batch 1240,  loss: 0.23574572205543518\n",
      "Batch 1245,  loss: 0.204481303691864\n",
      "Batch 1250,  loss: 0.22036691904067993\n",
      "Batch 1255,  loss: 0.2656936407089233\n",
      "Batch 1260,  loss: 0.2154284566640854\n",
      "Batch 1265,  loss: 0.22676684260368346\n",
      "Batch 1270,  loss: 0.23633332848548888\n",
      "Batch 1275,  loss: 0.22106220424175263\n",
      "Batch 1280,  loss: 0.16942150592803956\n",
      "Batch 1285,  loss: 0.21565492451190948\n",
      "Batch 1290,  loss: 0.2351601243019104\n",
      "Batch 1295,  loss: 0.29378842413425443\n",
      "Batch 1300,  loss: 0.31577280163764954\n",
      "Batch 1305,  loss: 0.19164054989814758\n",
      "Batch 1310,  loss: 0.24784586429595948\n",
      "Batch 1315,  loss: 0.26514652371406555\n",
      "Batch 1320,  loss: 0.1978117883205414\n",
      "Batch 1325,  loss: 0.25458419919013975\n",
      "Batch 1330,  loss: 0.21146574318408967\n",
      "Batch 1335,  loss: 0.19833723306655884\n",
      "Batch 1340,  loss: 0.23974473774433136\n",
      "Batch 1345,  loss: 0.2528770327568054\n",
      "Batch 1350,  loss: 0.19745513498783113\n",
      "Batch 1355,  loss: 0.25309970378875735\n",
      "Batch 1360,  loss: 0.32367353737354276\n",
      "Batch 1365,  loss: 0.20984481573104857\n",
      "Batch 1370,  loss: 0.205354505777359\n",
      "Batch 1375,  loss: 0.24754310250282288\n",
      "Batch 1380,  loss: 0.19016206562519072\n",
      "Batch 1385,  loss: 0.19700236916542052\n",
      "Batch 1390,  loss: 0.20318718254566193\n",
      "Batch 1395,  loss: 0.18649942874908448\n",
      "Batch 1400,  loss: 0.25562912225723267\n",
      "Batch 1405,  loss: 0.2480260908603668\n",
      "Batch 1410,  loss: 0.22786280512809753\n",
      "Batch 1415,  loss: 0.21308887898921966\n",
      "Batch 1420,  loss: 0.28392834663391114\n",
      "Batch 1425,  loss: 0.23556590974330902\n",
      "Batch 1430,  loss: 0.18164744675159455\n",
      "Batch 1435,  loss: 0.229901322722435\n",
      "Batch 1440,  loss: 0.23039343655109407\n",
      "Batch 1445,  loss: 0.23138427734375\n",
      "Batch 1450,  loss: 0.24858008623123168\n",
      "Batch 1455,  loss: 0.23027456402778626\n",
      "Batch 1460,  loss: 0.17094894945621492\n",
      "Batch 1465,  loss: 0.28967152535915375\n",
      "Batch 1470,  loss: 0.2398139327764511\n",
      "Batch 1475,  loss: 0.2621800810098648\n",
      "Batch 1480,  loss: 0.19297735691070556\n",
      "Batch 1485,  loss: 0.23050563633441926\n",
      "Batch 1490,  loss: 0.2369786947965622\n",
      "Batch 1495,  loss: 0.21690971851348878\n",
      "Batch 1500,  loss: 0.22238354086875917\n",
      "Batch 1505,  loss: 0.23589576482772828\n",
      "Batch 1510,  loss: 0.23749938905239104\n",
      "Batch 1515,  loss: 0.23736109137535094\n",
      "Batch 1520,  loss: 0.2662354826927185\n",
      "Batch 1525,  loss: 0.22013078331947328\n",
      "Batch 1530,  loss: 0.2720631152391434\n",
      "Batch 1535,  loss: 0.2678788363933563\n",
      "Batch 1540,  loss: 0.2082846850156784\n",
      "Batch 1545,  loss: 0.2377036839723587\n",
      "Batch 1550,  loss: 0.26784417033195496\n",
      "Batch 1555,  loss: 0.2255810096859932\n",
      "Batch 1560,  loss: 0.2024228662252426\n",
      "Batch 1565,  loss: 0.2318779170513153\n",
      "Batch 1570,  loss: 0.2957914352416992\n",
      "Batch 1575,  loss: 0.27362783849239347\n",
      "Batch 1580,  loss: 0.19521016478538514\n",
      "Batch 1585,  loss: 0.18965555131435394\n",
      "Batch 1590,  loss: 0.2138765722513199\n",
      "Batch 1595,  loss: 0.2260860949754715\n",
      "Batch 1600,  loss: 0.2469499886035919\n",
      "Batch 1605,  loss: 0.26127341389656067\n",
      "Batch 1610,  loss: 0.20152202844619752\n",
      "Batch 1615,  loss: 0.24784113168716432\n",
      "Batch 1620,  loss: 0.2799276113510132\n",
      "Batch 1625,  loss: 0.24465012550354004\n",
      "Batch 1630,  loss: 0.2436240404844284\n",
      "Batch 1635,  loss: 0.23869589865207672\n",
      "Batch 1640,  loss: 0.225486221909523\n",
      "Batch 1645,  loss: 0.28859255015850066\n",
      "Batch 1650,  loss: 0.19325360655784607\n",
      "Batch 1655,  loss: 0.17637527287006377\n",
      "Batch 1660,  loss: 0.16556143164634704\n",
      "Batch 1665,  loss: 0.21877980530261992\n",
      "Batch 1670,  loss: 0.227895587682724\n",
      "Batch 1675,  loss: 0.22418015003204345\n",
      "Batch 1680,  loss: 0.240467369556427\n",
      "Batch 1685,  loss: 0.205360347032547\n",
      "Batch 1690,  loss: 0.21696839928627015\n",
      "Batch 1695,  loss: 0.2511679887771606\n",
      "Batch 1700,  loss: 0.23972576558589936\n",
      "Batch 1705,  loss: 0.21723317503929138\n",
      "Batch 1710,  loss: 0.2132798135280609\n",
      "Batch 1715,  loss: 0.27543971240520476\n",
      "Batch 1720,  loss: 0.17472503930330277\n",
      "Batch 1725,  loss: 0.24417824149131775\n",
      "Batch 1730,  loss: 0.24723618924617768\n",
      "Batch 1735,  loss: 0.2015068471431732\n",
      "Batch 1740,  loss: 0.2081659257411957\n",
      "Batch 1745,  loss: 0.27070807218551635\n",
      "Batch 1750,  loss: 0.18111561834812165\n",
      "Batch 1755,  loss: 0.2498502641916275\n",
      "Batch 1760,  loss: 0.16374175548553466\n",
      "Batch 1765,  loss: 0.2147953361272812\n",
      "Batch 1770,  loss: 0.2904110670089722\n",
      "Batch 1775,  loss: 0.18823995292186738\n",
      "Batch 1780,  loss: 0.19152589440345763\n",
      "Batch 1785,  loss: 0.2756235897541046\n",
      "Batch 1790,  loss: 0.22187614738941192\n",
      "Batch 1795,  loss: 0.18399719893932343\n",
      "Batch 1800,  loss: 0.23094436824321746\n",
      "Batch 1805,  loss: 0.25126287937164304\n",
      "Batch 1810,  loss: 0.2228950470685959\n",
      "Batch 1815,  loss: 0.20826670825481414\n",
      "Batch 1820,  loss: 0.23550358712673186\n",
      "Batch 1825,  loss: 0.2366526335477829\n",
      "Batch 1830,  loss: 0.18881796002388002\n",
      "Batch 1835,  loss: 0.2616446167230606\n",
      "Batch 1840,  loss: 0.176058828830719\n",
      "Batch 1845,  loss: 0.213367822766304\n",
      "Batch 1850,  loss: 0.24305457174777984\n",
      "Batch 1855,  loss: 0.24094888865947722\n",
      "Batch 1860,  loss: 0.21003085672855376\n",
      "Batch 1865,  loss: 0.26957565546035767\n",
      "Batch 1870,  loss: 0.2779832541942596\n",
      "Batch 1875,  loss: 0.2081279367208481\n",
      "Batch 1880,  loss: 0.24397470951080322\n",
      "Batch 1885,  loss: 0.25704062581062315\n",
      "Batch 1890,  loss: 0.2274458348751068\n",
      "Batch 1895,  loss: 0.24936121702194214\n",
      "Batch 1900,  loss: 0.22318885028362273\n",
      "Batch 1905,  loss: 0.25247939229011535\n",
      "Batch 1910,  loss: 0.18853118419647216\n",
      "Batch 1915,  loss: 0.20604425370693208\n",
      "Batch 1920,  loss: 0.2204293817281723\n",
      "Batch 1925,  loss: 0.19213996678590775\n",
      "Batch 1930,  loss: 0.24247924685478212\n",
      "Batch 1935,  loss: 0.24315972328186036\n",
      "Batch 1940,  loss: 0.20235202014446257\n",
      "Batch 1945,  loss: 0.19593234062194825\n",
      "Batch 1950,  loss: 0.1963919073343277\n",
      "Batch 1955,  loss: 0.20448002815246583\n",
      "Batch 1960,  loss: 0.21365342736244203\n",
      "Batch 1965,  loss: 0.24496916234493255\n",
      "Batch 1970,  loss: 0.2286345511674881\n",
      "Batch 1975,  loss: 0.19014704823493958\n",
      "Batch 1980,  loss: 0.218901389837265\n",
      "Batch 1985,  loss: 0.21373894214630126\n",
      "Batch 1990,  loss: 0.2038710117340088\n",
      "Batch 1995,  loss: 0.26036081910133363\n",
      "Batch 2000,  loss: 0.2756646633148193\n",
      "Batch 2005,  loss: 0.20207116305828093\n",
      "Batch 2010,  loss: 0.1942719042301178\n",
      "Batch 2015,  loss: 0.20247609317302703\n",
      "Batch 2020,  loss: 0.21474722623825074\n",
      "Batch 2025,  loss: 0.2557532608509064\n",
      "Batch 2030,  loss: 0.2349936693906784\n",
      "Batch 2035,  loss: 0.2508946806192398\n",
      "Batch 2040,  loss: 0.27608250379562377\n",
      "Batch 2045,  loss: 0.17634219229221343\n",
      "Batch 2050,  loss: 0.1988564610481262\n",
      "Batch 2055,  loss: 0.24020128846168518\n",
      "Batch 2060,  loss: 0.23000966012477875\n",
      "Batch 2065,  loss: 0.23141558170318605\n",
      "Batch 2070,  loss: 0.2015775114297867\n",
      "Batch 2075,  loss: 0.21792297661304474\n",
      "Batch 2080,  loss: 0.2827004075050354\n",
      "Batch 2085,  loss: 0.20637139678001404\n",
      "Batch 2090,  loss: 0.2318086415529251\n",
      "Batch 2095,  loss: 0.2330316424369812\n",
      "Batch 2100,  loss: 0.20779447257518768\n",
      "Batch 2105,  loss: 0.2667300462722778\n",
      "Batch 2110,  loss: 0.21724285185337067\n",
      "Batch 2115,  loss: 0.1807195156812668\n",
      "Batch 2120,  loss: 0.2670034408569336\n",
      "Batch 2125,  loss: 0.2359042286872864\n",
      "Batch 2130,  loss: 0.20173312723636627\n",
      "Batch 2135,  loss: 0.20207452774047852\n",
      "Batch 2140,  loss: 0.1998744010925293\n",
      "Batch 2145,  loss: 0.2520177036523819\n",
      "Batch 2150,  loss: 0.23118604719638824\n",
      "Batch 2155,  loss: 0.22913843393325806\n",
      "Batch 2160,  loss: 0.20897030532360078\n",
      "Batch 2165,  loss: 0.2705071210861206\n",
      "Batch 2170,  loss: 0.17853948324918748\n",
      "Batch 2175,  loss: 0.19096864461898805\n",
      "Batch 2180,  loss: 0.2197892189025879\n",
      "Batch 2185,  loss: 0.2182950794696808\n",
      "Batch 2190,  loss: 0.21000144332647325\n",
      "Batch 2195,  loss: 0.25469127893447874\n",
      "Batch 2200,  loss: 0.2155805915594101\n",
      "Batch 2205,  loss: 0.22393765449523925\n",
      "Batch 2210,  loss: 0.18487554788589478\n",
      "Batch 2215,  loss: 0.203777015209198\n",
      "Batch 2220,  loss: 0.21563331484794618\n",
      "Batch 2225,  loss: 0.1975322276353836\n",
      "Batch 2230,  loss: 0.253979954123497\n",
      "Batch 2235,  loss: 0.26307934522628784\n",
      "Batch 2240,  loss: 0.246309494972229\n",
      "Batch 2245,  loss: 0.19810623228549956\n",
      "Batch 2250,  loss: 0.23756353855133056\n",
      "Batch 2255,  loss: 0.2212417095899582\n",
      "Batch 2260,  loss: 0.23335313498973848\n",
      "Batch 2265,  loss: 0.21936691403388978\n",
      "Batch 2270,  loss: 0.21979131996631623\n",
      "Batch 2275,  loss: 0.22345027923583985\n",
      "Batch 2280,  loss: 0.2393186181783676\n",
      "Batch 2285,  loss: 0.23259468674659728\n",
      "Batch 2290,  loss: 0.20802295804023743\n",
      "Batch 2295,  loss: 0.23715122938156127\n",
      "Batch 2300,  loss: 0.17347079515457153\n",
      "Batch 2305,  loss: 0.23653473556041718\n",
      "Batch 2310,  loss: 0.23573036193847657\n",
      "Batch 2315,  loss: 0.29162715971469877\n",
      "Batch 2320,  loss: 0.20958378911018372\n",
      "Batch 2325,  loss: 0.23277116119861602\n",
      "Batch 2330,  loss: 0.21197204738855363\n",
      "Batch 2335,  loss: 0.2161283850669861\n",
      "Batch 2340,  loss: 0.2687347024679184\n",
      "Batch 2345,  loss: 0.2327529937028885\n",
      "Batch 2350,  loss: 0.20406093299388886\n",
      "Batch 2355,  loss: 0.2402016967535019\n",
      "Batch 2360,  loss: 0.24575924575328828\n",
      "Batch 2365,  loss: 0.2586614191532135\n",
      "Batch 2370,  loss: 0.18892066478729247\n",
      "Batch 2375,  loss: 0.2847982108592987\n",
      "Batch 2380,  loss: 0.2587236762046814\n",
      "Batch 2385,  loss: 0.2318507671356201\n",
      "Batch 2390,  loss: 0.23624369204044343\n",
      "Batch 2395,  loss: 0.27731184661388397\n",
      "Batch 2400,  loss: 0.22573075890541078\n",
      "Batch 2405,  loss: 0.1968718558549881\n",
      "Batch 2410,  loss: 0.22130419909954072\n",
      "Batch 2415,  loss: 0.24529004096984863\n",
      "Batch 2420,  loss: 0.2867328554391861\n",
      "Batch 2425,  loss: 0.2291724443435669\n",
      "Batch 2430,  loss: 0.2739732563495636\n",
      "Batch 2435,  loss: 0.23450701236724852\n",
      "Batch 2440,  loss: 0.22562164962291717\n",
      "Batch 2445,  loss: 0.19033972918987274\n",
      "Batch 2450,  loss: 0.2702944099903107\n",
      "Batch 2455,  loss: 0.22104046046733855\n",
      "Batch 2460,  loss: 0.18684132099151612\n",
      "Batch 2465,  loss: 0.15626937448978423\n",
      "Batch 2470,  loss: 0.192547407746315\n",
      "Batch 2475,  loss: 0.22885305881500245\n",
      "Batch 2480,  loss: 0.2795180082321167\n",
      "Batch 2485,  loss: 0.246009960770607\n",
      "Batch 2490,  loss: 0.27513099610805514\n",
      "Batch 2495,  loss: 0.24205987453460692\n",
      "Batch 2500,  loss: 0.2122189521789551\n",
      "Batch 2505,  loss: 0.25291234254837036\n",
      "Batch 2510,  loss: 0.20306823551654815\n",
      "Batch 2515,  loss: 0.25916768014431\n",
      "Batch 2520,  loss: 0.2910585880279541\n",
      "Batch 2525,  loss: 0.2223084568977356\n",
      "Batch 2530,  loss: 0.20741268396377563\n",
      "Batch 2535,  loss: 0.21447132229804994\n",
      "Batch 2540,  loss: 0.22140429317951202\n",
      "Batch 2545,  loss: 0.26030419766902924\n",
      "Batch 2550,  loss: 0.22413864731788635\n",
      "Batch 2555,  loss: 0.2145555168390274\n",
      "Batch 2560,  loss: 0.1713534414768219\n",
      "Batch 2565,  loss: 0.1800853967666626\n",
      "Batch 2570,  loss: 0.21907636523246765\n",
      "Batch 2575,  loss: 0.211710324883461\n",
      "Batch 2580,  loss: 0.239312806725502\n",
      "Batch 2585,  loss: 0.22126283049583434\n",
      "Batch 2590,  loss: 0.24373779296875\n",
      "Batch 2595,  loss: 0.24397504329681396\n",
      "Batch 2600,  loss: 0.18045352399349213\n",
      "Batch 2605,  loss: 0.1926937520503998\n",
      "Batch 2610,  loss: 0.21046425104141236\n",
      "Batch 2615,  loss: 0.22965511083602905\n",
      "Batch 2620,  loss: 0.2999665796756744\n",
      "Batch 2625,  loss: 0.2366606891155243\n",
      "Batch 2630,  loss: 0.22377194464206696\n",
      "Batch 2635,  loss: 0.22749385833740235\n",
      "Batch 2640,  loss: 0.20724977254867555\n",
      "Batch 2645,  loss: 0.19627925157546997\n",
      "Batch 2650,  loss: 0.24792640507221222\n",
      "Batch 2655,  loss: 0.26259511411190034\n",
      "Batch 2660,  loss: 0.21430956423282624\n",
      "Batch 2665,  loss: 0.16953262388706208\n",
      "Batch 2670,  loss: 0.2453884482383728\n",
      "Batch 2675,  loss: 0.1644704520702362\n",
      "Batch 2680,  loss: 0.2037136435508728\n",
      "Batch 2685,  loss: 0.20709110796451569\n",
      "Batch 2690,  loss: 0.2469382703304291\n",
      "Batch 2695,  loss: 0.21576689183712006\n",
      "Batch 2700,  loss: 0.23460919857025148\n",
      "Batch 2705,  loss: 0.2086251348257065\n",
      "Batch 2710,  loss: 0.22433255910873412\n",
      "Batch 2715,  loss: 0.20832136869430543\n",
      "Batch 2720,  loss: 0.24671247005462646\n",
      "Batch 2725,  loss: 0.28775463104248045\n",
      "Batch 2730,  loss: 0.24988678395748137\n",
      "Batch 2735,  loss: 0.2870211660861969\n",
      "Batch 2740,  loss: 0.2503036320209503\n",
      "Batch 2745,  loss: 0.20971178114414216\n",
      "Batch 2750,  loss: 0.2183438092470169\n",
      "Batch 2755,  loss: 0.16839976608753204\n",
      "Batch 2760,  loss: 0.2319796174764633\n",
      "Batch 2765,  loss: 0.17843964993953704\n",
      "Batch 2770,  loss: 0.2690309524536133\n",
      "LOSS train 0.2690309524536133. Validation loss: 0.19718152021954732 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 5:\n",
      "Batch 5,  loss: 0.20797832012176515\n",
      "Batch 10,  loss: 0.22913580238819123\n",
      "Batch 15,  loss: 0.22766787111759185\n",
      "Batch 20,  loss: 0.2292879432439804\n",
      "Batch 25,  loss: 0.20373542308807374\n",
      "Batch 30,  loss: 0.23226000666618346\n",
      "Batch 35,  loss: 0.2592144936323166\n",
      "Batch 40,  loss: 0.2577642470598221\n",
      "Batch 45,  loss: 0.20554042756557464\n",
      "Batch 50,  loss: 0.20259925723075867\n",
      "Batch 55,  loss: 0.22006140947341918\n",
      "Batch 60,  loss: 0.25497333109378817\n",
      "Batch 65,  loss: 0.20777564942836763\n",
      "Batch 70,  loss: 0.2289827734231949\n",
      "Batch 75,  loss: 0.2301337867975235\n",
      "Batch 80,  loss: 0.23707247376441956\n",
      "Batch 85,  loss: 0.26264269948005675\n",
      "Batch 90,  loss: 0.21312825083732606\n",
      "Batch 95,  loss: 0.19199850261211396\n",
      "Batch 100,  loss: 0.2130927860736847\n",
      "Batch 105,  loss: 0.191011181473732\n",
      "Batch 110,  loss: 0.2471368432044983\n",
      "Batch 115,  loss: 0.2083519756793976\n",
      "Batch 120,  loss: 0.22017938494682313\n",
      "Batch 125,  loss: 0.22735342383384705\n",
      "Batch 130,  loss: 0.24109302163124086\n",
      "Batch 135,  loss: 0.22323964536190033\n",
      "Batch 140,  loss: 0.1867995947599411\n",
      "Batch 145,  loss: 0.2378660500049591\n",
      "Batch 150,  loss: 0.16841260194778443\n",
      "Batch 155,  loss: 0.1934933304786682\n",
      "Batch 160,  loss: 0.23082236647605897\n",
      "Batch 165,  loss: 0.2213837593793869\n",
      "Batch 170,  loss: 0.2654416859149933\n",
      "Batch 175,  loss: 0.21391266584396362\n",
      "Batch 180,  loss: 0.20751652717590333\n",
      "Batch 185,  loss: 0.18101332038640977\n",
      "Batch 190,  loss: 0.1869594246149063\n",
      "Batch 195,  loss: 0.15630302876234053\n",
      "Batch 200,  loss: 0.18898605406284333\n",
      "Batch 205,  loss: 0.27088706493377684\n",
      "Batch 210,  loss: 0.21579625010490416\n",
      "Batch 215,  loss: 0.22846263647079468\n",
      "Batch 220,  loss: 0.21673377454280854\n",
      "Batch 225,  loss: 0.20092692375183105\n",
      "Batch 230,  loss: 0.2175008624792099\n",
      "Batch 235,  loss: 0.22642848491668702\n",
      "Batch 240,  loss: 0.2103008508682251\n",
      "Batch 245,  loss: 0.2215631514787674\n",
      "Batch 250,  loss: 0.21838241815567017\n",
      "Batch 255,  loss: 0.20438637137413024\n",
      "Batch 260,  loss: 0.20992230772972106\n",
      "Batch 265,  loss: 0.20928122401237487\n",
      "Batch 270,  loss: 0.237925985455513\n",
      "Batch 275,  loss: 0.1656297266483307\n",
      "Batch 280,  loss: 0.24306232631206512\n",
      "Batch 285,  loss: 0.19990875124931334\n",
      "Batch 290,  loss: 0.192037732899189\n",
      "Batch 295,  loss: 0.17774767577648162\n",
      "Batch 300,  loss: 0.28736694157123566\n",
      "Batch 305,  loss: 0.19098927974700927\n",
      "Batch 310,  loss: 0.1824954479932785\n",
      "Batch 315,  loss: 0.2172821044921875\n",
      "Batch 320,  loss: 0.23609424531459808\n",
      "Batch 325,  loss: 0.2359818071126938\n",
      "Batch 330,  loss: 0.1816357344388962\n",
      "Batch 335,  loss: 0.25237753987312317\n",
      "Batch 340,  loss: 0.22256969213485717\n",
      "Batch 345,  loss: 0.2223484843969345\n",
      "Batch 350,  loss: 0.28103067278862\n",
      "Batch 355,  loss: 0.2170700579881668\n",
      "Batch 360,  loss: 0.19018323421478273\n",
      "Batch 365,  loss: 0.20928119421005248\n",
      "Batch 370,  loss: 0.24362073540687562\n",
      "Batch 375,  loss: 0.22332717180252076\n",
      "Batch 380,  loss: 0.2069556564092636\n",
      "Batch 385,  loss: 0.25258617997169497\n",
      "Batch 390,  loss: 0.28582256138324735\n",
      "Batch 395,  loss: 0.22557608485221864\n",
      "Batch 400,  loss: 0.2129954218864441\n",
      "Batch 405,  loss: 0.2648691713809967\n",
      "Batch 410,  loss: 0.19647955000400544\n",
      "Batch 415,  loss: 0.20980343520641326\n",
      "Batch 420,  loss: 0.22805164754390717\n",
      "Batch 425,  loss: 0.21338481903076173\n",
      "Batch 430,  loss: 0.21569214165210723\n",
      "Batch 435,  loss: 0.20064054131507875\n",
      "Batch 440,  loss: 0.3086248874664307\n",
      "Batch 445,  loss: 0.2278415620326996\n",
      "Batch 450,  loss: 0.23567672967910766\n",
      "Batch 455,  loss: 0.25517032146453855\n",
      "Batch 460,  loss: 0.19027235209941865\n",
      "Batch 465,  loss: 0.21599480509757996\n",
      "Batch 470,  loss: 0.2383622109889984\n",
      "Batch 475,  loss: 0.23046633899211882\n",
      "Batch 480,  loss: 0.2612263947725296\n",
      "Batch 485,  loss: 0.22511109709739685\n",
      "Batch 490,  loss: 0.2013084441423416\n",
      "Batch 495,  loss: 0.24860477447509766\n",
      "Batch 500,  loss: 0.22775985598564147\n",
      "Batch 505,  loss: 0.2067336320877075\n",
      "Batch 510,  loss: 0.23836766481399535\n",
      "Batch 515,  loss: 0.24762707352638244\n",
      "Batch 520,  loss: 0.23456020057201385\n",
      "Batch 525,  loss: 0.22147215604782106\n",
      "Batch 530,  loss: 0.25360243022441864\n",
      "Batch 535,  loss: 0.20186916291713713\n",
      "Batch 540,  loss: 0.24020456075668334\n",
      "Batch 545,  loss: 0.2032951980829239\n",
      "Batch 550,  loss: 0.21109608113765715\n",
      "Batch 555,  loss: 0.23947034180164337\n",
      "Batch 560,  loss: 0.2097857564687729\n",
      "Batch 565,  loss: 0.26793572306632996\n",
      "Batch 570,  loss: 0.25553489327430723\n",
      "Batch 575,  loss: 0.24357625246047973\n",
      "Batch 580,  loss: 0.23965053558349608\n",
      "Batch 585,  loss: 0.2595458745956421\n",
      "Batch 590,  loss: 0.20161661207675935\n",
      "Batch 595,  loss: 0.18902490735054017\n",
      "Batch 600,  loss: 0.25632553100585936\n",
      "Batch 605,  loss: 0.20254182815551758\n",
      "Batch 610,  loss: 0.2650789082050323\n",
      "Batch 615,  loss: 0.21174471080303192\n",
      "Batch 620,  loss: 0.18594137728214263\n",
      "Batch 625,  loss: 0.18954087495803834\n",
      "Batch 630,  loss: 0.22973596751689912\n",
      "Batch 635,  loss: 0.2464798539876938\n",
      "Batch 640,  loss: 0.23339009881019593\n",
      "Batch 645,  loss: 0.2055653691291809\n",
      "Batch 650,  loss: 0.20911641120910646\n",
      "Batch 655,  loss: 0.20847300291061402\n",
      "Batch 660,  loss: 0.2378501683473587\n",
      "Batch 665,  loss: 0.22750634253025054\n",
      "Batch 670,  loss: 0.22751141488552093\n",
      "Batch 675,  loss: 0.21218613982200624\n",
      "Batch 680,  loss: 0.19282355308532714\n",
      "Batch 685,  loss: 0.24414125084877014\n",
      "Batch 690,  loss: 0.24142826795578004\n",
      "Batch 695,  loss: 0.2283362090587616\n",
      "Batch 700,  loss: 0.2502678394317627\n",
      "Batch 705,  loss: 0.1966068297624588\n",
      "Batch 710,  loss: 0.25275416374206544\n",
      "Batch 715,  loss: 0.275114569067955\n",
      "Batch 720,  loss: 0.2361723691225052\n",
      "Batch 725,  loss: 0.2122604578733444\n",
      "Batch 730,  loss: 0.20962113738059998\n",
      "Batch 735,  loss: 0.20323936343193055\n",
      "Batch 740,  loss: 0.23392822444438935\n",
      "Batch 745,  loss: 0.2533624768257141\n",
      "Batch 750,  loss: 0.19162988662719727\n",
      "Batch 755,  loss: 0.1745312750339508\n",
      "Batch 760,  loss: 0.24317671060562135\n",
      "Batch 765,  loss: 0.21710891425609588\n",
      "Batch 770,  loss: 0.25046671032905576\n",
      "Batch 775,  loss: 0.21272617280483247\n",
      "Batch 780,  loss: 0.2215670019388199\n",
      "Batch 785,  loss: 0.20120169818401337\n",
      "Batch 790,  loss: 0.21754409223794938\n",
      "Batch 795,  loss: 0.24499390721321107\n",
      "Batch 800,  loss: 0.23437223434448243\n",
      "Batch 805,  loss: 0.17936291992664338\n",
      "Batch 810,  loss: 0.25138736367225645\n",
      "Batch 815,  loss: 0.16281899213790893\n",
      "Batch 820,  loss: 0.2167243927717209\n",
      "Batch 825,  loss: 0.2731425017118454\n",
      "Batch 830,  loss: 0.25998926162719727\n",
      "Batch 835,  loss: 0.2116277724504471\n",
      "Batch 840,  loss: 0.23054078817367554\n",
      "Batch 845,  loss: 0.2058837205171585\n",
      "Batch 850,  loss: 0.25928411185741423\n",
      "Batch 855,  loss: 0.21281773447990418\n",
      "Batch 860,  loss: 0.16410993039608002\n",
      "Batch 865,  loss: 0.23400318920612334\n",
      "Batch 870,  loss: 0.21425600945949555\n",
      "Batch 875,  loss: 0.2884980320930481\n",
      "Batch 880,  loss: 0.26537320017814636\n",
      "Batch 885,  loss: 0.23438799679279326\n",
      "Batch 890,  loss: 0.2464470237493515\n",
      "Batch 895,  loss: 0.23078757226467134\n",
      "Batch 900,  loss: 0.2090309113264084\n",
      "Batch 905,  loss: 0.18866934776306152\n",
      "Batch 910,  loss: 0.1924356073141098\n",
      "Batch 915,  loss: 0.26644990742206576\n",
      "Batch 920,  loss: 0.20515785813331605\n",
      "Batch 925,  loss: 0.19106622636318207\n",
      "Batch 930,  loss: 0.2226629823446274\n",
      "Batch 935,  loss: 0.24288323223590852\n",
      "Batch 940,  loss: 0.2656264632940292\n",
      "Batch 945,  loss: 0.23229615092277528\n",
      "Batch 950,  loss: 0.22219395339488984\n",
      "Batch 955,  loss: 0.21476396322250366\n",
      "Batch 960,  loss: 0.22315506339073182\n",
      "Batch 965,  loss: 0.2287341445684433\n",
      "Batch 970,  loss: 0.2148318499326706\n",
      "Batch 975,  loss: 0.21377727389335632\n",
      "Batch 980,  loss: 0.17692473530769348\n",
      "Batch 985,  loss: 0.19455809593200685\n",
      "Batch 990,  loss: 0.21946267187595367\n",
      "Batch 995,  loss: 0.31379342675209043\n",
      "Batch 1000,  loss: 0.2076404333114624\n",
      "Batch 1005,  loss: 0.17872090488672257\n",
      "Batch 1010,  loss: 0.27935704588890076\n",
      "Batch 1015,  loss: 0.23726605772972106\n",
      "Batch 1020,  loss: 0.24181514382362365\n",
      "Batch 1025,  loss: 0.23779916167259216\n",
      "Batch 1030,  loss: 0.24579262137413024\n",
      "Batch 1035,  loss: 0.18687988221645355\n",
      "Batch 1040,  loss: 0.20984447598457337\n",
      "Batch 1045,  loss: 0.24329352378845215\n",
      "Batch 1050,  loss: 0.18537672162055968\n",
      "Batch 1055,  loss: 0.21031129360198975\n",
      "Batch 1060,  loss: 0.2155469685792923\n",
      "Batch 1065,  loss: 0.1888392060995102\n",
      "Batch 1070,  loss: 0.19316183179616928\n",
      "Batch 1075,  loss: 0.20797464847564698\n",
      "Batch 1080,  loss: 0.2256421446800232\n",
      "Batch 1085,  loss: 0.204774808883667\n",
      "Batch 1090,  loss: 0.2496119260787964\n",
      "Batch 1095,  loss: 0.23919774889945983\n",
      "Batch 1100,  loss: 0.2811130464076996\n",
      "Batch 1105,  loss: 0.25291635990142824\n",
      "Batch 1110,  loss: 0.2404997318983078\n",
      "Batch 1115,  loss: 0.1895628184080124\n",
      "Batch 1120,  loss: 0.20498962700366974\n",
      "Batch 1125,  loss: 0.22469868063926696\n",
      "Batch 1130,  loss: 0.25263392329216006\n",
      "Batch 1135,  loss: 0.24257707297801973\n",
      "Batch 1140,  loss: 0.23466179072856902\n",
      "Batch 1145,  loss: 0.21285010278224945\n",
      "Batch 1150,  loss: 0.23663246631622314\n",
      "Batch 1155,  loss: 0.23729952275753022\n",
      "Batch 1160,  loss: 0.20631185173988342\n",
      "Batch 1165,  loss: 0.18731435537338256\n",
      "Batch 1170,  loss: 0.23497214317321777\n",
      "Batch 1175,  loss: 0.2781882703304291\n",
      "Batch 1180,  loss: 0.2220008671283722\n",
      "Batch 1185,  loss: 0.26170059442520144\n",
      "Batch 1190,  loss: 0.24318476617336274\n",
      "Batch 1195,  loss: 0.20319018959999086\n",
      "Batch 1200,  loss: 0.25624496936798097\n",
      "Batch 1205,  loss: 0.2333792746067047\n",
      "Batch 1210,  loss: 0.19610060453414918\n",
      "Batch 1215,  loss: 0.23848846852779387\n",
      "Batch 1220,  loss: 0.20079939365386962\n",
      "Batch 1225,  loss: 0.1887718617916107\n",
      "Batch 1230,  loss: 0.2430710256099701\n",
      "Batch 1235,  loss: 0.20770586431026458\n",
      "Batch 1240,  loss: 0.24699512124061584\n",
      "Batch 1245,  loss: 0.2484212338924408\n",
      "Batch 1250,  loss: 0.19909682869911194\n",
      "Batch 1255,  loss: 0.2221451222896576\n",
      "Batch 1260,  loss: 0.20123476386070252\n",
      "Batch 1265,  loss: 0.2746366113424301\n",
      "Batch 1270,  loss: 0.21843492984771729\n",
      "Batch 1275,  loss: 0.22910519540309907\n",
      "Batch 1280,  loss: 0.202153480052948\n",
      "Batch 1285,  loss: 0.27766661047935487\n",
      "Batch 1290,  loss: 0.26059565842151644\n",
      "Batch 1295,  loss: 0.23022609651088716\n",
      "Batch 1300,  loss: 0.23968420624732972\n",
      "Batch 1305,  loss: 0.26844851970672606\n",
      "Batch 1310,  loss: 0.2185905694961548\n",
      "Batch 1315,  loss: 0.2475216120481491\n",
      "Batch 1320,  loss: 0.2516588568687439\n",
      "Batch 1325,  loss: 0.26891319155693055\n",
      "Batch 1330,  loss: 0.1764416962862015\n",
      "Batch 1335,  loss: 0.22292625308036804\n",
      "Batch 1340,  loss: 0.2233211249113083\n",
      "Batch 1345,  loss: 0.21359682977199554\n",
      "Batch 1350,  loss: 0.19678010642528534\n",
      "Batch 1355,  loss: 0.2641593039035797\n",
      "Batch 1360,  loss: 0.22310842275619508\n",
      "Batch 1365,  loss: 0.19615475535392762\n",
      "Batch 1370,  loss: 0.19427074790000914\n",
      "Batch 1375,  loss: 0.19916818141937256\n",
      "Batch 1380,  loss: 0.23518260419368744\n",
      "Batch 1385,  loss: 0.18637655675411224\n",
      "Batch 1390,  loss: 0.23232853412628174\n",
      "Batch 1395,  loss: 0.20072052478790284\n",
      "Batch 1400,  loss: 0.23746344447135925\n",
      "Batch 1405,  loss: 0.17440985441207885\n",
      "Batch 1410,  loss: 0.2218375623226166\n",
      "Batch 1415,  loss: 0.24366507679224014\n",
      "Batch 1420,  loss: 0.22468020617961884\n",
      "Batch 1425,  loss: 0.2535450130701065\n",
      "Batch 1430,  loss: 0.2061542749404907\n",
      "Batch 1435,  loss: 0.2346118837594986\n",
      "Batch 1440,  loss: 0.22397840023040771\n",
      "Batch 1445,  loss: 0.21322128772735596\n",
      "Batch 1450,  loss: 0.1930524528026581\n",
      "Batch 1455,  loss: 0.19567252397537233\n",
      "Batch 1460,  loss: 0.25085807740688326\n",
      "Batch 1465,  loss: 0.2214852750301361\n",
      "Batch 1470,  loss: 0.22148183584213257\n",
      "Batch 1475,  loss: 0.20601292252540587\n",
      "Batch 1480,  loss: 0.28757649958133696\n",
      "Batch 1485,  loss: 0.28620734214782717\n",
      "Batch 1490,  loss: 0.24284107685089112\n",
      "Batch 1495,  loss: 0.21852893829345704\n",
      "Batch 1500,  loss: 0.19678175449371338\n",
      "Batch 1505,  loss: 0.1981909990310669\n",
      "Batch 1510,  loss: 0.22994510233402252\n",
      "Batch 1515,  loss: 0.2572048604488373\n",
      "Batch 1520,  loss: 0.22138671576976776\n",
      "Batch 1525,  loss: 0.21944560110569\n",
      "Batch 1530,  loss: 0.2634972155094147\n",
      "Batch 1535,  loss: 0.2311916708946228\n",
      "Batch 1540,  loss: 0.23216604590415954\n",
      "Batch 1545,  loss: 0.24278689324855804\n",
      "Batch 1550,  loss: 0.21797580122947693\n",
      "Batch 1555,  loss: 0.2701691806316376\n",
      "Batch 1560,  loss: 0.2773946404457092\n",
      "Batch 1565,  loss: 0.24146097302436828\n",
      "Batch 1570,  loss: 0.23522980213165284\n",
      "Batch 1575,  loss: 0.23676949143409728\n",
      "Batch 1580,  loss: 0.23558797538280488\n",
      "Batch 1585,  loss: 0.19071123301982879\n",
      "Batch 1590,  loss: 0.2045534908771515\n",
      "Batch 1595,  loss: 0.19579321444034575\n",
      "Batch 1600,  loss: 0.2565197914838791\n",
      "Batch 1605,  loss: 0.20999164283275604\n",
      "Batch 1610,  loss: 0.2581924647092819\n",
      "Batch 1615,  loss: 0.22804528176784516\n",
      "Batch 1620,  loss: 0.20879316926002503\n",
      "Batch 1625,  loss: 0.24435486197471618\n",
      "Batch 1630,  loss: 0.2736306846141815\n",
      "Batch 1635,  loss: 0.2145552307367325\n",
      "Batch 1640,  loss: 0.21556157767772674\n",
      "Batch 1645,  loss: 0.21363521218299866\n",
      "Batch 1650,  loss: 0.19722815454006196\n",
      "Batch 1655,  loss: 0.2108465999364853\n",
      "Batch 1660,  loss: 0.23513499200344085\n",
      "Batch 1665,  loss: 0.23136215209960936\n",
      "Batch 1670,  loss: 0.20188441574573518\n",
      "Batch 1675,  loss: 0.26599131226539613\n",
      "Batch 1680,  loss: 0.20869493186473848\n",
      "Batch 1685,  loss: 0.1929369866847992\n",
      "Batch 1690,  loss: 0.2035287141799927\n",
      "Batch 1695,  loss: 0.2750761091709137\n",
      "Batch 1700,  loss: 0.17479537427425385\n",
      "Batch 1705,  loss: 0.22114049792289733\n",
      "Batch 1710,  loss: 0.22029090523719788\n",
      "Batch 1715,  loss: 0.24522736966609954\n",
      "Batch 1720,  loss: 0.1768653243780136\n",
      "Batch 1725,  loss: 0.23304602205753328\n",
      "Batch 1730,  loss: 0.2186000496149063\n",
      "Batch 1735,  loss: 0.2018043279647827\n",
      "Batch 1740,  loss: 0.22598109543323516\n",
      "Batch 1745,  loss: 0.2589400470256805\n",
      "Batch 1750,  loss: 0.23041021227836608\n",
      "Batch 1755,  loss: 0.1993276745080948\n",
      "Batch 1760,  loss: 0.2166750341653824\n",
      "Batch 1765,  loss: 0.1952194392681122\n",
      "Batch 1770,  loss: 0.2348353922367096\n",
      "Batch 1775,  loss: 0.17221645265817642\n",
      "Batch 1780,  loss: 0.15327326357364654\n",
      "Batch 1785,  loss: 0.24795516729354858\n",
      "Batch 1790,  loss: 0.24776926934719085\n",
      "Batch 1795,  loss: 0.1761149823665619\n",
      "Batch 1800,  loss: 0.20121503472328187\n",
      "Batch 1805,  loss: 0.2322618305683136\n",
      "Batch 1810,  loss: 0.21640219390392304\n",
      "Batch 1815,  loss: 0.20185238420963286\n",
      "Batch 1820,  loss: 0.21057084202766418\n",
      "Batch 1825,  loss: 0.2643240839242935\n",
      "Batch 1830,  loss: 0.18305172324180602\n",
      "Batch 1835,  loss: 0.20557350516319275\n",
      "Batch 1840,  loss: 0.21464858949184418\n",
      "Batch 1845,  loss: 0.1814164400100708\n",
      "Batch 1850,  loss: 0.20940751135349273\n",
      "Batch 1855,  loss: 0.1845340460538864\n",
      "Batch 1860,  loss: 0.17562264204025269\n",
      "Batch 1865,  loss: 0.19379575848579406\n",
      "Batch 1870,  loss: 0.2078947901725769\n",
      "Batch 1875,  loss: 0.23288535177707673\n",
      "Batch 1880,  loss: 0.1567290723323822\n",
      "Batch 1885,  loss: 0.25545731782913206\n",
      "Batch 1890,  loss: 0.2550203502178192\n",
      "Batch 1895,  loss: 0.17397848665714263\n",
      "Batch 1900,  loss: 0.2322690784931183\n",
      "Batch 1905,  loss: 0.21964085400104522\n",
      "Batch 1910,  loss: 0.23350950181484223\n",
      "Batch 1915,  loss: 0.284972083568573\n",
      "Batch 1920,  loss: 0.2202631115913391\n",
      "Batch 1925,  loss: 0.18300751447677613\n",
      "Batch 1930,  loss: 0.22783657014369965\n",
      "Batch 1935,  loss: 0.22573792934417725\n",
      "Batch 1940,  loss: 0.22446396350860595\n",
      "Batch 1945,  loss: 0.1788925811648369\n",
      "Batch 1950,  loss: 0.22269838750362397\n",
      "Batch 1955,  loss: 0.21366768181324006\n",
      "Batch 1960,  loss: 0.1668488711118698\n",
      "Batch 1965,  loss: 0.19163025617599488\n",
      "Batch 1970,  loss: 0.2141746163368225\n",
      "Batch 1975,  loss: 0.2560809463262558\n",
      "Batch 1980,  loss: 0.1986195057630539\n",
      "Batch 1985,  loss: 0.19313417971134186\n",
      "Batch 1990,  loss: 0.23184250593185424\n",
      "Batch 1995,  loss: 0.22263717651367188\n",
      "Batch 2000,  loss: 0.20094456225633622\n",
      "Batch 2005,  loss: 0.22145739048719407\n",
      "Batch 2010,  loss: 0.16284150779247283\n",
      "Batch 2015,  loss: 0.1826722353696823\n",
      "Batch 2020,  loss: 0.2304982990026474\n",
      "Batch 2025,  loss: 0.23862165510654448\n",
      "Batch 2030,  loss: 0.22758966982364653\n",
      "Batch 2035,  loss: 0.28810458779335024\n",
      "Batch 2040,  loss: 0.16881179213523864\n",
      "Batch 2045,  loss: 0.19659279882907868\n",
      "Batch 2050,  loss: 0.22487254738807677\n",
      "Batch 2055,  loss: 0.21817402243614198\n",
      "Batch 2060,  loss: 0.20403620302677156\n",
      "Batch 2065,  loss: 0.21704626977443695\n",
      "Batch 2070,  loss: 0.2537190139293671\n",
      "Batch 2075,  loss: 0.21947384774684905\n",
      "Batch 2080,  loss: 0.23824214041233063\n",
      "Batch 2085,  loss: 0.2105357825756073\n",
      "Batch 2090,  loss: 0.26713076531887053\n",
      "Batch 2095,  loss: 0.16075250059366225\n",
      "Batch 2100,  loss: 0.2642304837703705\n",
      "Batch 2105,  loss: 0.21593084633350373\n",
      "Batch 2110,  loss: 0.22810859382152557\n",
      "Batch 2115,  loss: 0.2380262553691864\n",
      "Batch 2120,  loss: 0.21833361089229583\n",
      "Batch 2125,  loss: 0.24457507133483886\n",
      "Batch 2130,  loss: 0.22812314331531525\n",
      "Batch 2135,  loss: 0.21916573941707612\n",
      "Batch 2140,  loss: 0.20641101002693177\n",
      "Batch 2145,  loss: 0.23777824640274048\n",
      "Batch 2150,  loss: 0.18233822286128998\n",
      "Batch 2155,  loss: 0.21941681504249572\n",
      "Batch 2160,  loss: 0.2042602092027664\n",
      "Batch 2165,  loss: 0.22649633288383483\n",
      "Batch 2170,  loss: 0.22280015349388121\n",
      "Batch 2175,  loss: 0.20284817218780518\n",
      "Batch 2180,  loss: 0.21493028998374938\n",
      "Batch 2185,  loss: 0.20957804322242737\n",
      "Batch 2190,  loss: 0.2410068392753601\n",
      "Batch 2195,  loss: 0.263700070977211\n",
      "Batch 2200,  loss: 0.16906385719776154\n",
      "Batch 2205,  loss: 0.15595950335264205\n",
      "Batch 2210,  loss: 0.23507874310016633\n",
      "Batch 2215,  loss: 0.19906724989414215\n",
      "Batch 2220,  loss: 0.22720035314559936\n",
      "Batch 2225,  loss: 0.2413272365927696\n",
      "Batch 2230,  loss: 0.17495913803577423\n",
      "Batch 2235,  loss: 0.22964222729206085\n",
      "Batch 2240,  loss: 0.23894254267215728\n",
      "Batch 2245,  loss: 0.22318657636642455\n",
      "Batch 2250,  loss: 0.17820194661617278\n",
      "Batch 2255,  loss: 0.19722287952899933\n",
      "Batch 2260,  loss: 0.27351572513580324\n",
      "Batch 2265,  loss: 0.19874192178249359\n",
      "Batch 2270,  loss: 0.20734157860279084\n",
      "Batch 2275,  loss: 0.21184898912906647\n",
      "Batch 2280,  loss: 0.23045392334461212\n",
      "Batch 2285,  loss: 0.16976565718650818\n",
      "Batch 2290,  loss: 0.21913595795631408\n",
      "Batch 2295,  loss: 0.21526755392551422\n",
      "Batch 2300,  loss: 0.19278942942619323\n",
      "Batch 2305,  loss: 0.2312670588493347\n",
      "Batch 2310,  loss: 0.1935973584651947\n",
      "Batch 2315,  loss: 0.21646997034549714\n",
      "Batch 2320,  loss: 0.18217695355415345\n",
      "Batch 2325,  loss: 0.20533921718597412\n",
      "Batch 2330,  loss: 0.20437175333499907\n",
      "Batch 2335,  loss: 0.22558747231960297\n",
      "Batch 2340,  loss: 0.20455809235572814\n",
      "Batch 2345,  loss: 0.24099322259426117\n",
      "Batch 2350,  loss: 0.23618825823068618\n",
      "Batch 2355,  loss: 0.2577913165092468\n",
      "Batch 2360,  loss: 0.22951006293296813\n",
      "Batch 2365,  loss: 0.22727836966514586\n",
      "Batch 2370,  loss: 0.2690316319465637\n",
      "Batch 2375,  loss: 0.21622894406318666\n",
      "Batch 2380,  loss: 0.3344074487686157\n",
      "Batch 2385,  loss: 0.23202906548976898\n",
      "Batch 2390,  loss: 0.22526441216468812\n",
      "Batch 2395,  loss: 0.2112685889005661\n",
      "Batch 2400,  loss: 0.24751549065113068\n",
      "Batch 2405,  loss: 0.17033672332763672\n",
      "Batch 2410,  loss: 0.24630287289619446\n",
      "Batch 2415,  loss: 0.18668589890003204\n",
      "Batch 2420,  loss: 0.20843712985515594\n",
      "Batch 2425,  loss: 0.258751580119133\n",
      "Batch 2430,  loss: 0.17672222554683686\n",
      "Batch 2435,  loss: 0.21590980291366577\n",
      "Batch 2440,  loss: 0.2154534190893173\n",
      "Batch 2445,  loss: 0.24841173589229584\n",
      "Batch 2450,  loss: 0.1821394830942154\n",
      "Batch 2455,  loss: 0.20372140407562256\n",
      "Batch 2460,  loss: 0.20136525630950927\n",
      "Batch 2465,  loss: 0.24237268567085266\n",
      "Batch 2470,  loss: 0.2682895690202713\n",
      "Batch 2475,  loss: 0.23426633477210998\n",
      "Batch 2480,  loss: 0.20323726832866668\n",
      "Batch 2485,  loss: 0.24775202572345734\n",
      "Batch 2490,  loss: 0.21463193446397782\n",
      "Batch 2495,  loss: 0.2113986372947693\n",
      "Batch 2500,  loss: 0.22086038887500764\n",
      "Batch 2505,  loss: 0.23657549619674684\n",
      "Batch 2510,  loss: 0.23495457470417022\n",
      "Batch 2515,  loss: 0.21286458075046538\n",
      "Batch 2520,  loss: 0.24046650826931\n",
      "Batch 2525,  loss: 0.24337229132652283\n",
      "Batch 2530,  loss: 0.18993240594863892\n",
      "Batch 2535,  loss: 0.23946188688278197\n",
      "Batch 2540,  loss: 0.21781984269618987\n",
      "Batch 2545,  loss: 0.23046845197677612\n",
      "Batch 2550,  loss: 0.22940143942832947\n",
      "Batch 2555,  loss: 0.23689180612564087\n",
      "Batch 2560,  loss: 0.23833842873573302\n",
      "Batch 2565,  loss: 0.22067329585552214\n",
      "Batch 2570,  loss: 0.19351881444454194\n",
      "Batch 2575,  loss: 0.20412799715995789\n",
      "Batch 2580,  loss: 0.2250886768102646\n",
      "Batch 2585,  loss: 0.26756847500801084\n",
      "Batch 2590,  loss: 0.2187667578458786\n",
      "Batch 2595,  loss: 0.21621352285146714\n",
      "Batch 2600,  loss: 0.2411265105009079\n",
      "Batch 2605,  loss: 0.1652179479598999\n",
      "Batch 2610,  loss: 0.18192723393440247\n",
      "Batch 2615,  loss: 0.21258951127529144\n",
      "Batch 2620,  loss: 0.23444339632987976\n",
      "Batch 2625,  loss: 0.18235343396663667\n",
      "Batch 2630,  loss: 0.2014792412519455\n",
      "Batch 2635,  loss: 0.21968158483505248\n",
      "Batch 2640,  loss: 0.22026872187852858\n",
      "Batch 2645,  loss: 0.20146208703517915\n",
      "Batch 2650,  loss: 0.23364852368831635\n",
      "Batch 2655,  loss: 0.23849910199642183\n",
      "Batch 2660,  loss: 0.2539594441652298\n",
      "Batch 2665,  loss: 0.22774196714162825\n",
      "Batch 2670,  loss: 0.2505213290452957\n",
      "Batch 2675,  loss: 0.2079248309135437\n",
      "Batch 2680,  loss: 0.2459978461265564\n",
      "Batch 2685,  loss: 0.22691479921340943\n",
      "Batch 2690,  loss: 0.25897787809371947\n",
      "Batch 2695,  loss: 0.19159237146377564\n",
      "Batch 2700,  loss: 0.20173147022724153\n",
      "Batch 2705,  loss: 0.20216103196144103\n",
      "Batch 2710,  loss: 0.24051766693592072\n",
      "Batch 2715,  loss: 0.15147631168365477\n",
      "Batch 2720,  loss: 0.208556604385376\n",
      "Batch 2725,  loss: 0.24189114570617676\n",
      "Batch 2730,  loss: 0.22594189047813415\n",
      "Batch 2735,  loss: 0.2624248117208481\n",
      "Batch 2740,  loss: 0.23017712831497192\n",
      "Batch 2745,  loss: 0.20978964865207672\n",
      "Batch 2750,  loss: 0.20427729785442353\n",
      "Batch 2755,  loss: 0.21861587166786195\n",
      "Batch 2760,  loss: 0.16799744069576264\n",
      "Batch 2765,  loss: 0.22321366369724274\n",
      "Batch 2770,  loss: 0.20793522000312806\n",
      "LOSS train 0.20793522000312806. Validation loss: 0.19085566570154494 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 6:\n",
      "Batch 5,  loss: 0.20330035984516143\n",
      "Batch 10,  loss: 0.17176249474287034\n",
      "Batch 15,  loss: 0.20795993506908417\n",
      "Batch 20,  loss: 0.21496036350727082\n",
      "Batch 25,  loss: 0.19263048470020294\n",
      "Batch 30,  loss: 0.18270782828330995\n",
      "Batch 35,  loss: 0.1615294724702835\n",
      "Batch 40,  loss: 0.21863245964050293\n",
      "Batch 45,  loss: 0.2243787944316864\n",
      "Batch 50,  loss: 0.18683856427669526\n",
      "Batch 55,  loss: 0.22522766888141632\n",
      "Batch 60,  loss: 0.2644040912389755\n",
      "Batch 65,  loss: 0.2157248169183731\n",
      "Batch 70,  loss: 0.2359720140695572\n",
      "Batch 75,  loss: 0.22266283631324768\n",
      "Batch 80,  loss: 0.2279102087020874\n",
      "Batch 85,  loss: 0.21914576590061188\n",
      "Batch 90,  loss: 0.19105247408151627\n",
      "Batch 95,  loss: 0.2566234141588211\n",
      "Batch 100,  loss: 0.2626290559768677\n",
      "Batch 105,  loss: 0.19422079622745514\n",
      "Batch 110,  loss: 0.22612801492214202\n",
      "Batch 115,  loss: 0.21509189903736115\n",
      "Batch 120,  loss: 0.2171318084001541\n",
      "Batch 125,  loss: 0.22406727969646453\n",
      "Batch 130,  loss: 0.21491193920373916\n",
      "Batch 135,  loss: 0.20407965779304504\n",
      "Batch 140,  loss: 0.18935757279396057\n",
      "Batch 145,  loss: 0.22998446822166443\n",
      "Batch 150,  loss: 0.24228290617465972\n",
      "Batch 155,  loss: 0.2207544207572937\n",
      "Batch 160,  loss: 0.1888425514101982\n",
      "Batch 165,  loss: 0.23839479088783264\n",
      "Batch 170,  loss: 0.20162779986858367\n",
      "Batch 175,  loss: 0.25354490280151365\n",
      "Batch 180,  loss: 0.21263073682785033\n",
      "Batch 185,  loss: 0.2238471806049347\n",
      "Batch 190,  loss: 0.23942381739616395\n",
      "Batch 195,  loss: 0.24794159233570098\n",
      "Batch 200,  loss: 0.1606979101896286\n",
      "Batch 205,  loss: 0.24060839414596558\n",
      "Batch 210,  loss: 0.2812507152557373\n",
      "Batch 215,  loss: 0.21682938039302826\n",
      "Batch 220,  loss: 0.22560727894306182\n",
      "Batch 225,  loss: 0.20921983122825621\n",
      "Batch 230,  loss: 0.25487746596336364\n",
      "Batch 235,  loss: 0.2041969358921051\n",
      "Batch 240,  loss: 0.23037346601486205\n",
      "Batch 245,  loss: 0.24588317275047303\n",
      "Batch 250,  loss: 0.22062887549400328\n",
      "Batch 255,  loss: 0.35700586140155793\n",
      "Batch 260,  loss: 0.19683404564857482\n",
      "Batch 265,  loss: 0.1627635419368744\n",
      "Batch 270,  loss: 0.22471746802330017\n",
      "Batch 275,  loss: 0.22778995037078859\n",
      "Batch 280,  loss: 0.2574919492006302\n",
      "Batch 285,  loss: 0.2597645103931427\n",
      "Batch 290,  loss: 0.21175947189331054\n",
      "Batch 295,  loss: 0.2725400924682617\n",
      "Batch 300,  loss: 0.1834749311208725\n",
      "Batch 305,  loss: 0.2545753002166748\n",
      "Batch 310,  loss: 0.2006262242794037\n",
      "Batch 315,  loss: 0.21361688673496246\n",
      "Batch 320,  loss: 0.21093838214874266\n",
      "Batch 325,  loss: 0.2175254374742508\n",
      "Batch 330,  loss: 0.187782946228981\n",
      "Batch 335,  loss: 0.21278737485408783\n",
      "Batch 340,  loss: 0.1871835082769394\n",
      "Batch 345,  loss: 0.24910417199134827\n",
      "Batch 350,  loss: 0.2596659779548645\n",
      "Batch 355,  loss: 0.23890984058380127\n",
      "Batch 360,  loss: 0.2991457343101501\n",
      "Batch 365,  loss: 0.22641130089759826\n",
      "Batch 370,  loss: 0.22870582044124604\n",
      "Batch 375,  loss: 0.1988806426525116\n",
      "Batch 380,  loss: 0.20714536011219026\n",
      "Batch 385,  loss: 0.21498132944107057\n",
      "Batch 390,  loss: 0.21756249368190766\n",
      "Batch 395,  loss: 0.24604081213474274\n",
      "Batch 400,  loss: 0.18096720576286315\n",
      "Batch 405,  loss: 0.22726202011108398\n",
      "Batch 410,  loss: 0.195261612534523\n",
      "Batch 415,  loss: 0.18190389573574067\n",
      "Batch 420,  loss: 0.20462315678596496\n",
      "Batch 425,  loss: 0.16951074302196503\n",
      "Batch 430,  loss: 0.19341776967048646\n",
      "Batch 435,  loss: 0.24285928308963775\n",
      "Batch 440,  loss: 0.17580094635486604\n",
      "Batch 445,  loss: 0.22697106897830963\n",
      "Batch 450,  loss: 0.22281477451324463\n",
      "Batch 455,  loss: 0.2860052317380905\n",
      "Batch 460,  loss: 0.16368348598480226\n",
      "Batch 465,  loss: 0.22427767217159272\n",
      "Batch 470,  loss: 0.20015135109424592\n",
      "Batch 475,  loss: 0.23881942331790923\n",
      "Batch 480,  loss: 0.206027115881443\n",
      "Batch 485,  loss: 0.2329588681459427\n",
      "Batch 490,  loss: 0.19840361773967743\n",
      "Batch 495,  loss: 0.21527479887008666\n",
      "Batch 500,  loss: 0.2014073297381401\n",
      "Batch 505,  loss: 0.20875178575515746\n",
      "Batch 510,  loss: 0.25447264313697815\n",
      "Batch 515,  loss: 0.20229941010475158\n",
      "Batch 520,  loss: 0.26633787155151367\n",
      "Batch 525,  loss: 0.1920007050037384\n",
      "Batch 530,  loss: 0.2534118205308914\n",
      "Batch 535,  loss: 0.2098652243614197\n",
      "Batch 540,  loss: 0.1851709246635437\n",
      "Batch 545,  loss: 0.21974965333938598\n",
      "Batch 550,  loss: 0.18184812366962433\n",
      "Batch 555,  loss: 0.2122276693582535\n",
      "Batch 560,  loss: 0.2795278862118721\n",
      "Batch 565,  loss: 0.20344571471214296\n",
      "Batch 570,  loss: 0.21052169501781465\n",
      "Batch 575,  loss: 0.224102121591568\n",
      "Batch 580,  loss: 0.22337002754211427\n",
      "Batch 585,  loss: 0.18306926488876343\n",
      "Batch 590,  loss: 0.2101224735379219\n",
      "Batch 595,  loss: 0.19787448048591613\n",
      "Batch 600,  loss: 0.23811849057674409\n",
      "Batch 605,  loss: 0.1755148559808731\n",
      "Batch 610,  loss: 0.18387217521667482\n",
      "Batch 615,  loss: 0.20728145241737367\n",
      "Batch 620,  loss: 0.24029616713523866\n",
      "Batch 625,  loss: 0.2465774744749069\n",
      "Batch 630,  loss: 0.21361808478832245\n",
      "Batch 635,  loss: 0.20410324335098268\n",
      "Batch 640,  loss: 0.2257857710123062\n",
      "Batch 645,  loss: 0.19404707551002504\n",
      "Batch 650,  loss: 0.19606297910213472\n",
      "Batch 655,  loss: 0.22497014105319976\n",
      "Batch 660,  loss: 0.1832267999649048\n",
      "Batch 665,  loss: 0.18782047033309937\n",
      "Batch 670,  loss: 0.19661295115947724\n",
      "Batch 675,  loss: 0.26123263537883756\n",
      "Batch 680,  loss: 0.18489553928375244\n",
      "Batch 685,  loss: 0.2026568979024887\n",
      "Batch 690,  loss: 0.21562693417072296\n",
      "Batch 695,  loss: 0.208684042096138\n",
      "Batch 700,  loss: 0.20866352915763856\n",
      "Batch 705,  loss: 0.21493192315101622\n",
      "Batch 710,  loss: 0.26391754746437074\n",
      "Batch 715,  loss: 0.21261495649814605\n",
      "Batch 720,  loss: 0.24961698651313782\n",
      "Batch 725,  loss: 0.22237172424793245\n",
      "Batch 730,  loss: 0.2207544267177582\n",
      "Batch 735,  loss: 0.2533699065446854\n",
      "Batch 740,  loss: 0.21948417127132416\n",
      "Batch 745,  loss: 0.26471531987190244\n",
      "Batch 750,  loss: 0.225737327337265\n",
      "Batch 755,  loss: 0.1875531405210495\n",
      "Batch 760,  loss: 0.2051836520433426\n",
      "Batch 765,  loss: 0.22534582316875457\n",
      "Batch 770,  loss: 0.2783228099346161\n",
      "Batch 775,  loss: 0.18162194788455963\n",
      "Batch 780,  loss: 0.24559908509254455\n",
      "Batch 785,  loss: 0.1922486901283264\n",
      "Batch 790,  loss: 0.2905505120754242\n",
      "Batch 795,  loss: 0.21013416349887848\n",
      "Batch 800,  loss: 0.26342737674713135\n",
      "Batch 805,  loss: 0.2376061499118805\n",
      "Batch 810,  loss: 0.2601823717355728\n",
      "Batch 815,  loss: 0.1999654233455658\n",
      "Batch 820,  loss: 0.19536381363868713\n",
      "Batch 825,  loss: 0.18392098248004912\n",
      "Batch 830,  loss: 0.18363593220710756\n",
      "Batch 835,  loss: 0.25046675801277163\n",
      "Batch 840,  loss: 0.23532855808734893\n",
      "Batch 845,  loss: 0.18289466053247452\n",
      "Batch 850,  loss: 0.2331039160490036\n",
      "Batch 855,  loss: 0.17604000270366668\n",
      "Batch 860,  loss: 0.18752025365829467\n",
      "Batch 865,  loss: 0.2232103615999222\n",
      "Batch 870,  loss: 0.1900990754365921\n",
      "Batch 875,  loss: 0.2030847489833832\n",
      "Batch 880,  loss: 0.22733929455280305\n",
      "Batch 885,  loss: 0.2381281793117523\n",
      "Batch 890,  loss: 0.22119034826755524\n",
      "Batch 895,  loss: 0.17494117021560668\n",
      "Batch 900,  loss: 0.2110930860042572\n",
      "Batch 905,  loss: 0.21803467571735383\n",
      "Batch 910,  loss: 0.23350154757499694\n",
      "Batch 915,  loss: 0.18148210644721985\n",
      "Batch 920,  loss: 0.2186417579650879\n",
      "Batch 925,  loss: 0.17194495499134063\n",
      "Batch 930,  loss: 0.21187706291675568\n",
      "Batch 935,  loss: 0.266112869977951\n",
      "Batch 940,  loss: 0.25037246346473696\n",
      "Batch 945,  loss: 0.20138950347900392\n",
      "Batch 950,  loss: 0.19138453304767608\n",
      "Batch 955,  loss: 0.19974595457315444\n",
      "Batch 960,  loss: 0.21762897074222565\n",
      "Batch 965,  loss: 0.24384207129478455\n",
      "Batch 970,  loss: 0.2527869910001755\n",
      "Batch 975,  loss: 0.22814967334270478\n",
      "Batch 980,  loss: 0.22331055402755737\n",
      "Batch 985,  loss: 0.1927584230899811\n",
      "Batch 990,  loss: 0.20663635432720184\n",
      "Batch 995,  loss: 0.2441202074289322\n",
      "Batch 1000,  loss: 0.19509605169296265\n",
      "Batch 1005,  loss: 0.22824963331222534\n",
      "Batch 1010,  loss: 0.19202882945537567\n",
      "Batch 1015,  loss: 0.21742899417877198\n",
      "Batch 1020,  loss: 0.25304114818573\n",
      "Batch 1025,  loss: 0.26181532740592955\n",
      "Batch 1030,  loss: 0.1995167315006256\n",
      "Batch 1035,  loss: 0.23595995903015138\n",
      "Batch 1040,  loss: 0.19081562161445617\n",
      "Batch 1045,  loss: 0.2552042692899704\n",
      "Batch 1050,  loss: 0.23004190921783446\n",
      "Batch 1055,  loss: 0.21353646814823152\n",
      "Batch 1060,  loss: 0.17650236338376998\n",
      "Batch 1065,  loss: 0.15554167628288268\n",
      "Batch 1070,  loss: 0.20882975161075593\n",
      "Batch 1075,  loss: 0.17935569882392882\n",
      "Batch 1080,  loss: 0.2181106060743332\n",
      "Batch 1085,  loss: 0.24026098549365998\n",
      "Batch 1090,  loss: 0.20228710025548935\n",
      "Batch 1095,  loss: 0.25340122878551485\n",
      "Batch 1100,  loss: 0.19798584878444672\n",
      "Batch 1105,  loss: 0.19079460501670836\n",
      "Batch 1110,  loss: 0.20070295929908752\n",
      "Batch 1115,  loss: 0.1950315684080124\n",
      "Batch 1120,  loss: 0.17042123079299926\n",
      "Batch 1125,  loss: 0.22726545333862305\n",
      "Batch 1130,  loss: 0.22671773731708528\n",
      "Batch 1135,  loss: 0.181362783908844\n",
      "Batch 1140,  loss: 0.21470096409320832\n",
      "Batch 1145,  loss: 0.2698288321495056\n",
      "Batch 1150,  loss: 0.25320138335227965\n",
      "Batch 1155,  loss: 0.26957632303237916\n",
      "Batch 1160,  loss: 0.2266432136297226\n",
      "Batch 1165,  loss: 0.20331183075904846\n",
      "Batch 1170,  loss: 0.1976255565881729\n",
      "Batch 1175,  loss: 0.19178275763988495\n",
      "Batch 1180,  loss: 0.2477442890405655\n",
      "Batch 1185,  loss: 0.20940247178077698\n",
      "Batch 1190,  loss: 0.24957523345947266\n",
      "Batch 1195,  loss: 0.2089798331260681\n",
      "Batch 1200,  loss: 0.23000322580337523\n",
      "Batch 1205,  loss: 0.19487421810626984\n",
      "Batch 1210,  loss: 0.23584461212158203\n",
      "Batch 1215,  loss: 0.20490732192993164\n",
      "Batch 1220,  loss: 0.22622429132461547\n",
      "Batch 1225,  loss: 0.2706284403800964\n",
      "Batch 1230,  loss: 0.25231246948242186\n",
      "Batch 1235,  loss: 0.19297782182693482\n",
      "Batch 1240,  loss: 0.2067260593175888\n",
      "Batch 1245,  loss: 0.2152491331100464\n",
      "Batch 1250,  loss: 0.22278091311454773\n",
      "Batch 1255,  loss: 0.25899691581726075\n",
      "Batch 1260,  loss: 0.23998965322971344\n",
      "Batch 1265,  loss: 0.20454165637493132\n",
      "Batch 1270,  loss: 0.16621633470058442\n",
      "Batch 1275,  loss: 0.18686316013336182\n",
      "Batch 1280,  loss: 0.2217496156692505\n",
      "Batch 1285,  loss: 0.2951006948947906\n",
      "Batch 1290,  loss: 0.24256015717983245\n",
      "Batch 1295,  loss: 0.2590227395296097\n",
      "Batch 1300,  loss: 0.2732207477092743\n",
      "Batch 1305,  loss: 0.22505038976669312\n",
      "Batch 1310,  loss: 0.2314492344856262\n",
      "Batch 1315,  loss: 0.2274417281150818\n",
      "Batch 1320,  loss: 0.21731429696083068\n",
      "Batch 1325,  loss: 0.20113617181777954\n",
      "Batch 1330,  loss: 0.2293499380350113\n",
      "Batch 1335,  loss: 0.23476989269256593\n",
      "Batch 1340,  loss: 0.22252323627471923\n",
      "Batch 1345,  loss: 0.2009590119123459\n",
      "Batch 1350,  loss: 0.20418350994586945\n",
      "Batch 1355,  loss: 0.2417502760887146\n",
      "Batch 1360,  loss: 0.19489050507545472\n",
      "Batch 1365,  loss: 0.21809439361095428\n",
      "Batch 1370,  loss: 0.19182050824165345\n",
      "Batch 1375,  loss: 0.2735177934169769\n",
      "Batch 1380,  loss: 0.23976506888866425\n",
      "Batch 1385,  loss: 0.19208928644657136\n",
      "Batch 1390,  loss: 0.22646400928497315\n",
      "Batch 1395,  loss: 0.2585020989179611\n",
      "Batch 1400,  loss: 0.22175258994102479\n",
      "Batch 1405,  loss: 0.2200443297624588\n",
      "Batch 1410,  loss: 0.25779885351657866\n",
      "Batch 1415,  loss: 0.21252348124980927\n",
      "Batch 1420,  loss: 0.1998056173324585\n",
      "Batch 1425,  loss: 0.1898039311170578\n",
      "Batch 1430,  loss: 0.16928169429302214\n",
      "Batch 1435,  loss: 0.17160778790712355\n",
      "Batch 1440,  loss: 0.18214086592197418\n",
      "Batch 1445,  loss: 0.20855879485607148\n",
      "Batch 1450,  loss: 0.20274308919906617\n",
      "Batch 1455,  loss: 0.23638770282268523\n",
      "Batch 1460,  loss: 0.20780591070652008\n",
      "Batch 1465,  loss: 0.16644546687602996\n",
      "Batch 1470,  loss: 0.23151269257068635\n",
      "Batch 1475,  loss: 0.31761817932128905\n",
      "Batch 1480,  loss: 0.20043057799339295\n",
      "Batch 1485,  loss: 0.21766454875469207\n",
      "Batch 1490,  loss: 0.24048055410385133\n",
      "Batch 1495,  loss: 0.24426624774932862\n",
      "Batch 1500,  loss: 0.21960722506046296\n",
      "Batch 1505,  loss: 0.27897967398166656\n",
      "Batch 1510,  loss: 0.2543472647666931\n",
      "Batch 1515,  loss: 0.2074132442474365\n",
      "Batch 1520,  loss: 0.19297648072242737\n",
      "Batch 1525,  loss: 0.19949324131011964\n",
      "Batch 1530,  loss: 0.19805965721607208\n",
      "Batch 1535,  loss: 0.191642826795578\n",
      "Batch 1540,  loss: 0.15451373755931855\n",
      "Batch 1545,  loss: 0.2135547548532486\n",
      "Batch 1550,  loss: 0.21704483032226562\n",
      "Batch 1555,  loss: 0.16930515170097352\n",
      "Batch 1560,  loss: 0.1817563146352768\n",
      "Batch 1565,  loss: 0.28723684549331663\n",
      "Batch 1570,  loss: 0.27251079976558684\n",
      "Batch 1575,  loss: 0.2172151267528534\n",
      "Batch 1580,  loss: 0.21542818546295167\n",
      "Batch 1585,  loss: 0.17357677966356277\n",
      "Batch 1590,  loss: 0.22096452116966248\n",
      "Batch 1595,  loss: 0.19578866362571717\n",
      "Batch 1600,  loss: 0.19395803809165954\n",
      "Batch 1605,  loss: 0.17224903404712677\n",
      "Batch 1610,  loss: 0.2320931538939476\n",
      "Batch 1615,  loss: 0.19962730407714843\n",
      "Batch 1620,  loss: 0.2491581082344055\n",
      "Batch 1625,  loss: 0.24909019470214844\n",
      "Batch 1630,  loss: 0.21302930414676666\n",
      "Batch 1635,  loss: 0.17454900443553925\n",
      "Batch 1640,  loss: 0.2609809905290604\n",
      "Batch 1645,  loss: 0.209194353222847\n",
      "Batch 1650,  loss: 0.19000622630119324\n",
      "Batch 1655,  loss: 0.2229057103395462\n",
      "Batch 1660,  loss: 0.19991428256034852\n",
      "Batch 1665,  loss: 0.20281709730625153\n",
      "Batch 1670,  loss: 0.206728932261467\n",
      "Batch 1675,  loss: 0.21535811424255372\n",
      "Batch 1680,  loss: 0.1704177051782608\n",
      "Batch 1685,  loss: 0.20335250794887544\n",
      "Batch 1690,  loss: 0.20888330340385436\n",
      "Batch 1695,  loss: 0.21797511279582976\n",
      "Batch 1700,  loss: 0.2398541808128357\n",
      "Batch 1705,  loss: 0.2754974067211151\n",
      "Batch 1710,  loss: 0.2029212683439255\n",
      "Batch 1715,  loss: 0.24662960469722747\n",
      "Batch 1720,  loss: 0.20372381806373596\n",
      "Batch 1725,  loss: 0.18270582258701323\n",
      "Batch 1730,  loss: 0.1777769461274147\n",
      "Batch 1735,  loss: 0.2265926867723465\n",
      "Batch 1740,  loss: 0.21773507297039033\n",
      "Batch 1745,  loss: 0.1856112778186798\n",
      "Batch 1750,  loss: 0.22092355489730836\n",
      "Batch 1755,  loss: 0.2097124457359314\n",
      "Batch 1760,  loss: 0.20146616101264953\n",
      "Batch 1765,  loss: 0.2038177251815796\n",
      "Batch 1770,  loss: 0.21912308037281036\n",
      "Batch 1775,  loss: 0.21798916161060333\n",
      "Batch 1780,  loss: 0.22083500027656555\n",
      "Batch 1785,  loss: 0.2243626594543457\n",
      "Batch 1790,  loss: 0.22481510639190674\n",
      "Batch 1795,  loss: 0.21257172226905824\n",
      "Batch 1800,  loss: 0.20190505981445311\n",
      "Batch 1805,  loss: 0.2591911107301712\n",
      "Batch 1810,  loss: 0.2108997792005539\n",
      "Batch 1815,  loss: 0.20643860697746277\n",
      "Batch 1820,  loss: 0.24998294115066527\n",
      "Batch 1825,  loss: 0.1434948906302452\n",
      "Batch 1830,  loss: 0.2036284476518631\n",
      "Batch 1835,  loss: 0.1978435456752777\n",
      "Batch 1840,  loss: 0.2461531639099121\n",
      "Batch 1845,  loss: 0.19997778236865998\n",
      "Batch 1850,  loss: 0.18212083578109742\n",
      "Batch 1855,  loss: 0.19191932678222656\n",
      "Batch 1860,  loss: 0.21591125428676605\n",
      "Batch 1865,  loss: 0.20982804596424104\n",
      "Batch 1870,  loss: 0.2261412560939789\n",
      "Batch 1875,  loss: 0.26052483916282654\n",
      "Batch 1880,  loss: 0.1764876902103424\n",
      "Batch 1885,  loss: 0.20706835389137268\n",
      "Batch 1890,  loss: 0.2436535596847534\n",
      "Batch 1895,  loss: 0.2468135178089142\n",
      "Batch 1900,  loss: 0.21830664277076722\n",
      "Batch 1905,  loss: 0.25400447845458984\n",
      "Batch 1910,  loss: 0.1977438747882843\n",
      "Batch 1915,  loss: 0.26249637007713317\n",
      "Batch 1920,  loss: 0.24749711155891418\n",
      "Batch 1925,  loss: 0.18190096616744994\n",
      "Batch 1930,  loss: 0.26868522465229033\n",
      "Batch 1935,  loss: 0.21900752782821656\n",
      "Batch 1940,  loss: 0.2202199876308441\n",
      "Batch 1945,  loss: 0.23793529570102692\n",
      "Batch 1950,  loss: 0.264627081155777\n",
      "Batch 1955,  loss: 0.20003795623779297\n",
      "Batch 1960,  loss: 0.23911181092262268\n",
      "Batch 1965,  loss: 0.18760338723659514\n",
      "Batch 1970,  loss: 0.1903125524520874\n",
      "Batch 1975,  loss: 0.18521313071250917\n",
      "Batch 1980,  loss: 0.2037868916988373\n",
      "Batch 1985,  loss: 0.18871577382087706\n",
      "Batch 1990,  loss: 0.19559999108314513\n",
      "Batch 1995,  loss: 0.21684445440769196\n",
      "Batch 2000,  loss: 0.2506722271442413\n",
      "Batch 2005,  loss: 0.172384874522686\n",
      "Batch 2010,  loss: 0.22613608241081237\n",
      "Batch 2015,  loss: 0.19194802939891814\n",
      "Batch 2020,  loss: 0.29562942385673524\n",
      "Batch 2025,  loss: 0.24426072239875793\n",
      "Batch 2030,  loss: 0.23622812926769257\n",
      "Batch 2035,  loss: 0.20624321401119233\n",
      "Batch 2040,  loss: 0.24700255692005157\n",
      "Batch 2045,  loss: 0.23126485347747802\n",
      "Batch 2050,  loss: 0.20460530519485473\n",
      "Batch 2055,  loss: 0.1824437916278839\n",
      "Batch 2060,  loss: 0.226337006688118\n",
      "Batch 2065,  loss: 0.20530452728271484\n",
      "Batch 2070,  loss: 0.2284758895635605\n",
      "Batch 2075,  loss: 0.19099454581737518\n",
      "Batch 2080,  loss: 0.21198505759239197\n",
      "Batch 2085,  loss: 0.19684066921472548\n",
      "Batch 2090,  loss: 0.1673378437757492\n",
      "Batch 2095,  loss: 0.21639144718647002\n",
      "Batch 2100,  loss: 0.21610013544559478\n",
      "Batch 2105,  loss: 0.2109100937843323\n",
      "Batch 2110,  loss: 0.1859359934926033\n",
      "Batch 2115,  loss: 0.18106122314929962\n",
      "Batch 2120,  loss: 0.21673543453216554\n",
      "Batch 2125,  loss: 0.2426707550883293\n",
      "Batch 2130,  loss: 0.23113727271556855\n",
      "Batch 2135,  loss: 0.2220258593559265\n",
      "Batch 2140,  loss: 0.22310622334480285\n",
      "Batch 2145,  loss: 0.21068911850452424\n",
      "Batch 2150,  loss: 0.18828239142894745\n",
      "Batch 2155,  loss: 0.23219254612922668\n",
      "Batch 2160,  loss: 0.18844983279705046\n",
      "Batch 2165,  loss: 0.22061471343040467\n",
      "Batch 2170,  loss: 0.18390680849552155\n",
      "Batch 2175,  loss: 0.27444711327552795\n",
      "Batch 2180,  loss: 0.23472421169281005\n",
      "Batch 2185,  loss: 0.19342591166496276\n",
      "Batch 2190,  loss: 0.19814019203186034\n",
      "Batch 2195,  loss: 0.2941817343235016\n",
      "Batch 2200,  loss: 0.25799415409564974\n",
      "Batch 2205,  loss: 0.2499592959880829\n",
      "Batch 2210,  loss: 0.18110240399837493\n",
      "Batch 2215,  loss: 0.2705327033996582\n",
      "Batch 2220,  loss: 0.21685779094696045\n",
      "Batch 2225,  loss: 0.21349639296531678\n",
      "Batch 2230,  loss: 0.204709392786026\n",
      "Batch 2235,  loss: 0.20826563835144044\n",
      "Batch 2240,  loss: 0.2101865977048874\n",
      "Batch 2245,  loss: 0.22458955347537995\n",
      "Batch 2250,  loss: 0.1704219937324524\n",
      "Batch 2255,  loss: 0.21674666702747344\n",
      "Batch 2260,  loss: 0.2531451404094696\n",
      "Batch 2265,  loss: 0.24436794221401215\n",
      "Batch 2270,  loss: 0.25474347472190856\n",
      "Batch 2275,  loss: 0.24174099564552307\n",
      "Batch 2280,  loss: 0.21497096717357636\n",
      "Batch 2285,  loss: 0.2336033582687378\n",
      "Batch 2290,  loss: 0.19300669133663179\n",
      "Batch 2295,  loss: 0.18034899830818177\n",
      "Batch 2300,  loss: 0.21912975311279298\n",
      "Batch 2305,  loss: 0.2353975683450699\n",
      "Batch 2310,  loss: 0.24770180583000184\n",
      "Batch 2315,  loss: 0.18421027958393096\n",
      "Batch 2320,  loss: 0.18632008731365204\n",
      "Batch 2325,  loss: 0.22515042424201964\n",
      "Batch 2330,  loss: 0.18752967864274978\n",
      "Batch 2335,  loss: 0.18576841950416564\n",
      "Batch 2340,  loss: 0.200255885720253\n",
      "Batch 2345,  loss: 0.18494056910276413\n",
      "Batch 2350,  loss: 0.23137214183807372\n",
      "Batch 2355,  loss: 0.17387950867414476\n",
      "Batch 2360,  loss: 0.1863411396741867\n",
      "Batch 2365,  loss: 0.19424692690372466\n",
      "Batch 2370,  loss: 0.2184729427099228\n",
      "Batch 2375,  loss: 0.19446678459644318\n",
      "Batch 2380,  loss: 0.17799025774002075\n",
      "Batch 2385,  loss: 0.19876183867454528\n",
      "Batch 2390,  loss: 0.22488557398319245\n",
      "Batch 2395,  loss: 0.2464565873146057\n",
      "Batch 2400,  loss: 0.21273355185985565\n",
      "Batch 2405,  loss: 0.2212577521800995\n",
      "Batch 2410,  loss: 0.2068801313638687\n",
      "Batch 2415,  loss: 0.21375324726104736\n",
      "Batch 2420,  loss: 0.21366461217403412\n",
      "Batch 2425,  loss: 0.21918287575244905\n",
      "Batch 2430,  loss: 0.2266562134027481\n",
      "Batch 2435,  loss: 0.2150582790374756\n",
      "Batch 2440,  loss: 0.20345716476440429\n",
      "Batch 2445,  loss: 0.21902222335338592\n",
      "Batch 2450,  loss: 0.19221581816673278\n",
      "Batch 2455,  loss: 0.20949546992778778\n",
      "Batch 2460,  loss: 0.20479085743427278\n",
      "Batch 2465,  loss: 0.20021223723888398\n",
      "Batch 2470,  loss: 0.24348099231719972\n",
      "Batch 2475,  loss: 0.16833552122116088\n",
      "Batch 2480,  loss: 0.1970002084970474\n",
      "Batch 2485,  loss: 0.17964617609977723\n",
      "Batch 2490,  loss: 0.21192354261875151\n",
      "Batch 2495,  loss: 0.2422369420528412\n",
      "Batch 2500,  loss: 0.21314361989498137\n",
      "Batch 2505,  loss: 0.2203548014163971\n",
      "Batch 2510,  loss: 0.20575782358646394\n",
      "Batch 2515,  loss: 0.21867252588272096\n",
      "Batch 2520,  loss: 0.20090800225734712\n",
      "Batch 2525,  loss: 0.20807841420173645\n",
      "Batch 2530,  loss: 0.22889810800552368\n",
      "Batch 2535,  loss: 0.16534066796302796\n",
      "Batch 2540,  loss: 0.21353907287120819\n",
      "Batch 2545,  loss: 0.1931613117456436\n",
      "Batch 2550,  loss: 0.19484201073646545\n",
      "Batch 2555,  loss: 0.2155962958931923\n",
      "Batch 2560,  loss: 0.21405474841594696\n",
      "Batch 2565,  loss: 0.1940688520669937\n",
      "Batch 2570,  loss: 0.18324689865112304\n",
      "Batch 2575,  loss: 0.1952410578727722\n",
      "Batch 2580,  loss: 0.20807344913482667\n",
      "Batch 2585,  loss: 0.2023869276046753\n",
      "Batch 2590,  loss: 0.21850024163722992\n",
      "Batch 2595,  loss: 0.21725927591323851\n",
      "Batch 2600,  loss: 0.2033817708492279\n",
      "Batch 2605,  loss: 0.17563868016004563\n",
      "Batch 2610,  loss: 0.19933127462863923\n",
      "Batch 2615,  loss: 0.2128368318080902\n",
      "Batch 2620,  loss: 0.2020609200000763\n",
      "Batch 2625,  loss: 0.17365961968898774\n",
      "Batch 2630,  loss: 0.23233791291713715\n",
      "Batch 2635,  loss: 0.23160158693790436\n",
      "Batch 2640,  loss: 0.19249362051486968\n",
      "Batch 2645,  loss: 0.2114771544933319\n",
      "Batch 2650,  loss: 0.1875795990228653\n",
      "Batch 2655,  loss: 0.2548648864030838\n",
      "Batch 2660,  loss: 0.1921979457139969\n",
      "Batch 2665,  loss: 0.2143332153558731\n",
      "Batch 2670,  loss: 0.18788879066705705\n",
      "Batch 2675,  loss: 0.20976684391498565\n",
      "Batch 2680,  loss: 0.2561012774705887\n",
      "Batch 2685,  loss: 0.218692085146904\n",
      "Batch 2690,  loss: 0.24052008092403412\n",
      "Batch 2695,  loss: 0.18369895815849305\n",
      "Batch 2700,  loss: 0.21870056688785552\n",
      "Batch 2705,  loss: 0.16984048783779143\n",
      "Batch 2710,  loss: 0.18743673861026763\n",
      "Batch 2715,  loss: 0.24693225026130677\n",
      "Batch 2720,  loss: 0.20157844424247742\n",
      "Batch 2725,  loss: 0.16895168721675874\n",
      "Batch 2730,  loss: 0.15996531248092652\n",
      "Batch 2735,  loss: 0.2270416647195816\n",
      "Batch 2740,  loss: 0.19269350469112395\n",
      "Batch 2745,  loss: 0.2283473491668701\n",
      "Batch 2750,  loss: 0.1944034844636917\n",
      "Batch 2755,  loss: 0.20595853328704833\n",
      "Batch 2760,  loss: 0.205537748336792\n",
      "Batch 2765,  loss: 0.2508577346801758\n",
      "Batch 2770,  loss: 0.2248862564563751\n",
      "LOSS train 0.2248862564563751. Validation loss: 0.1861918505630456 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 7:\n",
      "Batch 5,  loss: 0.22805082499980928\n",
      "Batch 10,  loss: 0.25520904660224913\n",
      "Batch 15,  loss: 0.21143871694803237\n",
      "Batch 20,  loss: 0.209139946103096\n",
      "Batch 25,  loss: 0.19991908073425294\n",
      "Batch 30,  loss: 0.23865988850593567\n",
      "Batch 35,  loss: 0.2117792010307312\n",
      "Batch 40,  loss: 0.26255691051483154\n",
      "Batch 45,  loss: 0.15249075889587402\n",
      "Batch 50,  loss: 0.2758858144283295\n",
      "Batch 55,  loss: 0.21854425072669983\n",
      "Batch 60,  loss: 0.2001834124326706\n",
      "Batch 65,  loss: 0.1910071611404419\n",
      "Batch 70,  loss: 0.23005068600177764\n",
      "Batch 75,  loss: 0.19055316150188445\n",
      "Batch 80,  loss: 0.18652780652046203\n",
      "Batch 85,  loss: 0.1970417320728302\n",
      "Batch 90,  loss: 0.23634883761405945\n",
      "Batch 95,  loss: 0.23206902146339417\n",
      "Batch 100,  loss: 0.25133023262023924\n",
      "Batch 105,  loss: 0.18482206761837006\n",
      "Batch 110,  loss: 0.2502111792564392\n",
      "Batch 115,  loss: 0.2307003140449524\n",
      "Batch 120,  loss: 0.20853790938854216\n",
      "Batch 125,  loss: 0.2091403603553772\n",
      "Batch 130,  loss: 0.22598614990711213\n",
      "Batch 135,  loss: 0.29859424829483033\n",
      "Batch 140,  loss: 0.2402327448129654\n",
      "Batch 145,  loss: 0.21842017769813538\n",
      "Batch 150,  loss: 0.22254494130611419\n",
      "Batch 155,  loss: 0.16886626183986664\n",
      "Batch 160,  loss: 0.18377092778682708\n",
      "Batch 165,  loss: 0.21899792551994324\n",
      "Batch 170,  loss: 0.20990718007087708\n",
      "Batch 175,  loss: 0.17831729650497435\n",
      "Batch 180,  loss: 0.24478702545166015\n",
      "Batch 185,  loss: 0.1986211895942688\n",
      "Batch 190,  loss: 0.21435870826244355\n",
      "Batch 195,  loss: 0.212220898270607\n",
      "Batch 200,  loss: 0.2014589637517929\n",
      "Batch 205,  loss: 0.21767941415309905\n",
      "Batch 210,  loss: 0.1846298098564148\n",
      "Batch 215,  loss: 0.2631518363952637\n",
      "Batch 220,  loss: 0.20921705067157745\n",
      "Batch 225,  loss: 0.2139393299818039\n",
      "Batch 230,  loss: 0.29134221374988556\n",
      "Batch 235,  loss: 0.21483369767665864\n",
      "Batch 240,  loss: 0.19580066800117493\n",
      "Batch 245,  loss: 0.23140130341053008\n",
      "Batch 250,  loss: 0.27185961306095124\n",
      "Batch 255,  loss: 0.20713579654693604\n",
      "Batch 260,  loss: 0.2401019662618637\n",
      "Batch 265,  loss: 0.22418988347053528\n",
      "Batch 270,  loss: 0.201430144906044\n",
      "Batch 275,  loss: 0.2203250139951706\n",
      "Batch 280,  loss: 0.20235354006290435\n",
      "Batch 285,  loss: 0.20859815180301666\n",
      "Batch 290,  loss: 0.21250035166740416\n",
      "Batch 295,  loss: 0.2297942191362381\n",
      "Batch 300,  loss: 0.2147032231092453\n",
      "Batch 305,  loss: 0.23341396749019622\n",
      "Batch 310,  loss: 0.1824670761823654\n",
      "Batch 315,  loss: 0.21077151894569396\n",
      "Batch 320,  loss: 0.1859562039375305\n",
      "Batch 325,  loss: 0.258240219950676\n",
      "Batch 330,  loss: 0.21916171312332153\n",
      "Batch 335,  loss: 0.18814678192138673\n",
      "Batch 340,  loss: 0.2218872934579849\n",
      "Batch 345,  loss: 0.2561402082443237\n",
      "Batch 350,  loss: 0.205354505777359\n",
      "Batch 355,  loss: 0.21102652847766876\n",
      "Batch 360,  loss: 0.199130517244339\n",
      "Batch 365,  loss: 0.17786757051944732\n",
      "Batch 370,  loss: 0.18346860408782958\n",
      "Batch 375,  loss: 0.22337283194065094\n",
      "Batch 380,  loss: 0.246046581864357\n",
      "Batch 385,  loss: 0.2156125009059906\n",
      "Batch 390,  loss: 0.18177807033061982\n",
      "Batch 395,  loss: 0.2324754685163498\n",
      "Batch 400,  loss: 0.21467555165290833\n",
      "Batch 405,  loss: 0.22892431318759918\n",
      "Batch 410,  loss: 0.2340648204088211\n",
      "Batch 415,  loss: 0.19674547910690307\n",
      "Batch 420,  loss: 0.27394980788230894\n",
      "Batch 425,  loss: 0.19173178374767302\n",
      "Batch 430,  loss: 0.22670095562934875\n",
      "Batch 435,  loss: 0.18468085825443267\n",
      "Batch 440,  loss: 0.23486381769180298\n",
      "Batch 445,  loss: 0.19802155792713166\n",
      "Batch 450,  loss: 0.22486199736595153\n",
      "Batch 455,  loss: 0.1857268750667572\n",
      "Batch 460,  loss: 0.1918536901473999\n",
      "Batch 465,  loss: 0.19121596813201905\n",
      "Batch 470,  loss: 0.2239902585744858\n",
      "Batch 475,  loss: 0.18719478249549865\n",
      "Batch 480,  loss: 0.23883176743984222\n",
      "Batch 485,  loss: 0.20209819376468657\n",
      "Batch 490,  loss: 0.19921715855598449\n",
      "Batch 495,  loss: 0.17095462381839752\n",
      "Batch 500,  loss: 0.21751471757888793\n",
      "Batch 505,  loss: 0.18290733098983764\n",
      "Batch 510,  loss: 0.1873303085565567\n",
      "Batch 515,  loss: 0.2414516896009445\n",
      "Batch 520,  loss: 0.15844068229198455\n",
      "Batch 525,  loss: 0.1694112092256546\n",
      "Batch 530,  loss: 0.23002182841300964\n",
      "Batch 535,  loss: 0.2093245267868042\n",
      "Batch 540,  loss: 0.22769048810005188\n",
      "Batch 545,  loss: 0.19304477274417878\n",
      "Batch 550,  loss: 0.22731553316116332\n",
      "Batch 555,  loss: 0.20296385884284973\n",
      "Batch 560,  loss: 0.23120722770690919\n",
      "Batch 565,  loss: 0.24364683032035828\n",
      "Batch 570,  loss: 0.20512768030166625\n",
      "Batch 575,  loss: 0.1746811717748642\n",
      "Batch 580,  loss: 0.2099167913198471\n",
      "Batch 585,  loss: 0.21704668402671815\n",
      "Batch 590,  loss: 0.2071305513381958\n",
      "Batch 595,  loss: 0.20950495898723603\n",
      "Batch 600,  loss: 0.24269138276576996\n",
      "Batch 605,  loss: 0.2196516990661621\n",
      "Batch 610,  loss: 0.18584380447864532\n",
      "Batch 615,  loss: 0.20558145344257356\n",
      "Batch 620,  loss: 0.191212460398674\n",
      "Batch 625,  loss: 0.22432591617107392\n",
      "Batch 630,  loss: 0.22413011491298676\n",
      "Batch 635,  loss: 0.18756833672523499\n",
      "Batch 640,  loss: 0.2091340959072113\n",
      "Batch 645,  loss: 0.23447643518447875\n",
      "Batch 650,  loss: 0.19415570497512818\n",
      "Batch 655,  loss: 0.2516744941473007\n",
      "Batch 660,  loss: 0.19218036532402039\n",
      "Batch 665,  loss: 0.2447560667991638\n",
      "Batch 670,  loss: 0.2517784535884857\n",
      "Batch 675,  loss: 0.264956060051918\n",
      "Batch 680,  loss: 0.1947230279445648\n",
      "Batch 685,  loss: 0.23611751496791838\n",
      "Batch 690,  loss: 0.17422063946723937\n",
      "Batch 695,  loss: 0.20342427790164946\n",
      "Batch 700,  loss: 0.194898721575737\n",
      "Batch 705,  loss: 0.1823679983615875\n",
      "Batch 710,  loss: 0.18784514665603638\n",
      "Batch 715,  loss: 0.20210271775722505\n",
      "Batch 720,  loss: 0.22770737409591674\n",
      "Batch 725,  loss: 0.22166795134544373\n",
      "Batch 730,  loss: 0.19400924146175386\n",
      "Batch 735,  loss: 0.20480991899967194\n",
      "Batch 740,  loss: 0.17152504920959472\n",
      "Batch 745,  loss: 0.1912211373448372\n",
      "Batch 750,  loss: 0.1736731559038162\n",
      "Batch 755,  loss: 0.19839450120925903\n",
      "Batch 760,  loss: 0.21709822118282318\n",
      "Batch 765,  loss: 0.20949480533599854\n",
      "Batch 770,  loss: 0.18164028823375702\n",
      "Batch 775,  loss: 0.19927725791931153\n",
      "Batch 780,  loss: 0.22514450252056123\n",
      "Batch 785,  loss: 0.20958233177661895\n",
      "Batch 790,  loss: 0.19449001550674438\n",
      "Batch 795,  loss: 0.22695890069007874\n",
      "Batch 800,  loss: 0.26829599738121035\n",
      "Batch 805,  loss: 0.2602783203125\n",
      "Batch 810,  loss: 0.2589906245470047\n",
      "Batch 815,  loss: 0.2283823773264885\n",
      "Batch 820,  loss: 0.21855801045894624\n",
      "Batch 825,  loss: 0.1990850567817688\n",
      "Batch 830,  loss: 0.20931475162506102\n",
      "Batch 835,  loss: 0.21318960189819336\n",
      "Batch 840,  loss: 0.17013805210590363\n",
      "Batch 845,  loss: 0.2519964724779129\n",
      "Batch 850,  loss: 0.2535396724939346\n",
      "Batch 855,  loss: 0.2492184042930603\n",
      "Batch 860,  loss: 0.22167860567569733\n",
      "Batch 865,  loss: 0.25014686286449433\n",
      "Batch 870,  loss: 0.20075240433216096\n",
      "Batch 875,  loss: 0.20851289331912995\n",
      "Batch 880,  loss: 0.19638388752937316\n",
      "Batch 885,  loss: 0.22225614488124848\n",
      "Batch 890,  loss: 0.17931166887283326\n",
      "Batch 895,  loss: 0.18430517613887787\n",
      "Batch 900,  loss: 0.2058014988899231\n",
      "Batch 905,  loss: 0.2462136149406433\n",
      "Batch 910,  loss: 0.2327354907989502\n",
      "Batch 915,  loss: 0.19429707229137422\n",
      "Batch 920,  loss: 0.2028707206249237\n",
      "Batch 925,  loss: 0.2004391461610794\n",
      "Batch 930,  loss: 0.17496271282434464\n",
      "Batch 935,  loss: 0.19807341694831848\n",
      "Batch 940,  loss: 0.24891254901885987\n",
      "Batch 945,  loss: 0.23061224222183227\n",
      "Batch 950,  loss: 0.2298431694507599\n",
      "Batch 955,  loss: 0.2102378338575363\n",
      "Batch 960,  loss: 0.1821223944425583\n",
      "Batch 965,  loss: 0.2135399043560028\n",
      "Batch 970,  loss: 0.212390473484993\n",
      "Batch 975,  loss: 0.21588005423545836\n",
      "Batch 980,  loss: 0.19092437922954558\n",
      "Batch 985,  loss: 0.21594065129756929\n",
      "Batch 990,  loss: 0.2005053222179413\n",
      "Batch 995,  loss: 0.1839389607310295\n",
      "Batch 1000,  loss: 0.18441785871982574\n",
      "Batch 1005,  loss: 0.17487410306930543\n",
      "Batch 1010,  loss: 0.2095062702894211\n",
      "Batch 1015,  loss: 0.2148774743080139\n",
      "Batch 1020,  loss: 0.23656110763549804\n",
      "Batch 1025,  loss: 0.2331976115703583\n",
      "Batch 1030,  loss: 0.2171610713005066\n",
      "Batch 1035,  loss: 0.2813032180070877\n",
      "Batch 1040,  loss: 0.18660354912281035\n",
      "Batch 1045,  loss: 0.191500461101532\n",
      "Batch 1050,  loss: 0.20948190689086915\n",
      "Batch 1055,  loss: 0.22072287499904633\n",
      "Batch 1060,  loss: 0.228801167011261\n",
      "Batch 1065,  loss: 0.18239787518978118\n",
      "Batch 1070,  loss: 0.21448648869991302\n",
      "Batch 1075,  loss: 0.16445533633232118\n",
      "Batch 1080,  loss: 0.3003833591938019\n",
      "Batch 1085,  loss: 0.22079553008079528\n",
      "Batch 1090,  loss: 0.22556819319725036\n",
      "Batch 1095,  loss: 0.25248497128486636\n",
      "Batch 1100,  loss: 0.17481663525104524\n",
      "Batch 1105,  loss: 0.1722061365842819\n",
      "Batch 1110,  loss: 0.20955621004104613\n",
      "Batch 1115,  loss: 0.19323778450489043\n",
      "Batch 1120,  loss: 0.20244707465171813\n",
      "Batch 1125,  loss: 0.23183868825435638\n",
      "Batch 1130,  loss: 0.20163647830486298\n",
      "Batch 1135,  loss: 0.24221466481685638\n",
      "Batch 1140,  loss: 0.20649925470352173\n",
      "Batch 1145,  loss: 0.24789065718650818\n",
      "Batch 1150,  loss: 0.18562114834785462\n",
      "Batch 1155,  loss: 0.1664839893579483\n",
      "Batch 1160,  loss: 0.19403152614831926\n",
      "Batch 1165,  loss: 0.24445639103651046\n",
      "Batch 1170,  loss: 0.18249844312667846\n",
      "Batch 1175,  loss: 0.1997953325510025\n",
      "Batch 1180,  loss: 0.19889581799507142\n",
      "Batch 1185,  loss: 0.24180608689785005\n",
      "Batch 1190,  loss: 0.23063509166240692\n",
      "Batch 1195,  loss: 0.17728736996650696\n",
      "Batch 1200,  loss: 0.23120857477188111\n",
      "Batch 1205,  loss: 0.14803563952445983\n",
      "Batch 1210,  loss: 0.23131150007247925\n",
      "Batch 1215,  loss: 0.20161201655864716\n",
      "Batch 1220,  loss: 0.26813057363033294\n",
      "Batch 1225,  loss: 0.20196940898895263\n",
      "Batch 1230,  loss: 0.26995829641819\n",
      "Batch 1235,  loss: 0.14424762427806853\n",
      "Batch 1240,  loss: 0.18674468398094177\n",
      "Batch 1245,  loss: 0.19430062174797058\n",
      "Batch 1250,  loss: 0.1870017796754837\n",
      "Batch 1255,  loss: 0.1675480455160141\n",
      "Batch 1260,  loss: 0.21393825113773346\n",
      "Batch 1265,  loss: 0.2349934160709381\n",
      "Batch 1270,  loss: 0.178597891330719\n",
      "Batch 1275,  loss: 0.24092278778553008\n",
      "Batch 1280,  loss: 0.20390817224979402\n",
      "Batch 1285,  loss: 0.19131258130073547\n",
      "Batch 1290,  loss: 0.20916917324066162\n",
      "Batch 1295,  loss: 0.2045045554637909\n",
      "Batch 1300,  loss: 0.24635614156723024\n",
      "Batch 1305,  loss: 0.17500246465206146\n",
      "Batch 1310,  loss: 0.23456423878669738\n",
      "Batch 1315,  loss: 0.20474176108837128\n",
      "Batch 1320,  loss: 0.2023122251033783\n",
      "Batch 1325,  loss: 0.15761769264936448\n",
      "Batch 1330,  loss: 0.24532871544361115\n",
      "Batch 1335,  loss: 0.22191190123558044\n",
      "Batch 1340,  loss: 0.22648097276687623\n",
      "Batch 1345,  loss: 0.2008938193321228\n",
      "Batch 1350,  loss: 0.23538486659526825\n",
      "Batch 1355,  loss: 0.2028809368610382\n",
      "Batch 1360,  loss: 0.1669587254524231\n",
      "Batch 1365,  loss: 0.19645736813545228\n",
      "Batch 1370,  loss: 0.16336147785186766\n",
      "Batch 1375,  loss: 0.20814988017082214\n",
      "Batch 1380,  loss: 0.2020754784345627\n",
      "Batch 1385,  loss: 0.1741986319422722\n",
      "Batch 1390,  loss: 0.17568379789590835\n",
      "Batch 1395,  loss: 0.17188465893268584\n",
      "Batch 1400,  loss: 0.18065859675407409\n",
      "Batch 1405,  loss: 0.20631508827209472\n",
      "Batch 1410,  loss: 0.24534709453582765\n",
      "Batch 1415,  loss: 0.22864685952663422\n",
      "Batch 1420,  loss: 0.22379982769489287\n",
      "Batch 1425,  loss: 0.20753089487552642\n",
      "Batch 1430,  loss: 0.25319155752658845\n",
      "Batch 1435,  loss: 0.21128880679607392\n",
      "Batch 1440,  loss: 0.19982945024967194\n",
      "Batch 1445,  loss: 0.2650494515895844\n",
      "Batch 1450,  loss: 0.19484258592128753\n",
      "Batch 1455,  loss: 0.20356080830097198\n",
      "Batch 1460,  loss: 0.2090672105550766\n",
      "Batch 1465,  loss: 0.15051357746124266\n",
      "Batch 1470,  loss: 0.21382668018341064\n",
      "Batch 1475,  loss: 0.13770715594291688\n",
      "Batch 1480,  loss: 0.19649178981781007\n",
      "Batch 1485,  loss: 0.19570786952972413\n",
      "Batch 1490,  loss: 0.25464882552623747\n",
      "Batch 1495,  loss: 0.2115156129002571\n",
      "Batch 1500,  loss: 0.20161196291446687\n",
      "Batch 1505,  loss: 0.23186164498329162\n",
      "Batch 1510,  loss: 0.18294620513916016\n",
      "Batch 1515,  loss: 0.2170136660337448\n",
      "Batch 1520,  loss: 0.2215391904115677\n",
      "Batch 1525,  loss: 0.2112936109304428\n",
      "Batch 1530,  loss: 0.20680216550827027\n",
      "Batch 1535,  loss: 0.17581709027290343\n",
      "Batch 1540,  loss: 0.192003470659256\n",
      "Batch 1545,  loss: 0.2304893970489502\n",
      "Batch 1550,  loss: 0.1897409290075302\n",
      "Batch 1555,  loss: 0.1660079464316368\n",
      "Batch 1560,  loss: 0.1945309191942215\n",
      "Batch 1565,  loss: 0.2240103468298912\n",
      "Batch 1570,  loss: 0.24927073419094087\n",
      "Batch 1575,  loss: 0.26873232126235963\n",
      "Batch 1580,  loss: 0.22271319031715392\n",
      "Batch 1585,  loss: 0.1989331215620041\n",
      "Batch 1590,  loss: 0.17191850543022155\n",
      "Batch 1595,  loss: 0.221893709897995\n",
      "Batch 1600,  loss: 0.2312738209962845\n",
      "Batch 1605,  loss: 0.15428077280521393\n",
      "Batch 1610,  loss: 0.23333262801170349\n",
      "Batch 1615,  loss: 0.20417381525039674\n",
      "Batch 1620,  loss: 0.20765704810619354\n",
      "Batch 1625,  loss: 0.20958492457866668\n",
      "Batch 1630,  loss: 0.22392297089099883\n",
      "Batch 1635,  loss: 0.17785778045654296\n",
      "Batch 1640,  loss: 0.1857483834028244\n",
      "Batch 1645,  loss: 0.19153665602207184\n",
      "Batch 1650,  loss: 0.23563192486763002\n",
      "Batch 1655,  loss: 0.22302646338939666\n",
      "Batch 1660,  loss: 0.1786666989326477\n",
      "Batch 1665,  loss: 0.22288646101951598\n",
      "Batch 1670,  loss: 0.2030986249446869\n",
      "Batch 1675,  loss: 0.1871836245059967\n",
      "Batch 1680,  loss: 0.1925000488758087\n",
      "Batch 1685,  loss: 0.25674971640110017\n",
      "Batch 1690,  loss: 0.18205676972866058\n",
      "Batch 1695,  loss: 0.210928213596344\n",
      "Batch 1700,  loss: 0.2158968687057495\n",
      "Batch 1705,  loss: 0.21942929923534393\n",
      "Batch 1710,  loss: 0.20765303671360016\n",
      "Batch 1715,  loss: 0.20419184863567352\n",
      "Batch 1720,  loss: 0.20486151576042175\n",
      "Batch 1725,  loss: 0.21279129087924958\n",
      "Batch 1730,  loss: 0.20549514293670654\n",
      "Batch 1735,  loss: 0.16830828487873079\n",
      "Batch 1740,  loss: 0.2060779243707657\n",
      "Batch 1745,  loss: 0.2188701868057251\n",
      "Batch 1750,  loss: 0.20908892750740052\n",
      "Batch 1755,  loss: 0.21401353776454926\n",
      "Batch 1760,  loss: 0.25714256167411803\n",
      "Batch 1765,  loss: 0.20958172380924225\n",
      "Batch 1770,  loss: 0.29948111474514005\n",
      "Batch 1775,  loss: 0.19467993080615997\n",
      "Batch 1780,  loss: 0.22643629908561708\n",
      "Batch 1785,  loss: 0.19971632361412048\n",
      "Batch 1790,  loss: 0.18033130764961242\n",
      "Batch 1795,  loss: 0.1724493533372879\n",
      "Batch 1800,  loss: 0.25682546496391295\n",
      "Batch 1805,  loss: 0.2354190468788147\n",
      "Batch 1810,  loss: 0.23147553503513335\n",
      "Batch 1815,  loss: 0.1883618250489235\n",
      "Batch 1820,  loss: 0.17659692466259003\n",
      "Batch 1825,  loss: 0.21214728355407714\n",
      "Batch 1830,  loss: 0.17786121964454651\n",
      "Batch 1835,  loss: 0.2045154392719269\n",
      "Batch 1840,  loss: 0.2570572137832642\n",
      "Batch 1845,  loss: 0.26742467284202576\n",
      "Batch 1850,  loss: 0.2270891934633255\n",
      "Batch 1855,  loss: 0.17580500841140748\n",
      "Batch 1860,  loss: 0.20849795043468475\n",
      "Batch 1865,  loss: 0.1937225043773651\n",
      "Batch 1870,  loss: 0.2300410509109497\n",
      "Batch 1875,  loss: 0.217623370885849\n",
      "Batch 1880,  loss: 0.17823874950408936\n",
      "Batch 1885,  loss: 0.1846156597137451\n",
      "Batch 1890,  loss: 0.15371735543012618\n",
      "Batch 1895,  loss: 0.25299822688102724\n",
      "Batch 1900,  loss: 0.18947712779045106\n",
      "Batch 1905,  loss: 0.20534138083457948\n",
      "Batch 1910,  loss: 0.25248111188411715\n",
      "Batch 1915,  loss: 0.2425609141588211\n",
      "Batch 1920,  loss: 0.20438225865364074\n",
      "Batch 1925,  loss: 0.18602266013622284\n",
      "Batch 1930,  loss: 0.2049950510263443\n",
      "Batch 1935,  loss: 0.24249283075332642\n",
      "Batch 1940,  loss: 0.2435521125793457\n",
      "Batch 1945,  loss: 0.20294047594070436\n",
      "Batch 1950,  loss: 0.191928830742836\n",
      "Batch 1955,  loss: 0.2584676265716553\n",
      "Batch 1960,  loss: 0.23708139061927797\n",
      "Batch 1965,  loss: 0.18543970584869385\n",
      "Batch 1970,  loss: 0.21598839163780212\n",
      "Batch 1975,  loss: 0.17373035848140717\n",
      "Batch 1980,  loss: 0.2022080600261688\n",
      "Batch 1985,  loss: 0.1640641987323761\n",
      "Batch 1990,  loss: 0.2453461080789566\n",
      "Batch 1995,  loss: 0.18435800969600677\n",
      "Batch 2000,  loss: 0.1743042528629303\n",
      "Batch 2005,  loss: 0.20642645359039308\n",
      "Batch 2010,  loss: 0.24705284535884858\n",
      "Batch 2015,  loss: 0.2291974812746048\n",
      "Batch 2020,  loss: 0.22649400532245637\n",
      "Batch 2025,  loss: 0.18316840827465058\n",
      "Batch 2030,  loss: 0.22464796602725984\n",
      "Batch 2035,  loss: 0.2006443440914154\n",
      "Batch 2040,  loss: 0.21166052520275117\n",
      "Batch 2045,  loss: 0.20423180013895034\n",
      "Batch 2050,  loss: 0.19373598098754882\n",
      "Batch 2055,  loss: 0.18498707413673401\n",
      "Batch 2060,  loss: 0.22907682061195372\n",
      "Batch 2065,  loss: 0.19412029385566712\n",
      "Batch 2070,  loss: 0.19632981419563295\n",
      "Batch 2075,  loss: 0.19410947859287261\n",
      "Batch 2080,  loss: 0.23574258983135224\n",
      "Batch 2085,  loss: 0.19643256664276124\n",
      "Batch 2090,  loss: 0.20163590908050538\n",
      "Batch 2095,  loss: 0.15740822851657868\n",
      "Batch 2100,  loss: 0.20810055434703828\n",
      "Batch 2105,  loss: 0.17783533930778503\n",
      "Batch 2110,  loss: 0.2266598492860794\n",
      "Batch 2115,  loss: 0.20983292460441588\n",
      "Batch 2120,  loss: 0.2658235728740692\n",
      "Batch 2125,  loss: 0.2658871620893478\n",
      "Batch 2130,  loss: 0.19489988386631013\n",
      "Batch 2135,  loss: 0.19058572351932526\n",
      "Batch 2140,  loss: 0.1843430519104004\n",
      "Batch 2145,  loss: 0.24694419503211976\n",
      "Batch 2150,  loss: 0.1638844281435013\n",
      "Batch 2155,  loss: 0.24283041954040527\n",
      "Batch 2160,  loss: 0.24429554641246795\n",
      "Batch 2165,  loss: 0.16896274089813232\n",
      "Batch 2170,  loss: 0.17525232434272767\n",
      "Batch 2175,  loss: 0.21000965535640717\n",
      "Batch 2180,  loss: 0.21768386363983155\n",
      "Batch 2185,  loss: 0.23197477757930757\n",
      "Batch 2190,  loss: 0.2244444251060486\n",
      "Batch 2195,  loss: 0.19040498733520508\n",
      "Batch 2200,  loss: 0.21039273142814635\n",
      "Batch 2205,  loss: 0.18967078924179076\n",
      "Batch 2210,  loss: 0.1682459145784378\n",
      "Batch 2215,  loss: 0.19187389612197875\n",
      "Batch 2220,  loss: 0.18173441290855408\n",
      "Batch 2225,  loss: 0.1603130966424942\n",
      "Batch 2230,  loss: 0.1976121485233307\n",
      "Batch 2235,  loss: 0.19095318466424943\n",
      "Batch 2240,  loss: 0.28506168723106384\n",
      "Batch 2245,  loss: 0.16900655031204223\n",
      "Batch 2250,  loss: 0.21290241777896882\n",
      "Batch 2255,  loss: 0.2073180392384529\n",
      "Batch 2260,  loss: 0.21570638418197632\n",
      "Batch 2265,  loss: 0.26446616649627686\n",
      "Batch 2270,  loss: 0.1936790019273758\n",
      "Batch 2275,  loss: 0.2274693012237549\n",
      "Batch 2280,  loss: 0.24578770995140076\n",
      "Batch 2285,  loss: 0.21448135673999785\n",
      "Batch 2290,  loss: 0.21421741545200348\n",
      "Batch 2295,  loss: 0.21487022936344147\n",
      "Batch 2300,  loss: 0.21978432834148406\n",
      "Batch 2305,  loss: 0.23506010472774505\n",
      "Batch 2310,  loss: 0.2322472393512726\n",
      "Batch 2315,  loss: 0.25754840672016144\n",
      "Batch 2320,  loss: 0.22567915320396423\n",
      "Batch 2325,  loss: 0.19605669677257537\n",
      "Batch 2330,  loss: 0.21224910914897918\n",
      "Batch 2335,  loss: 0.22877851724624634\n",
      "Batch 2340,  loss: 0.17893717885017396\n",
      "Batch 2345,  loss: 0.22276101708412172\n",
      "Batch 2350,  loss: 0.2681061625480652\n",
      "Batch 2355,  loss: 0.16019557118415834\n",
      "Batch 2360,  loss: 0.18999764323234558\n",
      "Batch 2365,  loss: 0.22080501914024353\n",
      "Batch 2370,  loss: 0.18153620809316634\n",
      "Batch 2375,  loss: 0.18508569598197938\n",
      "Batch 2380,  loss: 0.19767823219299316\n",
      "Batch 2385,  loss: 0.20777018666267394\n",
      "Batch 2390,  loss: 0.197928586602211\n",
      "Batch 2395,  loss: 0.21075575351715087\n",
      "Batch 2400,  loss: 0.19239842891693115\n",
      "Batch 2405,  loss: 0.1842494010925293\n",
      "Batch 2410,  loss: 0.2251957267522812\n",
      "Batch 2415,  loss: 0.19486218988895415\n",
      "Batch 2420,  loss: 0.1833174467086792\n",
      "Batch 2425,  loss: 0.21992215514183044\n",
      "Batch 2430,  loss: 0.22345212996006011\n",
      "Batch 2435,  loss: 0.2308174192905426\n",
      "Batch 2440,  loss: 0.22060780525207518\n",
      "Batch 2445,  loss: 0.19386115074157714\n",
      "Batch 2450,  loss: 0.20848097205162047\n",
      "Batch 2455,  loss: 0.23802469968795775\n",
      "Batch 2460,  loss: 0.18360291719436644\n",
      "Batch 2465,  loss: 0.20947307348251343\n",
      "Batch 2470,  loss: 0.23386994004249573\n",
      "Batch 2475,  loss: 0.21082026958465577\n",
      "Batch 2480,  loss: 0.22102383375167847\n",
      "Batch 2485,  loss: 0.19137551188468932\n",
      "Batch 2490,  loss: 0.17985854744911195\n",
      "Batch 2495,  loss: 0.20560197085142135\n",
      "Batch 2500,  loss: 0.18429747223854065\n",
      "Batch 2505,  loss: 0.2587322354316711\n",
      "Batch 2510,  loss: 0.1838238224387169\n",
      "Batch 2515,  loss: 0.17235776484012605\n",
      "Batch 2520,  loss: 0.18596549332141876\n",
      "Batch 2525,  loss: 0.21708453595638275\n",
      "Batch 2530,  loss: 0.21990799009799958\n",
      "Batch 2535,  loss: 0.19770394563674926\n",
      "Batch 2540,  loss: 0.1926514595746994\n",
      "Batch 2545,  loss: 0.2206244558095932\n",
      "Batch 2550,  loss: 0.19232977628707887\n",
      "Batch 2555,  loss: 0.234988471865654\n",
      "Batch 2560,  loss: 0.16996409595012665\n",
      "Batch 2565,  loss: 0.1978804349899292\n",
      "Batch 2570,  loss: 0.2275972157716751\n",
      "Batch 2575,  loss: 0.20964058637619018\n",
      "Batch 2580,  loss: 0.25319802165031435\n",
      "Batch 2585,  loss: 0.17500786185264589\n",
      "Batch 2590,  loss: 0.2010842651128769\n",
      "Batch 2595,  loss: 0.21613650918006896\n",
      "Batch 2600,  loss: 0.17298220992088317\n",
      "Batch 2605,  loss: 0.19103346467018129\n",
      "Batch 2610,  loss: 0.23883649110794067\n",
      "Batch 2615,  loss: 0.19287245273590087\n",
      "Batch 2620,  loss: 0.19496126770973204\n",
      "Batch 2625,  loss: 0.20616173148155212\n",
      "Batch 2630,  loss: 0.16445396840572357\n",
      "Batch 2635,  loss: 0.16335773468017578\n",
      "Batch 2640,  loss: 0.18062996864318848\n",
      "Batch 2645,  loss: 0.2094952493906021\n",
      "Batch 2650,  loss: 0.1687164396047592\n",
      "Batch 2655,  loss: 0.20415552258491515\n",
      "Batch 2660,  loss: 0.21740858554840087\n",
      "Batch 2665,  loss: 0.21076744496822358\n",
      "Batch 2670,  loss: 0.22321859300136565\n",
      "Batch 2675,  loss: 0.2425384998321533\n",
      "Batch 2680,  loss: 0.21027058660984038\n",
      "Batch 2685,  loss: 0.17451632022857666\n",
      "Batch 2690,  loss: 0.22070124447345735\n",
      "Batch 2695,  loss: 0.20564515888690948\n",
      "Batch 2700,  loss: 0.21857820451259613\n",
      "Batch 2705,  loss: 0.20780783891677856\n",
      "Batch 2710,  loss: 0.18474670946598054\n",
      "Batch 2715,  loss: 0.21446160674095155\n",
      "Batch 2720,  loss: 0.15714370161294938\n",
      "Batch 2725,  loss: 0.16615365147590638\n",
      "Batch 2730,  loss: 0.19879697412252426\n",
      "Batch 2735,  loss: 0.19465352594852448\n",
      "Batch 2740,  loss: 0.20839169323444368\n",
      "Batch 2745,  loss: 0.22315372824668883\n",
      "Batch 2750,  loss: 0.1855977416038513\n",
      "Batch 2755,  loss: 0.27552708983421326\n",
      "Batch 2760,  loss: 0.2311641663312912\n",
      "Batch 2765,  loss: 0.23759036064147948\n",
      "Batch 2770,  loss: 0.17791340351104737\n",
      "LOSS train 0.17791340351104737. Validation loss: 0.17943706819701388 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 8:\n",
      "Batch 5,  loss: 0.22528993785381318\n",
      "Batch 10,  loss: 0.16595406830310822\n",
      "Batch 15,  loss: 0.21010698974132538\n",
      "Batch 20,  loss: 0.22974806129932404\n",
      "Batch 25,  loss: 0.1854589104652405\n",
      "Batch 30,  loss: 0.182430961728096\n",
      "Batch 35,  loss: 0.19466368854045868\n",
      "Batch 40,  loss: 0.17858914136886597\n",
      "Batch 45,  loss: 0.2047583967447281\n",
      "Batch 50,  loss: 0.21279273927211761\n",
      "Batch 55,  loss: 0.14892847687005997\n",
      "Batch 60,  loss: 0.20804127156734467\n",
      "Batch 65,  loss: 0.21866817772388458\n",
      "Batch 70,  loss: 0.22530981302261352\n",
      "Batch 75,  loss: 0.2276402920484543\n",
      "Batch 80,  loss: 0.20103389620780945\n",
      "Batch 85,  loss: 0.14547956883907318\n",
      "Batch 90,  loss: 0.23006735742092133\n",
      "Batch 95,  loss: 0.24163070619106292\n",
      "Batch 100,  loss: 0.21348319053649903\n",
      "Batch 105,  loss: 0.21307397186756133\n",
      "Batch 110,  loss: 0.21129783391952514\n",
      "Batch 115,  loss: 0.23203688859939575\n",
      "Batch 120,  loss: 0.17979066967964172\n",
      "Batch 125,  loss: 0.1643529236316681\n",
      "Batch 130,  loss: 0.22126090824604033\n",
      "Batch 135,  loss: 0.18267942368984222\n",
      "Batch 140,  loss: 0.2068117469549179\n",
      "Batch 145,  loss: 0.1755300059914589\n",
      "Batch 150,  loss: 0.16845175623893738\n",
      "Batch 155,  loss: 0.23143462538719178\n",
      "Batch 160,  loss: 0.20351737439632417\n",
      "Batch 165,  loss: 0.21613686680793762\n",
      "Batch 170,  loss: 0.22801999300718306\n",
      "Batch 175,  loss: 0.19407200813293457\n",
      "Batch 180,  loss: 0.16938240826129913\n",
      "Batch 185,  loss: 0.29464682936668396\n",
      "Batch 190,  loss: 0.21091672480106355\n",
      "Batch 195,  loss: 0.18430671095848083\n",
      "Batch 200,  loss: 0.23437295556068422\n",
      "Batch 205,  loss: 0.25718275308609007\n",
      "Batch 210,  loss: 0.24358881115913392\n",
      "Batch 215,  loss: 0.17760041058063508\n",
      "Batch 220,  loss: 0.17699106633663178\n",
      "Batch 225,  loss: 0.20561587512493135\n",
      "Batch 230,  loss: 0.17297061979770662\n",
      "Batch 235,  loss: 0.23235728591680527\n",
      "Batch 240,  loss: 0.2256155252456665\n",
      "Batch 245,  loss: 0.2255494624376297\n",
      "Batch 250,  loss: 0.23208822011947633\n",
      "Batch 255,  loss: 0.2061101973056793\n",
      "Batch 260,  loss: 0.20015234053134917\n",
      "Batch 265,  loss: 0.2157171994447708\n",
      "Batch 270,  loss: 0.21790942251682283\n",
      "Batch 275,  loss: 0.23763637542724608\n",
      "Batch 280,  loss: 0.1831197828054428\n",
      "Batch 285,  loss: 0.18322597742080687\n",
      "Batch 290,  loss: 0.21070510745048524\n",
      "Batch 295,  loss: 0.16977730840444566\n",
      "Batch 300,  loss: 0.18787960857152938\n",
      "Batch 305,  loss: 0.19747239351272583\n",
      "Batch 310,  loss: 0.18116401135921478\n",
      "Batch 315,  loss: 0.19163089692592622\n",
      "Batch 320,  loss: 0.19069025069475173\n",
      "Batch 325,  loss: 0.20049845576286315\n",
      "Batch 330,  loss: 0.22563052475452422\n",
      "Batch 335,  loss: 0.18275978565216064\n",
      "Batch 340,  loss: 0.22613601684570311\n",
      "Batch 345,  loss: 0.22089507579803466\n",
      "Batch 350,  loss: 0.20845355987548828\n",
      "Batch 355,  loss: 0.19073187708854675\n",
      "Batch 360,  loss: 0.21119357347488404\n",
      "Batch 365,  loss: 0.20558879673480987\n",
      "Batch 370,  loss: 0.21062001585960388\n",
      "Batch 375,  loss: 0.18563591837882995\n",
      "Batch 380,  loss: 0.17473803460597992\n",
      "Batch 385,  loss: 0.20834222435951233\n",
      "Batch 390,  loss: 0.17047781348228455\n",
      "Batch 395,  loss: 0.18840135931968688\n",
      "Batch 400,  loss: 0.19060028791427613\n",
      "Batch 405,  loss: 0.2136004835367203\n",
      "Batch 410,  loss: 0.18521395921707154\n",
      "Batch 415,  loss: 0.21484784483909608\n",
      "Batch 420,  loss: 0.2166926920413971\n",
      "Batch 425,  loss: 0.19726817309856415\n",
      "Batch 430,  loss: 0.19480032324790955\n",
      "Batch 435,  loss: 0.18454734981060028\n",
      "Batch 440,  loss: 0.213476499915123\n",
      "Batch 445,  loss: 0.2292377158999443\n",
      "Batch 450,  loss: 0.2291894108057022\n",
      "Batch 455,  loss: 0.19104019403457642\n",
      "Batch 460,  loss: 0.20243784338235854\n",
      "Batch 465,  loss: 0.23643856793642043\n",
      "Batch 470,  loss: 0.1627544045448303\n",
      "Batch 475,  loss: 0.21936068832874298\n",
      "Batch 480,  loss: 0.20280082821846007\n",
      "Batch 485,  loss: 0.22719656825065612\n",
      "Batch 490,  loss: 0.17244030237197877\n",
      "Batch 495,  loss: 0.21854326128959656\n",
      "Batch 500,  loss: 0.216329687833786\n",
      "Batch 505,  loss: 0.24579769372940063\n",
      "Batch 510,  loss: 0.18655819892883302\n",
      "Batch 515,  loss: 0.18726103752851486\n",
      "Batch 520,  loss: 0.2100460171699524\n",
      "Batch 525,  loss: 0.17927231788635253\n",
      "Batch 530,  loss: 0.21686884462833406\n",
      "Batch 535,  loss: 0.23442647457122803\n",
      "Batch 540,  loss: 0.1916497141122818\n",
      "Batch 545,  loss: 0.23216474056243896\n",
      "Batch 550,  loss: 0.20689059793949127\n",
      "Batch 555,  loss: 0.20419024527072907\n",
      "Batch 560,  loss: 0.23250231444835662\n",
      "Batch 565,  loss: 0.16631928384304046\n",
      "Batch 570,  loss: 0.22833515405654908\n",
      "Batch 575,  loss: 0.23511405289173126\n",
      "Batch 580,  loss: 0.19264529943466185\n",
      "Batch 585,  loss: 0.23896785378456115\n",
      "Batch 590,  loss: 0.24998847544193267\n",
      "Batch 595,  loss: 0.1811584159731865\n",
      "Batch 600,  loss: 0.20635990500450135\n",
      "Batch 605,  loss: 0.19859404861927032\n",
      "Batch 610,  loss: 0.2690237194299698\n",
      "Batch 615,  loss: 0.17948452532291412\n",
      "Batch 620,  loss: 0.169370436668396\n",
      "Batch 625,  loss: 0.22159722447395325\n",
      "Batch 630,  loss: 0.19731462001800537\n",
      "Batch 635,  loss: 0.2482575923204422\n",
      "Batch 640,  loss: 0.1570701628923416\n",
      "Batch 645,  loss: 0.19118714928627015\n",
      "Batch 650,  loss: 0.2336476683616638\n",
      "Batch 655,  loss: 0.19486833214759827\n",
      "Batch 660,  loss: 0.2478533059358597\n",
      "Batch 665,  loss: 0.22862857580184937\n",
      "Batch 670,  loss: 0.25401474833488463\n",
      "Batch 675,  loss: 0.1912298709154129\n",
      "Batch 680,  loss: 0.2302803248167038\n",
      "Batch 685,  loss: 0.19107723832130433\n",
      "Batch 690,  loss: 0.20590335130691528\n",
      "Batch 695,  loss: 0.19241747558116912\n",
      "Batch 700,  loss: 0.225249046087265\n",
      "Batch 705,  loss: 0.17897656708955764\n",
      "Batch 710,  loss: 0.15781144201755523\n",
      "Batch 715,  loss: 0.19845184683799744\n",
      "Batch 720,  loss: 0.15460988879203796\n",
      "Batch 725,  loss: 0.19154511392116547\n",
      "Batch 730,  loss: 0.2347551167011261\n",
      "Batch 735,  loss: 0.22753622829914094\n",
      "Batch 740,  loss: 0.2120136260986328\n",
      "Batch 745,  loss: 0.2119351029396057\n",
      "Batch 750,  loss: 0.19174728393554688\n",
      "Batch 755,  loss: 0.20105680525302888\n",
      "Batch 760,  loss: 0.16989564001560212\n",
      "Batch 765,  loss: 0.209792885184288\n",
      "Batch 770,  loss: 0.24148474335670472\n",
      "Batch 775,  loss: 0.17067563980817796\n",
      "Batch 780,  loss: 0.2398076057434082\n",
      "Batch 785,  loss: 0.2533033311367035\n",
      "Batch 790,  loss: 0.23809781968593596\n",
      "Batch 795,  loss: 0.20287444293498993\n",
      "Batch 800,  loss: 0.23131294548511505\n",
      "Batch 805,  loss: 0.2466452717781067\n",
      "Batch 810,  loss: 0.22360402196645737\n",
      "Batch 815,  loss: 0.17829157263040543\n",
      "Batch 820,  loss: 0.2250494658946991\n",
      "Batch 825,  loss: 0.2101548582315445\n",
      "Batch 830,  loss: 0.20473683774471282\n",
      "Batch 835,  loss: 0.20923224091529846\n",
      "Batch 840,  loss: 0.17716019302606584\n",
      "Batch 845,  loss: 0.19540919214487076\n",
      "Batch 850,  loss: 0.23069909512996672\n",
      "Batch 855,  loss: 0.18833684921264648\n",
      "Batch 860,  loss: 0.21299971342086793\n",
      "Batch 865,  loss: 0.19508402049541473\n",
      "Batch 870,  loss: 0.16665919721126557\n",
      "Batch 875,  loss: 0.16353173553943634\n",
      "Batch 880,  loss: 0.19742468297481536\n",
      "Batch 885,  loss: 0.19436334073543549\n",
      "Batch 890,  loss: 0.2374948799610138\n",
      "Batch 895,  loss: 0.22540820240974427\n",
      "Batch 900,  loss: 0.1825078934431076\n",
      "Batch 905,  loss: 0.24409806728363037\n",
      "Batch 910,  loss: 0.22702413499355317\n",
      "Batch 915,  loss: 0.2152249038219452\n",
      "Batch 920,  loss: 0.18529116213321686\n",
      "Batch 925,  loss: 0.19350455105304717\n",
      "Batch 930,  loss: 0.2684429049491882\n",
      "Batch 935,  loss: 0.20255148708820342\n",
      "Batch 940,  loss: 0.22691487073898314\n",
      "Batch 945,  loss: 0.20354557633399964\n",
      "Batch 950,  loss: 0.17282287180423736\n",
      "Batch 955,  loss: 0.20997575521469117\n",
      "Batch 960,  loss: 0.2126585602760315\n",
      "Batch 965,  loss: 0.272014519572258\n",
      "Batch 970,  loss: 0.1974829465150833\n",
      "Batch 975,  loss: 0.17399280071258544\n",
      "Batch 980,  loss: 0.21550227403640748\n",
      "Batch 985,  loss: 0.20450144708156587\n",
      "Batch 990,  loss: 0.21714470982551576\n",
      "Batch 995,  loss: 0.2136508047580719\n",
      "Batch 1000,  loss: 0.25635515451431273\n",
      "Batch 1005,  loss: 0.135459566116333\n",
      "Batch 1010,  loss: 0.15191552489995958\n",
      "Batch 1015,  loss: 0.21189913749694825\n",
      "Batch 1020,  loss: 0.27522844076156616\n",
      "Batch 1025,  loss: 0.22614270746707915\n",
      "Batch 1030,  loss: 0.16854665279388428\n",
      "Batch 1035,  loss: 0.23293431103229523\n",
      "Batch 1040,  loss: 0.2039960354566574\n",
      "Batch 1045,  loss: 0.23694683015346527\n",
      "Batch 1050,  loss: 0.23128922283649445\n",
      "Batch 1055,  loss: 0.19986718595027925\n",
      "Batch 1060,  loss: 0.1944142371416092\n",
      "Batch 1065,  loss: 0.19826061129570008\n",
      "Batch 1070,  loss: 0.18417286574840547\n",
      "Batch 1075,  loss: 0.21668745577335358\n",
      "Batch 1080,  loss: 0.21633946448564528\n",
      "Batch 1085,  loss: 0.20747009217739104\n",
      "Batch 1090,  loss: 0.20097769498825074\n",
      "Batch 1095,  loss: 0.1718758225440979\n",
      "Batch 1100,  loss: 0.2132509469985962\n",
      "Batch 1105,  loss: 0.21638016104698182\n",
      "Batch 1110,  loss: 0.2220871239900589\n",
      "Batch 1115,  loss: 0.20995537042617798\n",
      "Batch 1120,  loss: 0.2093752235174179\n",
      "Batch 1125,  loss: 0.1803770899772644\n",
      "Batch 1130,  loss: 0.2606190413236618\n",
      "Batch 1135,  loss: 0.21741329729557038\n",
      "Batch 1140,  loss: 0.21326680183410646\n",
      "Batch 1145,  loss: 0.19111249446868897\n",
      "Batch 1150,  loss: 0.21362276673316954\n",
      "Batch 1155,  loss: 0.20619249045848848\n",
      "Batch 1160,  loss: 0.1890205353498459\n",
      "Batch 1165,  loss: 0.18742227256298066\n",
      "Batch 1170,  loss: 0.18022001683712005\n",
      "Batch 1175,  loss: 0.2261195808649063\n",
      "Batch 1180,  loss: 0.21397894620895386\n",
      "Batch 1185,  loss: 0.28746538162231444\n",
      "Batch 1190,  loss: 0.19408015608787538\n",
      "Batch 1195,  loss: 0.23750530183315277\n",
      "Batch 1200,  loss: 0.18968527317047118\n",
      "Batch 1205,  loss: 0.1816689282655716\n",
      "Batch 1210,  loss: 0.18166316002607347\n",
      "Batch 1215,  loss: 0.15085871815681456\n",
      "Batch 1220,  loss: 0.23470363914966583\n",
      "Batch 1225,  loss: 0.22047645449638367\n",
      "Batch 1230,  loss: 0.21312648952007293\n",
      "Batch 1235,  loss: 0.22703489959239959\n",
      "Batch 1240,  loss: 0.1840418577194214\n",
      "Batch 1245,  loss: 0.21612215638160706\n",
      "Batch 1250,  loss: 0.19566757082939149\n",
      "Batch 1255,  loss: 0.18314522206783296\n",
      "Batch 1260,  loss: 0.22003812491893768\n",
      "Batch 1265,  loss: 0.18143115639686586\n",
      "Batch 1270,  loss: 0.19157107174396515\n",
      "Batch 1275,  loss: 0.28550745844841\n",
      "Batch 1280,  loss: 0.18170723170042039\n",
      "Batch 1285,  loss: 0.20796650648117065\n",
      "Batch 1290,  loss: 0.16847747713327407\n",
      "Batch 1295,  loss: 0.1863714873790741\n",
      "Batch 1300,  loss: 0.2453575998544693\n",
      "Batch 1305,  loss: 0.20189464688301087\n",
      "Batch 1310,  loss: 0.21164246499538422\n",
      "Batch 1315,  loss: 0.20405977070331574\n",
      "Batch 1320,  loss: 0.19665950685739517\n",
      "Batch 1325,  loss: 0.18548232913017274\n",
      "Batch 1330,  loss: 0.18110322207212448\n",
      "Batch 1335,  loss: 0.22936626970767976\n",
      "Batch 1340,  loss: 0.18311983048915864\n",
      "Batch 1345,  loss: 0.2286732465028763\n",
      "Batch 1350,  loss: 0.18931318670511246\n",
      "Batch 1355,  loss: 0.22882935106754304\n",
      "Batch 1360,  loss: 0.2281542181968689\n",
      "Batch 1365,  loss: 0.17850519716739655\n",
      "Batch 1370,  loss: 0.15525347888469695\n",
      "Batch 1375,  loss: 0.17605179250240327\n",
      "Batch 1380,  loss: 0.2247304230928421\n",
      "Batch 1385,  loss: 0.24379688799381255\n",
      "Batch 1390,  loss: 0.21506564021110536\n",
      "Batch 1395,  loss: 0.23860196769237518\n",
      "Batch 1400,  loss: 0.18782755136489868\n",
      "Batch 1405,  loss: 0.22906606793403625\n",
      "Batch 1410,  loss: 0.20694990456104279\n",
      "Batch 1415,  loss: 0.17959093898534775\n",
      "Batch 1420,  loss: 0.2091076761484146\n",
      "Batch 1425,  loss: 0.2027602881193161\n",
      "Batch 1430,  loss: 0.21835116744041444\n",
      "Batch 1435,  loss: 0.1844567060470581\n",
      "Batch 1440,  loss: 0.2206927388906479\n",
      "Batch 1445,  loss: 0.23769818544387816\n",
      "Batch 1450,  loss: 0.17082690298557282\n",
      "Batch 1455,  loss: 0.19402244687080383\n",
      "Batch 1460,  loss: 0.19875489473342894\n",
      "Batch 1465,  loss: 0.20691868662834167\n",
      "Batch 1470,  loss: 0.21591705679893494\n",
      "Batch 1475,  loss: 0.207280170917511\n",
      "Batch 1480,  loss: 0.25799550116062164\n",
      "Batch 1485,  loss: 0.15290284156799316\n",
      "Batch 1490,  loss: 0.24284120202064513\n",
      "Batch 1495,  loss: 0.25448083579540254\n",
      "Batch 1500,  loss: 0.21719360053539277\n",
      "Batch 1505,  loss: 0.20855218768119813\n",
      "Batch 1510,  loss: 0.21287042498588563\n",
      "Batch 1515,  loss: 0.271856951713562\n",
      "Batch 1520,  loss: 0.19876827597618102\n",
      "Batch 1525,  loss: 0.22943924367427826\n",
      "Batch 1530,  loss: 0.16644957959651946\n",
      "Batch 1535,  loss: 0.21055699586868287\n",
      "Batch 1540,  loss: 0.2267240822315216\n",
      "Batch 1545,  loss: 0.1893890380859375\n",
      "Batch 1550,  loss: 0.20767417848110198\n",
      "Batch 1555,  loss: 0.16500312834978104\n",
      "Batch 1560,  loss: 0.21112783253192902\n",
      "Batch 1565,  loss: 0.17010070979595185\n",
      "Batch 1570,  loss: 0.2001647710800171\n",
      "Batch 1575,  loss: 0.18809959292411804\n",
      "Batch 1580,  loss: 0.1809518441557884\n",
      "Batch 1585,  loss: 0.1627858281135559\n",
      "Batch 1590,  loss: 0.18772566318511963\n",
      "Batch 1595,  loss: 0.18305373191833496\n",
      "Batch 1600,  loss: 0.16981270909309387\n",
      "Batch 1605,  loss: 0.21795351803302765\n",
      "Batch 1610,  loss: 0.2380702793598175\n",
      "Batch 1615,  loss: 0.19656331241130828\n",
      "Batch 1620,  loss: 0.1672798752784729\n",
      "Batch 1625,  loss: 0.15185505598783494\n",
      "Batch 1630,  loss: 0.16383614540100097\n",
      "Batch 1635,  loss: 0.21358795166015626\n",
      "Batch 1640,  loss: 0.22169775366783143\n",
      "Batch 1645,  loss: 0.21837637424468995\n",
      "Batch 1650,  loss: 0.19787076413631438\n",
      "Batch 1655,  loss: 0.1896461546421051\n",
      "Batch 1660,  loss: 0.18447066098451614\n",
      "Batch 1665,  loss: 0.2334126651287079\n",
      "Batch 1670,  loss: 0.16651637554168702\n",
      "Batch 1675,  loss: 0.16680773496627807\n",
      "Batch 1680,  loss: 0.15858147144317628\n",
      "Batch 1685,  loss: 0.25058319568634035\n",
      "Batch 1690,  loss: 0.19046927392482757\n",
      "Batch 1695,  loss: 0.18700425922870637\n",
      "Batch 1700,  loss: 0.1857455164194107\n",
      "Batch 1705,  loss: 0.2393997311592102\n",
      "Batch 1710,  loss: 0.2278991460800171\n",
      "Batch 1715,  loss: 0.2301339328289032\n",
      "Batch 1720,  loss: 0.18941591084003448\n",
      "Batch 1725,  loss: 0.16670029610395432\n",
      "Batch 1730,  loss: 0.2043566107749939\n",
      "Batch 1735,  loss: 0.20433657765388488\n",
      "Batch 1740,  loss: 0.2040436238050461\n",
      "Batch 1745,  loss: 0.18382124602794647\n",
      "Batch 1750,  loss: 0.176738378405571\n",
      "Batch 1755,  loss: 0.17051733285188675\n",
      "Batch 1760,  loss: 0.2414954572916031\n",
      "Batch 1765,  loss: 0.2187262624502182\n",
      "Batch 1770,  loss: 0.22967300117015838\n",
      "Batch 1775,  loss: 0.1748897075653076\n",
      "Batch 1780,  loss: 0.20836803913116456\n",
      "Batch 1785,  loss: 0.16583193391561507\n",
      "Batch 1790,  loss: 0.19199519455432892\n",
      "Batch 1795,  loss: 0.17880907654762268\n",
      "Batch 1800,  loss: 0.16794682294130325\n",
      "Batch 1805,  loss: 0.1717720866203308\n",
      "Batch 1810,  loss: 0.19314207136631012\n",
      "Batch 1815,  loss: 0.19345272183418274\n",
      "Batch 1820,  loss: 0.19371598958969116\n",
      "Batch 1825,  loss: 0.17009339034557341\n",
      "Batch 1830,  loss: 0.22616424262523652\n",
      "Batch 1835,  loss: 0.164253169298172\n",
      "Batch 1840,  loss: 0.16862960159778595\n",
      "Batch 1845,  loss: 0.2272259086370468\n",
      "Batch 1850,  loss: 0.1969461500644684\n",
      "Batch 1855,  loss: 0.24382019639015198\n",
      "Batch 1860,  loss: 0.19304659068584443\n",
      "Batch 1865,  loss: 0.1840052917599678\n",
      "Batch 1870,  loss: 0.16981369853019715\n",
      "Batch 1875,  loss: 0.1921737402677536\n",
      "Batch 1880,  loss: 0.207409131526947\n",
      "Batch 1885,  loss: 0.19334325790405274\n",
      "Batch 1890,  loss: 0.223710834980011\n",
      "Batch 1895,  loss: 0.22141448855400087\n",
      "Batch 1900,  loss: 0.2739470094442368\n",
      "Batch 1905,  loss: 0.18669604361057282\n",
      "Batch 1910,  loss: 0.2293120801448822\n",
      "Batch 1915,  loss: 0.22394128739833832\n",
      "Batch 1920,  loss: 0.14612916558980943\n",
      "Batch 1925,  loss: 0.2111295461654663\n",
      "Batch 1930,  loss: 0.1625311255455017\n",
      "Batch 1935,  loss: 0.2007083401083946\n",
      "Batch 1940,  loss: 0.2024821162223816\n",
      "Batch 1945,  loss: 0.19147730767726898\n",
      "Batch 1950,  loss: 0.23681167364120484\n",
      "Batch 1955,  loss: 0.2507932513952255\n",
      "Batch 1960,  loss: 0.23051555156707765\n",
      "Batch 1965,  loss: 0.21761855781078338\n",
      "Batch 1970,  loss: 0.18265914618968965\n",
      "Batch 1975,  loss: 0.22498331367969512\n",
      "Batch 1980,  loss: 0.18696657717227935\n",
      "Batch 1985,  loss: 0.23747831881046294\n",
      "Batch 1990,  loss: 0.24828779697418213\n",
      "Batch 1995,  loss: 0.15153205692768096\n",
      "Batch 2000,  loss: 0.2022689700126648\n",
      "Batch 2005,  loss: 0.16910032331943511\n",
      "Batch 2010,  loss: 0.16277355551719666\n",
      "Batch 2015,  loss: 0.243174746632576\n",
      "Batch 2020,  loss: 0.19472171366214752\n",
      "Batch 2025,  loss: 0.17498058080673218\n",
      "Batch 2030,  loss: 0.1735217958688736\n",
      "Batch 2035,  loss: 0.2452288120985031\n",
      "Batch 2040,  loss: 0.19034323692321778\n",
      "Batch 2045,  loss: 0.20623952001333237\n",
      "Batch 2050,  loss: 0.23084074556827544\n",
      "Batch 2055,  loss: 0.21627724766731263\n",
      "Batch 2060,  loss: 0.186576247215271\n",
      "Batch 2065,  loss: 0.2009993687272072\n",
      "Batch 2070,  loss: 0.25502489805221557\n",
      "Batch 2075,  loss: 0.19655628502368927\n",
      "Batch 2080,  loss: 0.21803229451179504\n",
      "Batch 2085,  loss: 0.25039135813713076\n",
      "Batch 2090,  loss: 0.1769472688436508\n",
      "Batch 2095,  loss: 0.22041461169719695\n",
      "Batch 2100,  loss: 0.20210495442152024\n",
      "Batch 2105,  loss: 0.19439164400100709\n",
      "Batch 2110,  loss: 0.2177772969007492\n",
      "Batch 2115,  loss: 0.19811009466648102\n",
      "Batch 2120,  loss: 0.1945864051580429\n",
      "Batch 2125,  loss: 0.23245157897472382\n",
      "Batch 2130,  loss: 0.21063279509544372\n",
      "Batch 2135,  loss: 0.17274223566055297\n",
      "Batch 2140,  loss: 0.2745095074176788\n",
      "Batch 2145,  loss: 0.20894665718078614\n",
      "Batch 2150,  loss: 0.17603927850723267\n",
      "Batch 2155,  loss: 0.21709610819816588\n",
      "Batch 2160,  loss: 0.15320041179656982\n",
      "Batch 2165,  loss: 0.20999644994735717\n",
      "Batch 2170,  loss: 0.2326551556587219\n",
      "Batch 2175,  loss: 0.25048173069953916\n",
      "Batch 2180,  loss: 0.17815531492233277\n",
      "Batch 2185,  loss: 0.19899600744247437\n",
      "Batch 2190,  loss: 0.2863016128540039\n",
      "Batch 2195,  loss: 0.2165556699037552\n",
      "Batch 2200,  loss: 0.21304943263530732\n",
      "Batch 2205,  loss: 0.21297288835048675\n",
      "Batch 2210,  loss: 0.19516831636428833\n",
      "Batch 2215,  loss: 0.19374631345272064\n",
      "Batch 2220,  loss: 0.2394645869731903\n",
      "Batch 2225,  loss: 0.22994727194309234\n",
      "Batch 2230,  loss: 0.21177746653556823\n",
      "Batch 2235,  loss: 0.218270942568779\n",
      "Batch 2240,  loss: 0.18833413124084472\n",
      "Batch 2245,  loss: 0.198110231757164\n",
      "Batch 2250,  loss: 0.20972275733947754\n",
      "Batch 2255,  loss: 0.197355780005455\n",
      "Batch 2260,  loss: 0.18808605074882506\n",
      "Batch 2265,  loss: 0.17314974665641786\n",
      "Batch 2270,  loss: 0.23110654652118684\n",
      "Batch 2275,  loss: 0.20715757310390473\n",
      "Batch 2280,  loss: 0.1924379900097847\n",
      "Batch 2285,  loss: 0.20498766899108886\n",
      "Batch 2290,  loss: 0.2247256815433502\n",
      "Batch 2295,  loss: 0.19473389983177186\n",
      "Batch 2300,  loss: 0.2047915369272232\n",
      "Batch 2305,  loss: 0.16711824536323547\n",
      "Batch 2310,  loss: 0.20665698051452636\n",
      "Batch 2315,  loss: 0.23318008184432984\n",
      "Batch 2320,  loss: 0.21451003849506378\n",
      "Batch 2325,  loss: 0.1695982664823532\n",
      "Batch 2330,  loss: 0.24943785071372987\n",
      "Batch 2335,  loss: 0.21159131526947023\n",
      "Batch 2340,  loss: 0.22485307455062867\n",
      "Batch 2345,  loss: 0.207005375623703\n",
      "Batch 2350,  loss: 0.15674880445003508\n",
      "Batch 2355,  loss: 0.16209375411272048\n",
      "Batch 2360,  loss: 0.18316068649291992\n",
      "Batch 2365,  loss: 0.17457795143127441\n",
      "Batch 2370,  loss: 0.27064651548862456\n",
      "Batch 2375,  loss: 0.245257169008255\n",
      "Batch 2380,  loss: 0.22335826754570007\n",
      "Batch 2385,  loss: 0.22687474489212037\n",
      "Batch 2390,  loss: 0.1958934873342514\n",
      "Batch 2395,  loss: 0.20834712088108062\n",
      "Batch 2400,  loss: 0.22072551846504213\n",
      "Batch 2405,  loss: 0.1842229664325714\n",
      "Batch 2410,  loss: 0.1964499533176422\n",
      "Batch 2415,  loss: 0.22138740122318268\n",
      "Batch 2420,  loss: 0.24457340240478515\n",
      "Batch 2425,  loss: 0.17843702733516692\n",
      "Batch 2430,  loss: 0.21044125854969026\n",
      "Batch 2435,  loss: 0.2030065178871155\n",
      "Batch 2440,  loss: 0.19792723059654235\n",
      "Batch 2445,  loss: 0.1982085347175598\n",
      "Batch 2450,  loss: 0.20537080764770507\n",
      "Batch 2455,  loss: 0.19402650892734527\n",
      "Batch 2460,  loss: 0.20354407131671906\n",
      "Batch 2465,  loss: 0.19092170894145966\n",
      "Batch 2470,  loss: 0.2489573121070862\n",
      "Batch 2475,  loss: 0.19891324043273925\n",
      "Batch 2480,  loss: 0.18474407494068146\n",
      "Batch 2485,  loss: 0.2491845428943634\n",
      "Batch 2490,  loss: 0.20082666873931884\n",
      "Batch 2495,  loss: 0.1974225252866745\n",
      "Batch 2500,  loss: 0.18131945431232452\n",
      "Batch 2505,  loss: 0.1708182454109192\n",
      "Batch 2510,  loss: 0.14754019677639008\n",
      "Batch 2515,  loss: 0.21377423405647278\n",
      "Batch 2520,  loss: 0.17042650282382965\n",
      "Batch 2525,  loss: 0.23020049929618835\n",
      "Batch 2530,  loss: 0.19259776175022125\n",
      "Batch 2535,  loss: 0.19746115207672119\n",
      "Batch 2540,  loss: 0.16592166423797608\n",
      "Batch 2545,  loss: 0.23600541353225707\n",
      "Batch 2550,  loss: 0.1992598980665207\n",
      "Batch 2555,  loss: 0.1951947659254074\n",
      "Batch 2560,  loss: 0.19034136235713958\n",
      "Batch 2565,  loss: 0.223013037443161\n",
      "Batch 2570,  loss: 0.20944292843341827\n",
      "Batch 2575,  loss: 0.16202150285243988\n",
      "Batch 2580,  loss: 0.1726925939321518\n",
      "Batch 2585,  loss: 0.22927591502666472\n",
      "Batch 2590,  loss: 0.21562129259109497\n",
      "Batch 2595,  loss: 0.19160405397415162\n",
      "Batch 2600,  loss: 0.20043681859970092\n",
      "Batch 2605,  loss: 0.1809920310974121\n",
      "Batch 2610,  loss: 0.2661744475364685\n",
      "Batch 2615,  loss: 0.25880944132804873\n",
      "Batch 2620,  loss: 0.20118744671344757\n",
      "Batch 2625,  loss: 0.14496255964040755\n",
      "Batch 2630,  loss: 0.20631903558969497\n",
      "Batch 2635,  loss: 0.19845985472202302\n",
      "Batch 2640,  loss: 0.18607762157917024\n",
      "Batch 2645,  loss: 0.18082254827022554\n",
      "Batch 2650,  loss: 0.21075851023197173\n",
      "Batch 2655,  loss: 0.24100902378559114\n",
      "Batch 2660,  loss: 0.18361228704452515\n",
      "Batch 2665,  loss: 0.2094699651002884\n",
      "Batch 2670,  loss: 0.23616667687892914\n",
      "Batch 2675,  loss: 0.1706263989210129\n",
      "Batch 2680,  loss: 0.22055138647556305\n",
      "Batch 2685,  loss: 0.1738462597131729\n",
      "Batch 2690,  loss: 0.2371147394180298\n",
      "Batch 2695,  loss: 0.18175603151321412\n",
      "Batch 2700,  loss: 0.1918674498796463\n",
      "Batch 2705,  loss: 0.19683676362037658\n",
      "Batch 2710,  loss: 0.27550363540649414\n",
      "Batch 2715,  loss: 0.22252715528011321\n",
      "Batch 2720,  loss: 0.19378231167793275\n",
      "Batch 2725,  loss: 0.22373203933238983\n",
      "Batch 2730,  loss: 0.2090085670351982\n",
      "Batch 2735,  loss: 0.15344748497009278\n",
      "Batch 2740,  loss: 0.17945834398269653\n",
      "Batch 2745,  loss: 0.21835465133190154\n",
      "Batch 2750,  loss: 0.17450197041034698\n",
      "Batch 2755,  loss: 0.17044322490692138\n",
      "Batch 2760,  loss: 0.225444296002388\n",
      "Batch 2765,  loss: 0.1856343299150467\n",
      "Batch 2770,  loss: 0.17855232059955597\n",
      "LOSS train 0.17855232059955597. Validation loss: 0.17503674724139273 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 9:\n",
      "Batch 5,  loss: 0.2412463665008545\n",
      "Batch 10,  loss: 0.18998904675245284\n",
      "Batch 15,  loss: 0.18717245757579803\n",
      "Batch 20,  loss: 0.22685804665088655\n",
      "Batch 25,  loss: 0.2229819655418396\n",
      "Batch 30,  loss: 0.17946527004241944\n",
      "Batch 35,  loss: 0.20348914861679077\n",
      "Batch 40,  loss: 0.17209564745426179\n",
      "Batch 45,  loss: 0.19394150972366334\n",
      "Batch 50,  loss: 0.2006622552871704\n",
      "Batch 55,  loss: 0.2118836134672165\n",
      "Batch 60,  loss: 0.19344440400600432\n",
      "Batch 65,  loss: 0.202862212061882\n",
      "Batch 70,  loss: 0.2784158080816269\n",
      "Batch 75,  loss: 0.16630465686321258\n",
      "Batch 80,  loss: 0.1935815066099167\n",
      "Batch 85,  loss: 0.1861729085445404\n",
      "Batch 90,  loss: 0.20234466195106507\n",
      "Batch 95,  loss: 0.19958048462867736\n",
      "Batch 100,  loss: 0.18152916431427002\n",
      "Batch 105,  loss: 0.20642168521881105\n",
      "Batch 110,  loss: 0.230699560046196\n",
      "Batch 115,  loss: 0.19558113515377046\n",
      "Batch 120,  loss: 0.19873296320438386\n",
      "Batch 125,  loss: 0.18645993769168853\n",
      "Batch 130,  loss: 0.21179601848125457\n",
      "Batch 135,  loss: 0.1982406944036484\n",
      "Batch 140,  loss: 0.21309952437877655\n",
      "Batch 145,  loss: 0.19693038910627364\n",
      "Batch 150,  loss: 0.14907526075839997\n",
      "Batch 155,  loss: 0.22184802293777467\n",
      "Batch 160,  loss: 0.2295936167240143\n",
      "Batch 165,  loss: 0.18467196226119995\n",
      "Batch 170,  loss: 0.2291673541069031\n",
      "Batch 175,  loss: 0.17287341952323915\n",
      "Batch 180,  loss: 0.22465317845344543\n",
      "Batch 185,  loss: 0.2710157960653305\n",
      "Batch 190,  loss: 0.21574425846338272\n",
      "Batch 195,  loss: 0.2043342411518097\n",
      "Batch 200,  loss: 0.166232892870903\n",
      "Batch 205,  loss: 0.16911892592906952\n",
      "Batch 210,  loss: 0.22038410007953643\n",
      "Batch 215,  loss: 0.15748825669288635\n",
      "Batch 220,  loss: 0.21225623190402984\n",
      "Batch 225,  loss: 0.24791240096092224\n",
      "Batch 230,  loss: 0.23533199429512025\n",
      "Batch 235,  loss: 0.21675654947757722\n",
      "Batch 240,  loss: 0.20420840829610826\n",
      "Batch 245,  loss: 0.22345386147499086\n",
      "Batch 250,  loss: 0.23017288744449615\n",
      "Batch 255,  loss: 0.210925629734993\n",
      "Batch 260,  loss: 0.20196566879749298\n",
      "Batch 265,  loss: 0.16191716194152833\n",
      "Batch 270,  loss: 0.2129222571849823\n",
      "Batch 275,  loss: 0.20457297265529634\n",
      "Batch 280,  loss: 0.23399698138237\n",
      "Batch 285,  loss: 0.16786362528800963\n",
      "Batch 290,  loss: 0.18718897700309753\n",
      "Batch 295,  loss: 0.18209148049354554\n",
      "Batch 300,  loss: 0.2117588311433792\n",
      "Batch 305,  loss: 0.18504270017147065\n",
      "Batch 310,  loss: 0.2008767306804657\n",
      "Batch 315,  loss: 0.19376445114612578\n",
      "Batch 320,  loss: 0.18294907212257386\n",
      "Batch 325,  loss: 0.21018989384174347\n",
      "Batch 330,  loss: 0.20568246245384217\n",
      "Batch 335,  loss: 0.24337126612663268\n",
      "Batch 340,  loss: 0.20177037119865418\n",
      "Batch 345,  loss: 0.20340538918972015\n",
      "Batch 350,  loss: 0.20579960346221923\n",
      "Batch 355,  loss: 0.2045164704322815\n",
      "Batch 360,  loss: 0.2410413920879364\n",
      "Batch 365,  loss: 0.2180651068687439\n",
      "Batch 370,  loss: 0.20463071167469024\n",
      "Batch 375,  loss: 0.217363640666008\n",
      "Batch 380,  loss: 0.2323521375656128\n",
      "Batch 385,  loss: 0.3049843966960907\n",
      "Batch 390,  loss: 0.21578716486692429\n",
      "Batch 395,  loss: 0.22927999794483184\n",
      "Batch 400,  loss: 0.17454126477241516\n",
      "Batch 405,  loss: 0.229589581489563\n",
      "Batch 410,  loss: 0.22289376556873322\n",
      "Batch 415,  loss: 0.24161053895950318\n",
      "Batch 420,  loss: 0.16817751228809358\n",
      "Batch 425,  loss: 0.21840422749519348\n",
      "Batch 430,  loss: 0.15762898027896882\n",
      "Batch 435,  loss: 0.19957683086395264\n",
      "Batch 440,  loss: 0.20535691678524018\n",
      "Batch 445,  loss: 0.18334985375404358\n",
      "Batch 450,  loss: 0.1917128771543503\n",
      "Batch 455,  loss: 0.20858649909496307\n",
      "Batch 460,  loss: 0.19885706305503845\n",
      "Batch 465,  loss: 0.19657934308052064\n",
      "Batch 470,  loss: 0.19763609766960144\n",
      "Batch 475,  loss: 0.2199661284685135\n",
      "Batch 480,  loss: 0.21396642029285431\n",
      "Batch 485,  loss: 0.228200563788414\n",
      "Batch 490,  loss: 0.23517806828022003\n",
      "Batch 495,  loss: 0.20968491435050965\n",
      "Batch 500,  loss: 0.2079789698123932\n",
      "Batch 505,  loss: 0.24059035778045654\n",
      "Batch 510,  loss: 0.17668656408786773\n",
      "Batch 515,  loss: 0.1908160299062729\n",
      "Batch 520,  loss: 0.24221215546131133\n",
      "Batch 525,  loss: 0.2212957888841629\n",
      "Batch 530,  loss: 0.14866848289966583\n",
      "Batch 535,  loss: 0.21959729492664337\n",
      "Batch 540,  loss: 0.20088969469070433\n",
      "Batch 545,  loss: 0.20793805420398712\n",
      "Batch 550,  loss: 0.16716285049915314\n",
      "Batch 555,  loss: 0.2016710877418518\n",
      "Batch 560,  loss: 0.2138748735189438\n",
      "Batch 565,  loss: 0.16467225253582002\n",
      "Batch 570,  loss: 0.172764952480793\n",
      "Batch 575,  loss: 0.18908305019140242\n",
      "Batch 580,  loss: 0.205711729824543\n",
      "Batch 585,  loss: 0.18273535072803498\n",
      "Batch 590,  loss: 0.1756450891494751\n",
      "Batch 595,  loss: 0.20765577554702758\n",
      "Batch 600,  loss: 0.17588758766651152\n",
      "Batch 605,  loss: 0.17572861015796662\n",
      "Batch 610,  loss: 0.19081718921661378\n",
      "Batch 615,  loss: 0.2211320608854294\n",
      "Batch 620,  loss: 0.21044731736183167\n",
      "Batch 625,  loss: 0.20398155748844146\n",
      "Batch 630,  loss: 0.23577123880386353\n",
      "Batch 635,  loss: 0.2342388242483139\n",
      "Batch 640,  loss: 0.18922798931598664\n",
      "Batch 645,  loss: 0.19326238930225373\n",
      "Batch 650,  loss: 0.1886908620595932\n",
      "Batch 655,  loss: 0.1954359918832779\n",
      "Batch 660,  loss: 0.17280508875846862\n",
      "Batch 665,  loss: 0.18787835240364076\n",
      "Batch 670,  loss: 0.20329728424549104\n",
      "Batch 675,  loss: 0.19828654825687408\n",
      "Batch 680,  loss: 0.22505033016204834\n",
      "Batch 685,  loss: 0.2202455699443817\n",
      "Batch 690,  loss: 0.22023964822292327\n",
      "Batch 695,  loss: 0.19887089729309082\n",
      "Batch 700,  loss: 0.1840382546186447\n",
      "Batch 705,  loss: 0.18596997559070588\n",
      "Batch 710,  loss: 0.2441970467567444\n",
      "Batch 715,  loss: 0.21878012716770173\n",
      "Batch 720,  loss: 0.17855354249477387\n",
      "Batch 725,  loss: 0.19918764233589173\n",
      "Batch 730,  loss: 0.21423880159854888\n",
      "Batch 735,  loss: 0.18925743401050568\n",
      "Batch 740,  loss: 0.27746646404266356\n",
      "Batch 745,  loss: 0.16125490367412568\n",
      "Batch 750,  loss: 0.18727727979421616\n",
      "Batch 755,  loss: 0.20660667419433593\n",
      "Batch 760,  loss: 0.16931393444538118\n",
      "Batch 765,  loss: 0.24426910877227784\n",
      "Batch 770,  loss: 0.18246634900569916\n",
      "Batch 775,  loss: 0.2194021850824356\n",
      "Batch 780,  loss: 0.2251201242208481\n",
      "Batch 785,  loss: 0.20147524774074554\n",
      "Batch 790,  loss: 0.22468746304512024\n",
      "Batch 795,  loss: 0.22747205793857575\n",
      "Batch 800,  loss: 0.18613382130861283\n",
      "Batch 805,  loss: 0.16019336879253387\n",
      "Batch 810,  loss: 0.17801318168640137\n",
      "Batch 815,  loss: 0.16838945150375367\n",
      "Batch 820,  loss: 0.1747374027967453\n",
      "Batch 825,  loss: 0.22052607238292693\n",
      "Batch 830,  loss: 0.15510238707065582\n",
      "Batch 835,  loss: 0.17885990738868712\n",
      "Batch 840,  loss: 0.20171353220939636\n",
      "Batch 845,  loss: 0.24216322898864745\n",
      "Batch 850,  loss: 0.21952342689037324\n",
      "Batch 855,  loss: 0.20833469331264495\n",
      "Batch 860,  loss: 0.20337364673614503\n",
      "Batch 865,  loss: 0.1744506388902664\n",
      "Batch 870,  loss: 0.1659287080168724\n",
      "Batch 875,  loss: 0.2270999073982239\n",
      "Batch 880,  loss: 0.22822414338588715\n",
      "Batch 885,  loss: 0.178006312251091\n",
      "Batch 890,  loss: 0.2025005489587784\n",
      "Batch 895,  loss: 0.18139738142490386\n",
      "Batch 900,  loss: 0.19272566735744476\n",
      "Batch 905,  loss: 0.24064752757549285\n",
      "Batch 910,  loss: 0.1920699045062065\n",
      "Batch 915,  loss: 0.18548621833324433\n",
      "Batch 920,  loss: 0.19853139221668242\n",
      "Batch 925,  loss: 0.18309351801872253\n",
      "Batch 930,  loss: 0.16103910356760026\n",
      "Batch 935,  loss: 0.26265424191951753\n",
      "Batch 940,  loss: 0.186789408326149\n",
      "Batch 945,  loss: 0.23322701454162598\n",
      "Batch 950,  loss: 0.21101492196321486\n",
      "Batch 955,  loss: 0.2261653184890747\n",
      "Batch 960,  loss: 0.19303672015666962\n",
      "Batch 965,  loss: 0.2163378268480301\n",
      "Batch 970,  loss: 0.16245753914117814\n",
      "Batch 975,  loss: 0.18726431727409362\n",
      "Batch 980,  loss: 0.20628170073032379\n",
      "Batch 985,  loss: 0.19605138301849365\n",
      "Batch 990,  loss: 0.18486477434635162\n",
      "Batch 995,  loss: 0.1522377222776413\n",
      "Batch 1000,  loss: 0.22464244365692138\n",
      "Batch 1005,  loss: 0.2160469114780426\n",
      "Batch 1010,  loss: 0.18720695078372956\n",
      "Batch 1015,  loss: 0.18094535917043686\n",
      "Batch 1020,  loss: 0.17638402581214904\n",
      "Batch 1025,  loss: 0.20006616413593292\n",
      "Batch 1030,  loss: 0.1847846746444702\n",
      "Batch 1035,  loss: 0.166097092628479\n",
      "Batch 1040,  loss: 0.2388659566640854\n",
      "Batch 1045,  loss: 0.203073388338089\n",
      "Batch 1050,  loss: 0.19968345165252685\n",
      "Batch 1055,  loss: 0.18534461557865142\n",
      "Batch 1060,  loss: 0.20851862132549287\n",
      "Batch 1065,  loss: 0.17733959555625917\n",
      "Batch 1070,  loss: 0.2284966826438904\n",
      "Batch 1075,  loss: 0.2048790693283081\n",
      "Batch 1080,  loss: 0.16437534093856812\n",
      "Batch 1085,  loss: 0.14456480145454406\n",
      "Batch 1090,  loss: 0.22305466532707213\n",
      "Batch 1095,  loss: 0.16648911833763122\n",
      "Batch 1100,  loss: 0.24048925638198854\n",
      "Batch 1105,  loss: 0.19440127313137054\n",
      "Batch 1110,  loss: 0.25907514095306394\n",
      "Batch 1115,  loss: 0.2340828448534012\n",
      "Batch 1120,  loss: 0.21419136524200438\n",
      "Batch 1125,  loss: 0.1847066432237625\n",
      "Batch 1130,  loss: 0.19556281566619874\n",
      "Batch 1135,  loss: 0.19961806237697602\n",
      "Batch 1140,  loss: 0.22453971207141876\n",
      "Batch 1145,  loss: 0.19629035294055938\n",
      "Batch 1150,  loss: 0.1587797522544861\n",
      "Batch 1155,  loss: 0.18403058350086213\n",
      "Batch 1160,  loss: 0.23733968138694764\n",
      "Batch 1165,  loss: 0.20866506397724152\n",
      "Batch 1170,  loss: 0.15835953652858734\n",
      "Batch 1175,  loss: 0.21567064821720122\n",
      "Batch 1180,  loss: 0.20314554274082183\n",
      "Batch 1185,  loss: 0.17520488798618317\n",
      "Batch 1190,  loss: 0.1848996877670288\n",
      "Batch 1195,  loss: 0.22450566589832305\n",
      "Batch 1200,  loss: 0.23451407849788666\n",
      "Batch 1205,  loss: 0.18256209790706635\n",
      "Batch 1210,  loss: 0.2237200915813446\n",
      "Batch 1215,  loss: 0.18664515018463135\n",
      "Batch 1220,  loss: 0.21330309212207793\n",
      "Batch 1225,  loss: 0.24406681060791016\n",
      "Batch 1230,  loss: 0.1578450992703438\n",
      "Batch 1235,  loss: 0.16482116878032685\n",
      "Batch 1240,  loss: 0.1900339812040329\n",
      "Batch 1245,  loss: 0.15688549280166625\n",
      "Batch 1250,  loss: 0.1943577527999878\n",
      "Batch 1255,  loss: 0.18304610550403594\n",
      "Batch 1260,  loss: 0.2230384021997452\n",
      "Batch 1265,  loss: 0.2595828175544739\n",
      "Batch 1270,  loss: 0.208993062376976\n",
      "Batch 1275,  loss: 0.171829491853714\n",
      "Batch 1280,  loss: 0.2192971885204315\n",
      "Batch 1285,  loss: 0.21046515554189682\n",
      "Batch 1290,  loss: 0.1820671170949936\n",
      "Batch 1295,  loss: 0.22365085482597352\n",
      "Batch 1300,  loss: 0.22095966935157776\n",
      "Batch 1305,  loss: 0.2481529414653778\n",
      "Batch 1310,  loss: 0.18907137513160704\n",
      "Batch 1315,  loss: 0.1723621279001236\n",
      "Batch 1320,  loss: 0.2049121856689453\n",
      "Batch 1325,  loss: 0.1613784909248352\n",
      "Batch 1330,  loss: 0.21175827085971832\n",
      "Batch 1335,  loss: 0.21519244611263275\n",
      "Batch 1340,  loss: 0.1597682386636734\n",
      "Batch 1345,  loss: 0.20545700788497925\n",
      "Batch 1350,  loss: 0.22477600276470183\n",
      "Batch 1355,  loss: 0.1746245563030243\n",
      "Batch 1360,  loss: 0.17117946445941926\n",
      "Batch 1365,  loss: 0.17435944676399232\n",
      "Batch 1370,  loss: 0.1775568962097168\n",
      "Batch 1375,  loss: 0.18295634984970094\n",
      "Batch 1380,  loss: 0.2174267590045929\n",
      "Batch 1385,  loss: 0.14710294604301452\n",
      "Batch 1390,  loss: 0.1953006535768509\n",
      "Batch 1395,  loss: 0.20443674325942993\n",
      "Batch 1400,  loss: 0.2755203485488892\n",
      "Batch 1405,  loss: 0.20829610228538514\n",
      "Batch 1410,  loss: 0.17935782968997954\n",
      "Batch 1415,  loss: 0.18081286251544954\n",
      "Batch 1420,  loss: 0.18065060526132584\n",
      "Batch 1425,  loss: 0.2342957615852356\n",
      "Batch 1430,  loss: 0.18182152211666108\n",
      "Batch 1435,  loss: 0.17492252737283706\n",
      "Batch 1440,  loss: 0.20152056217193604\n",
      "Batch 1445,  loss: 0.19686126708984375\n",
      "Batch 1450,  loss: 0.16805802881717682\n",
      "Batch 1455,  loss: 0.16567162573337554\n",
      "Batch 1460,  loss: 0.23081310838460922\n",
      "Batch 1465,  loss: 0.29726733565330504\n",
      "Batch 1470,  loss: 0.21392919421195983\n",
      "Batch 1475,  loss: 0.19743141829967498\n",
      "Batch 1480,  loss: 0.17896079421043395\n",
      "Batch 1485,  loss: 0.1885544776916504\n",
      "Batch 1490,  loss: 0.23674526810646057\n",
      "Batch 1495,  loss: 0.19822439551353455\n",
      "Batch 1500,  loss: 0.20932386815547943\n",
      "Batch 1505,  loss: 0.20189681947231292\n",
      "Batch 1510,  loss: 0.1338118016719818\n",
      "Batch 1515,  loss: 0.2021573692560196\n",
      "Batch 1520,  loss: 0.19349915087223052\n",
      "Batch 1525,  loss: 0.20393750071525574\n",
      "Batch 1530,  loss: 0.2250797986984253\n",
      "Batch 1535,  loss: 0.20798808932304383\n",
      "Batch 1540,  loss: 0.20240411758422852\n",
      "Batch 1545,  loss: 0.18273847699165344\n",
      "Batch 1550,  loss: 0.19009624123573304\n",
      "Batch 1555,  loss: 0.17637802064418792\n",
      "Batch 1560,  loss: 0.220991113781929\n",
      "Batch 1565,  loss: 0.22722937762737275\n",
      "Batch 1570,  loss: 0.21854083240032196\n",
      "Batch 1575,  loss: 0.1896226167678833\n",
      "Batch 1580,  loss: 0.18770456612110137\n",
      "Batch 1585,  loss: 0.2010693609714508\n",
      "Batch 1590,  loss: 0.23184056878089904\n",
      "Batch 1595,  loss: 0.16246073544025422\n",
      "Batch 1600,  loss: 0.2698941469192505\n",
      "Batch 1605,  loss: 0.22764993607997894\n",
      "Batch 1610,  loss: 0.22010430693626404\n",
      "Batch 1615,  loss: 0.18443253338336946\n",
      "Batch 1620,  loss: 0.23006121814250946\n",
      "Batch 1625,  loss: 0.20822116136550903\n",
      "Batch 1630,  loss: 0.20679698884487152\n",
      "Batch 1635,  loss: 0.20615797936916352\n",
      "Batch 1640,  loss: 0.24318040609359742\n",
      "Batch 1645,  loss: 0.20838295221328734\n",
      "Batch 1650,  loss: 0.2172349601984024\n",
      "Batch 1655,  loss: 0.21578994989395142\n",
      "Batch 1660,  loss: 0.19338037371635436\n",
      "Batch 1665,  loss: 0.17320424914360047\n",
      "Batch 1670,  loss: 0.1701485425233841\n",
      "Batch 1675,  loss: 0.20894019901752472\n",
      "Batch 1680,  loss: 0.17329344749450684\n",
      "Batch 1685,  loss: 0.23109673261642455\n",
      "Batch 1690,  loss: 0.1838856339454651\n",
      "Batch 1695,  loss: 0.173542320728302\n",
      "Batch 1700,  loss: 0.2208625018596649\n",
      "Batch 1705,  loss: 0.25374395549297335\n",
      "Batch 1710,  loss: 0.18182067573070526\n",
      "Batch 1715,  loss: 0.22541787028312682\n",
      "Batch 1720,  loss: 0.15770115405321122\n",
      "Batch 1725,  loss: 0.2171812415122986\n",
      "Batch 1730,  loss: 0.19896189570426942\n",
      "Batch 1735,  loss: 0.19317847788333892\n",
      "Batch 1740,  loss: 0.1697926789522171\n",
      "Batch 1745,  loss: 0.19498310983181\n",
      "Batch 1750,  loss: 0.17880577147006987\n",
      "Batch 1755,  loss: 0.2099159449338913\n",
      "Batch 1760,  loss: 0.2595625132322311\n",
      "Batch 1765,  loss: 0.180133655667305\n",
      "Batch 1770,  loss: 0.205625456571579\n",
      "Batch 1775,  loss: 0.19671596586704254\n",
      "Batch 1780,  loss: 0.13833692967891692\n",
      "Batch 1785,  loss: 0.15372194796800615\n",
      "Batch 1790,  loss: 0.1667349621653557\n",
      "Batch 1795,  loss: 0.21380460858345032\n",
      "Batch 1800,  loss: 0.22189049422740936\n",
      "Batch 1805,  loss: 0.1881403774023056\n",
      "Batch 1810,  loss: 0.1973334163427353\n",
      "Batch 1815,  loss: 0.25227129459381104\n",
      "Batch 1820,  loss: 0.18275785446166992\n",
      "Batch 1825,  loss: 0.28771701753139495\n",
      "Batch 1830,  loss: 0.2347404181957245\n",
      "Batch 1835,  loss: 0.18012021780014037\n",
      "Batch 1840,  loss: 0.17075102031230927\n",
      "Batch 1845,  loss: 0.1644826740026474\n",
      "Batch 1850,  loss: 0.17559686601161956\n",
      "Batch 1855,  loss: 0.23210328817367554\n",
      "Batch 1860,  loss: 0.1676057755947113\n",
      "Batch 1865,  loss: 0.20135680139064788\n",
      "Batch 1870,  loss: 0.17880236506462097\n",
      "Batch 1875,  loss: 0.22190309762954713\n",
      "Batch 1880,  loss: 0.14368487000465394\n",
      "Batch 1885,  loss: 0.2248394399881363\n",
      "Batch 1890,  loss: 0.2720165133476257\n",
      "Batch 1895,  loss: 0.1856232166290283\n",
      "Batch 1900,  loss: 0.16620999872684478\n",
      "Batch 1905,  loss: 0.20496698915958406\n",
      "Batch 1910,  loss: 0.21602894365787506\n",
      "Batch 1915,  loss: 0.22033756375312805\n",
      "Batch 1920,  loss: 0.18035948276519775\n",
      "Batch 1925,  loss: 0.2132304459810257\n",
      "Batch 1930,  loss: 0.200290709733963\n",
      "Batch 1935,  loss: 0.2049558013677597\n",
      "Batch 1940,  loss: 0.19761857986450196\n",
      "Batch 1945,  loss: 0.19577869772911072\n",
      "Batch 1950,  loss: 0.19445814788341523\n",
      "Batch 1955,  loss: 0.16490504443645476\n",
      "Batch 1960,  loss: 0.15212816894054412\n",
      "Batch 1965,  loss: 0.20505483448505402\n",
      "Batch 1970,  loss: 0.21411443650722503\n",
      "Batch 1975,  loss: 0.2204797387123108\n",
      "Batch 1980,  loss: 0.17656515091657637\n",
      "Batch 1985,  loss: 0.20904047191143035\n",
      "Batch 1990,  loss: 0.233672097325325\n",
      "Batch 1995,  loss: 0.19586993753910065\n",
      "Batch 2000,  loss: 0.17165528237819672\n",
      "Batch 2005,  loss: 0.21654402315616608\n",
      "Batch 2010,  loss: 0.22482590079307557\n",
      "Batch 2015,  loss: 0.22521717548370362\n",
      "Batch 2020,  loss: 0.14939384311437606\n",
      "Batch 2025,  loss: 0.22434327900409698\n",
      "Batch 2030,  loss: 0.19752834141254424\n",
      "Batch 2035,  loss: 0.1999455437064171\n",
      "Batch 2040,  loss: 0.18268961906433107\n",
      "Batch 2045,  loss: 0.18340299129486085\n",
      "Batch 2050,  loss: 0.15966273546218873\n",
      "Batch 2055,  loss: 0.21494130790233612\n",
      "Batch 2060,  loss: 0.1981201708316803\n",
      "Batch 2065,  loss: 0.20051706731319427\n",
      "Batch 2070,  loss: 0.20074510872364043\n",
      "Batch 2075,  loss: 0.19295610189437867\n",
      "Batch 2080,  loss: 0.20394305884838104\n",
      "Batch 2085,  loss: 0.2047913759946823\n",
      "Batch 2090,  loss: 0.25200376510620115\n",
      "Batch 2095,  loss: 0.18151420056819917\n",
      "Batch 2100,  loss: 0.1581251785159111\n",
      "Batch 2105,  loss: 0.15018477141857148\n",
      "Batch 2110,  loss: 0.15979785919189454\n",
      "Batch 2115,  loss: 0.18532009720802306\n",
      "Batch 2120,  loss: 0.19536276161670685\n",
      "Batch 2125,  loss: 0.23326674997806549\n",
      "Batch 2130,  loss: 0.20470365285873413\n",
      "Batch 2135,  loss: 0.20216136872768403\n",
      "Batch 2140,  loss: 0.20057086646556854\n",
      "Batch 2145,  loss: 0.22538070380687714\n",
      "Batch 2150,  loss: 0.21077808141708373\n",
      "Batch 2155,  loss: 0.19219230115413666\n",
      "Batch 2160,  loss: 0.21825644373893738\n",
      "Batch 2165,  loss: 0.21604878902435304\n",
      "Batch 2170,  loss: 0.18243609964847565\n",
      "Batch 2175,  loss: 0.2059008449316025\n",
      "Batch 2180,  loss: 0.20141945779323578\n",
      "Batch 2185,  loss: 0.16643013954162597\n",
      "Batch 2190,  loss: 0.21611546277999877\n",
      "Batch 2195,  loss: 0.19007578492164612\n",
      "Batch 2200,  loss: 0.2113162726163864\n",
      "Batch 2205,  loss: 0.21140934228897096\n",
      "Batch 2210,  loss: 0.20555481612682341\n",
      "Batch 2215,  loss: 0.17088451683521272\n",
      "Batch 2220,  loss: 0.18266061842441558\n",
      "Batch 2225,  loss: 0.177553591132164\n",
      "Batch 2230,  loss: 0.16246798038482665\n",
      "Batch 2235,  loss: 0.2062134027481079\n",
      "Batch 2240,  loss: 0.21472858488559723\n",
      "Batch 2245,  loss: 0.19490541219711305\n",
      "Batch 2250,  loss: 0.14765444546937942\n",
      "Batch 2255,  loss: 0.19618956446647645\n",
      "Batch 2260,  loss: 0.18971773982048035\n",
      "Batch 2265,  loss: 0.188846218585968\n",
      "Batch 2270,  loss: 0.1877170115709305\n",
      "Batch 2275,  loss: 0.21949227750301362\n",
      "Batch 2280,  loss: 0.22069074511528014\n",
      "Batch 2285,  loss: 0.2284298747777939\n",
      "Batch 2290,  loss: 0.1941480040550232\n",
      "Batch 2295,  loss: 0.19632333219051362\n",
      "Batch 2300,  loss: 0.1728871926665306\n",
      "Batch 2305,  loss: 0.1859469935297966\n",
      "Batch 2310,  loss: 0.18583546280860902\n",
      "Batch 2315,  loss: 0.20213955044746398\n",
      "Batch 2320,  loss: 0.17007712870836258\n",
      "Batch 2325,  loss: 0.18739353716373444\n",
      "Batch 2330,  loss: 0.2149861991405487\n",
      "Batch 2335,  loss: 0.21514607965946198\n",
      "Batch 2340,  loss: 0.1624378591775894\n",
      "Batch 2345,  loss: 0.20671095401048661\n",
      "Batch 2350,  loss: 0.19896432161331176\n",
      "Batch 2355,  loss: 0.17637763619422914\n",
      "Batch 2360,  loss: 0.20381912887096404\n",
      "Batch 2365,  loss: 0.27211875319480894\n",
      "Batch 2370,  loss: 0.20418991446495055\n",
      "Batch 2375,  loss: 0.18732353746891023\n",
      "Batch 2380,  loss: 0.1949615776538849\n",
      "Batch 2385,  loss: 0.17241259813308715\n",
      "Batch 2390,  loss: 0.2223238915205002\n",
      "Batch 2395,  loss: 0.26682538986206056\n",
      "Batch 2400,  loss: 0.18637582957744597\n",
      "Batch 2405,  loss: 0.24449130296707153\n",
      "Batch 2410,  loss: 0.20188895463943482\n",
      "Batch 2415,  loss: 0.2082300752401352\n",
      "Batch 2420,  loss: 0.2011075109243393\n",
      "Batch 2425,  loss: 0.18659963309764863\n",
      "Batch 2430,  loss: 0.14712371081113815\n",
      "Batch 2435,  loss: 0.2019129902124405\n",
      "Batch 2440,  loss: 0.20421538650989532\n",
      "Batch 2445,  loss: 0.19192269146442414\n",
      "Batch 2450,  loss: 0.17359698116779326\n",
      "Batch 2455,  loss: 0.19521467983722687\n",
      "Batch 2460,  loss: 0.17653611302375793\n",
      "Batch 2465,  loss: 0.18273550570011138\n",
      "Batch 2470,  loss: 0.1768761545419693\n",
      "Batch 2475,  loss: 0.20060537457466127\n",
      "Batch 2480,  loss: 0.19523183703422547\n",
      "Batch 2485,  loss: 0.16899095773696898\n",
      "Batch 2490,  loss: 0.18040027916431428\n",
      "Batch 2495,  loss: 0.23799293637275695\n",
      "Batch 2500,  loss: 0.18531056940555574\n",
      "Batch 2505,  loss: 0.19036245048046113\n",
      "Batch 2510,  loss: 0.2069320023059845\n",
      "Batch 2515,  loss: 0.23453949391841888\n",
      "Batch 2520,  loss: 0.2186829060316086\n",
      "Batch 2525,  loss: 0.1726765364408493\n",
      "Batch 2530,  loss: 0.18439966142177583\n",
      "Batch 2535,  loss: 0.24778868556022643\n",
      "Batch 2540,  loss: 0.1777954578399658\n",
      "Batch 2545,  loss: 0.21364856660366058\n",
      "Batch 2550,  loss: 0.168499094247818\n",
      "Batch 2555,  loss: 0.197295942902565\n",
      "Batch 2560,  loss: 0.20976814031600952\n",
      "Batch 2565,  loss: 0.203383469581604\n",
      "Batch 2570,  loss: 0.21805140674114226\n",
      "Batch 2575,  loss: 0.17784475684165954\n",
      "Batch 2580,  loss: 0.27043699026107787\n",
      "Batch 2585,  loss: 0.1835593104362488\n",
      "Batch 2590,  loss: 0.21375996470451356\n",
      "Batch 2595,  loss: 0.22016324996948242\n",
      "Batch 2600,  loss: 0.2223970353603363\n",
      "Batch 2605,  loss: 0.23045248091220855\n",
      "Batch 2610,  loss: 0.15662443935871123\n",
      "Batch 2615,  loss: 0.19567128419876098\n",
      "Batch 2620,  loss: 0.15502074956893921\n",
      "Batch 2625,  loss: 0.1779389888048172\n",
      "Batch 2630,  loss: 0.19418974220752716\n",
      "Batch 2635,  loss: 0.18438892364501952\n",
      "Batch 2640,  loss: 0.1587549030780792\n",
      "Batch 2645,  loss: 0.17403018176555635\n",
      "Batch 2650,  loss: 0.16619965732097625\n",
      "Batch 2655,  loss: 0.1731968939304352\n",
      "Batch 2660,  loss: 0.1657445728778839\n",
      "Batch 2665,  loss: 0.22033583223819733\n",
      "Batch 2670,  loss: 0.222286394238472\n",
      "Batch 2675,  loss: 0.20050362944602967\n",
      "Batch 2680,  loss: 0.19881571531295777\n",
      "Batch 2685,  loss: 0.1924048602581024\n",
      "Batch 2690,  loss: 0.1610415369272232\n",
      "Batch 2695,  loss: 0.20867326259613037\n",
      "Batch 2700,  loss: 0.25023292899131777\n",
      "Batch 2705,  loss: 0.2610356599092484\n",
      "Batch 2710,  loss: 0.17198902368545532\n",
      "Batch 2715,  loss: 0.20903362035751344\n",
      "Batch 2720,  loss: 0.17227182388305665\n",
      "Batch 2725,  loss: 0.1996975600719452\n",
      "Batch 2730,  loss: 0.19520579874515534\n",
      "Batch 2735,  loss: 0.1842631906270981\n",
      "Batch 2740,  loss: 0.17443849742412568\n",
      "Batch 2745,  loss: 0.20480992794036865\n",
      "Batch 2750,  loss: 0.22755784988403321\n",
      "Batch 2755,  loss: 0.2038938283920288\n",
      "Batch 2760,  loss: 0.1887570947408676\n",
      "Batch 2765,  loss: 0.22957866191864013\n",
      "Batch 2770,  loss: 0.18632522225379944\n",
      "LOSS train 0.18632522225379944. Validation loss: 0.17817192894009942 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 10:\n",
      "Batch 5,  loss: 0.20227532386779784\n",
      "Batch 10,  loss: 0.2140989661216736\n",
      "Batch 15,  loss: 0.23154304623603822\n",
      "Batch 20,  loss: 0.19200258553028107\n",
      "Batch 25,  loss: 0.18999629616737365\n",
      "Batch 30,  loss: 0.2085416555404663\n",
      "Batch 35,  loss: 0.19294130951166152\n",
      "Batch 40,  loss: 0.2150885969400406\n",
      "Batch 45,  loss: 0.18658779859542846\n",
      "Batch 50,  loss: 0.17061318457126617\n",
      "Batch 55,  loss: 0.21378577053546904\n",
      "Batch 60,  loss: 0.1974278286099434\n",
      "Batch 65,  loss: 0.23922905027866365\n",
      "Batch 70,  loss: 0.2329715758562088\n",
      "Batch 75,  loss: 0.18959785103797913\n",
      "Batch 80,  loss: 0.19167221784591676\n",
      "Batch 85,  loss: 0.23128849864006043\n",
      "Batch 90,  loss: 0.2793607860803604\n",
      "Batch 95,  loss: 0.2119114875793457\n",
      "Batch 100,  loss: 0.16617986857891082\n",
      "Batch 105,  loss: 0.20055584609508514\n",
      "Batch 110,  loss: 0.2064641922712326\n",
      "Batch 115,  loss: 0.17819204926490784\n",
      "Batch 120,  loss: 0.17526435554027558\n",
      "Batch 125,  loss: 0.22880420982837676\n",
      "Batch 130,  loss: 0.20552140176296235\n",
      "Batch 135,  loss: 0.16558242440223694\n",
      "Batch 140,  loss: 0.19148609638214112\n",
      "Batch 145,  loss: 0.16687833964824678\n",
      "Batch 150,  loss: 0.18599409162998198\n",
      "Batch 155,  loss: 0.1413731187582016\n",
      "Batch 160,  loss: 0.1934428781270981\n",
      "Batch 165,  loss: 0.204948890209198\n",
      "Batch 170,  loss: 0.171852408349514\n",
      "Batch 175,  loss: 0.181503963470459\n",
      "Batch 180,  loss: 0.21616738736629487\n",
      "Batch 185,  loss: 0.2121965393424034\n",
      "Batch 190,  loss: 0.2054353564977646\n",
      "Batch 195,  loss: 0.18310212194919587\n",
      "Batch 200,  loss: 0.18682091534137726\n",
      "Batch 205,  loss: 0.23665163516998292\n",
      "Batch 210,  loss: 0.17956627011299134\n",
      "Batch 215,  loss: 0.18386002779006957\n",
      "Batch 220,  loss: 0.2397951990365982\n",
      "Batch 225,  loss: 0.19172816574573517\n",
      "Batch 230,  loss: 0.1686336189508438\n",
      "Batch 235,  loss: 0.1541397601366043\n",
      "Batch 240,  loss: 0.18452199995517732\n",
      "Batch 245,  loss: 0.21968116760253906\n",
      "Batch 250,  loss: 0.21776945292949676\n",
      "Batch 255,  loss: 0.1922549217939377\n",
      "Batch 260,  loss: 0.1599052906036377\n",
      "Batch 265,  loss: 0.19787878543138504\n",
      "Batch 270,  loss: 0.1698720335960388\n",
      "Batch 275,  loss: 0.2066764384508133\n",
      "Batch 280,  loss: 0.19176459908485413\n",
      "Batch 285,  loss: 0.21747591197490693\n",
      "Batch 290,  loss: 0.1865863472223282\n",
      "Batch 295,  loss: 0.18726772665977479\n",
      "Batch 300,  loss: 0.186739382147789\n",
      "Batch 305,  loss: 0.14624529480934143\n",
      "Batch 310,  loss: 0.16684104800224303\n",
      "Batch 315,  loss: 0.21297893822193145\n",
      "Batch 320,  loss: 0.1681978076696396\n",
      "Batch 325,  loss: 0.19963027834892272\n",
      "Batch 330,  loss: 0.16922480314970018\n",
      "Batch 335,  loss: 0.23683202564716338\n",
      "Batch 340,  loss: 0.15602305680513381\n",
      "Batch 345,  loss: 0.20504180192947388\n",
      "Batch 350,  loss: 0.18676514625549318\n",
      "Batch 355,  loss: 0.2566347509622574\n",
      "Batch 360,  loss: 0.22765999436378478\n",
      "Batch 365,  loss: 0.23957813382148743\n",
      "Batch 370,  loss: 0.13832387030124665\n",
      "Batch 375,  loss: 0.18911172151565553\n",
      "Batch 380,  loss: 0.1630502700805664\n",
      "Batch 385,  loss: 0.16512030661106109\n",
      "Batch 390,  loss: 0.21642471551895143\n",
      "Batch 395,  loss: 0.2255435436964035\n",
      "Batch 400,  loss: 0.18634371757507323\n",
      "Batch 405,  loss: 0.19109990298748017\n",
      "Batch 410,  loss: 0.1663697510957718\n",
      "Batch 415,  loss: 0.2010394662618637\n",
      "Batch 420,  loss: 0.2247082144021988\n",
      "Batch 425,  loss: 0.21142955124378204\n",
      "Batch 430,  loss: 0.20526536405086518\n",
      "Batch 435,  loss: 0.18439356982707977\n",
      "Batch 440,  loss: 0.19935811758041383\n",
      "Batch 445,  loss: 0.19890134334564208\n",
      "Batch 450,  loss: 0.17780667841434478\n",
      "Batch 455,  loss: 0.20825704038143159\n",
      "Batch 460,  loss: 0.22105963826179503\n",
      "Batch 465,  loss: 0.2317903906106949\n",
      "Batch 470,  loss: 0.19431608021259308\n",
      "Batch 475,  loss: 0.22159577012062073\n",
      "Batch 480,  loss: 0.1603629320859909\n",
      "Batch 485,  loss: 0.21765369176864624\n",
      "Batch 490,  loss: 0.18497080504894256\n",
      "Batch 495,  loss: 0.21680614948272706\n",
      "Batch 500,  loss: 0.17874506413936614\n",
      "Batch 505,  loss: 0.21054663360118867\n",
      "Batch 510,  loss: 0.17871767282485962\n",
      "Batch 515,  loss: 0.20688495188951492\n",
      "Batch 520,  loss: 0.17761131525039672\n",
      "Batch 525,  loss: 0.24331468045711518\n",
      "Batch 530,  loss: 0.19613989889621736\n",
      "Batch 535,  loss: 0.2123529613018036\n",
      "Batch 540,  loss: 0.23147053122520447\n",
      "Batch 545,  loss: 0.2062489241361618\n",
      "Batch 550,  loss: 0.18003731369972228\n",
      "Batch 555,  loss: 0.15326104462146758\n",
      "Batch 560,  loss: 0.17924579679965974\n",
      "Batch 565,  loss: 0.1580158680677414\n",
      "Batch 570,  loss: 0.16654868572950363\n",
      "Batch 575,  loss: 0.19344621300697326\n",
      "Batch 580,  loss: 0.24779949188232422\n",
      "Batch 585,  loss: 0.1905614823102951\n",
      "Batch 590,  loss: 0.20194106698036193\n",
      "Batch 595,  loss: 0.1681453675031662\n",
      "Batch 600,  loss: 0.23948554396629335\n",
      "Batch 605,  loss: 0.2263976126909256\n",
      "Batch 610,  loss: 0.19883679449558259\n",
      "Batch 615,  loss: 0.22171410620212556\n",
      "Batch 620,  loss: 0.18179477155208587\n",
      "Batch 625,  loss: 0.2020635038614273\n",
      "Batch 630,  loss: 0.1970392256975174\n",
      "Batch 635,  loss: 0.16714704930782318\n",
      "Batch 640,  loss: 0.21262364387512206\n",
      "Batch 645,  loss: 0.21969301104545594\n",
      "Batch 650,  loss: 0.20012728571891786\n",
      "Batch 655,  loss: 0.1902716040611267\n",
      "Batch 660,  loss: 0.22872711420059205\n",
      "Batch 665,  loss: 0.21010325998067855\n",
      "Batch 670,  loss: 0.16314733326435088\n",
      "Batch 675,  loss: 0.17132821977138518\n",
      "Batch 680,  loss: 0.17784009277820587\n",
      "Batch 685,  loss: 0.19399504363536835\n",
      "Batch 690,  loss: 0.19696355164051055\n",
      "Batch 695,  loss: 0.19422752857208253\n",
      "Batch 700,  loss: 0.20065617859363555\n",
      "Batch 705,  loss: 0.16514652222394943\n",
      "Batch 710,  loss: 0.2551924169063568\n",
      "Batch 715,  loss: 0.22298437356948853\n",
      "Batch 720,  loss: 0.18305646479129792\n",
      "Batch 725,  loss: 0.1618122100830078\n",
      "Batch 730,  loss: 0.17964893579483032\n",
      "Batch 735,  loss: 0.1931520074605942\n",
      "Batch 740,  loss: 0.16147886216640472\n",
      "Batch 745,  loss: 0.1904507964849472\n",
      "Batch 750,  loss: 0.22517821788787842\n",
      "Batch 755,  loss: 0.21601883471012115\n",
      "Batch 760,  loss: 0.19104094207286834\n",
      "Batch 765,  loss: 0.2111200511455536\n",
      "Batch 770,  loss: 0.17313503324985505\n",
      "Batch 775,  loss: 0.1904439076781273\n",
      "Batch 780,  loss: 0.17804399728775025\n",
      "Batch 785,  loss: 0.22171359956264497\n",
      "Batch 790,  loss: 0.20925717651844025\n",
      "Batch 795,  loss: 0.2007461130619049\n",
      "Batch 800,  loss: 0.18616219758987426\n",
      "Batch 805,  loss: 0.1595095291733742\n",
      "Batch 810,  loss: 0.19059965908527374\n",
      "Batch 815,  loss: 0.21064761877059937\n",
      "Batch 820,  loss: 0.17266147434711457\n",
      "Batch 825,  loss: 0.1863200068473816\n",
      "Batch 830,  loss: 0.17771334648132325\n",
      "Batch 835,  loss: 0.20568872690200807\n",
      "Batch 840,  loss: 0.18409357368946075\n",
      "Batch 845,  loss: 0.2300117164850235\n",
      "Batch 850,  loss: 0.17879194617271424\n",
      "Batch 855,  loss: 0.16732622385025026\n",
      "Batch 860,  loss: 0.18707570135593415\n",
      "Batch 865,  loss: 0.18303875625133514\n",
      "Batch 870,  loss: 0.2016550838947296\n",
      "Batch 875,  loss: 0.21945545375347136\n",
      "Batch 880,  loss: 0.22250196039676667\n",
      "Batch 885,  loss: 0.16591113060712814\n",
      "Batch 890,  loss: 0.2599650025367737\n",
      "Batch 895,  loss: 0.18152244985103608\n",
      "Batch 900,  loss: 0.22300490140914916\n",
      "Batch 905,  loss: 0.21224781423807143\n",
      "Batch 910,  loss: 0.23443942070007323\n",
      "Batch 915,  loss: 0.20441196262836456\n",
      "Batch 920,  loss: 0.17573963701725007\n",
      "Batch 925,  loss: 0.16893576979637145\n",
      "Batch 930,  loss: 0.1523791402578354\n",
      "Batch 935,  loss: 0.18315089643001556\n",
      "Batch 940,  loss: 0.17857256084680556\n",
      "Batch 945,  loss: 0.16052695512771606\n",
      "Batch 950,  loss: 0.2002379983663559\n",
      "Batch 955,  loss: 0.15570229291915894\n",
      "Batch 960,  loss: 0.21627842485904694\n",
      "Batch 965,  loss: 0.19831523299217224\n",
      "Batch 970,  loss: 0.170844367146492\n",
      "Batch 975,  loss: 0.16512300968170165\n",
      "Batch 980,  loss: 0.18637282848358155\n",
      "Batch 985,  loss: 0.19386248886585236\n",
      "Batch 990,  loss: 0.21371364295482637\n",
      "Batch 995,  loss: 0.24908844828605653\n",
      "Batch 1000,  loss: 0.1637708067893982\n",
      "Batch 1005,  loss: 0.23161905109882355\n",
      "Batch 1010,  loss: 0.17965098172426225\n",
      "Batch 1015,  loss: 0.18323403000831603\n",
      "Batch 1020,  loss: 0.1866029292345047\n",
      "Batch 1025,  loss: 0.2084759682416916\n",
      "Batch 1030,  loss: 0.17390565276145936\n",
      "Batch 1035,  loss: 0.22234551310539247\n",
      "Batch 1040,  loss: 0.22325968146324157\n",
      "Batch 1045,  loss: 0.16539748013019562\n",
      "Batch 1050,  loss: 0.21943509876728057\n",
      "Batch 1055,  loss: 0.18137135803699495\n",
      "Batch 1060,  loss: 0.191961607336998\n",
      "Batch 1065,  loss: 0.2142460376024246\n",
      "Batch 1070,  loss: 0.23969396352767944\n",
      "Batch 1075,  loss: 0.14952842742204667\n",
      "Batch 1080,  loss: 0.2191024750471115\n",
      "Batch 1085,  loss: 0.18179660737514497\n",
      "Batch 1090,  loss: 0.18533045947551727\n",
      "Batch 1095,  loss: 0.20330372154712678\n",
      "Batch 1100,  loss: 0.19902593195438384\n",
      "Batch 1105,  loss: 0.20126062333583833\n",
      "Batch 1110,  loss: 0.22140873074531556\n",
      "Batch 1115,  loss: 0.16755182147026063\n",
      "Batch 1120,  loss: 0.23001367151737212\n",
      "Batch 1125,  loss: 0.22448660731315612\n",
      "Batch 1130,  loss: 0.2124466687440872\n",
      "Batch 1135,  loss: 0.1859459400177002\n",
      "Batch 1140,  loss: 0.22427230775356294\n",
      "Batch 1145,  loss: 0.15784431695938111\n",
      "Batch 1150,  loss: 0.17604479491710662\n",
      "Batch 1155,  loss: 0.2478339046239853\n",
      "Batch 1160,  loss: 0.18772184550762178\n",
      "Batch 1165,  loss: 0.20567918717861175\n",
      "Batch 1170,  loss: 0.1691658616065979\n",
      "Batch 1175,  loss: 0.25542053282260896\n",
      "Batch 1180,  loss: 0.18608335554599761\n",
      "Batch 1185,  loss: 0.21557950377464294\n",
      "Batch 1190,  loss: 0.207644522190094\n",
      "Batch 1195,  loss: 0.20038340091705323\n",
      "Batch 1200,  loss: 0.2333558350801468\n",
      "Batch 1205,  loss: 0.14302881956100463\n",
      "Batch 1210,  loss: 0.14671992212533952\n",
      "Batch 1215,  loss: 0.16510192900896073\n",
      "Batch 1220,  loss: 0.21345444321632384\n",
      "Batch 1225,  loss: 0.1743302747607231\n",
      "Batch 1230,  loss: 0.1866961747407913\n",
      "Batch 1235,  loss: 0.24732982814311982\n",
      "Batch 1240,  loss: 0.2095155119895935\n",
      "Batch 1245,  loss: 0.17279918789863585\n",
      "Batch 1250,  loss: 0.19455924034118652\n",
      "Batch 1255,  loss: 0.1947912871837616\n",
      "Batch 1260,  loss: 0.20031720995903016\n",
      "Batch 1265,  loss: 0.16691598892211915\n",
      "Batch 1270,  loss: 0.17510519474744796\n",
      "Batch 1275,  loss: 0.19348423033952714\n",
      "Batch 1280,  loss: 0.14062108248472213\n",
      "Batch 1285,  loss: 0.2546587586402893\n",
      "Batch 1290,  loss: 0.19673459231853485\n",
      "Batch 1295,  loss: 0.20735870003700257\n",
      "Batch 1300,  loss: 0.18404076099395753\n",
      "Batch 1305,  loss: 0.18896032273769378\n",
      "Batch 1310,  loss: 0.22324441075325013\n",
      "Batch 1315,  loss: 0.15825263559818267\n",
      "Batch 1320,  loss: 0.2134651482105255\n",
      "Batch 1325,  loss: 0.14439716637134553\n",
      "Batch 1330,  loss: 0.13776124715805055\n",
      "Batch 1335,  loss: 0.21414229273796082\n",
      "Batch 1340,  loss: 0.18503864407539367\n",
      "Batch 1345,  loss: 0.17542965412139894\n",
      "Batch 1350,  loss: 0.18387433886528015\n",
      "Batch 1355,  loss: 0.18987862765789032\n",
      "Batch 1360,  loss: 0.17405893206596373\n",
      "Batch 1365,  loss: 0.2909624993801117\n",
      "Batch 1370,  loss: 0.18793721497058868\n",
      "Batch 1375,  loss: 0.20311246812343597\n",
      "Batch 1380,  loss: 0.20208728909492493\n",
      "Batch 1385,  loss: 0.21852893233299256\n",
      "Batch 1390,  loss: 0.1553465873003006\n",
      "Batch 1395,  loss: 0.19178597033023834\n",
      "Batch 1400,  loss: 0.20528421103954314\n",
      "Batch 1405,  loss: 0.24849212765693665\n",
      "Batch 1410,  loss: 0.16417653262615203\n",
      "Batch 1415,  loss: 0.19585745334625243\n",
      "Batch 1420,  loss: 0.17721810638904573\n",
      "Batch 1425,  loss: 0.14180610179901124\n",
      "Batch 1430,  loss: 0.15813231766223906\n",
      "Batch 1435,  loss: 0.19710295796394348\n",
      "Batch 1440,  loss: 0.24428769648075105\n",
      "Batch 1445,  loss: 0.20347193777561187\n",
      "Batch 1450,  loss: 0.1918446183204651\n",
      "Batch 1455,  loss: 0.18300635665655135\n",
      "Batch 1460,  loss: 0.1728698194026947\n",
      "Batch 1465,  loss: 0.19602824598550797\n",
      "Batch 1470,  loss: 0.16799092590808867\n",
      "Batch 1475,  loss: 0.25901601314544676\n",
      "Batch 1480,  loss: 0.15006549656391144\n",
      "Batch 1485,  loss: 0.2222678542137146\n",
      "Batch 1490,  loss: 0.17126522660255433\n",
      "Batch 1495,  loss: 0.1700848162174225\n",
      "Batch 1500,  loss: 0.1773895502090454\n",
      "Batch 1505,  loss: 0.16027557253837585\n",
      "Batch 1510,  loss: 0.17110800743103027\n",
      "Batch 1515,  loss: 0.26226890087127686\n",
      "Batch 1520,  loss: 0.23043000996112822\n",
      "Batch 1525,  loss: 0.19558802843093873\n",
      "Batch 1530,  loss: 0.1843599945306778\n",
      "Batch 1535,  loss: 0.18594704270362855\n",
      "Batch 1540,  loss: 0.17194986045360566\n",
      "Batch 1545,  loss: 0.21241859793663026\n",
      "Batch 1550,  loss: 0.2038581043481827\n",
      "Batch 1555,  loss: 0.23800860941410065\n",
      "Batch 1560,  loss: 0.2015920639038086\n",
      "Batch 1565,  loss: 0.17609613239765168\n",
      "Batch 1570,  loss: 0.17693911790847777\n",
      "Batch 1575,  loss: 0.1939619928598404\n",
      "Batch 1580,  loss: 0.1454715609550476\n",
      "Batch 1585,  loss: 0.1893087387084961\n",
      "Batch 1590,  loss: 0.1728454202413559\n",
      "Batch 1595,  loss: 0.21071754544973373\n",
      "Batch 1600,  loss: 0.21866515278816223\n",
      "Batch 1605,  loss: 0.22176519334316253\n",
      "Batch 1610,  loss: 0.23613327741622925\n",
      "Batch 1615,  loss: 0.1817363202571869\n",
      "Batch 1620,  loss: 0.18500313758850098\n",
      "Batch 1625,  loss: 0.21069343388080597\n",
      "Batch 1630,  loss: 0.1842700183391571\n",
      "Batch 1635,  loss: 0.20235308706760408\n",
      "Batch 1640,  loss: 0.18515392243862153\n",
      "Batch 1645,  loss: 0.17729817628860473\n",
      "Batch 1650,  loss: 0.24207670688629152\n",
      "Batch 1655,  loss: 0.20987253189086913\n",
      "Batch 1660,  loss: 0.20106181502342224\n",
      "Batch 1665,  loss: 0.2329510986804962\n",
      "Batch 1670,  loss: 0.14198852628469466\n",
      "Batch 1675,  loss: 0.16972851157188415\n",
      "Batch 1680,  loss: 0.18712271749973297\n",
      "Batch 1685,  loss: 0.20984610617160798\n",
      "Batch 1690,  loss: 0.20501336455345154\n",
      "Batch 1695,  loss: 0.1683889865875244\n",
      "Batch 1700,  loss: 0.22386379539966583\n",
      "Batch 1705,  loss: 0.22375818490982055\n",
      "Batch 1710,  loss: 0.2583754241466522\n",
      "Batch 1715,  loss: 0.2228556752204895\n",
      "Batch 1720,  loss: 0.21527695655822754\n",
      "Batch 1725,  loss: 0.1772829681634903\n",
      "Batch 1730,  loss: 0.21505578458309174\n",
      "Batch 1735,  loss: 0.18034277558326722\n",
      "Batch 1740,  loss: 0.16796356439590454\n",
      "Batch 1745,  loss: 0.2435723513364792\n",
      "Batch 1750,  loss: 0.2254297435283661\n",
      "Batch 1755,  loss: 0.17951860576868056\n",
      "Batch 1760,  loss: 0.236243736743927\n",
      "Batch 1765,  loss: 0.22628942430019378\n",
      "Batch 1770,  loss: 0.20238801687955857\n",
      "Batch 1775,  loss: 0.17176636308431625\n",
      "Batch 1780,  loss: 0.22797016203403472\n",
      "Batch 1785,  loss: 0.19377226680517196\n",
      "Batch 1790,  loss: 0.1546141654253006\n",
      "Batch 1795,  loss: 0.1550583377480507\n",
      "Batch 1800,  loss: 0.21281110346317292\n",
      "Batch 1805,  loss: 0.1995599865913391\n",
      "Batch 1810,  loss: 0.18897217512130737\n",
      "Batch 1815,  loss: 0.24925280511379241\n",
      "Batch 1820,  loss: 0.2309783935546875\n",
      "Batch 1825,  loss: 0.21998220086097717\n",
      "Batch 1830,  loss: 0.16021889746189116\n",
      "Batch 1835,  loss: 0.19117971360683442\n",
      "Batch 1840,  loss: 0.20677205324172973\n",
      "Batch 1845,  loss: 0.16452538073062897\n",
      "Batch 1850,  loss: 0.22150449752807616\n",
      "Batch 1855,  loss: 0.18747136890888214\n",
      "Batch 1860,  loss: 0.1579288050532341\n",
      "Batch 1865,  loss: 0.20823278427124023\n",
      "Batch 1870,  loss: 0.16381554305553436\n",
      "Batch 1875,  loss: 0.19359196126461028\n",
      "Batch 1880,  loss: 0.18014463782310486\n",
      "Batch 1885,  loss: 0.19276918172836305\n",
      "Batch 1890,  loss: 0.21715224385261536\n",
      "Batch 1895,  loss: 0.21549673080444337\n",
      "Batch 1900,  loss: 0.15583798587322234\n",
      "Batch 1905,  loss: 0.1684060662984848\n",
      "Batch 1910,  loss: 0.21344459801912308\n",
      "Batch 1915,  loss: 0.24024367928504944\n",
      "Batch 1920,  loss: 0.23802578151226045\n",
      "Batch 1925,  loss: 0.18444357812404633\n",
      "Batch 1930,  loss: 0.19749827384948732\n",
      "Batch 1935,  loss: 0.1802026242017746\n",
      "Batch 1940,  loss: 0.16270684599876403\n",
      "Batch 1945,  loss: 0.189482182264328\n",
      "Batch 1950,  loss: 0.21781614422798157\n",
      "Batch 1955,  loss: 0.14912809580564498\n",
      "Batch 1960,  loss: 0.17035243511199952\n",
      "Batch 1965,  loss: 0.19272738993167876\n",
      "Batch 1970,  loss: 0.19750472903251648\n",
      "Batch 1975,  loss: 0.18379853069782257\n",
      "Batch 1980,  loss: 0.16707011461257934\n",
      "Batch 1985,  loss: 0.18174381256103517\n",
      "Batch 1990,  loss: 0.251953661441803\n",
      "Batch 1995,  loss: 0.23503947257995605\n",
      "Batch 2000,  loss: 0.17996363043785096\n",
      "Batch 2005,  loss: 0.2172282248735428\n",
      "Batch 2010,  loss: 0.19011058211326598\n",
      "Batch 2015,  loss: 0.20135448575019838\n",
      "Batch 2020,  loss: 0.24537782073020936\n",
      "Batch 2025,  loss: 0.19510225355625152\n",
      "Batch 2030,  loss: 0.19857470095157623\n",
      "Batch 2035,  loss: 0.21605312824249268\n",
      "Batch 2040,  loss: 0.20971498191356658\n",
      "Batch 2045,  loss: 0.1821351408958435\n",
      "Batch 2050,  loss: 0.19040456861257554\n",
      "Batch 2055,  loss: 0.18419235646724702\n",
      "Batch 2060,  loss: 0.19468326568603517\n",
      "Batch 2065,  loss: 0.181277072429657\n",
      "Batch 2070,  loss: 0.1858796000480652\n",
      "Batch 2075,  loss: 0.21651386171579362\n",
      "Batch 2080,  loss: 0.15138288736343383\n",
      "Batch 2085,  loss: 0.17212461233139037\n",
      "Batch 2090,  loss: 0.21604101955890656\n",
      "Batch 2095,  loss: 0.17183519899845123\n",
      "Batch 2100,  loss: 0.1866341471672058\n",
      "Batch 2105,  loss: 0.20092586576938629\n",
      "Batch 2110,  loss: 0.1731044054031372\n",
      "Batch 2115,  loss: 0.18336793780326843\n",
      "Batch 2120,  loss: 0.2396008551120758\n",
      "Batch 2125,  loss: 0.1716699481010437\n",
      "Batch 2130,  loss: 0.17738493382930756\n",
      "Batch 2135,  loss: 0.1500232696533203\n",
      "Batch 2140,  loss: 0.21700386106967925\n",
      "Batch 2145,  loss: 0.20622141659259796\n",
      "Batch 2150,  loss: 0.18251049220561982\n",
      "Batch 2155,  loss: 0.22276812195777893\n",
      "Batch 2160,  loss: 0.1916605830192566\n",
      "Batch 2165,  loss: 0.19659729152917862\n",
      "Batch 2170,  loss: 0.21435872912406922\n",
      "Batch 2175,  loss: 0.21985969841480255\n",
      "Batch 2180,  loss: 0.24156754612922668\n",
      "Batch 2185,  loss: 0.18715964257717133\n",
      "Batch 2190,  loss: 0.23123206794261933\n",
      "Batch 2195,  loss: 0.20513927340507507\n",
      "Batch 2200,  loss: 0.17654883563518525\n",
      "Batch 2205,  loss: 0.2035004109144211\n",
      "Batch 2210,  loss: 0.17843303382396697\n",
      "Batch 2215,  loss: 0.21027534902095796\n",
      "Batch 2220,  loss: 0.18790063560009002\n",
      "Batch 2225,  loss: 0.2105420261621475\n",
      "Batch 2230,  loss: 0.16353797316551208\n",
      "Batch 2235,  loss: 0.18739539682865142\n",
      "Batch 2240,  loss: 0.1816830664873123\n",
      "Batch 2245,  loss: 0.2071780189871788\n",
      "Batch 2250,  loss: 0.19955772161483765\n",
      "Batch 2255,  loss: 0.17262183278799056\n",
      "Batch 2260,  loss: 0.1618548959493637\n",
      "Batch 2265,  loss: 0.2232936590909958\n",
      "Batch 2270,  loss: 0.15422111004590988\n",
      "Batch 2275,  loss: 0.1847115248441696\n",
      "Batch 2280,  loss: 0.20273589193820954\n",
      "Batch 2285,  loss: 0.14743984043598174\n",
      "Batch 2290,  loss: 0.18608906865119934\n",
      "Batch 2295,  loss: 0.20441502928733826\n",
      "Batch 2300,  loss: 0.21615290343761445\n",
      "Batch 2305,  loss: 0.21686829179525374\n",
      "Batch 2310,  loss: 0.22874971926212312\n",
      "Batch 2315,  loss: 0.23718550205230712\n",
      "Batch 2320,  loss: 0.20064381062984465\n",
      "Batch 2325,  loss: 0.15145600438117982\n",
      "Batch 2330,  loss: 0.1848570466041565\n",
      "Batch 2335,  loss: 0.1745784819126129\n",
      "Batch 2340,  loss: 0.20279714167118074\n",
      "Batch 2345,  loss: 0.19398168325424195\n",
      "Batch 2350,  loss: 0.18317601680755616\n",
      "Batch 2355,  loss: 0.17296386063098906\n",
      "Batch 2360,  loss: 0.17001111805438995\n",
      "Batch 2365,  loss: 0.22419283390045167\n",
      "Batch 2370,  loss: 0.16240094602108002\n",
      "Batch 2375,  loss: 0.15961094647645951\n",
      "Batch 2380,  loss: 0.16098507195711137\n",
      "Batch 2385,  loss: 0.20186320841312408\n",
      "Batch 2390,  loss: 0.27249317765235903\n",
      "Batch 2395,  loss: 0.20192324221134186\n",
      "Batch 2400,  loss: 0.1875853568315506\n",
      "Batch 2405,  loss: 0.20740464329719543\n",
      "Batch 2410,  loss: 0.21213669180870057\n",
      "Batch 2415,  loss: 0.19571002721786498\n",
      "Batch 2420,  loss: 0.13374864161014557\n",
      "Batch 2425,  loss: 0.20642878115177155\n",
      "Batch 2430,  loss: 0.17201170623302459\n",
      "Batch 2435,  loss: 0.2142443835735321\n",
      "Batch 2440,  loss: 0.17808138132095336\n",
      "Batch 2445,  loss: 0.23267409205436707\n",
      "Batch 2450,  loss: 0.20615771114826204\n",
      "Batch 2455,  loss: 0.21839667856693268\n",
      "Batch 2460,  loss: 0.2307220220565796\n",
      "Batch 2465,  loss: 0.20784340500831605\n",
      "Batch 2470,  loss: 0.17452118694782257\n",
      "Batch 2475,  loss: 0.20327962934970856\n",
      "Batch 2480,  loss: 0.15647200345993043\n",
      "Batch 2485,  loss: 0.23527280986309052\n",
      "Batch 2490,  loss: 0.19252078831195832\n",
      "Batch 2495,  loss: 0.2119532734155655\n",
      "Batch 2500,  loss: 0.16808000206947327\n",
      "Batch 2505,  loss: 0.19223126471042634\n",
      "Batch 2510,  loss: 0.18948708176612855\n",
      "Batch 2515,  loss: 0.23319481015205384\n",
      "Batch 2520,  loss: 0.19468820989131927\n",
      "Batch 2525,  loss: 0.18725430965423584\n",
      "Batch 2530,  loss: 0.17123704850673677\n",
      "Batch 2535,  loss: 0.17928519546985627\n",
      "Batch 2540,  loss: 0.21160030364990234\n",
      "Batch 2545,  loss: 0.2326511859893799\n",
      "Batch 2550,  loss: 0.20732203423976897\n",
      "Batch 2555,  loss: 0.16677305996418\n",
      "Batch 2560,  loss: 0.17736594378948212\n",
      "Batch 2565,  loss: 0.1947698712348938\n",
      "Batch 2570,  loss: 0.19178296029567718\n",
      "Batch 2575,  loss: 0.2081131249666214\n",
      "Batch 2580,  loss: 0.1468147963285446\n",
      "Batch 2585,  loss: 0.1549070030450821\n",
      "Batch 2590,  loss: 0.1816525638103485\n",
      "Batch 2595,  loss: 0.1865389972925186\n",
      "Batch 2600,  loss: 0.17144718170166015\n",
      "Batch 2605,  loss: 0.1798891991376877\n",
      "Batch 2610,  loss: 0.18817486763000488\n",
      "Batch 2615,  loss: 0.240947026014328\n",
      "Batch 2620,  loss: 0.17433909475803375\n",
      "Batch 2625,  loss: 0.23346062004566193\n",
      "Batch 2630,  loss: 0.15228682309389113\n",
      "Batch 2635,  loss: 0.192854805290699\n",
      "Batch 2640,  loss: 0.17411446571350098\n",
      "Batch 2645,  loss: 0.20679315328598022\n",
      "Batch 2650,  loss: 0.1874757319688797\n",
      "Batch 2655,  loss: 0.16949305832386016\n",
      "Batch 2660,  loss: 0.1912491112947464\n",
      "Batch 2665,  loss: 0.1970292419195175\n",
      "Batch 2670,  loss: 0.20214028805494308\n",
      "Batch 2675,  loss: 0.13706654459238052\n",
      "Batch 2680,  loss: 0.18720604181289674\n",
      "Batch 2685,  loss: 0.1699843406677246\n",
      "Batch 2690,  loss: 0.20239388346672058\n",
      "Batch 2695,  loss: 0.18601648807525634\n",
      "Batch 2700,  loss: 0.16038673520088195\n",
      "Batch 2705,  loss: 0.16353974044322966\n",
      "Batch 2710,  loss: 0.2108728274703026\n",
      "Batch 2715,  loss: 0.22684481143951415\n",
      "Batch 2720,  loss: 0.2336270660161972\n",
      "Batch 2725,  loss: 0.20691543817520142\n",
      "Batch 2730,  loss: 0.24801737070083618\n",
      "Batch 2735,  loss: 0.1923564165830612\n",
      "Batch 2740,  loss: 0.17156449556350709\n",
      "Batch 2745,  loss: 0.1954207181930542\n",
      "Batch 2750,  loss: 0.22535426616668702\n",
      "Batch 2755,  loss: 0.19622082114219666\n",
      "Batch 2760,  loss: 0.22856533527374268\n",
      "Batch 2765,  loss: 0.20979210436344148\n",
      "Batch 2770,  loss: 0.17723538875579833\n",
      "LOSS train 0.17723538875579833. Validation loss: 0.17130701829101547 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 11:\n",
      "Batch 5,  loss: 0.21487637162208556\n",
      "Batch 10,  loss: 0.20859462916851043\n",
      "Batch 15,  loss: 0.18821975588798523\n",
      "Batch 20,  loss: 0.1824624568223953\n",
      "Batch 25,  loss: 0.1972334712743759\n",
      "Batch 30,  loss: 0.15008260011672975\n",
      "Batch 35,  loss: 0.1458564043045044\n",
      "Batch 40,  loss: 0.19556022584438323\n",
      "Batch 45,  loss: 0.19881359338760377\n",
      "Batch 50,  loss: 0.20301284193992614\n",
      "Batch 55,  loss: 0.18600432872772216\n",
      "Batch 60,  loss: 0.1706258922815323\n",
      "Batch 65,  loss: 0.1989860713481903\n",
      "Batch 70,  loss: 0.18445694744586943\n",
      "Batch 75,  loss: 0.20885024964809418\n",
      "Batch 80,  loss: 0.1881936177611351\n",
      "Batch 85,  loss: 0.15891981422901152\n",
      "Batch 90,  loss: 0.2164896696805954\n",
      "Batch 95,  loss: 0.19028059542179107\n",
      "Batch 100,  loss: 0.1636674299836159\n",
      "Batch 105,  loss: 0.18373185992240906\n",
      "Batch 110,  loss: 0.20668951272964478\n",
      "Batch 115,  loss: 0.19557605683803558\n",
      "Batch 120,  loss: 0.18087977170944214\n",
      "Batch 125,  loss: 0.2149561643600464\n",
      "Batch 130,  loss: 0.1645282655954361\n",
      "Batch 135,  loss: 0.18154768347740174\n",
      "Batch 140,  loss: 0.166772723197937\n",
      "Batch 145,  loss: 0.19957314431667328\n",
      "Batch 150,  loss: 0.17631763219833374\n",
      "Batch 155,  loss: 0.20893536806106566\n",
      "Batch 160,  loss: 0.15632570385932923\n",
      "Batch 165,  loss: 0.20499964505434037\n",
      "Batch 170,  loss: 0.19053206443786622\n",
      "Batch 175,  loss: 0.22251320779323577\n",
      "Batch 180,  loss: 0.2019973427057266\n",
      "Batch 185,  loss: 0.21885285675525665\n",
      "Batch 190,  loss: 0.17985423505306244\n",
      "Batch 195,  loss: 0.19036078751087188\n",
      "Batch 200,  loss: 0.20763082206249237\n",
      "Batch 205,  loss: 0.17137813121080397\n",
      "Batch 210,  loss: 0.19649792611598968\n",
      "Batch 215,  loss: 0.20086480677127838\n",
      "Batch 220,  loss: 0.170322684943676\n",
      "Batch 225,  loss: 0.20901582837104798\n",
      "Batch 230,  loss: 0.2830005526542664\n",
      "Batch 235,  loss: 0.2109130471944809\n",
      "Batch 240,  loss: 0.1741564616560936\n",
      "Batch 245,  loss: 0.1998228758573532\n",
      "Batch 250,  loss: 0.20072475969791412\n",
      "Batch 255,  loss: 0.1649325370788574\n",
      "Batch 260,  loss: 0.18137820214033126\n",
      "Batch 265,  loss: 0.1631996214389801\n",
      "Batch 270,  loss: 0.15786994397640228\n",
      "Batch 275,  loss: 0.21682004034519195\n",
      "Batch 280,  loss: 0.16084609627723695\n",
      "Batch 285,  loss: 0.16660675406455994\n",
      "Batch 290,  loss: 0.1459788054227829\n",
      "Batch 295,  loss: 0.19490202367305756\n",
      "Batch 300,  loss: 0.1677206724882126\n",
      "Batch 305,  loss: 0.23449294567108153\n",
      "Batch 310,  loss: 0.20879244208335876\n",
      "Batch 315,  loss: 0.23521352410316468\n",
      "Batch 320,  loss: 0.18235376924276353\n",
      "Batch 325,  loss: 0.1912447541952133\n",
      "Batch 330,  loss: 0.15233549773693084\n",
      "Batch 335,  loss: 0.1809938967227936\n",
      "Batch 340,  loss: 0.15910061299800873\n",
      "Batch 345,  loss: 0.18026808202266692\n",
      "Batch 350,  loss: 0.14582570046186447\n",
      "Batch 355,  loss: 0.1999000996351242\n",
      "Batch 360,  loss: 0.16110028326511383\n",
      "Batch 365,  loss: 0.20862700641155243\n",
      "Batch 370,  loss: 0.22631433308124543\n",
      "Batch 375,  loss: 0.21305690258741378\n",
      "Batch 380,  loss: 0.20832796692848204\n",
      "Batch 385,  loss: 0.17689374089241028\n",
      "Batch 390,  loss: 0.2254892945289612\n",
      "Batch 395,  loss: 0.17207815796136855\n",
      "Batch 400,  loss: 0.2618568897247314\n",
      "Batch 405,  loss: 0.14183498919010162\n",
      "Batch 410,  loss: 0.21236854195594787\n",
      "Batch 415,  loss: 0.2351527690887451\n",
      "Batch 420,  loss: 0.22153564393520356\n",
      "Batch 425,  loss: 0.1725204333662987\n",
      "Batch 430,  loss: 0.18608313500881196\n",
      "Batch 435,  loss: 0.17738340198993682\n",
      "Batch 440,  loss: 0.18880678713321686\n",
      "Batch 445,  loss: 0.17584269493818283\n",
      "Batch 450,  loss: 0.21974711418151854\n",
      "Batch 455,  loss: 0.15804091095924377\n",
      "Batch 460,  loss: 0.1849653571844101\n",
      "Batch 465,  loss: 0.18820093870162963\n",
      "Batch 470,  loss: 0.16418367028236389\n",
      "Batch 475,  loss: 0.16429204642772674\n",
      "Batch 480,  loss: 0.2036331444978714\n",
      "Batch 485,  loss: 0.20856334269046783\n",
      "Batch 490,  loss: 0.19963208138942717\n",
      "Batch 495,  loss: 0.2114313080906868\n",
      "Batch 500,  loss: 0.18445129990577697\n",
      "Batch 505,  loss: 0.17882922291755676\n",
      "Batch 510,  loss: 0.1510125771164894\n",
      "Batch 515,  loss: 0.15449742078781128\n",
      "Batch 520,  loss: 0.23335719108581543\n",
      "Batch 525,  loss: 0.20669153928756714\n",
      "Batch 530,  loss: 0.19672867953777312\n",
      "Batch 535,  loss: 0.2448952615261078\n",
      "Batch 540,  loss: 0.2023901790380478\n",
      "Batch 545,  loss: 0.20432652533054352\n",
      "Batch 550,  loss: 0.19208823442459105\n",
      "Batch 555,  loss: 0.17177452147006989\n",
      "Batch 560,  loss: 0.16649261713027955\n",
      "Batch 565,  loss: 0.19314821511507035\n",
      "Batch 570,  loss: 0.18010860979557036\n",
      "Batch 575,  loss: 0.1875619560480118\n",
      "Batch 580,  loss: 0.1997595727443695\n",
      "Batch 585,  loss: 0.19144913405179978\n",
      "Batch 590,  loss: 0.19201331734657287\n",
      "Batch 595,  loss: 0.20693159401416777\n",
      "Batch 600,  loss: 0.2151120960712433\n",
      "Batch 605,  loss: 0.17283710539340974\n",
      "Batch 610,  loss: 0.1754956677556038\n",
      "Batch 615,  loss: 0.19999719858169557\n",
      "Batch 620,  loss: 0.1559093937277794\n",
      "Batch 625,  loss: 0.1741569995880127\n",
      "Batch 630,  loss: 0.2161762535572052\n",
      "Batch 635,  loss: 0.18037961125373841\n",
      "Batch 640,  loss: 0.15740756094455718\n",
      "Batch 645,  loss: 0.19904099702835082\n",
      "Batch 650,  loss: 0.2157920181751251\n",
      "Batch 655,  loss: 0.152749265730381\n",
      "Batch 660,  loss: 0.19078552424907685\n",
      "Batch 665,  loss: 0.20776810646057128\n",
      "Batch 670,  loss: 0.18973625004291533\n",
      "Batch 675,  loss: 0.17021517753601073\n",
      "Batch 680,  loss: 0.16381245255470275\n",
      "Batch 685,  loss: 0.17992685735225677\n",
      "Batch 690,  loss: 0.22538862228393555\n",
      "Batch 695,  loss: 0.23332713544368744\n",
      "Batch 700,  loss: 0.25229546427726746\n",
      "Batch 705,  loss: 0.19081056416034697\n",
      "Batch 710,  loss: 0.17618303000926971\n",
      "Batch 715,  loss: 0.1761101633310318\n",
      "Batch 720,  loss: 0.19155192673206328\n",
      "Batch 725,  loss: 0.20219235122203827\n",
      "Batch 730,  loss: 0.1678883507847786\n",
      "Batch 735,  loss: 0.17088230848312377\n",
      "Batch 740,  loss: 0.2337869867682457\n",
      "Batch 745,  loss: 0.22926583588123323\n",
      "Batch 750,  loss: 0.15178568065166473\n",
      "Batch 755,  loss: 0.21471360325813293\n",
      "Batch 760,  loss: 0.22112857103347777\n",
      "Batch 765,  loss: 0.211933633685112\n",
      "Batch 770,  loss: 0.19530907571315764\n",
      "Batch 775,  loss: 0.20030811429023743\n",
      "Batch 780,  loss: 0.23099823594093322\n",
      "Batch 785,  loss: 0.2383595108985901\n",
      "Batch 790,  loss: 0.2012135609984398\n",
      "Batch 795,  loss: 0.189669930934906\n",
      "Batch 800,  loss: 0.17564139366149903\n",
      "Batch 805,  loss: 0.1867104321718216\n",
      "Batch 810,  loss: 0.1905687764286995\n",
      "Batch 815,  loss: 0.1900218352675438\n",
      "Batch 820,  loss: 0.17138782143592834\n",
      "Batch 825,  loss: 0.17544649243354798\n",
      "Batch 830,  loss: 0.21271972060203553\n",
      "Batch 835,  loss: 0.1344526082277298\n",
      "Batch 840,  loss: 0.14629446864128112\n",
      "Batch 845,  loss: 0.17138103544712066\n",
      "Batch 850,  loss: 0.19317877292633057\n",
      "Batch 855,  loss: 0.2091697037220001\n",
      "Batch 860,  loss: 0.1787274032831192\n",
      "Batch 865,  loss: 0.19668341428041458\n",
      "Batch 870,  loss: 0.1939063310623169\n",
      "Batch 875,  loss: 0.18718284964561463\n",
      "Batch 880,  loss: 0.18389660269021987\n",
      "Batch 885,  loss: 0.21197525560855865\n",
      "Batch 890,  loss: 0.23892827033996583\n",
      "Batch 895,  loss: 0.21110116243362426\n",
      "Batch 900,  loss: 0.17031739056110382\n",
      "Batch 905,  loss: 0.17483181953430177\n",
      "Batch 910,  loss: 0.1473667651414871\n",
      "Batch 915,  loss: 0.18912074565887452\n",
      "Batch 920,  loss: 0.2031878799200058\n",
      "Batch 925,  loss: 0.18405941128730774\n",
      "Batch 930,  loss: 0.15978721976280214\n",
      "Batch 935,  loss: 0.234776172041893\n",
      "Batch 940,  loss: 0.17486331462860108\n",
      "Batch 945,  loss: 0.15199778825044633\n",
      "Batch 950,  loss: 0.15193025171756744\n",
      "Batch 955,  loss: 0.17941973507404327\n",
      "Batch 960,  loss: 0.16364606320858002\n",
      "Batch 965,  loss: 0.207593235373497\n",
      "Batch 970,  loss: 0.20160282850265504\n",
      "Batch 975,  loss: 0.22003243565559388\n",
      "Batch 980,  loss: 0.1620118498802185\n",
      "Batch 985,  loss: 0.2001734495162964\n",
      "Batch 990,  loss: 0.1863267034292221\n",
      "Batch 995,  loss: 0.16238385438919067\n",
      "Batch 1000,  loss: 0.1917585015296936\n",
      "Batch 1005,  loss: 0.198251211643219\n",
      "Batch 1010,  loss: 0.21288516521453857\n",
      "Batch 1015,  loss: 0.1753138780593872\n",
      "Batch 1020,  loss: 0.21554807722568511\n",
      "Batch 1025,  loss: 0.15602682530879974\n",
      "Batch 1030,  loss: 0.19042826294898987\n",
      "Batch 1035,  loss: 0.1850590318441391\n",
      "Batch 1040,  loss: 0.19073273837566376\n",
      "Batch 1045,  loss: 0.18268582820892335\n",
      "Batch 1050,  loss: 0.19436807334423065\n",
      "Batch 1055,  loss: 0.20477294325828552\n",
      "Batch 1060,  loss: 0.17331011295318605\n",
      "Batch 1065,  loss: 0.2110191285610199\n",
      "Batch 1070,  loss: 0.2507176846265793\n",
      "Batch 1075,  loss: 0.2331092119216919\n",
      "Batch 1080,  loss: 0.23672833144664765\n",
      "Batch 1085,  loss: 0.2216822922229767\n",
      "Batch 1090,  loss: 0.18807086795568467\n",
      "Batch 1095,  loss: 0.19726159870624543\n",
      "Batch 1100,  loss: 0.16286325752735137\n",
      "Batch 1105,  loss: 0.18292780518531798\n",
      "Batch 1110,  loss: 0.17396450638771058\n",
      "Batch 1115,  loss: 0.190165676176548\n",
      "Batch 1120,  loss: 0.206608547270298\n",
      "Batch 1125,  loss: 0.18340417444705964\n",
      "Batch 1130,  loss: 0.1847234845161438\n",
      "Batch 1135,  loss: 0.18762877583503723\n",
      "Batch 1140,  loss: 0.17191769778728486\n",
      "Batch 1145,  loss: 0.19494431614875793\n",
      "Batch 1150,  loss: 0.17019393146038056\n",
      "Batch 1155,  loss: 0.1829006552696228\n",
      "Batch 1160,  loss: 0.1501257985830307\n",
      "Batch 1165,  loss: 0.17834954857826232\n",
      "Batch 1170,  loss: 0.19041147232055664\n",
      "Batch 1175,  loss: 0.19854391515254974\n",
      "Batch 1180,  loss: 0.1864444613456726\n",
      "Batch 1185,  loss: 0.24398272931575776\n",
      "Batch 1190,  loss: 0.1918273538351059\n",
      "Batch 1195,  loss: 0.2241963267326355\n",
      "Batch 1200,  loss: 0.2748676836490631\n",
      "Batch 1205,  loss: 0.17090605795383454\n",
      "Batch 1210,  loss: 0.18694775700569152\n",
      "Batch 1215,  loss: 0.17392775118350984\n",
      "Batch 1220,  loss: 0.17336570620536804\n",
      "Batch 1225,  loss: 0.22219960391521454\n",
      "Batch 1230,  loss: 0.22264354526996613\n",
      "Batch 1235,  loss: 0.15908849090337754\n",
      "Batch 1240,  loss: 0.14658710360527039\n",
      "Batch 1245,  loss: 0.22939735949039458\n",
      "Batch 1250,  loss: 0.20863957107067108\n",
      "Batch 1255,  loss: 0.2008486270904541\n",
      "Batch 1260,  loss: 0.19151792526245118\n",
      "Batch 1265,  loss: 0.14787934571504593\n",
      "Batch 1270,  loss: 0.15497197806835175\n",
      "Batch 1275,  loss: 0.17562807500362396\n",
      "Batch 1280,  loss: 0.21465803682804108\n",
      "Batch 1285,  loss: 0.148735149204731\n",
      "Batch 1290,  loss: 0.15699096620082856\n",
      "Batch 1295,  loss: 0.2155139774084091\n",
      "Batch 1300,  loss: 0.19438823759555818\n",
      "Batch 1305,  loss: 0.24723079800605774\n",
      "Batch 1310,  loss: 0.22261822521686553\n",
      "Batch 1315,  loss: 0.23486444503068923\n",
      "Batch 1320,  loss: 0.18529284000396729\n",
      "Batch 1325,  loss: 0.23510027527809144\n",
      "Batch 1330,  loss: 0.19409841001033784\n",
      "Batch 1335,  loss: 0.19528938233852386\n",
      "Batch 1340,  loss: 0.17373201847076417\n",
      "Batch 1345,  loss: 0.19101676046848298\n",
      "Batch 1350,  loss: 0.22552785873413086\n",
      "Batch 1355,  loss: 0.1658059075474739\n",
      "Batch 1360,  loss: 0.18265478312969208\n",
      "Batch 1365,  loss: 0.18582087457180024\n",
      "Batch 1370,  loss: 0.2165220186114311\n",
      "Batch 1375,  loss: 0.18171958923339843\n",
      "Batch 1380,  loss: 0.20898807942867278\n",
      "Batch 1385,  loss: 0.14824936389923096\n",
      "Batch 1390,  loss: 0.16912160515785218\n",
      "Batch 1395,  loss: 0.16197284758090974\n",
      "Batch 1400,  loss: 0.20175234079360962\n",
      "Batch 1405,  loss: 0.1764736533164978\n",
      "Batch 1410,  loss: 0.17928179800510408\n",
      "Batch 1415,  loss: 0.19764796197414397\n",
      "Batch 1420,  loss: 0.17996942698955537\n",
      "Batch 1425,  loss: 0.19344083070755005\n",
      "Batch 1430,  loss: 0.16722587049007415\n",
      "Batch 1435,  loss: 0.20283533334732057\n",
      "Batch 1440,  loss: 0.14629335105419158\n",
      "Batch 1445,  loss: 0.26419169306755064\n",
      "Batch 1450,  loss: 0.18871164619922637\n",
      "Batch 1455,  loss: 0.16355402767658234\n",
      "Batch 1460,  loss: 0.21379750669002534\n",
      "Batch 1465,  loss: 0.19241127669811248\n",
      "Batch 1470,  loss: 0.17504942566156387\n",
      "Batch 1475,  loss: 0.1807700589299202\n",
      "Batch 1480,  loss: 0.13828292936086656\n",
      "Batch 1485,  loss: 0.1806679517030716\n",
      "Batch 1490,  loss: 0.20230807662010192\n",
      "Batch 1495,  loss: 0.18873668015003203\n",
      "Batch 1500,  loss: 0.15744305551052093\n",
      "Batch 1505,  loss: 0.1762126088142395\n",
      "Batch 1510,  loss: 0.20090193152427674\n",
      "Batch 1515,  loss: 0.19043971598148346\n",
      "Batch 1520,  loss: 0.15890000462532045\n",
      "Batch 1525,  loss: 0.19226407259702682\n",
      "Batch 1530,  loss: 0.14282652139663696\n",
      "Batch 1535,  loss: 0.1807383641600609\n",
      "Batch 1540,  loss: 0.19503874480724334\n",
      "Batch 1545,  loss: 0.18727895319461824\n",
      "Batch 1550,  loss: 0.15913112908601762\n",
      "Batch 1555,  loss: 0.1368442580103874\n",
      "Batch 1560,  loss: 0.227121901512146\n",
      "Batch 1565,  loss: 0.17118650376796724\n",
      "Batch 1570,  loss: 0.20916727781295777\n",
      "Batch 1575,  loss: 0.2090534448623657\n",
      "Batch 1580,  loss: 0.22131122648715973\n",
      "Batch 1585,  loss: 0.16671786308288575\n",
      "Batch 1590,  loss: 0.16711982786655427\n",
      "Batch 1595,  loss: 0.1803755134344101\n",
      "Batch 1600,  loss: 0.1679783970117569\n",
      "Batch 1605,  loss: 0.18580285012722014\n",
      "Batch 1610,  loss: 0.23508186191320418\n",
      "Batch 1615,  loss: 0.17645999789237976\n",
      "Batch 1620,  loss: 0.17290950417518616\n",
      "Batch 1625,  loss: 0.16592551320791243\n",
      "Batch 1630,  loss: 0.1859876662492752\n",
      "Batch 1635,  loss: 0.22286348342895507\n",
      "Batch 1640,  loss: 0.17290623486042023\n",
      "Batch 1645,  loss: 0.20303546786308288\n",
      "Batch 1650,  loss: 0.16258863508701324\n",
      "Batch 1655,  loss: 0.19748270511627197\n",
      "Batch 1660,  loss: 0.17879742681980132\n",
      "Batch 1665,  loss: 0.1531907081604004\n",
      "Batch 1670,  loss: 0.2219359338283539\n",
      "Batch 1675,  loss: 0.19900423884391785\n",
      "Batch 1680,  loss: 0.2028648793697357\n",
      "Batch 1685,  loss: 0.1527683675289154\n",
      "Batch 1690,  loss: 0.19191565364599228\n",
      "Batch 1695,  loss: 0.2590734988451004\n",
      "Batch 1700,  loss: 0.16238753497600555\n",
      "Batch 1705,  loss: 0.2097923457622528\n",
      "Batch 1710,  loss: 0.21430272310972215\n",
      "Batch 1715,  loss: 0.20350248217582703\n",
      "Batch 1720,  loss: 0.19335517436265945\n",
      "Batch 1725,  loss: 0.1840446949005127\n",
      "Batch 1730,  loss: 0.19006545692682267\n",
      "Batch 1735,  loss: 0.14208880215883254\n",
      "Batch 1740,  loss: 0.17836771309375762\n",
      "Batch 1745,  loss: 0.21353094279766083\n",
      "Batch 1750,  loss: 0.22540275156497955\n",
      "Batch 1755,  loss: 0.21538244783878327\n",
      "Batch 1760,  loss: 0.18721391260623932\n",
      "Batch 1765,  loss: 0.20155254304409026\n",
      "Batch 1770,  loss: 0.20232230722904204\n",
      "Batch 1775,  loss: 0.22249048948287964\n",
      "Batch 1780,  loss: 0.16954646706581117\n",
      "Batch 1785,  loss: 0.1837472528219223\n",
      "Batch 1790,  loss: 0.18293988555669785\n",
      "Batch 1795,  loss: 0.2196637660264969\n",
      "Batch 1800,  loss: 0.21766569018363952\n",
      "Batch 1805,  loss: 0.22058095932006835\n",
      "Batch 1810,  loss: 0.14579400420188904\n",
      "Batch 1815,  loss: 0.1929679721593857\n",
      "Batch 1820,  loss: 0.2003265917301178\n",
      "Batch 1825,  loss: 0.19989923536777496\n",
      "Batch 1830,  loss: 0.18572039902210236\n",
      "Batch 1835,  loss: 0.18076052367687226\n",
      "Batch 1840,  loss: 0.21007634699344635\n",
      "Batch 1845,  loss: 0.19534913152456285\n",
      "Batch 1850,  loss: 0.19552443027496338\n",
      "Batch 1855,  loss: 0.18698025345802308\n",
      "Batch 1860,  loss: 0.2524491876363754\n",
      "Batch 1865,  loss: 0.15395109802484513\n",
      "Batch 1870,  loss: 0.21371661722660065\n",
      "Batch 1875,  loss: 0.21616198420524596\n",
      "Batch 1880,  loss: 0.1933121234178543\n",
      "Batch 1885,  loss: 0.19202380180358886\n",
      "Batch 1890,  loss: 0.15842171907424926\n",
      "Batch 1895,  loss: 0.14736025780439377\n",
      "Batch 1900,  loss: 0.17299797236919404\n",
      "Batch 1905,  loss: 0.22749352902173997\n",
      "Batch 1910,  loss: 0.2255079984664917\n",
      "Batch 1915,  loss: 0.23232998251914977\n",
      "Batch 1920,  loss: 0.25747338533401487\n",
      "Batch 1925,  loss: 0.17480306029319764\n",
      "Batch 1930,  loss: 0.1847526401281357\n",
      "Batch 1935,  loss: 0.17950697839260102\n",
      "Batch 1940,  loss: 0.24124048948287963\n",
      "Batch 1945,  loss: 0.1956466943025589\n",
      "Batch 1950,  loss: 0.2283722698688507\n",
      "Batch 1955,  loss: 0.18760616183280945\n",
      "Batch 1960,  loss: 0.16762838512659073\n",
      "Batch 1965,  loss: 0.21956235766410828\n",
      "Batch 1970,  loss: 0.20903290212154388\n",
      "Batch 1975,  loss: 0.16525333225727082\n",
      "Batch 1980,  loss: 0.13610863387584687\n",
      "Batch 1985,  loss: 0.20934424698352813\n",
      "Batch 1990,  loss: 0.2006717562675476\n",
      "Batch 1995,  loss: 0.1819325193762779\n",
      "Batch 2000,  loss: 0.1560886561870575\n",
      "Batch 2005,  loss: 0.22432781755924225\n",
      "Batch 2010,  loss: 0.22862388491630553\n",
      "Batch 2015,  loss: 0.16781060695648192\n",
      "Batch 2020,  loss: 0.1609547734260559\n",
      "Batch 2025,  loss: 0.1631615698337555\n",
      "Batch 2030,  loss: 0.20696435868740082\n",
      "Batch 2035,  loss: 0.20489292740821838\n",
      "Batch 2040,  loss: 0.19525158107280732\n",
      "Batch 2045,  loss: 0.1800265222787857\n",
      "Batch 2050,  loss: 0.18845959901809692\n",
      "Batch 2055,  loss: 0.20754702389240265\n",
      "Batch 2060,  loss: 0.1259641095995903\n",
      "Batch 2065,  loss: 0.20506096482276917\n",
      "Batch 2070,  loss: 0.17998722791671753\n",
      "Batch 2075,  loss: 0.16278771460056304\n",
      "Batch 2080,  loss: 0.19376382529735564\n",
      "Batch 2085,  loss: 0.20409488379955293\n",
      "Batch 2090,  loss: 0.1808869555592537\n",
      "Batch 2095,  loss: 0.20215854048728943\n",
      "Batch 2100,  loss: 0.18343096673488618\n",
      "Batch 2105,  loss: 0.16714936196804048\n",
      "Batch 2110,  loss: 0.1903480812907219\n",
      "Batch 2115,  loss: 0.16872601509094237\n",
      "Batch 2120,  loss: 0.15887391865253447\n",
      "Batch 2125,  loss: 0.19750769138336183\n",
      "Batch 2130,  loss: 0.20745778679847718\n",
      "Batch 2135,  loss: 0.18207562267780303\n",
      "Batch 2140,  loss: 0.20576609969139098\n",
      "Batch 2145,  loss: 0.16540761590003966\n",
      "Batch 2150,  loss: 0.20830438733100892\n",
      "Batch 2155,  loss: 0.16747266948223113\n",
      "Batch 2160,  loss: 0.1695497751235962\n",
      "Batch 2165,  loss: 0.17821740508079528\n",
      "Batch 2170,  loss: 0.20267969369888306\n",
      "Batch 2175,  loss: 0.2587644100189209\n",
      "Batch 2180,  loss: 0.16098156273365022\n",
      "Batch 2185,  loss: 0.18372368365526198\n",
      "Batch 2190,  loss: 0.17436256110668183\n",
      "Batch 2195,  loss: 0.18708879351615906\n",
      "Batch 2200,  loss: 0.147663813829422\n",
      "Batch 2205,  loss: 0.17906338572502137\n",
      "Batch 2210,  loss: 0.18731530904769897\n",
      "Batch 2215,  loss: 0.18700439035892485\n",
      "Batch 2220,  loss: 0.21862520575523375\n",
      "Batch 2225,  loss: 0.2601208984851837\n",
      "Batch 2230,  loss: 0.13368213325738906\n",
      "Batch 2235,  loss: 0.17380671799182892\n",
      "Batch 2240,  loss: 0.15480449199676513\n",
      "Batch 2245,  loss: 0.24387792348861695\n",
      "Batch 2250,  loss: 0.1783214971423149\n",
      "Batch 2255,  loss: 0.22801079154014586\n",
      "Batch 2260,  loss: 0.1745558962225914\n",
      "Batch 2265,  loss: 0.2185786098241806\n",
      "Batch 2270,  loss: 0.2699546366930008\n",
      "Batch 2275,  loss: 0.18120228350162507\n",
      "Batch 2280,  loss: 0.19377152621746063\n",
      "Batch 2285,  loss: 0.2104903757572174\n",
      "Batch 2290,  loss: 0.191087543964386\n",
      "Batch 2295,  loss: 0.22686817944049836\n",
      "Batch 2300,  loss: 0.19685157239437104\n",
      "Batch 2305,  loss: 0.20609000325202942\n",
      "Batch 2310,  loss: 0.2134706199169159\n",
      "Batch 2315,  loss: 0.24081298410892488\n",
      "Batch 2320,  loss: 0.21748072803020477\n",
      "Batch 2325,  loss: 0.16717539429664613\n",
      "Batch 2330,  loss: 0.20455928146839142\n",
      "Batch 2335,  loss: 0.26863240599632265\n",
      "Batch 2340,  loss: 0.16049997508525848\n",
      "Batch 2345,  loss: 0.16450296938419343\n",
      "Batch 2350,  loss: 0.17875873744487764\n",
      "Batch 2355,  loss: 0.16441736221313477\n",
      "Batch 2360,  loss: 0.22767480909824372\n",
      "Batch 2365,  loss: 0.1971510648727417\n",
      "Batch 2370,  loss: 0.17588721215724945\n",
      "Batch 2375,  loss: 0.16108766496181487\n",
      "Batch 2380,  loss: 0.2227273017168045\n",
      "Batch 2385,  loss: 0.20537087917327881\n",
      "Batch 2390,  loss: 0.20286020934581755\n",
      "Batch 2395,  loss: 0.1923021987080574\n",
      "Batch 2400,  loss: 0.22231233417987822\n",
      "Batch 2405,  loss: 0.14285992085933685\n",
      "Batch 2410,  loss: 0.19276773035526276\n",
      "Batch 2415,  loss: 0.1740583598613739\n",
      "Batch 2420,  loss: 0.18239398300647736\n",
      "Batch 2425,  loss: 0.23409171998500825\n",
      "Batch 2430,  loss: 0.16891158521175384\n",
      "Batch 2435,  loss: 0.18085147738456725\n",
      "Batch 2440,  loss: 0.25245930552482604\n",
      "Batch 2445,  loss: 0.15902286767959595\n",
      "Batch 2450,  loss: 0.15957274436950683\n",
      "Batch 2455,  loss: 0.22617908716201782\n",
      "Batch 2460,  loss: 0.1839499443769455\n",
      "Batch 2465,  loss: 0.1657272219657898\n",
      "Batch 2470,  loss: 0.17607741951942443\n",
      "Batch 2475,  loss: 0.18272574245929718\n",
      "Batch 2480,  loss: 0.14128268212080003\n",
      "Batch 2485,  loss: 0.19598992317914962\n",
      "Batch 2490,  loss: 0.22003032267093658\n",
      "Batch 2495,  loss: 0.18244426250457763\n",
      "Batch 2500,  loss: 0.19111557006835939\n",
      "Batch 2505,  loss: 0.22346579730510713\n",
      "Batch 2510,  loss: 0.24506378471851348\n",
      "Batch 2515,  loss: 0.20691978335380554\n",
      "Batch 2520,  loss: 0.2220007598400116\n",
      "Batch 2525,  loss: 0.1955281287431717\n",
      "Batch 2530,  loss: 0.17406449913978578\n",
      "Batch 2535,  loss: 0.19302488565444947\n",
      "Batch 2540,  loss: 0.17996716797351836\n",
      "Batch 2545,  loss: 0.18595268726348876\n",
      "Batch 2550,  loss: 0.21064917445182801\n",
      "Batch 2555,  loss: 0.22362554520368577\n",
      "Batch 2560,  loss: 0.240672966837883\n",
      "Batch 2565,  loss: 0.23881622552871704\n",
      "Batch 2570,  loss: 0.19976697266101837\n",
      "Batch 2575,  loss: 0.19347251057624817\n",
      "Batch 2580,  loss: 0.22196742594242097\n",
      "Batch 2585,  loss: 0.16507525742053986\n",
      "Batch 2590,  loss: 0.18207679837942123\n",
      "Batch 2595,  loss: 0.18941400051116944\n",
      "Batch 2600,  loss: 0.21154384613037108\n",
      "Batch 2605,  loss: 0.2346576452255249\n",
      "Batch 2610,  loss: 0.16809769719839096\n",
      "Batch 2615,  loss: 0.16386926770210267\n",
      "Batch 2620,  loss: 0.20575959384441375\n",
      "Batch 2625,  loss: 0.15583548843860626\n",
      "Batch 2630,  loss: 0.15502604842185974\n",
      "Batch 2635,  loss: 0.19118643701076507\n",
      "Batch 2640,  loss: 0.21125175356864928\n",
      "Batch 2645,  loss: 0.196198570728302\n",
      "Batch 2650,  loss: 0.20023439228534698\n",
      "Batch 2655,  loss: 0.2133723944425583\n",
      "Batch 2660,  loss: 0.19476327896118165\n",
      "Batch 2665,  loss: 0.1706215411424637\n",
      "Batch 2670,  loss: 0.18008774966001512\n",
      "Batch 2675,  loss: 0.1989127829670906\n",
      "Batch 2680,  loss: 0.1699971929192543\n",
      "Batch 2685,  loss: 0.17200470268726348\n",
      "Batch 2690,  loss: 0.19433035254478453\n",
      "Batch 2695,  loss: 0.19546380043029785\n",
      "Batch 2700,  loss: 0.22873755395412446\n",
      "Batch 2705,  loss: 0.20852928459644318\n",
      "Batch 2710,  loss: 0.1839734435081482\n",
      "Batch 2715,  loss: 0.17033311128616332\n",
      "Batch 2720,  loss: 0.20693382918834685\n",
      "Batch 2725,  loss: 0.16892495453357698\n",
      "Batch 2730,  loss: 0.17945688366889953\n",
      "Batch 2735,  loss: 0.19142772555351256\n",
      "Batch 2740,  loss: 0.15586512684822082\n",
      "Batch 2745,  loss: 0.164987775683403\n",
      "Batch 2750,  loss: 0.1934240758419037\n",
      "Batch 2755,  loss: 0.1999143272638321\n",
      "Batch 2760,  loss: 0.17889578342437745\n",
      "Batch 2765,  loss: 0.18285158425569534\n",
      "Batch 2770,  loss: 0.17489833235740662\n",
      "LOSS train 0.17489833235740662. Validation loss: 0.1711386251953189 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 12:\n",
      "Batch 5,  loss: 0.20176216959953308\n",
      "Batch 10,  loss: 0.2079640358686447\n",
      "Batch 15,  loss: 0.2016596257686615\n",
      "Batch 20,  loss: 0.14578676223754883\n",
      "Batch 25,  loss: 0.18904513120651245\n",
      "Batch 30,  loss: 0.1618521973490715\n",
      "Batch 35,  loss: 0.2007134348154068\n",
      "Batch 40,  loss: 0.15410242676734925\n",
      "Batch 45,  loss: 0.1786922186613083\n",
      "Batch 50,  loss: 0.2230530470609665\n",
      "Batch 55,  loss: 0.21451505422592163\n",
      "Batch 60,  loss: 0.1977905422449112\n",
      "Batch 65,  loss: 0.16580272912979127\n",
      "Batch 70,  loss: 0.22096056044101714\n",
      "Batch 75,  loss: 0.21560557782649994\n",
      "Batch 80,  loss: 0.1895900011062622\n",
      "Batch 85,  loss: 0.18115632236003876\n",
      "Batch 90,  loss: 0.15691592991352082\n",
      "Batch 95,  loss: 0.18627047240734101\n",
      "Batch 100,  loss: 0.20529596209526063\n",
      "Batch 105,  loss: 0.17962823808193207\n",
      "Batch 110,  loss: 0.22075039148330688\n",
      "Batch 115,  loss: 0.18926663398742677\n",
      "Batch 120,  loss: 0.242095747590065\n",
      "Batch 125,  loss: 0.22015270441770554\n",
      "Batch 130,  loss: 0.20844444036483764\n",
      "Batch 135,  loss: 0.22951766848564148\n",
      "Batch 140,  loss: 0.15031042397022248\n",
      "Batch 145,  loss: 0.16986394822597503\n",
      "Batch 150,  loss: 0.23428190052509307\n",
      "Batch 155,  loss: 0.21539624333381652\n",
      "Batch 160,  loss: 0.17516982853412627\n",
      "Batch 165,  loss: 0.20414080917835237\n",
      "Batch 170,  loss: 0.23638397753238677\n",
      "Batch 175,  loss: 0.17891623377799987\n",
      "Batch 180,  loss: 0.1719034045934677\n",
      "Batch 185,  loss: 0.2151194453239441\n",
      "Batch 190,  loss: 0.16503751277923584\n",
      "Batch 195,  loss: 0.19148550629615785\n",
      "Batch 200,  loss: 0.20082052946090698\n",
      "Batch 205,  loss: 0.19501589983701706\n",
      "Batch 210,  loss: 0.16026056408882142\n",
      "Batch 215,  loss: 0.18093445301055908\n",
      "Batch 220,  loss: 0.15406161099672316\n",
      "Batch 225,  loss: 0.18879604935646058\n",
      "Batch 230,  loss: 0.18019298315048218\n",
      "Batch 235,  loss: 0.23800524771213533\n",
      "Batch 240,  loss: 0.15663108229637146\n",
      "Batch 245,  loss: 0.13350435197353364\n",
      "Batch 250,  loss: 0.18036497831344606\n",
      "Batch 255,  loss: 0.18051656782627107\n",
      "Batch 260,  loss: 0.19774277806282042\n",
      "Batch 265,  loss: 0.1524501472711563\n",
      "Batch 270,  loss: 0.1857171207666397\n",
      "Batch 275,  loss: 0.1802538275718689\n",
      "Batch 280,  loss: 0.158094921708107\n",
      "Batch 285,  loss: 0.17556520998477937\n",
      "Batch 290,  loss: 0.24419552981853485\n",
      "Batch 295,  loss: 0.21333855092525483\n",
      "Batch 300,  loss: 0.16210999190807343\n",
      "Batch 305,  loss: 0.18357967138290404\n",
      "Batch 310,  loss: 0.21337631344795227\n",
      "Batch 315,  loss: 0.16990570425987245\n",
      "Batch 320,  loss: 0.15795458257198333\n",
      "Batch 325,  loss: 0.18326297849416734\n",
      "Batch 330,  loss: 0.16889938414096833\n",
      "Batch 335,  loss: 0.1792360156774521\n",
      "Batch 340,  loss: 0.15948921740055083\n",
      "Batch 345,  loss: 0.19598084688186646\n",
      "Batch 350,  loss: 0.15918948054313659\n",
      "Batch 355,  loss: 0.20163248479366302\n",
      "Batch 360,  loss: 0.17785344123840333\n",
      "Batch 365,  loss: 0.17850618958473205\n",
      "Batch 370,  loss: 0.1774517297744751\n",
      "Batch 375,  loss: 0.19545693695545197\n",
      "Batch 380,  loss: 0.1741454482078552\n",
      "Batch 385,  loss: 0.19326165020465852\n",
      "Batch 390,  loss: 0.21353605687618255\n",
      "Batch 395,  loss: 0.15385002195835112\n",
      "Batch 400,  loss: 0.20713453590869904\n",
      "Batch 405,  loss: 0.1508765399456024\n",
      "Batch 410,  loss: 0.17747555673122406\n",
      "Batch 415,  loss: 0.21073492765426635\n",
      "Batch 420,  loss: 0.1870315730571747\n",
      "Batch 425,  loss: 0.1824986755847931\n",
      "Batch 430,  loss: 0.19733619689941406\n",
      "Batch 435,  loss: 0.2090587019920349\n",
      "Batch 440,  loss: 0.17185768783092498\n",
      "Batch 445,  loss: 0.20112963914871215\n",
      "Batch 450,  loss: 0.16229403614997864\n",
      "Batch 455,  loss: 0.19029034972190856\n",
      "Batch 460,  loss: 0.1615608289837837\n",
      "Batch 465,  loss: 0.15723822265863419\n",
      "Batch 470,  loss: 0.15557695627212526\n",
      "Batch 475,  loss: 0.21576033532619476\n",
      "Batch 480,  loss: 0.13801126182079315\n",
      "Batch 485,  loss: 0.21393225193023682\n",
      "Batch 490,  loss: 0.20191563963890075\n",
      "Batch 495,  loss: 0.17123990952968599\n",
      "Batch 500,  loss: 0.21437447667121887\n",
      "Batch 505,  loss: 0.1741752177476883\n",
      "Batch 510,  loss: 0.1543432965874672\n",
      "Batch 515,  loss: 0.2086273968219757\n",
      "Batch 520,  loss: 0.20315802097320557\n",
      "Batch 525,  loss: 0.1700268119573593\n",
      "Batch 530,  loss: 0.21428394913673401\n",
      "Batch 535,  loss: 0.16253597140312195\n",
      "Batch 540,  loss: 0.22181379199028015\n",
      "Batch 545,  loss: 0.1799347311258316\n",
      "Batch 550,  loss: 0.17116392850875856\n",
      "Batch 555,  loss: 0.1648781716823578\n",
      "Batch 560,  loss: 0.18690296411514282\n",
      "Batch 565,  loss: 0.18656365275382997\n",
      "Batch 570,  loss: 0.19537337720394135\n",
      "Batch 575,  loss: 0.18948754966259002\n",
      "Batch 580,  loss: 0.18928864896297454\n",
      "Batch 585,  loss: 0.16577301025390626\n",
      "Batch 590,  loss: 0.1661161959171295\n",
      "Batch 595,  loss: 0.16701388955116273\n",
      "Batch 600,  loss: 0.17890763580799102\n",
      "Batch 605,  loss: 0.1738862857222557\n",
      "Batch 610,  loss: 0.17911561131477355\n",
      "Batch 615,  loss: 0.19210593551397323\n",
      "Batch 620,  loss: 0.23470961749553682\n",
      "Batch 625,  loss: 0.22305381596088408\n",
      "Batch 630,  loss: 0.18823715001344682\n",
      "Batch 635,  loss: 0.1730044960975647\n",
      "Batch 640,  loss: 0.18764986097812653\n",
      "Batch 645,  loss: 0.22412447333335878\n",
      "Batch 650,  loss: 0.1738848567008972\n",
      "Batch 655,  loss: 0.22041276693344117\n",
      "Batch 660,  loss: 0.19934678971767425\n",
      "Batch 665,  loss: 0.2052608013153076\n",
      "Batch 670,  loss: 0.2206920027732849\n",
      "Batch 675,  loss: 0.2357001096010208\n",
      "Batch 680,  loss: 0.16184965521097183\n",
      "Batch 685,  loss: 0.23354827165603637\n",
      "Batch 690,  loss: 0.18960804641246795\n",
      "Batch 695,  loss: 0.1556306630373001\n",
      "Batch 700,  loss: 0.1625731974840164\n",
      "Batch 705,  loss: 0.16932269632816316\n",
      "Batch 710,  loss: 0.2303775042295456\n",
      "Batch 715,  loss: 0.1837651938199997\n",
      "Batch 720,  loss: 0.17357338666915895\n",
      "Batch 725,  loss: 0.19773347079753875\n",
      "Batch 730,  loss: 0.16790608167648316\n",
      "Batch 735,  loss: 0.20885278284549713\n",
      "Batch 740,  loss: 0.16096507906913757\n",
      "Batch 745,  loss: 0.16015363335609437\n",
      "Batch 750,  loss: 0.1741783544421196\n",
      "Batch 755,  loss: 0.21413714587688445\n",
      "Batch 760,  loss: 0.22169331163167955\n",
      "Batch 765,  loss: 0.1773996651172638\n",
      "Batch 770,  loss: 0.183631432056427\n",
      "Batch 775,  loss: 0.1945904701948166\n",
      "Batch 780,  loss: 0.1344968259334564\n",
      "Batch 785,  loss: 0.20903118401765824\n",
      "Batch 790,  loss: 0.18801743388175965\n",
      "Batch 795,  loss: 0.1827230930328369\n",
      "Batch 800,  loss: 0.18471578359603882\n",
      "Batch 805,  loss: 0.2582966148853302\n",
      "Batch 810,  loss: 0.18178630769252777\n",
      "Batch 815,  loss: 0.2130427837371826\n",
      "Batch 820,  loss: 0.19791271388530732\n",
      "Batch 825,  loss: 0.19193319380283355\n",
      "Batch 830,  loss: 0.1569461703300476\n",
      "Batch 835,  loss: 0.15982531011104584\n",
      "Batch 840,  loss: 0.16994421780109406\n",
      "Batch 845,  loss: 0.1538841098546982\n",
      "Batch 850,  loss: 0.2077726364135742\n",
      "Batch 855,  loss: 0.16075159311294557\n",
      "Batch 860,  loss: 0.23269510567188262\n",
      "Batch 865,  loss: 0.1966132789850235\n",
      "Batch 870,  loss: 0.17890560925006865\n",
      "Batch 875,  loss: 0.2239917993545532\n",
      "Batch 880,  loss: 0.2018607258796692\n",
      "Batch 885,  loss: 0.21406084001064302\n",
      "Batch 890,  loss: 0.1876938223838806\n",
      "Batch 895,  loss: 0.18134030997753142\n",
      "Batch 900,  loss: 0.16953270137310028\n",
      "Batch 905,  loss: 0.14670181572437285\n",
      "Batch 910,  loss: 0.1640533149242401\n",
      "Batch 915,  loss: 0.18162540197372437\n",
      "Batch 920,  loss: 0.14077508002519606\n",
      "Batch 925,  loss: 0.14899571537971495\n",
      "Batch 930,  loss: 0.14922023713588714\n",
      "Batch 935,  loss: 0.1579731822013855\n",
      "Batch 940,  loss: 0.19104579985141754\n",
      "Batch 945,  loss: 0.17764158472418784\n",
      "Batch 950,  loss: 0.18192814737558366\n",
      "Batch 955,  loss: 0.1829581528902054\n",
      "Batch 960,  loss: 0.1784196153283119\n",
      "Batch 965,  loss: 0.16544716954231262\n",
      "Batch 970,  loss: 0.20897510945796965\n",
      "Batch 975,  loss: 0.15589723885059356\n",
      "Batch 980,  loss: 0.1503203481435776\n",
      "Batch 985,  loss: 0.18804660737514495\n",
      "Batch 990,  loss: 0.18280237913131714\n",
      "Batch 995,  loss: 0.18126259744167328\n",
      "Batch 1000,  loss: 0.19717970490455627\n",
      "Batch 1005,  loss: 0.1933056592941284\n",
      "Batch 1010,  loss: 0.1723094403743744\n",
      "Batch 1015,  loss: 0.2011953741312027\n",
      "Batch 1020,  loss: 0.13245990872383118\n",
      "Batch 1025,  loss: 0.19138807952404022\n",
      "Batch 1030,  loss: 0.18035407662391661\n",
      "Batch 1035,  loss: 0.1621437266469002\n",
      "Batch 1040,  loss: 0.1958773136138916\n",
      "Batch 1045,  loss: 0.1821499526500702\n",
      "Batch 1050,  loss: 0.20223630368709564\n",
      "Batch 1055,  loss: 0.1916280448436737\n",
      "Batch 1060,  loss: 0.1594765618443489\n",
      "Batch 1065,  loss: 0.1749363899230957\n",
      "Batch 1070,  loss: 0.20154655277729033\n",
      "Batch 1075,  loss: 0.21208635866641998\n",
      "Batch 1080,  loss: 0.15104035139083863\n",
      "Batch 1085,  loss: 0.21051134467124938\n",
      "Batch 1090,  loss: 0.21380093991756438\n",
      "Batch 1095,  loss: 0.15551133453845978\n",
      "Batch 1100,  loss: 0.19311366826295853\n",
      "Batch 1105,  loss: 0.19403384625911713\n",
      "Batch 1110,  loss: 0.1998333603143692\n",
      "Batch 1115,  loss: 0.20539501905441285\n",
      "Batch 1120,  loss: 0.1979268014431\n",
      "Batch 1125,  loss: 0.16404473781585693\n",
      "Batch 1130,  loss: 0.20425856709480286\n",
      "Batch 1135,  loss: 0.20774143040180207\n",
      "Batch 1140,  loss: 0.16373709291219712\n",
      "Batch 1145,  loss: 0.16100846230983734\n",
      "Batch 1150,  loss: 0.1877817541360855\n",
      "Batch 1155,  loss: 0.16529726684093476\n",
      "Batch 1160,  loss: 0.18922967612743377\n",
      "Batch 1165,  loss: 0.20839239656925201\n",
      "Batch 1170,  loss: 0.19524359405040742\n",
      "Batch 1175,  loss: 0.16897314190864562\n",
      "Batch 1180,  loss: 0.1822704941034317\n",
      "Batch 1185,  loss: 0.21226296424865723\n",
      "Batch 1190,  loss: 0.13738348484039306\n",
      "Batch 1195,  loss: 0.15027211159467696\n",
      "Batch 1200,  loss: 0.131288380920887\n",
      "Batch 1205,  loss: 0.19097036123275757\n",
      "Batch 1210,  loss: 0.1888915479183197\n",
      "Batch 1215,  loss: 0.19713493287563325\n",
      "Batch 1220,  loss: 0.15785940289497374\n",
      "Batch 1225,  loss: 0.1935511976480484\n",
      "Batch 1230,  loss: 0.17877851128578187\n",
      "Batch 1235,  loss: 0.18293422907590867\n",
      "Batch 1240,  loss: 0.17502986788749694\n",
      "Batch 1245,  loss: 0.20118802189826965\n",
      "Batch 1250,  loss: 0.21066004335880278\n",
      "Batch 1255,  loss: 0.20043261349201202\n",
      "Batch 1260,  loss: 0.19731694906949998\n",
      "Batch 1265,  loss: 0.17484982311725616\n",
      "Batch 1270,  loss: 0.233420792222023\n",
      "Batch 1275,  loss: 0.20115629732608795\n",
      "Batch 1280,  loss: 0.1796802192926407\n",
      "Batch 1285,  loss: 0.24380396604537963\n",
      "Batch 1290,  loss: 0.19656998813152313\n",
      "Batch 1295,  loss: 0.19208874702453613\n",
      "Batch 1300,  loss: 0.19215731620788573\n",
      "Batch 1305,  loss: 0.19960889965295792\n",
      "Batch 1310,  loss: 0.17723302245140077\n",
      "Batch 1315,  loss: 0.24408052563667298\n",
      "Batch 1320,  loss: 0.18527958393096924\n",
      "Batch 1325,  loss: 0.18184866309165953\n",
      "Batch 1330,  loss: 0.2126380354166031\n",
      "Batch 1335,  loss: 0.14580426812171937\n",
      "Batch 1340,  loss: 0.18914414346218109\n",
      "Batch 1345,  loss: 0.2219904363155365\n",
      "Batch 1350,  loss: 0.23639486730098724\n",
      "Batch 1355,  loss: 0.161376191675663\n",
      "Batch 1360,  loss: 0.1637726306915283\n",
      "Batch 1365,  loss: 0.17280900478363037\n",
      "Batch 1370,  loss: 0.17844471633434295\n",
      "Batch 1375,  loss: 0.2106345534324646\n",
      "Batch 1380,  loss: 0.16477029919624328\n",
      "Batch 1385,  loss: 0.17517622709274291\n",
      "Batch 1390,  loss: 0.23548732399940492\n",
      "Batch 1395,  loss: 0.2349834531545639\n",
      "Batch 1400,  loss: 0.2523915797472\n",
      "Batch 1405,  loss: 0.2114827811717987\n",
      "Batch 1410,  loss: 0.2357552468776703\n",
      "Batch 1415,  loss: 0.18494621515274048\n",
      "Batch 1420,  loss: 0.19099594950675963\n",
      "Batch 1425,  loss: 0.1945156127214432\n",
      "Batch 1430,  loss: 0.20260667502880098\n",
      "Batch 1435,  loss: 0.1698259651660919\n",
      "Batch 1440,  loss: 0.16744074821472169\n",
      "Batch 1445,  loss: 0.21721132695674897\n",
      "Batch 1450,  loss: 0.1594061955809593\n",
      "Batch 1455,  loss: 0.19216375648975373\n",
      "Batch 1460,  loss: 0.18848324865102767\n",
      "Batch 1465,  loss: 0.20110975503921508\n",
      "Batch 1470,  loss: 0.23245740830898284\n",
      "Batch 1475,  loss: 0.15550432801246644\n",
      "Batch 1480,  loss: 0.19253984689712525\n",
      "Batch 1485,  loss: 0.1804373472929001\n",
      "Batch 1490,  loss: 0.16286596655845642\n",
      "Batch 1495,  loss: 0.14502550065517425\n",
      "Batch 1500,  loss: 0.17192206382751465\n",
      "Batch 1505,  loss: 0.20086338520050048\n",
      "Batch 1510,  loss: 0.17954867482185363\n",
      "Batch 1515,  loss: 0.19321986585855483\n",
      "Batch 1520,  loss: 0.2050460696220398\n",
      "Batch 1525,  loss: 0.16485418379306793\n",
      "Batch 1530,  loss: 0.19637031555175782\n",
      "Batch 1535,  loss: 0.20499354898929595\n",
      "Batch 1540,  loss: 0.18240290135145187\n",
      "Batch 1545,  loss: 0.20951960384845733\n",
      "Batch 1550,  loss: 0.1717934638261795\n",
      "Batch 1555,  loss: 0.17417224049568175\n",
      "Batch 1560,  loss: 0.1915266841650009\n",
      "Batch 1565,  loss: 0.15254985690116882\n",
      "Batch 1570,  loss: 0.15716191232204438\n",
      "Batch 1575,  loss: 0.18435461521148683\n",
      "Batch 1580,  loss: 0.1663769632577896\n",
      "Batch 1585,  loss: 0.15055152177810668\n",
      "Batch 1590,  loss: 0.1934041291475296\n",
      "Batch 1595,  loss: 0.16217975616455077\n",
      "Batch 1600,  loss: 0.17542070001363755\n",
      "Batch 1605,  loss: 0.18596387803554534\n",
      "Batch 1610,  loss: 0.19143455624580383\n",
      "Batch 1615,  loss: 0.17620784193277358\n",
      "Batch 1620,  loss: 0.2061910718679428\n",
      "Batch 1625,  loss: 0.1531434327363968\n",
      "Batch 1630,  loss: 0.24804382622241974\n",
      "Batch 1635,  loss: 0.20172764360904694\n",
      "Batch 1640,  loss: 0.20351215451955795\n",
      "Batch 1645,  loss: 0.1754236027598381\n",
      "Batch 1650,  loss: 0.18712755739688874\n",
      "Batch 1655,  loss: 0.19998783767223358\n",
      "Batch 1660,  loss: 0.19883675873279572\n",
      "Batch 1665,  loss: 0.1887858808040619\n",
      "Batch 1670,  loss: 0.21418479979038238\n",
      "Batch 1675,  loss: 0.17849961817264556\n",
      "Batch 1680,  loss: 0.16323876529932022\n",
      "Batch 1685,  loss: 0.18946174681186675\n",
      "Batch 1690,  loss: 0.17607592940330505\n",
      "Batch 1695,  loss: 0.14507995247840882\n",
      "Batch 1700,  loss: 0.1841877818107605\n",
      "Batch 1705,  loss: 0.12150534242391586\n",
      "Batch 1710,  loss: 0.2016986221075058\n",
      "Batch 1715,  loss: 0.2122571885585785\n",
      "Batch 1720,  loss: 0.17442224323749542\n",
      "Batch 1725,  loss: 0.1590999871492386\n",
      "Batch 1730,  loss: 0.166937193274498\n",
      "Batch 1735,  loss: 0.2786880522966385\n",
      "Batch 1740,  loss: 0.20719688534736633\n",
      "Batch 1745,  loss: 0.19590598344802856\n",
      "Batch 1750,  loss: 0.15945492684841156\n",
      "Batch 1755,  loss: 0.1539170801639557\n",
      "Batch 1760,  loss: 0.23008654415607452\n",
      "Batch 1765,  loss: 0.20706681907176971\n",
      "Batch 1770,  loss: 0.176103638112545\n",
      "Batch 1775,  loss: 0.24163422882556915\n",
      "Batch 1780,  loss: 0.17103158980607985\n",
      "Batch 1785,  loss: 0.1998094230890274\n",
      "Batch 1790,  loss: 0.25146271884441374\n",
      "Batch 1795,  loss: 0.16080567687749864\n",
      "Batch 1800,  loss: 0.16893841326236725\n",
      "Batch 1805,  loss: 0.19437102228403091\n",
      "Batch 1810,  loss: 0.21410629153251648\n",
      "Batch 1815,  loss: 0.2199167400598526\n",
      "Batch 1820,  loss: 0.18217270076274872\n",
      "Batch 1825,  loss: 0.16441883146762848\n",
      "Batch 1830,  loss: 0.18942317962646485\n",
      "Batch 1835,  loss: 0.18668803572654724\n",
      "Batch 1840,  loss: 0.14203052520751952\n",
      "Batch 1845,  loss: 0.2010941505432129\n",
      "Batch 1850,  loss: 0.1957763224840164\n",
      "Batch 1855,  loss: 0.18829847276210784\n",
      "Batch 1860,  loss: 0.1670564517378807\n",
      "Batch 1865,  loss: 0.18585867881774903\n",
      "Batch 1870,  loss: 0.24290271401405333\n",
      "Batch 1875,  loss: 0.2629545986652374\n",
      "Batch 1880,  loss: 0.1983717918395996\n",
      "Batch 1885,  loss: 0.16797076761722565\n",
      "Batch 1890,  loss: 0.20075732469558716\n",
      "Batch 1895,  loss: 0.21829028725624083\n",
      "Batch 1900,  loss: 0.1778569594025612\n",
      "Batch 1905,  loss: 0.2090135008096695\n",
      "Batch 1910,  loss: 0.19038515090942382\n",
      "Batch 1915,  loss: 0.18640415668487548\n",
      "Batch 1920,  loss: 0.21314119398593903\n",
      "Batch 1925,  loss: 0.23328129947185516\n",
      "Batch 1930,  loss: 0.20325556099414827\n",
      "Batch 1935,  loss: 0.23423922657966614\n",
      "Batch 1940,  loss: 0.17227490842342377\n",
      "Batch 1945,  loss: 0.2384633257985115\n",
      "Batch 1950,  loss: 0.18533168733119965\n",
      "Batch 1955,  loss: 0.17782608568668365\n",
      "Batch 1960,  loss: 0.15895995646715164\n",
      "Batch 1965,  loss: 0.17450015544891356\n",
      "Batch 1970,  loss: 0.17173532843589784\n",
      "Batch 1975,  loss: 0.15832513123750686\n",
      "Batch 1980,  loss: 0.19160026013851167\n",
      "Batch 1985,  loss: 0.15585843622684478\n",
      "Batch 1990,  loss: 0.23960603773593903\n",
      "Batch 1995,  loss: 0.16423710584640502\n",
      "Batch 2000,  loss: 0.2108382612466812\n",
      "Batch 2005,  loss: 0.17520129084587097\n",
      "Batch 2010,  loss: 0.2085239917039871\n",
      "Batch 2015,  loss: 0.1476014405488968\n",
      "Batch 2020,  loss: 0.17041927576065063\n",
      "Batch 2025,  loss: 0.15181363821029664\n",
      "Batch 2030,  loss: 0.17629547715187072\n",
      "Batch 2035,  loss: 0.15201399624347686\n",
      "Batch 2040,  loss: 0.16460586786270143\n",
      "Batch 2045,  loss: 0.14931836277246474\n",
      "Batch 2050,  loss: 0.20023596286773682\n",
      "Batch 2055,  loss: 0.23300433456897734\n",
      "Batch 2060,  loss: 0.20426439940929414\n",
      "Batch 2065,  loss: 0.15133779048919677\n",
      "Batch 2070,  loss: 0.19900543093681336\n",
      "Batch 2075,  loss: 0.18529051244258882\n",
      "Batch 2080,  loss: 0.24187251925468445\n",
      "Batch 2085,  loss: 0.1745062902569771\n",
      "Batch 2090,  loss: 0.1580043613910675\n",
      "Batch 2095,  loss: 0.16339830160140992\n",
      "Batch 2100,  loss: 0.17206595540046693\n",
      "Batch 2105,  loss: 0.15050998628139495\n",
      "Batch 2110,  loss: 0.1911773979663849\n",
      "Batch 2115,  loss: 0.19082325100898742\n",
      "Batch 2120,  loss: 0.14886218011379243\n",
      "Batch 2125,  loss: 0.17310861498117447\n",
      "Batch 2130,  loss: 0.19591211080551146\n",
      "Batch 2135,  loss: 0.24806243181228638\n",
      "Batch 2140,  loss: 0.17737322747707368\n",
      "Batch 2145,  loss: 0.15048976093530655\n",
      "Batch 2150,  loss: 0.2068507730960846\n",
      "Batch 2155,  loss: 0.23175527453422545\n",
      "Batch 2160,  loss: 0.17495331168174744\n",
      "Batch 2165,  loss: 0.17868989408016206\n",
      "Batch 2170,  loss: 0.15993136763572693\n",
      "Batch 2175,  loss: 0.21895647644996644\n",
      "Batch 2180,  loss: 0.24322754740715027\n",
      "Batch 2185,  loss: 0.19518879055976868\n",
      "Batch 2190,  loss: 0.15737414956092835\n",
      "Batch 2195,  loss: 0.17593701779842377\n",
      "Batch 2200,  loss: 0.21513729989528657\n",
      "Batch 2205,  loss: 0.18826493620872498\n",
      "Batch 2210,  loss: 0.2515134304761887\n",
      "Batch 2215,  loss: 0.23669583201408387\n",
      "Batch 2220,  loss: 0.17639919221401215\n",
      "Batch 2225,  loss: 0.1922033667564392\n",
      "Batch 2230,  loss: 0.1709830194711685\n",
      "Batch 2235,  loss: 0.21541643887758255\n",
      "Batch 2240,  loss: 0.2076589971780777\n",
      "Batch 2245,  loss: 0.1901744306087494\n",
      "Batch 2250,  loss: 0.16186290383338928\n",
      "Batch 2255,  loss: 0.1857104331254959\n",
      "Batch 2260,  loss: 0.19497409462928772\n",
      "Batch 2265,  loss: 0.18194935470819473\n",
      "Batch 2270,  loss: 0.2322932630777359\n",
      "Batch 2275,  loss: 0.21584577858448029\n",
      "Batch 2280,  loss: 0.16705459952354432\n",
      "Batch 2285,  loss: 0.18496561348438262\n",
      "Batch 2290,  loss: 0.15946816504001618\n",
      "Batch 2295,  loss: 0.19434854388237\n",
      "Batch 2300,  loss: 0.1614363431930542\n",
      "Batch 2305,  loss: 0.19342587888240814\n",
      "Batch 2310,  loss: 0.12787433713674545\n",
      "Batch 2315,  loss: 0.20413699746131897\n",
      "Batch 2320,  loss: 0.20407299399375917\n",
      "Batch 2325,  loss: 0.18469112515449523\n",
      "Batch 2330,  loss: 0.1831199675798416\n",
      "Batch 2335,  loss: 0.21015453934669495\n",
      "Batch 2340,  loss: 0.20766695141792296\n",
      "Batch 2345,  loss: 0.17271721065044404\n",
      "Batch 2350,  loss: 0.2073888212442398\n",
      "Batch 2355,  loss: 0.16108029782772065\n",
      "Batch 2360,  loss: 0.18146646320819854\n",
      "Batch 2365,  loss: 0.14802575558423997\n",
      "Batch 2370,  loss: 0.20036204159259796\n",
      "Batch 2375,  loss: 0.19247581958770751\n",
      "Batch 2380,  loss: 0.19632969200611114\n",
      "Batch 2385,  loss: 0.17181469798088073\n",
      "Batch 2390,  loss: 0.19396525025367736\n",
      "Batch 2395,  loss: 0.20706605017185212\n",
      "Batch 2400,  loss: 0.22539151906967164\n",
      "Batch 2405,  loss: 0.16724222004413605\n",
      "Batch 2410,  loss: 0.18076235055923462\n",
      "Batch 2415,  loss: 0.2439481496810913\n",
      "Batch 2420,  loss: 0.19733584076166152\n",
      "Batch 2425,  loss: 0.17198854982852935\n",
      "Batch 2430,  loss: 0.1792034313082695\n",
      "Batch 2435,  loss: 0.1766066372394562\n",
      "Batch 2440,  loss: 0.20121284276247026\n",
      "Batch 2445,  loss: 0.16643843948841094\n",
      "Batch 2450,  loss: 0.19166867434978485\n",
      "Batch 2455,  loss: 0.1626571998000145\n",
      "Batch 2460,  loss: 0.24242785573005676\n",
      "Batch 2465,  loss: 0.16178069412708282\n",
      "Batch 2470,  loss: 0.1691218912601471\n",
      "Batch 2475,  loss: 0.20188317000865935\n",
      "Batch 2480,  loss: 0.18885242342948913\n",
      "Batch 2485,  loss: 0.18559688627719878\n",
      "Batch 2490,  loss: 0.1643991604447365\n",
      "Batch 2495,  loss: 0.14198199957609176\n",
      "Batch 2500,  loss: 0.17060573250055314\n",
      "Batch 2505,  loss: 0.1722141534090042\n",
      "Batch 2510,  loss: 0.2177717536687851\n",
      "Batch 2515,  loss: 0.17527239620685578\n",
      "Batch 2520,  loss: 0.23912450075149536\n",
      "Batch 2525,  loss: 0.20978544652462006\n",
      "Batch 2530,  loss: 0.19614047706127166\n",
      "Batch 2535,  loss: 0.1373705506324768\n",
      "Batch 2540,  loss: 0.23981691002845765\n",
      "Batch 2545,  loss: 0.16509931683540344\n",
      "Batch 2550,  loss: 0.21298328936100006\n",
      "Batch 2555,  loss: 0.1712808668613434\n",
      "Batch 2560,  loss: 0.22357185184955597\n",
      "Batch 2565,  loss: 0.20329979956150054\n",
      "Batch 2570,  loss: 0.1637230709195137\n",
      "Batch 2575,  loss: 0.14466260373592377\n",
      "Batch 2580,  loss: 0.19128133356571198\n",
      "Batch 2585,  loss: 0.17887455672025682\n",
      "Batch 2590,  loss: 0.17617652416229249\n",
      "Batch 2595,  loss: 0.22826298475265502\n",
      "Batch 2600,  loss: 0.21606969237327575\n",
      "Batch 2605,  loss: 0.16680880934000014\n",
      "Batch 2610,  loss: 0.19920507818460464\n",
      "Batch 2615,  loss: 0.13944756984710693\n",
      "Batch 2620,  loss: 0.20939788222312927\n",
      "Batch 2625,  loss: 0.20153229981660842\n",
      "Batch 2630,  loss: 0.17808798253536223\n",
      "Batch 2635,  loss: 0.2000177264213562\n",
      "Batch 2640,  loss: 0.19593344926834105\n",
      "Batch 2645,  loss: 0.23321657478809357\n",
      "Batch 2650,  loss: 0.18576950579881668\n",
      "Batch 2655,  loss: 0.1907651662826538\n",
      "Batch 2660,  loss: 0.17163263857364655\n",
      "Batch 2665,  loss: 0.16840439438819885\n",
      "Batch 2670,  loss: 0.19369999170303345\n",
      "Batch 2675,  loss: 0.2078990340232849\n",
      "Batch 2680,  loss: 0.19529741406440734\n",
      "Batch 2685,  loss: 0.21523479521274566\n",
      "Batch 2690,  loss: 0.18585484027862548\n",
      "Batch 2695,  loss: 0.17652263343334199\n",
      "Batch 2700,  loss: 0.21185005605220794\n",
      "Batch 2705,  loss: 0.18551969826221465\n",
      "Batch 2710,  loss: 0.208293417096138\n",
      "Batch 2715,  loss: 0.19345984756946563\n",
      "Batch 2720,  loss: 0.20006283819675447\n",
      "Batch 2725,  loss: 0.18970226347446442\n",
      "Batch 2730,  loss: 0.1759829431772232\n",
      "Batch 2735,  loss: 0.170622256398201\n",
      "Batch 2740,  loss: 0.1536491870880127\n",
      "Batch 2745,  loss: 0.19049372971057893\n",
      "Batch 2750,  loss: 0.19011494815349578\n",
      "Batch 2755,  loss: 0.17084310054779053\n",
      "Batch 2760,  loss: 0.17096385061740876\n",
      "Batch 2765,  loss: 0.15938032269477845\n",
      "Batch 2770,  loss: 0.210567507147789\n",
      "LOSS train 0.210567507147789. Validation loss: 0.16951370947256994 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 13:\n",
      "Batch 5,  loss: 0.22221461534500123\n",
      "Batch 10,  loss: 0.14770152270793915\n",
      "Batch 15,  loss: 0.20288320779800414\n",
      "Batch 20,  loss: 0.21416543126106263\n",
      "Batch 25,  loss: 0.19136227965354918\n",
      "Batch 30,  loss: 0.23477339446544648\n",
      "Batch 35,  loss: 0.2287495493888855\n",
      "Batch 40,  loss: 0.16960331797599792\n",
      "Batch 45,  loss: 0.19487723410129548\n",
      "Batch 50,  loss: 0.18626613318920135\n",
      "Batch 55,  loss: 0.18929463028907775\n",
      "Batch 60,  loss: 0.22413861155509948\n",
      "Batch 65,  loss: 0.18473867774009706\n",
      "Batch 70,  loss: 0.18153149485588074\n",
      "Batch 75,  loss: 0.20867664217948914\n",
      "Batch 80,  loss: 0.24773463606834412\n",
      "Batch 85,  loss: 0.21036311686038972\n",
      "Batch 90,  loss: 0.17113623321056365\n",
      "Batch 95,  loss: 0.19273303747177123\n",
      "Batch 100,  loss: 0.24847526252269744\n",
      "Batch 105,  loss: 0.18423176407814026\n",
      "Batch 110,  loss: 0.20886181890964509\n",
      "Batch 115,  loss: 0.19536587297916413\n",
      "Batch 120,  loss: 0.1837206929922104\n",
      "Batch 125,  loss: 0.1845955044031143\n",
      "Batch 130,  loss: 0.17724000811576843\n",
      "Batch 135,  loss: 0.17588095664978026\n",
      "Batch 140,  loss: 0.17190867960453032\n",
      "Batch 145,  loss: 0.1931450605392456\n",
      "Batch 150,  loss: 0.14907366335391997\n",
      "Batch 155,  loss: 0.18327379524707793\n",
      "Batch 160,  loss: 0.16447248458862304\n",
      "Batch 165,  loss: 0.2519217193126678\n",
      "Batch 170,  loss: 0.20326341986656188\n",
      "Batch 175,  loss: 0.2250452756881714\n",
      "Batch 180,  loss: 0.1653169274330139\n",
      "Batch 185,  loss: 0.1912786364555359\n",
      "Batch 190,  loss: 0.15381502807140351\n",
      "Batch 195,  loss: 0.14019857048988343\n",
      "Batch 200,  loss: 0.21063121557235717\n",
      "Batch 205,  loss: 0.16853551864624022\n",
      "Batch 210,  loss: 0.22706429064273834\n",
      "Batch 215,  loss: 0.1693378210067749\n",
      "Batch 220,  loss: 0.1999201714992523\n",
      "Batch 225,  loss: 0.14788080006837845\n",
      "Batch 230,  loss: 0.20436671674251555\n",
      "Batch 235,  loss: 0.13642616271972657\n",
      "Batch 240,  loss: 0.17101680338382722\n",
      "Batch 245,  loss: 0.18393813371658324\n",
      "Batch 250,  loss: 0.18033259212970734\n",
      "Batch 255,  loss: 0.16755249351263046\n",
      "Batch 260,  loss: 0.15550279915332793\n",
      "Batch 265,  loss: 0.19395672976970674\n",
      "Batch 270,  loss: 0.23486745357513428\n",
      "Batch 275,  loss: 0.20055319666862487\n",
      "Batch 280,  loss: 0.19370986819267272\n",
      "Batch 285,  loss: 0.16952547878026963\n",
      "Batch 290,  loss: 0.19367488622665405\n",
      "Batch 295,  loss: 0.14873732030391693\n",
      "Batch 300,  loss: 0.18673112690448762\n",
      "Batch 305,  loss: 0.24753810167312623\n",
      "Batch 310,  loss: 0.1540190413594246\n",
      "Batch 315,  loss: 0.1599390834569931\n",
      "Batch 320,  loss: 0.18670940399169922\n",
      "Batch 325,  loss: 0.19237441718578338\n",
      "Batch 330,  loss: 0.18454390168190002\n",
      "Batch 335,  loss: 0.23411637544631958\n",
      "Batch 340,  loss: 0.2018604815006256\n",
      "Batch 345,  loss: 0.23819837719202042\n",
      "Batch 350,  loss: 0.20120924413204194\n",
      "Batch 355,  loss: 0.18440980315208436\n",
      "Batch 360,  loss: 0.1549108788371086\n",
      "Batch 365,  loss: 0.1475157380104065\n",
      "Batch 370,  loss: 0.18942204713821412\n",
      "Batch 375,  loss: 0.19285818338394164\n",
      "Batch 380,  loss: 0.18573373258113862\n",
      "Batch 385,  loss: 0.17526277601718904\n",
      "Batch 390,  loss: 0.17192385643720626\n",
      "Batch 395,  loss: 0.2146044999361038\n",
      "Batch 400,  loss: 0.20611271262168884\n",
      "Batch 405,  loss: 0.18615360260009767\n",
      "Batch 410,  loss: 0.19311118125915527\n",
      "Batch 415,  loss: 0.20540041029453276\n",
      "Batch 420,  loss: 0.1817449152469635\n",
      "Batch 425,  loss: 0.1616944134235382\n",
      "Batch 430,  loss: 0.1532142162322998\n",
      "Batch 435,  loss: 0.19357322454452514\n",
      "Batch 440,  loss: 0.24068357348442077\n",
      "Batch 445,  loss: 0.17588068842887877\n",
      "Batch 450,  loss: 0.1687362790107727\n",
      "Batch 455,  loss: 0.19089297950267792\n",
      "Batch 460,  loss: 0.15768536031246186\n",
      "Batch 465,  loss: 0.18594224154949188\n",
      "Batch 470,  loss: 0.19787830710411072\n",
      "Batch 475,  loss: 0.1485347867012024\n",
      "Batch 480,  loss: 0.1923288121819496\n",
      "Batch 485,  loss: 0.20613831877708436\n",
      "Batch 490,  loss: 0.177977155148983\n",
      "Batch 495,  loss: 0.16650017499923705\n",
      "Batch 500,  loss: 0.21063023805618286\n",
      "Batch 505,  loss: 0.15443046987056733\n",
      "Batch 510,  loss: 0.19026923179626465\n",
      "Batch 515,  loss: 0.2215367704629898\n",
      "Batch 520,  loss: 0.22079415023326873\n",
      "Batch 525,  loss: 0.17684214264154435\n",
      "Batch 530,  loss: 0.1856623739004135\n",
      "Batch 535,  loss: 0.2015264630317688\n",
      "Batch 540,  loss: 0.12151407301425934\n",
      "Batch 545,  loss: 0.18057519495487212\n",
      "Batch 550,  loss: 0.1392610937356949\n",
      "Batch 555,  loss: 0.1744192659854889\n",
      "Batch 560,  loss: 0.22044710218906402\n",
      "Batch 565,  loss: 0.20847724080085756\n",
      "Batch 570,  loss: 0.1837223470211029\n",
      "Batch 575,  loss: 0.18037303984165193\n",
      "Batch 580,  loss: 0.14413829743862153\n",
      "Batch 585,  loss: 0.178804150223732\n",
      "Batch 590,  loss: 0.18840590119361877\n",
      "Batch 595,  loss: 0.13986148685216904\n",
      "Batch 600,  loss: 0.1777453750371933\n",
      "Batch 605,  loss: 0.19576610624790192\n",
      "Batch 610,  loss: 0.17878256142139434\n",
      "Batch 615,  loss: 0.18151882886886597\n",
      "Batch 620,  loss: 0.18281304240226745\n",
      "Batch 625,  loss: 0.1494587242603302\n",
      "Batch 630,  loss: 0.16611149907112122\n",
      "Batch 635,  loss: 0.21129879355430603\n",
      "Batch 640,  loss: 0.18422878980636598\n",
      "Batch 645,  loss: 0.17442313730716705\n",
      "Batch 650,  loss: 0.24038648307323457\n",
      "Batch 655,  loss: 0.2027386888861656\n",
      "Batch 660,  loss: 0.143076092004776\n",
      "Batch 665,  loss: 0.18076970279216767\n",
      "Batch 670,  loss: 0.22720608115196228\n",
      "Batch 675,  loss: 0.18821948766708374\n",
      "Batch 680,  loss: 0.147351735830307\n",
      "Batch 685,  loss: 0.18174951374530793\n",
      "Batch 690,  loss: 0.18077669739723207\n",
      "Batch 695,  loss: 0.19666819125413895\n",
      "Batch 700,  loss: 0.1440446972846985\n",
      "Batch 705,  loss: 0.2021440714597702\n",
      "Batch 710,  loss: 0.194817715883255\n",
      "Batch 715,  loss: 0.17771269530057907\n",
      "Batch 720,  loss: 0.17195023745298385\n",
      "Batch 725,  loss: 0.19020469784736632\n",
      "Batch 730,  loss: 0.17907501012086868\n",
      "Batch 735,  loss: 0.16758744716644286\n",
      "Batch 740,  loss: 0.19672061502933502\n",
      "Batch 745,  loss: 0.15722185224294663\n",
      "Batch 750,  loss: 0.21272191107273103\n",
      "Batch 755,  loss: 0.23646929562091829\n",
      "Batch 760,  loss: 0.19571334421634673\n",
      "Batch 765,  loss: 0.1694190889596939\n",
      "Batch 770,  loss: 0.2094377636909485\n",
      "Batch 775,  loss: 0.150364688038826\n",
      "Batch 780,  loss: 0.1847820281982422\n",
      "Batch 785,  loss: 0.15928107351064683\n",
      "Batch 790,  loss: 0.21464956402778626\n",
      "Batch 795,  loss: 0.17780977189540864\n",
      "Batch 800,  loss: 0.2246591180562973\n",
      "Batch 805,  loss: 0.19228886663913727\n",
      "Batch 810,  loss: 0.17962798178195954\n",
      "Batch 815,  loss: 0.17131515145301818\n",
      "Batch 820,  loss: 0.21836015582084656\n",
      "Batch 825,  loss: 0.17773444801568986\n",
      "Batch 830,  loss: 0.21879681050777436\n",
      "Batch 835,  loss: 0.20240742862224578\n",
      "Batch 840,  loss: 0.16056190431118011\n",
      "Batch 845,  loss: 0.1593490183353424\n",
      "Batch 850,  loss: 0.21110775768756868\n",
      "Batch 855,  loss: 0.16212813556194305\n",
      "Batch 860,  loss: 0.2005818247795105\n",
      "Batch 865,  loss: 0.1578039839863777\n",
      "Batch 870,  loss: 0.19095026552677155\n",
      "Batch 875,  loss: 0.16996710300445556\n",
      "Batch 880,  loss: 0.21178703010082245\n",
      "Batch 885,  loss: 0.17605147808790206\n",
      "Batch 890,  loss: 0.20117877721786498\n",
      "Batch 895,  loss: 0.18314645886421205\n",
      "Batch 900,  loss: 0.2271612763404846\n",
      "Batch 905,  loss: 0.15375708937644958\n",
      "Batch 910,  loss: 0.1964581310749054\n",
      "Batch 915,  loss: 0.15749895572662354\n",
      "Batch 920,  loss: 0.21917904317378997\n",
      "Batch 925,  loss: 0.17723773121833802\n",
      "Batch 930,  loss: 0.16303480118513108\n",
      "Batch 935,  loss: 0.15876970291137696\n",
      "Batch 940,  loss: 0.17719115316867828\n",
      "Batch 945,  loss: 0.16630366146564485\n",
      "Batch 950,  loss: 0.1750363826751709\n",
      "Batch 955,  loss: 0.18878333866596222\n",
      "Batch 960,  loss: 0.1391025647521019\n",
      "Batch 965,  loss: 0.19272590875625611\n",
      "Batch 970,  loss: 0.1508621960878372\n",
      "Batch 975,  loss: 0.1544339656829834\n",
      "Batch 980,  loss: 0.21157882511615753\n",
      "Batch 985,  loss: 0.2087602883577347\n",
      "Batch 990,  loss: 0.14092279076576233\n",
      "Batch 995,  loss: 0.18587430119514464\n",
      "Batch 1000,  loss: 0.1814344972372055\n",
      "Batch 1005,  loss: 0.1494888812303543\n",
      "Batch 1010,  loss: 0.1835402250289917\n",
      "Batch 1015,  loss: 0.1926143079996109\n",
      "Batch 1020,  loss: 0.2160092383623123\n",
      "Batch 1025,  loss: 0.18159607648849488\n",
      "Batch 1030,  loss: 0.17616853713989258\n",
      "Batch 1035,  loss: 0.23072661608457565\n",
      "Batch 1040,  loss: 0.18035905957221984\n",
      "Batch 1045,  loss: 0.20997181236743928\n",
      "Batch 1050,  loss: 0.1678544759750366\n",
      "Batch 1055,  loss: 0.1876372516155243\n",
      "Batch 1060,  loss: 0.15010853707790375\n",
      "Batch 1065,  loss: 0.17354311048984528\n",
      "Batch 1070,  loss: 0.16966523826122284\n",
      "Batch 1075,  loss: 0.17654296159744262\n",
      "Batch 1080,  loss: 0.1982158124446869\n",
      "Batch 1085,  loss: 0.1799301326274872\n",
      "Batch 1090,  loss: 0.16059530079364776\n",
      "Batch 1095,  loss: 0.2031226187944412\n",
      "Batch 1100,  loss: 0.2316271185874939\n",
      "Batch 1105,  loss: 0.1891995906829834\n",
      "Batch 1110,  loss: 0.17758817374706268\n",
      "Batch 1115,  loss: 0.1717251092195511\n",
      "Batch 1120,  loss: 0.14950272142887117\n",
      "Batch 1125,  loss: 0.21482548862695694\n",
      "Batch 1130,  loss: 0.1428788810968399\n",
      "Batch 1135,  loss: 0.18349367380142212\n",
      "Batch 1140,  loss: 0.18505513966083526\n",
      "Batch 1145,  loss: 0.1932450920343399\n",
      "Batch 1150,  loss: 0.2167976289987564\n",
      "Batch 1155,  loss: 0.18931229412555695\n",
      "Batch 1160,  loss: 0.18083934783935546\n",
      "Batch 1165,  loss: 0.19152734577655792\n",
      "Batch 1170,  loss: 0.1651217520236969\n",
      "Batch 1175,  loss: 0.20488171875476838\n",
      "Batch 1180,  loss: 0.17852611988782882\n",
      "Batch 1185,  loss: 0.20296393930912018\n",
      "Batch 1190,  loss: 0.20513343214988708\n",
      "Batch 1195,  loss: 0.18099387884140014\n",
      "Batch 1200,  loss: 0.19599462449550628\n",
      "Batch 1205,  loss: 0.22029297649860383\n",
      "Batch 1210,  loss: 0.18404055386781693\n",
      "Batch 1215,  loss: 0.20130862295627594\n",
      "Batch 1220,  loss: 0.14869938790798187\n",
      "Batch 1225,  loss: 0.2170901745557785\n",
      "Batch 1230,  loss: 0.20691802203655243\n",
      "Batch 1235,  loss: 0.17825329899787903\n",
      "Batch 1240,  loss: 0.1809479385614395\n",
      "Batch 1245,  loss: 0.22391155660152434\n",
      "Batch 1250,  loss: 0.19385298490524291\n",
      "Batch 1255,  loss: 0.20116739273071288\n",
      "Batch 1260,  loss: 0.20581746995449066\n",
      "Batch 1265,  loss: 0.1959562659263611\n",
      "Batch 1270,  loss: 0.17774503380060197\n",
      "Batch 1275,  loss: 0.1378711685538292\n",
      "Batch 1280,  loss: 0.1603575825691223\n",
      "Batch 1285,  loss: 0.1906064361333847\n",
      "Batch 1290,  loss: 0.15780526548624038\n",
      "Batch 1295,  loss: 0.16050193309783936\n",
      "Batch 1300,  loss: 0.25498690605163576\n",
      "Batch 1305,  loss: 0.1750289171934128\n",
      "Batch 1310,  loss: 0.19756220430135726\n",
      "Batch 1315,  loss: 0.16521050333976744\n",
      "Batch 1320,  loss: 0.20203025937080382\n",
      "Batch 1325,  loss: 0.16592664420604705\n",
      "Batch 1330,  loss: 0.1712089240550995\n",
      "Batch 1335,  loss: 0.17560948729515075\n",
      "Batch 1340,  loss: 0.23267533183097838\n",
      "Batch 1345,  loss: 0.2050485596060753\n",
      "Batch 1350,  loss: 0.17660092413425446\n",
      "Batch 1355,  loss: 0.19997569620609285\n",
      "Batch 1360,  loss: 0.17758598923683167\n",
      "Batch 1365,  loss: 0.19389941096305846\n",
      "Batch 1370,  loss: 0.19432133436203003\n",
      "Batch 1375,  loss: 0.17012034058570863\n",
      "Batch 1380,  loss: 0.18021419942378997\n",
      "Batch 1385,  loss: 0.17835756242275239\n",
      "Batch 1390,  loss: 0.16608377993106843\n",
      "Batch 1395,  loss: 0.22615790367126465\n",
      "Batch 1400,  loss: 0.185043166577816\n",
      "Batch 1405,  loss: 0.15776908695697783\n",
      "Batch 1410,  loss: 0.19950638115406036\n",
      "Batch 1415,  loss: 0.15876426100730895\n",
      "Batch 1420,  loss: 0.15640981644392013\n",
      "Batch 1425,  loss: 0.1856657013297081\n",
      "Batch 1430,  loss: 0.21049313098192216\n",
      "Batch 1435,  loss: 0.1983548790216446\n",
      "Batch 1440,  loss: 0.17331677675247192\n",
      "Batch 1445,  loss: 0.21897929310798644\n",
      "Batch 1450,  loss: 0.17115949094295502\n",
      "Batch 1455,  loss: 0.18009483963251113\n",
      "Batch 1460,  loss: 0.23911601901054383\n",
      "Batch 1465,  loss: 0.18881800770759583\n",
      "Batch 1470,  loss: 0.2524827539920807\n",
      "Batch 1475,  loss: 0.18001292645931244\n",
      "Batch 1480,  loss: 0.18058858811855316\n",
      "Batch 1485,  loss: 0.1914300262928009\n",
      "Batch 1490,  loss: 0.1868165522813797\n",
      "Batch 1495,  loss: 0.19168806374073027\n",
      "Batch 1500,  loss: 0.1773565709590912\n",
      "Batch 1505,  loss: 0.15146200805902482\n",
      "Batch 1510,  loss: 0.1834000527858734\n",
      "Batch 1515,  loss: 0.20386366546154022\n",
      "Batch 1520,  loss: 0.18399908244609833\n",
      "Batch 1525,  loss: 0.22119597792625428\n",
      "Batch 1530,  loss: 0.2236051380634308\n",
      "Batch 1535,  loss: 0.19182974100112915\n",
      "Batch 1540,  loss: 0.16325999796390533\n",
      "Batch 1545,  loss: 0.1880777209997177\n",
      "Batch 1550,  loss: 0.17425926625728608\n",
      "Batch 1555,  loss: 0.17354823052883148\n",
      "Batch 1560,  loss: 0.15145391821861268\n",
      "Batch 1565,  loss: 0.1567317873239517\n",
      "Batch 1570,  loss: 0.16855090856552124\n",
      "Batch 1575,  loss: 0.1635467067360878\n",
      "Batch 1580,  loss: 0.17940232157707214\n",
      "Batch 1585,  loss: 0.17969039976596832\n",
      "Batch 1590,  loss: 0.20732736587524414\n",
      "Batch 1595,  loss: 0.17957013547420503\n",
      "Batch 1600,  loss: 0.16065342128276824\n",
      "Batch 1605,  loss: 0.1567865014076233\n",
      "Batch 1610,  loss: 0.1916678935289383\n",
      "Batch 1615,  loss: 0.18444880545139314\n",
      "Batch 1620,  loss: 0.1763864427804947\n",
      "Batch 1625,  loss: 0.16954203844070434\n",
      "Batch 1630,  loss: 0.12193672358989716\n",
      "Batch 1635,  loss: 0.1972670704126358\n",
      "Batch 1640,  loss: 0.20884754955768586\n",
      "Batch 1645,  loss: 0.2211954414844513\n",
      "Batch 1650,  loss: 0.1957434743642807\n",
      "Batch 1655,  loss: 0.20185088217258454\n",
      "Batch 1660,  loss: 0.1563692197203636\n",
      "Batch 1665,  loss: 0.16324088871479034\n",
      "Batch 1670,  loss: 0.1907428175210953\n",
      "Batch 1675,  loss: 0.19504763782024384\n",
      "Batch 1680,  loss: 0.15700972974300384\n",
      "Batch 1685,  loss: 0.19398621022701262\n",
      "Batch 1690,  loss: 0.20103893280029297\n",
      "Batch 1695,  loss: 0.1614305466413498\n",
      "Batch 1700,  loss: 0.15749476253986358\n",
      "Batch 1705,  loss: 0.19247784912586213\n",
      "Batch 1710,  loss: 0.17531688809394835\n",
      "Batch 1715,  loss: 0.18700410127639772\n",
      "Batch 1720,  loss: 0.21319016218185424\n",
      "Batch 1725,  loss: 0.2238418996334076\n",
      "Batch 1730,  loss: 0.22262295484542846\n",
      "Batch 1735,  loss: 0.1864508181810379\n",
      "Batch 1740,  loss: 0.15190424919128417\n",
      "Batch 1745,  loss: 0.2039452761411667\n",
      "Batch 1750,  loss: 0.1834967851638794\n",
      "Batch 1755,  loss: 0.15538872182369232\n",
      "Batch 1760,  loss: 0.21138705611228942\n",
      "Batch 1765,  loss: 0.1691467434167862\n",
      "Batch 1770,  loss: 0.2100587695837021\n",
      "Batch 1775,  loss: 0.13911239057779312\n",
      "Batch 1780,  loss: 0.17738530039787292\n",
      "Batch 1785,  loss: 0.19242344796657562\n",
      "Batch 1790,  loss: 0.1971906453371048\n",
      "Batch 1795,  loss: 0.19497996866703032\n",
      "Batch 1800,  loss: 0.1567400351166725\n",
      "Batch 1805,  loss: 0.18859956860542298\n",
      "Batch 1810,  loss: 0.162581142783165\n",
      "Batch 1815,  loss: 0.17815302908420563\n",
      "Batch 1820,  loss: 0.1655276224017143\n",
      "Batch 1825,  loss: 0.19318449795246123\n",
      "Batch 1830,  loss: 0.20297039896249772\n",
      "Batch 1835,  loss: 0.2118998259305954\n",
      "Batch 1840,  loss: 0.17152196168899536\n",
      "Batch 1845,  loss: 0.20766675472259521\n",
      "Batch 1850,  loss: 0.17606221735477448\n",
      "Batch 1855,  loss: 0.1620718538761139\n",
      "Batch 1860,  loss: 0.1514568567276001\n",
      "Batch 1865,  loss: 0.1567055106163025\n",
      "Batch 1870,  loss: 0.13443225473165513\n",
      "Batch 1875,  loss: 0.1703439325094223\n",
      "Batch 1880,  loss: 0.16777555048465728\n",
      "Batch 1885,  loss: 0.1872006833553314\n",
      "Batch 1890,  loss: 0.1513885498046875\n",
      "Batch 1895,  loss: 0.22344920933246612\n",
      "Batch 1900,  loss: 0.15473901927471162\n",
      "Batch 1905,  loss: 0.17240753173828124\n",
      "Batch 1910,  loss: 0.17499218583106996\n",
      "Batch 1915,  loss: 0.17880654335021973\n",
      "Batch 1920,  loss: 0.17899700552225112\n",
      "Batch 1925,  loss: 0.20523593723773956\n",
      "Batch 1930,  loss: 0.22038032114505768\n",
      "Batch 1935,  loss: 0.2146353006362915\n",
      "Batch 1940,  loss: 0.18093162178993225\n",
      "Batch 1945,  loss: 0.18970171809196473\n",
      "Batch 1950,  loss: 0.1478198543190956\n",
      "Batch 1955,  loss: 0.2089514672756195\n",
      "Batch 1960,  loss: 0.2057807117700577\n",
      "Batch 1965,  loss: 0.18366390466690063\n",
      "Batch 1970,  loss: 0.15689358115196228\n",
      "Batch 1975,  loss: 0.15846511572599412\n",
      "Batch 1980,  loss: 0.1983972817659378\n",
      "Batch 1985,  loss: 0.18563269674777985\n",
      "Batch 1990,  loss: 0.1700926810503006\n",
      "Batch 1995,  loss: 0.15017902106046677\n",
      "Batch 2000,  loss: 0.19833529591560364\n",
      "Batch 2005,  loss: 0.2646262764930725\n",
      "Batch 2010,  loss: 0.17057987153530121\n",
      "Batch 2015,  loss: 0.23011771887540816\n",
      "Batch 2020,  loss: 0.15913381278514863\n",
      "Batch 2025,  loss: 0.17841777801513672\n",
      "Batch 2030,  loss: 0.15050964057445526\n",
      "Batch 2035,  loss: 0.19877237677574158\n",
      "Batch 2040,  loss: 0.19536864757537842\n",
      "Batch 2045,  loss: 0.18070076107978822\n",
      "Batch 2050,  loss: 0.19252225756645203\n",
      "Batch 2055,  loss: 0.23209248483181\n",
      "Batch 2060,  loss: 0.22108012735843657\n",
      "Batch 2065,  loss: 0.20044387578964235\n",
      "Batch 2070,  loss: 0.17698925733566284\n",
      "Batch 2075,  loss: 0.15916805118322372\n",
      "Batch 2080,  loss: 0.20804142355918884\n",
      "Batch 2085,  loss: 0.1482596665620804\n",
      "Batch 2090,  loss: 0.16514091491699218\n",
      "Batch 2095,  loss: 0.15415372252464293\n",
      "Batch 2100,  loss: 0.21499912142753602\n",
      "Batch 2105,  loss: 0.20236800014972686\n",
      "Batch 2110,  loss: 0.20085425674915314\n",
      "Batch 2115,  loss: 0.1744099110364914\n",
      "Batch 2120,  loss: 0.17014641165733338\n",
      "Batch 2125,  loss: 0.18217018842697144\n",
      "Batch 2130,  loss: 0.16355342268943787\n",
      "Batch 2135,  loss: 0.17036700546741484\n",
      "Batch 2140,  loss: 0.1761461466550827\n",
      "Batch 2145,  loss: 0.17619873136281966\n",
      "Batch 2150,  loss: 0.1464365929365158\n",
      "Batch 2155,  loss: 0.18367498517036437\n",
      "Batch 2160,  loss: 0.19403161108493805\n",
      "Batch 2165,  loss: 0.1362628757953644\n",
      "Batch 2170,  loss: 0.1970508873462677\n",
      "Batch 2175,  loss: 0.2021384507417679\n",
      "Batch 2180,  loss: 0.16779331266880035\n",
      "Batch 2185,  loss: 0.18881373703479767\n",
      "Batch 2190,  loss: 0.16813690215349197\n",
      "Batch 2195,  loss: 0.20292237550020217\n",
      "Batch 2200,  loss: 0.16483536809682847\n",
      "Batch 2205,  loss: 0.22150048315525056\n",
      "Batch 2210,  loss: 0.19762755632400514\n",
      "Batch 2215,  loss: 0.16019976735115052\n",
      "Batch 2220,  loss: 0.189331579208374\n",
      "Batch 2225,  loss: 0.16500619947910308\n",
      "Batch 2230,  loss: 0.16552478820085526\n",
      "Batch 2235,  loss: 0.23615070581436157\n",
      "Batch 2240,  loss: 0.1841552585363388\n",
      "Batch 2245,  loss: 0.2301633432507515\n",
      "Batch 2250,  loss: 0.1965039923787117\n",
      "Batch 2255,  loss: 0.20076376497745513\n",
      "Batch 2260,  loss: 0.19006452560424805\n",
      "Batch 2265,  loss: 0.20956396758556367\n",
      "Batch 2270,  loss: 0.17859575450420379\n",
      "Batch 2275,  loss: 0.18848450779914855\n",
      "Batch 2280,  loss: 0.22309697270393372\n",
      "Batch 2285,  loss: 0.18036867678165436\n",
      "Batch 2290,  loss: 0.20192169547080993\n",
      "Batch 2295,  loss: 0.2265903741121292\n",
      "Batch 2300,  loss: 0.164930622279644\n",
      "Batch 2305,  loss: 0.19289856851100923\n",
      "Batch 2310,  loss: 0.1739561527967453\n",
      "Batch 2315,  loss: 0.17041486948728563\n",
      "Batch 2320,  loss: 0.19238118827342987\n",
      "Batch 2325,  loss: 0.23221553564071656\n",
      "Batch 2330,  loss: 0.17847344875335694\n",
      "Batch 2335,  loss: 0.15312075316905976\n",
      "Batch 2340,  loss: 0.19119751155376435\n",
      "Batch 2345,  loss: 0.18679515421390533\n",
      "Batch 2350,  loss: 0.20489472150802612\n",
      "Batch 2355,  loss: 0.18643345832824706\n",
      "Batch 2360,  loss: 0.18572018444538116\n",
      "Batch 2365,  loss: 0.17540741860866546\n",
      "Batch 2370,  loss: 0.1363981619477272\n",
      "Batch 2375,  loss: 0.16136461794376372\n",
      "Batch 2380,  loss: 0.20138412117958068\n",
      "Batch 2385,  loss: 0.18793363869190216\n",
      "Batch 2390,  loss: 0.1722679078578949\n",
      "Batch 2395,  loss: 0.21860138177871705\n",
      "Batch 2400,  loss: 0.19557233154773712\n",
      "Batch 2405,  loss: 0.16025992333889008\n",
      "Batch 2410,  loss: 0.2242864489555359\n",
      "Batch 2415,  loss: 0.17151492238044738\n",
      "Batch 2420,  loss: 0.1934129148721695\n",
      "Batch 2425,  loss: 0.17379070520401002\n",
      "Batch 2430,  loss: 0.16473828852176667\n",
      "Batch 2435,  loss: 0.1853488266468048\n",
      "Batch 2440,  loss: 0.2134230226278305\n",
      "Batch 2445,  loss: 0.20695292055606843\n",
      "Batch 2450,  loss: 0.21665734946727752\n",
      "Batch 2455,  loss: 0.19077054858207704\n",
      "Batch 2460,  loss: 0.1327776402235031\n",
      "Batch 2465,  loss: 0.19683813750743867\n",
      "Batch 2470,  loss: 0.18216890394687651\n",
      "Batch 2475,  loss: 0.14020578563213348\n",
      "Batch 2480,  loss: 0.1985163450241089\n",
      "Batch 2485,  loss: 0.1513460397720337\n",
      "Batch 2490,  loss: 0.21894416809082032\n",
      "Batch 2495,  loss: 0.15935748517513276\n",
      "Batch 2500,  loss: 0.2569642186164856\n",
      "Batch 2505,  loss: 0.18285751342773438\n",
      "Batch 2510,  loss: 0.19165892153978348\n",
      "Batch 2515,  loss: 0.1824685364961624\n",
      "Batch 2520,  loss: 0.18168446719646453\n",
      "Batch 2525,  loss: 0.17299212962388993\n",
      "Batch 2530,  loss: 0.18542915135622023\n",
      "Batch 2535,  loss: 0.2137529581785202\n",
      "Batch 2540,  loss: 0.19444771707057953\n",
      "Batch 2545,  loss: 0.20230155885219575\n",
      "Batch 2550,  loss: 0.17386215329170226\n",
      "Batch 2555,  loss: 0.2046248197555542\n",
      "Batch 2560,  loss: 0.1527437299489975\n",
      "Batch 2565,  loss: 0.1981149882078171\n",
      "Batch 2570,  loss: 0.17939173877239228\n",
      "Batch 2575,  loss: 0.20022866129875183\n",
      "Batch 2580,  loss: 0.17771233022212982\n",
      "Batch 2585,  loss: 0.18785804212093354\n",
      "Batch 2590,  loss: 0.16065821945667266\n",
      "Batch 2595,  loss: 0.17372082471847533\n",
      "Batch 2600,  loss: 0.19914232790470124\n",
      "Batch 2605,  loss: 0.18963843882083892\n",
      "Batch 2610,  loss: 0.17990839779376983\n",
      "Batch 2615,  loss: 0.20824695229530335\n",
      "Batch 2620,  loss: 0.1779682606458664\n",
      "Batch 2625,  loss: 0.18835739493370057\n",
      "Batch 2630,  loss: 0.16723365783691407\n",
      "Batch 2635,  loss: 0.18296654820442199\n",
      "Batch 2640,  loss: 0.16220975220203399\n",
      "Batch 2645,  loss: 0.1428430825471878\n",
      "Batch 2650,  loss: 0.1413862884044647\n",
      "Batch 2655,  loss: 0.20900256037712098\n",
      "Batch 2660,  loss: 0.14661460220813752\n",
      "Batch 2665,  loss: 0.1461083322763443\n",
      "Batch 2670,  loss: 0.19275657832622528\n",
      "Batch 2675,  loss: 0.1409737914800644\n",
      "Batch 2680,  loss: 0.15581706911325455\n",
      "Batch 2685,  loss: 0.17551267743110657\n",
      "Batch 2690,  loss: 0.16702218353748322\n",
      "Batch 2695,  loss: 0.16052224040031432\n",
      "Batch 2700,  loss: 0.12378408014774323\n",
      "Batch 2705,  loss: 0.2005034014582634\n",
      "Batch 2710,  loss: 0.20007280111312867\n",
      "Batch 2715,  loss: 0.1958048611879349\n",
      "Batch 2720,  loss: 0.15395780205726622\n",
      "Batch 2725,  loss: 0.15900283455848693\n",
      "Batch 2730,  loss: 0.21414453089237212\n",
      "Batch 2735,  loss: 0.1543799325823784\n",
      "Batch 2740,  loss: 0.1671692758798599\n",
      "Batch 2745,  loss: 0.16410312354564666\n",
      "Batch 2750,  loss: 0.1994534969329834\n",
      "Batch 2755,  loss: 0.20828293561935424\n",
      "Batch 2760,  loss: 0.17285687625408172\n",
      "Batch 2765,  loss: 0.16099725514650345\n",
      "Batch 2770,  loss: 0.20334860682487488\n",
      "LOSS train 0.20334860682487488. Validation loss: 0.18099263920103786 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 14:\n",
      "Batch 5,  loss: 0.1755538046360016\n",
      "Batch 10,  loss: 0.16816765666007996\n",
      "Batch 15,  loss: 0.19990376383066177\n",
      "Batch 20,  loss: 0.17821480333805084\n",
      "Batch 25,  loss: 0.23862801790237426\n",
      "Batch 30,  loss: 0.207982137799263\n",
      "Batch 35,  loss: 0.15822280645370485\n",
      "Batch 40,  loss: 0.20957321375608445\n",
      "Batch 45,  loss: 0.2066301703453064\n",
      "Batch 50,  loss: 0.1959913730621338\n",
      "Batch 55,  loss: 0.2259252190589905\n",
      "Batch 60,  loss: 0.15000093281269072\n",
      "Batch 65,  loss: 0.19829194545745848\n",
      "Batch 70,  loss: 0.16643127351999282\n",
      "Batch 75,  loss: 0.19096063077449799\n",
      "Batch 80,  loss: 0.17414991855621337\n",
      "Batch 85,  loss: 0.22009487748146056\n",
      "Batch 90,  loss: 0.1814567804336548\n",
      "Batch 95,  loss: 0.18693974018096923\n",
      "Batch 100,  loss: 0.17763520181179046\n",
      "Batch 105,  loss: 0.1816515952348709\n",
      "Batch 110,  loss: 0.15575418770313262\n",
      "Batch 115,  loss: 0.14819323122501374\n",
      "Batch 120,  loss: 0.1914947062730789\n",
      "Batch 125,  loss: 0.1602267414331436\n",
      "Batch 130,  loss: 0.19964344203472137\n",
      "Batch 135,  loss: 0.1677062064409256\n",
      "Batch 140,  loss: 0.15111448019742965\n",
      "Batch 145,  loss: 0.16847295314073563\n",
      "Batch 150,  loss: 0.20326300263404845\n",
      "Batch 155,  loss: 0.16304793506860732\n",
      "Batch 160,  loss: 0.2005082458257675\n",
      "Batch 165,  loss: 0.1909354329109192\n",
      "Batch 170,  loss: 0.18349039554595947\n",
      "Batch 175,  loss: 0.18752006888389589\n",
      "Batch 180,  loss: 0.20040152072906495\n",
      "Batch 185,  loss: 0.12967378348112107\n",
      "Batch 190,  loss: 0.23655199706554414\n",
      "Batch 195,  loss: 0.16578004360198975\n",
      "Batch 200,  loss: 0.20455121695995332\n",
      "Batch 205,  loss: 0.15550852119922637\n",
      "Batch 210,  loss: 0.2143690586090088\n",
      "Batch 215,  loss: 0.1632646754384041\n",
      "Batch 220,  loss: 0.18584552705287932\n",
      "Batch 225,  loss: 0.191627836227417\n",
      "Batch 230,  loss: 0.18938591778278352\n",
      "Batch 235,  loss: 0.18916510045528412\n",
      "Batch 240,  loss: 0.1654396653175354\n",
      "Batch 245,  loss: 0.1519818365573883\n",
      "Batch 250,  loss: 0.20537043511867523\n",
      "Batch 255,  loss: 0.148722605407238\n",
      "Batch 260,  loss: 0.17833884060382843\n",
      "Batch 265,  loss: 0.16961209177970887\n",
      "Batch 270,  loss: 0.2064350128173828\n",
      "Batch 275,  loss: 0.1530731737613678\n",
      "Batch 280,  loss: 0.20703338980674743\n",
      "Batch 285,  loss: 0.1582595005631447\n",
      "Batch 290,  loss: 0.16020802557468414\n",
      "Batch 295,  loss: 0.15641842633485795\n",
      "Batch 300,  loss: 0.1757809638977051\n",
      "Batch 305,  loss: 0.2007911264896393\n",
      "Batch 310,  loss: 0.17159477919340133\n",
      "Batch 315,  loss: 0.17828956842422486\n",
      "Batch 320,  loss: 0.15428058803081512\n",
      "Batch 325,  loss: 0.1826625496149063\n",
      "Batch 330,  loss: 0.1616642326116562\n",
      "Batch 335,  loss: 0.16755032539367676\n",
      "Batch 340,  loss: 0.19090681970119477\n",
      "Batch 345,  loss: 0.18448758423328399\n",
      "Batch 350,  loss: 0.2222426265478134\n",
      "Batch 355,  loss: 0.17457923889160157\n",
      "Batch 360,  loss: 0.18398650139570236\n",
      "Batch 365,  loss: 0.23430993258953095\n",
      "Batch 370,  loss: 0.21112906336784362\n",
      "Batch 375,  loss: 0.16386733651161195\n",
      "Batch 380,  loss: 0.15996357947587966\n",
      "Batch 385,  loss: 0.2016439765691757\n",
      "Batch 390,  loss: 0.14656920731067657\n",
      "Batch 395,  loss: 0.17052967697381974\n",
      "Batch 400,  loss: 0.1505328968167305\n",
      "Batch 405,  loss: 0.17202341556549072\n",
      "Batch 410,  loss: 0.1542958527803421\n",
      "Batch 415,  loss: 0.186894953250885\n",
      "Batch 420,  loss: 0.20665706992149352\n",
      "Batch 425,  loss: 0.22036259472370148\n",
      "Batch 430,  loss: 0.17541764080524444\n",
      "Batch 435,  loss: 0.14226382970809937\n",
      "Batch 440,  loss: 0.1747632473707199\n",
      "Batch 445,  loss: 0.22044069766998292\n",
      "Batch 450,  loss: 0.1844699501991272\n",
      "Batch 455,  loss: 0.1970741331577301\n",
      "Batch 460,  loss: 0.17087897956371306\n",
      "Batch 465,  loss: 0.14103002846240997\n",
      "Batch 470,  loss: 0.18621113300323486\n",
      "Batch 475,  loss: 0.17564967572689055\n",
      "Batch 480,  loss: 0.15821946859359742\n",
      "Batch 485,  loss: 0.17166315913200378\n",
      "Batch 490,  loss: 0.16907578259706496\n",
      "Batch 495,  loss: 0.1753864198923111\n",
      "Batch 500,  loss: 0.15247813016176223\n",
      "Batch 505,  loss: 0.16031925827264787\n",
      "Batch 510,  loss: 0.16334255635738373\n",
      "Batch 515,  loss: 0.18655926287174224\n",
      "Batch 520,  loss: 0.22443895041942596\n",
      "Batch 525,  loss: 0.16734654009342192\n",
      "Batch 530,  loss: 0.1800235390663147\n",
      "Batch 535,  loss: 0.16267088204622268\n",
      "Batch 540,  loss: 0.16512821912765502\n",
      "Batch 545,  loss: 0.1786317616701126\n",
      "Batch 550,  loss: 0.16541255116462708\n",
      "Batch 555,  loss: 0.15088235437870026\n",
      "Batch 560,  loss: 0.19612570405006408\n",
      "Batch 565,  loss: 0.19930830001831054\n",
      "Batch 570,  loss: 0.17873282432556153\n",
      "Batch 575,  loss: 0.19406867623329163\n",
      "Batch 580,  loss: 0.17264414727687835\n",
      "Batch 585,  loss: 0.1857436865568161\n",
      "Batch 590,  loss: 0.22041214406490325\n",
      "Batch 595,  loss: 0.19151757061481475\n",
      "Batch 600,  loss: 0.1849961519241333\n",
      "Batch 605,  loss: 0.1935655027627945\n",
      "Batch 610,  loss: 0.17001810073852539\n",
      "Batch 615,  loss: 0.21315650641918182\n",
      "Batch 620,  loss: 0.17215563356876373\n",
      "Batch 625,  loss: 0.16001639813184737\n",
      "Batch 630,  loss: 0.18991838991642\n",
      "Batch 635,  loss: 0.2000047504901886\n",
      "Batch 640,  loss: 0.1855652630329132\n",
      "Batch 645,  loss: 0.15391182601451875\n",
      "Batch 650,  loss: 0.1876090496778488\n",
      "Batch 655,  loss: 0.18745907843112947\n",
      "Batch 660,  loss: 0.15150012224912643\n",
      "Batch 665,  loss: 0.1700782522559166\n",
      "Batch 670,  loss: 0.19876736998558045\n",
      "Batch 675,  loss: 0.16259872913360596\n",
      "Batch 680,  loss: 0.1849202334880829\n",
      "Batch 685,  loss: 0.22241244912147523\n",
      "Batch 690,  loss: 0.1662325754761696\n",
      "Batch 695,  loss: 0.19406957626342775\n",
      "Batch 700,  loss: 0.24009984433650972\n",
      "Batch 705,  loss: 0.19781022369861603\n",
      "Batch 710,  loss: 0.1935872718691826\n",
      "Batch 715,  loss: 0.16967532336711882\n",
      "Batch 720,  loss: 0.20779395401477813\n",
      "Batch 725,  loss: 0.20535206496715547\n",
      "Batch 730,  loss: 0.1803307294845581\n",
      "Batch 735,  loss: 0.17877489626407622\n",
      "Batch 740,  loss: 0.13815172910690307\n",
      "Batch 745,  loss: 0.2072431206703186\n",
      "Batch 750,  loss: 0.18223797082901\n",
      "Batch 755,  loss: 0.14586209654808044\n",
      "Batch 760,  loss: 0.17132478505373\n",
      "Batch 765,  loss: 0.24000715911388398\n",
      "Batch 770,  loss: 0.17869303822517396\n",
      "Batch 775,  loss: 0.14425784349441528\n",
      "Batch 780,  loss: 0.17875238209962846\n",
      "Batch 785,  loss: 0.1767602175474167\n",
      "Batch 790,  loss: 0.19048437476158142\n",
      "Batch 795,  loss: 0.19294967353343964\n",
      "Batch 800,  loss: 0.14780119955539703\n",
      "Batch 805,  loss: 0.17348188608884813\n",
      "Batch 810,  loss: 0.23293697237968444\n",
      "Batch 815,  loss: 0.1639963999390602\n",
      "Batch 820,  loss: 0.17893100678920745\n",
      "Batch 825,  loss: 0.16218636631965638\n",
      "Batch 830,  loss: 0.17032533288002014\n",
      "Batch 835,  loss: 0.18106745034456254\n",
      "Batch 840,  loss: 0.22741314470767976\n",
      "Batch 845,  loss: 0.19463004618883134\n",
      "Batch 850,  loss: 0.15863783955574035\n",
      "Batch 855,  loss: 0.18555524647235871\n",
      "Batch 860,  loss: 0.17277460396289826\n",
      "Batch 865,  loss: 0.16953678727149962\n",
      "Batch 870,  loss: 0.18232058584690095\n",
      "Batch 875,  loss: 0.20178049355745314\n",
      "Batch 880,  loss: 0.2233448624610901\n",
      "Batch 885,  loss: 0.20791946947574616\n",
      "Batch 890,  loss: 0.18896520137786865\n",
      "Batch 895,  loss: 0.16581363081932068\n",
      "Batch 900,  loss: 0.1648150324821472\n",
      "Batch 905,  loss: 0.23271629214286804\n",
      "Batch 910,  loss: 0.20801711976528167\n",
      "Batch 915,  loss: 0.15468393862247468\n",
      "Batch 920,  loss: 0.1682411253452301\n",
      "Batch 925,  loss: 0.18648416101932525\n",
      "Batch 930,  loss: 0.2097318708896637\n",
      "Batch 935,  loss: 0.20155813694000244\n",
      "Batch 940,  loss: 0.154408261179924\n",
      "Batch 945,  loss: 0.17225320935249328\n",
      "Batch 950,  loss: 0.15846116840839386\n",
      "Batch 955,  loss: 0.2213243931531906\n",
      "Batch 960,  loss: 0.15717021822929383\n",
      "Batch 965,  loss: 0.18494854420423507\n",
      "Batch 970,  loss: 0.19116196632385254\n",
      "Batch 975,  loss: 0.18790106773376464\n",
      "Batch 980,  loss: 0.1645629435777664\n",
      "Batch 985,  loss: 0.1556752860546112\n",
      "Batch 990,  loss: 0.20509229600429535\n",
      "Batch 995,  loss: 0.23432877361774446\n",
      "Batch 1000,  loss: 0.15726370066404344\n",
      "Batch 1005,  loss: 0.17011141777038574\n",
      "Batch 1010,  loss: 0.1577339068055153\n",
      "Batch 1015,  loss: 0.17760199606418609\n",
      "Batch 1020,  loss: 0.1409802407026291\n",
      "Batch 1025,  loss: 0.15736941397190093\n",
      "Batch 1030,  loss: 0.19479200839996338\n",
      "Batch 1035,  loss: 0.16133722364902497\n",
      "Batch 1040,  loss: 0.19852543771266937\n",
      "Batch 1045,  loss: 0.14200748950242997\n",
      "Batch 1050,  loss: 0.17338889241218566\n",
      "Batch 1055,  loss: 0.2126413255929947\n",
      "Batch 1060,  loss: 0.1991361290216446\n",
      "Batch 1065,  loss: 0.11743858158588409\n",
      "Batch 1070,  loss: 0.21273334324359894\n",
      "Batch 1075,  loss: 0.1422308549284935\n",
      "Batch 1080,  loss: 0.19730208218097686\n",
      "Batch 1085,  loss: 0.1908651977777481\n",
      "Batch 1090,  loss: 0.207465997338295\n",
      "Batch 1095,  loss: 0.20421243011951445\n",
      "Batch 1100,  loss: 0.19043402671813964\n",
      "Batch 1105,  loss: 0.16707535684108735\n",
      "Batch 1110,  loss: 0.16098666191101074\n",
      "Batch 1115,  loss: 0.1886699378490448\n",
      "Batch 1120,  loss: 0.21272972524166106\n",
      "Batch 1125,  loss: 0.17208958864212037\n",
      "Batch 1130,  loss: 0.20490052700042724\n",
      "Batch 1135,  loss: 0.2299441933631897\n",
      "Batch 1140,  loss: 0.15114054828882217\n",
      "Batch 1145,  loss: 0.17240937650203705\n",
      "Batch 1150,  loss: 0.16117595732212067\n",
      "Batch 1155,  loss: 0.19438546597957612\n",
      "Batch 1160,  loss: 0.20686765015125275\n",
      "Batch 1165,  loss: 0.20548376441001892\n",
      "Batch 1170,  loss: 0.1779948115348816\n",
      "Batch 1175,  loss: 0.1698356568813324\n",
      "Batch 1180,  loss: 0.22659718096256257\n",
      "Batch 1185,  loss: 0.1732134610414505\n",
      "Batch 1190,  loss: 0.2564607262611389\n",
      "Batch 1195,  loss: 0.19558013379573821\n",
      "Batch 1200,  loss: 0.20587953925132751\n",
      "Batch 1205,  loss: 0.19731559455394745\n",
      "Batch 1210,  loss: 0.19781818389892578\n",
      "Batch 1215,  loss: 0.18062873780727387\n",
      "Batch 1220,  loss: 0.18481177240610122\n",
      "Batch 1225,  loss: 0.2077542096376419\n",
      "Batch 1230,  loss: 0.2528070658445358\n",
      "Batch 1235,  loss: 0.23696860671043396\n",
      "Batch 1240,  loss: 0.20198497772216797\n",
      "Batch 1245,  loss: 0.15909525156021118\n",
      "Batch 1250,  loss: 0.16432554721832277\n",
      "Batch 1255,  loss: 0.18020076155662537\n",
      "Batch 1260,  loss: 0.1977826714515686\n",
      "Batch 1265,  loss: 0.18934510946273803\n",
      "Batch 1270,  loss: 0.1695144444704056\n",
      "Batch 1275,  loss: 0.17148114442825318\n",
      "Batch 1280,  loss: 0.16622587740421296\n",
      "Batch 1285,  loss: 0.14325038492679595\n",
      "Batch 1290,  loss: 0.18611026108264922\n",
      "Batch 1295,  loss: 0.1845427095890045\n",
      "Batch 1300,  loss: 0.14562391340732575\n",
      "Batch 1305,  loss: 0.18445651233196259\n",
      "Batch 1310,  loss: 0.20459029972553253\n",
      "Batch 1315,  loss: 0.17149531841278076\n",
      "Batch 1320,  loss: 0.17417152225971222\n",
      "Batch 1325,  loss: 0.1401477187871933\n",
      "Batch 1330,  loss: 0.14520817548036574\n",
      "Batch 1335,  loss: 0.19890135228633882\n",
      "Batch 1340,  loss: 0.19061275124549865\n",
      "Batch 1345,  loss: 0.14229295700788497\n",
      "Batch 1350,  loss: 0.18846177011728288\n",
      "Batch 1355,  loss: 0.1477775752544403\n",
      "Batch 1360,  loss: 0.17168707251548768\n",
      "Batch 1365,  loss: 0.2723347991704941\n",
      "Batch 1370,  loss: 0.17414070665836334\n",
      "Batch 1375,  loss: 0.22037428617477417\n",
      "Batch 1380,  loss: 0.15277490764856339\n",
      "Batch 1385,  loss: 0.15521768480539322\n",
      "Batch 1390,  loss: 0.15636834353208542\n",
      "Batch 1395,  loss: 0.14481949359178542\n",
      "Batch 1400,  loss: 0.16562249660491943\n",
      "Batch 1405,  loss: 0.14951418042182923\n",
      "Batch 1410,  loss: 0.17153307497501374\n",
      "Batch 1415,  loss: 0.17733739614486693\n",
      "Batch 1420,  loss: 0.1961185574531555\n",
      "Batch 1425,  loss: 0.14998126775026321\n",
      "Batch 1430,  loss: 0.1729203939437866\n",
      "Batch 1435,  loss: 0.1477164015173912\n",
      "Batch 1440,  loss: 0.16988094449043273\n",
      "Batch 1445,  loss: 0.18061843514442444\n",
      "Batch 1450,  loss: 0.19741616547107696\n",
      "Batch 1455,  loss: 0.22453240156173707\n",
      "Batch 1460,  loss: 0.18192404210567475\n",
      "Batch 1465,  loss: 0.21657954156398773\n",
      "Batch 1470,  loss: 0.2557628661394119\n",
      "Batch 1475,  loss: 0.15774895548820494\n",
      "Batch 1480,  loss: 0.1599601000547409\n",
      "Batch 1485,  loss: 0.19467446804046631\n",
      "Batch 1490,  loss: 0.18499311804771423\n",
      "Batch 1495,  loss: 0.1850037693977356\n",
      "Batch 1500,  loss: 0.17133163511753083\n",
      "Batch 1505,  loss: 0.16678943037986754\n",
      "Batch 1510,  loss: 0.17009329199790954\n",
      "Batch 1515,  loss: 0.17408037185668945\n",
      "Batch 1520,  loss: 0.20690342485904695\n",
      "Batch 1525,  loss: 0.16819506883621216\n",
      "Batch 1530,  loss: 0.15017330944538115\n",
      "Batch 1535,  loss: 0.17158551067113875\n",
      "Batch 1540,  loss: 0.16902866065502167\n",
      "Batch 1545,  loss: 0.1697342038154602\n",
      "Batch 1550,  loss: 0.1494172751903534\n",
      "Batch 1555,  loss: 0.17514351904392242\n",
      "Batch 1560,  loss: 0.1417900338768959\n",
      "Batch 1565,  loss: 0.1742513209581375\n",
      "Batch 1570,  loss: 0.20892041623592378\n",
      "Batch 1575,  loss: 0.1842374935746193\n",
      "Batch 1580,  loss: 0.19295852184295653\n",
      "Batch 1585,  loss: 0.16082426607608796\n",
      "Batch 1590,  loss: 0.14508000612258912\n",
      "Batch 1595,  loss: 0.15531731843948365\n",
      "Batch 1600,  loss: 0.1895523875951767\n",
      "Batch 1605,  loss: 0.20522594451904297\n",
      "Batch 1610,  loss: 0.1824462115764618\n",
      "Batch 1615,  loss: 0.22228411734104156\n",
      "Batch 1620,  loss: 0.19768937826156616\n",
      "Batch 1625,  loss: 0.17088955491781235\n",
      "Batch 1630,  loss: 0.19561006724834443\n",
      "Batch 1635,  loss: 0.17812296450138093\n",
      "Batch 1640,  loss: 0.1904577374458313\n",
      "Batch 1645,  loss: 0.20144015699625015\n",
      "Batch 1650,  loss: 0.1926496922969818\n",
      "Batch 1655,  loss: 0.16132960319519044\n",
      "Batch 1660,  loss: 0.19666422307491302\n",
      "Batch 1665,  loss: 0.15338268280029296\n",
      "Batch 1670,  loss: 0.17153640687465668\n",
      "Batch 1675,  loss: 0.2510638564825058\n",
      "Batch 1680,  loss: 0.16634891629219056\n",
      "Batch 1685,  loss: 0.1439051568508148\n",
      "Batch 1690,  loss: 0.1783948928117752\n",
      "Batch 1695,  loss: 0.1908275455236435\n",
      "Batch 1700,  loss: 0.1466514840722084\n",
      "Batch 1705,  loss: 0.15730884969234465\n",
      "Batch 1710,  loss: 0.18974874764680863\n",
      "Batch 1715,  loss: 0.2470440149307251\n",
      "Batch 1720,  loss: 0.17585859447717667\n",
      "Batch 1725,  loss: 0.18109426498413086\n",
      "Batch 1730,  loss: 0.21351175904273986\n",
      "Batch 1735,  loss: 0.1735102653503418\n",
      "Batch 1740,  loss: 0.1489672228693962\n",
      "Batch 1745,  loss: 0.20090629756450654\n",
      "Batch 1750,  loss: 0.19554345607757567\n",
      "Batch 1755,  loss: 0.1866586059331894\n",
      "Batch 1760,  loss: 0.1799836128950119\n",
      "Batch 1765,  loss: 0.18872150480747224\n",
      "Batch 1770,  loss: 0.16110890954732895\n",
      "Batch 1775,  loss: 0.16375303268432617\n",
      "Batch 1780,  loss: 0.1757627993822098\n",
      "Batch 1785,  loss: 0.17093899846076965\n",
      "Batch 1790,  loss: 0.16936081945896148\n",
      "Batch 1795,  loss: 0.1759827107191086\n",
      "Batch 1800,  loss: 0.15611973106861116\n",
      "Batch 1805,  loss: 0.14551297575235367\n",
      "Batch 1810,  loss: 0.18840201199054718\n",
      "Batch 1815,  loss: 0.180489182472229\n",
      "Batch 1820,  loss: 0.2102120816707611\n",
      "Batch 1825,  loss: 0.21781456768512725\n",
      "Batch 1830,  loss: 0.1697611168026924\n",
      "Batch 1835,  loss: 0.16178684085607528\n",
      "Batch 1840,  loss: 0.1819013774394989\n",
      "Batch 1845,  loss: 0.17923795580863952\n",
      "Batch 1850,  loss: 0.15513170063495635\n",
      "Batch 1855,  loss: 0.23448250889778138\n",
      "Batch 1860,  loss: 0.15632963329553604\n",
      "Batch 1865,  loss: 0.1925139009952545\n",
      "Batch 1870,  loss: 0.160973197221756\n",
      "Batch 1875,  loss: 0.18026560246944429\n",
      "Batch 1880,  loss: 0.17861189544200898\n",
      "Batch 1885,  loss: 0.21164262890815735\n",
      "Batch 1890,  loss: 0.2004319816827774\n",
      "Batch 1895,  loss: 0.18998468667268753\n",
      "Batch 1900,  loss: 0.18507709503173828\n",
      "Batch 1905,  loss: 0.21292713284492493\n",
      "Batch 1910,  loss: 0.20938736498355864\n",
      "Batch 1915,  loss: 0.1742858797311783\n",
      "Batch 1920,  loss: 0.17008742988109588\n",
      "Batch 1925,  loss: 0.1886279284954071\n",
      "Batch 1930,  loss: 0.18494077771902084\n",
      "Batch 1935,  loss: 0.15413723289966583\n",
      "Batch 1940,  loss: 0.23033497035503386\n",
      "Batch 1945,  loss: 0.18101792335510253\n",
      "Batch 1950,  loss: 0.164070463180542\n",
      "Batch 1955,  loss: 0.15269522070884706\n",
      "Batch 1960,  loss: 0.19924008548259736\n",
      "Batch 1965,  loss: 0.18842942714691163\n",
      "Batch 1970,  loss: 0.15121518671512604\n",
      "Batch 1975,  loss: 0.15886105298995973\n",
      "Batch 1980,  loss: 0.20384930670261384\n",
      "Batch 1985,  loss: 0.1800166219472885\n",
      "Batch 1990,  loss: 0.16132056713104248\n",
      "Batch 1995,  loss: 0.22529112696647643\n",
      "Batch 2000,  loss: 0.16839003562927246\n",
      "Batch 2005,  loss: 0.24551970064640044\n",
      "Batch 2010,  loss: 0.16550120562314988\n",
      "Batch 2015,  loss: 0.1944709002971649\n",
      "Batch 2020,  loss: 0.1373996078968048\n",
      "Batch 2025,  loss: 0.20001426786184312\n",
      "Batch 2030,  loss: 0.20903109312057494\n",
      "Batch 2035,  loss: 0.20122028291225433\n",
      "Batch 2040,  loss: 0.20016077160835266\n",
      "Batch 2045,  loss: 0.16486993730068206\n",
      "Batch 2050,  loss: 0.15390570014715194\n",
      "Batch 2055,  loss: 0.15341026186943055\n",
      "Batch 2060,  loss: 0.20378800928592683\n",
      "Batch 2065,  loss: 0.20679156482219696\n",
      "Batch 2070,  loss: 0.2071591556072235\n",
      "Batch 2075,  loss: 0.18148685693740846\n",
      "Batch 2080,  loss: 0.17589851021766661\n",
      "Batch 2085,  loss: 0.2240179032087326\n",
      "Batch 2090,  loss: 0.20688245296478272\n",
      "Batch 2095,  loss: 0.2198657751083374\n",
      "Batch 2100,  loss: 0.18864994943141938\n",
      "Batch 2105,  loss: 0.2179841011762619\n",
      "Batch 2110,  loss: 0.21990255117416382\n",
      "Batch 2115,  loss: 0.163106968998909\n",
      "Batch 2120,  loss: 0.1812635689973831\n",
      "Batch 2125,  loss: 0.19707990288734437\n",
      "Batch 2130,  loss: 0.20084112584590913\n",
      "Batch 2135,  loss: 0.1727702796459198\n",
      "Batch 2140,  loss: 0.21297461092472075\n",
      "Batch 2145,  loss: 0.1821183979511261\n",
      "Batch 2150,  loss: 0.23826580345630646\n",
      "Batch 2155,  loss: 0.18203341960906982\n",
      "Batch 2160,  loss: 0.19224265813827515\n",
      "Batch 2165,  loss: 0.1979289621114731\n",
      "Batch 2170,  loss: 0.1932304561138153\n",
      "Batch 2175,  loss: 0.1422771245241165\n",
      "Batch 2180,  loss: 0.17724522799253464\n",
      "Batch 2185,  loss: 0.1682501584291458\n",
      "Batch 2190,  loss: 0.16543377339839935\n",
      "Batch 2195,  loss: 0.16501988768577575\n",
      "Batch 2200,  loss: 0.1670744776725769\n",
      "Batch 2205,  loss: 0.1838644415140152\n",
      "Batch 2210,  loss: 0.23403004705905914\n",
      "Batch 2215,  loss: 0.18387265503406525\n",
      "Batch 2220,  loss: 0.17933814972639084\n",
      "Batch 2225,  loss: 0.2019905686378479\n",
      "Batch 2230,  loss: 0.1502743184566498\n",
      "Batch 2235,  loss: 0.1756383642554283\n",
      "Batch 2240,  loss: 0.17316959351301192\n",
      "Batch 2245,  loss: 0.19703624546527862\n",
      "Batch 2250,  loss: 0.14791831374168396\n",
      "Batch 2255,  loss: 0.1428140938282013\n",
      "Batch 2260,  loss: 0.16996294260025024\n",
      "Batch 2265,  loss: 0.16062869131565094\n",
      "Batch 2270,  loss: 0.2151849389076233\n",
      "Batch 2275,  loss: 0.1541255757212639\n",
      "Batch 2280,  loss: 0.16613764315843582\n",
      "Batch 2285,  loss: 0.1817651852965355\n",
      "Batch 2290,  loss: 0.21083944141864777\n",
      "Batch 2295,  loss: 0.2258070409297943\n",
      "Batch 2300,  loss: 0.1901908278465271\n",
      "Batch 2305,  loss: 0.15402258932590485\n",
      "Batch 2310,  loss: 0.17011163234710694\n",
      "Batch 2315,  loss: 0.19349675476551056\n",
      "Batch 2320,  loss: 0.20136115849018096\n",
      "Batch 2325,  loss: 0.17204726338386536\n",
      "Batch 2330,  loss: 0.16186424791812898\n",
      "Batch 2335,  loss: 0.15704548060894014\n",
      "Batch 2340,  loss: 0.17276481539011002\n",
      "Batch 2345,  loss: 0.14225537478923797\n",
      "Batch 2350,  loss: 0.16469996869564058\n",
      "Batch 2355,  loss: 0.20325141847133638\n",
      "Batch 2360,  loss: 0.1427423194050789\n",
      "Batch 2365,  loss: 0.169965922832489\n",
      "Batch 2370,  loss: 0.1957551807165146\n",
      "Batch 2375,  loss: 0.17436553835868834\n",
      "Batch 2380,  loss: 0.1571862816810608\n",
      "Batch 2385,  loss: 0.16993462145328522\n",
      "Batch 2390,  loss: 0.1831190049648285\n",
      "Batch 2395,  loss: 0.21471457481384276\n",
      "Batch 2400,  loss: 0.16530443131923675\n",
      "Batch 2405,  loss: 0.1893041491508484\n",
      "Batch 2410,  loss: 0.14841271936893463\n",
      "Batch 2415,  loss: 0.1853776231408119\n",
      "Batch 2420,  loss: 0.14956369400024414\n",
      "Batch 2425,  loss: 0.1524621844291687\n",
      "Batch 2430,  loss: 0.17985337376594543\n",
      "Batch 2435,  loss: 0.18950120508670806\n",
      "Batch 2440,  loss: 0.18956951200962066\n",
      "Batch 2445,  loss: 0.20006747245788575\n",
      "Batch 2450,  loss: 0.18891876339912414\n",
      "Batch 2455,  loss: 0.19626773595809938\n",
      "Batch 2460,  loss: 0.20316652357578277\n",
      "Batch 2465,  loss: 0.1793816864490509\n",
      "Batch 2470,  loss: 0.20707656741142272\n",
      "Batch 2475,  loss: 0.16589537560939788\n",
      "Batch 2480,  loss: 0.24552165865898132\n",
      "Batch 2485,  loss: 0.20789392590522765\n",
      "Batch 2490,  loss: 0.14438059628009797\n",
      "Batch 2495,  loss: 0.1660046547651291\n",
      "Batch 2500,  loss: 0.18770260512828826\n",
      "Batch 2505,  loss: 0.16865462362766265\n",
      "Batch 2510,  loss: 0.17051116228103638\n",
      "Batch 2515,  loss: 0.1977295011281967\n",
      "Batch 2520,  loss: 0.2094426214694977\n",
      "Batch 2525,  loss: 0.18367029428482057\n",
      "Batch 2530,  loss: 0.23907639384269713\n",
      "Batch 2535,  loss: 0.20120421051979065\n",
      "Batch 2540,  loss: 0.16280301064252853\n",
      "Batch 2545,  loss: 0.17088132500648498\n",
      "Batch 2550,  loss: 0.17075012624263763\n",
      "Batch 2555,  loss: 0.18271597921848298\n",
      "Batch 2560,  loss: 0.18582823872566223\n",
      "Batch 2565,  loss: 0.162080055475235\n",
      "Batch 2570,  loss: 0.18842009007930755\n",
      "Batch 2575,  loss: 0.21837034225463867\n",
      "Batch 2580,  loss: 0.1583915174007416\n",
      "Batch 2585,  loss: 0.19357562959194183\n",
      "Batch 2590,  loss: 0.15634205639362336\n",
      "Batch 2595,  loss: 0.18125616908073425\n",
      "Batch 2600,  loss: 0.20891607999801637\n",
      "Batch 2605,  loss: 0.20796154141426088\n",
      "Batch 2610,  loss: 0.16434729099273682\n",
      "Batch 2615,  loss: 0.17950755059719087\n",
      "Batch 2620,  loss: 0.21074748933315277\n",
      "Batch 2625,  loss: 0.16713539958000184\n",
      "Batch 2630,  loss: 0.1960790902376175\n",
      "Batch 2635,  loss: 0.16717098653316498\n",
      "Batch 2640,  loss: 0.17322282642126083\n",
      "Batch 2645,  loss: 0.2007325142621994\n",
      "Batch 2650,  loss: 0.14705124646425247\n",
      "Batch 2655,  loss: 0.18839502930641175\n",
      "Batch 2660,  loss: 0.16002621054649352\n",
      "Batch 2665,  loss: 0.19958626180887223\n",
      "Batch 2670,  loss: 0.16451845765113832\n",
      "Batch 2675,  loss: 0.15080457627773286\n",
      "Batch 2680,  loss: 0.16076481938362122\n",
      "Batch 2685,  loss: 0.19891510605812074\n",
      "Batch 2690,  loss: 0.17815947085618972\n",
      "Batch 2695,  loss: 0.21529473662376403\n",
      "Batch 2700,  loss: 0.1723264902830124\n",
      "Batch 2705,  loss: 0.18210484981536865\n",
      "Batch 2710,  loss: 0.21099109053611756\n",
      "Batch 2715,  loss: 0.18097566366195678\n",
      "Batch 2720,  loss: 0.184655100107193\n",
      "Batch 2725,  loss: 0.12969342470169068\n",
      "Batch 2730,  loss: 0.16970148980617522\n",
      "Batch 2735,  loss: 0.19452299624681474\n",
      "Batch 2740,  loss: 0.1801593780517578\n",
      "Batch 2745,  loss: 0.1706590846180916\n",
      "Batch 2750,  loss: 0.15880924165248872\n",
      "Batch 2755,  loss: 0.1827526271343231\n",
      "Batch 2760,  loss: 0.24934012591838836\n",
      "Batch 2765,  loss: 0.19431768357753754\n",
      "Batch 2770,  loss: 0.15516409575939177\n",
      "LOSS train 0.15516409575939177. Validation loss: 0.17246221140613435 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 15:\n",
      "Batch 5,  loss: 0.1457533434033394\n",
      "Batch 10,  loss: 0.15719615221023558\n",
      "Batch 15,  loss: 0.1614713728427887\n",
      "Batch 20,  loss: 0.1671936631202698\n",
      "Batch 25,  loss: 0.1269132137298584\n",
      "Batch 30,  loss: 0.20192913711071014\n",
      "Batch 35,  loss: 0.21217000782489776\n",
      "Batch 40,  loss: 0.19954587817192077\n",
      "Batch 45,  loss: 0.1450283169746399\n",
      "Batch 50,  loss: 0.20344111919403077\n",
      "Batch 55,  loss: 0.18230075538158416\n",
      "Batch 60,  loss: 0.18869025707244874\n",
      "Batch 65,  loss: 0.18624521493911744\n",
      "Batch 70,  loss: 0.17352272272109986\n",
      "Batch 75,  loss: 0.16472443640232087\n",
      "Batch 80,  loss: 0.1793018639087677\n",
      "Batch 85,  loss: 0.17020272016525267\n",
      "Batch 90,  loss: 0.15370544493198396\n",
      "Batch 95,  loss: 0.18977282643318177\n",
      "Batch 100,  loss: 0.18164026141166686\n",
      "Batch 105,  loss: 0.1762989193201065\n",
      "Batch 110,  loss: 0.15274569392204285\n",
      "Batch 115,  loss: 0.17532490491867064\n",
      "Batch 120,  loss: 0.16989440321922303\n",
      "Batch 125,  loss: 0.21748834550380708\n",
      "Batch 130,  loss: 0.1893705040216446\n",
      "Batch 135,  loss: 0.14756554514169692\n",
      "Batch 140,  loss: 0.18626387119293214\n",
      "Batch 145,  loss: 0.19963789135217666\n",
      "Batch 150,  loss: 0.17885320037603378\n",
      "Batch 155,  loss: 0.16518151760101318\n",
      "Batch 160,  loss: 0.18596612811088561\n",
      "Batch 165,  loss: 0.1973553329706192\n",
      "Batch 170,  loss: 0.1504617765545845\n",
      "Batch 175,  loss: 0.21139952540397644\n",
      "Batch 180,  loss: 0.20614518523216246\n",
      "Batch 185,  loss: 0.17210661321878434\n",
      "Batch 190,  loss: 0.17493434846401215\n",
      "Batch 195,  loss: 0.1862664371728897\n",
      "Batch 200,  loss: 0.20221006870269775\n",
      "Batch 205,  loss: 0.16996851861476897\n",
      "Batch 210,  loss: 0.17718491852283477\n",
      "Batch 215,  loss: 0.17796961665153505\n",
      "Batch 220,  loss: 0.1719308614730835\n",
      "Batch 225,  loss: 0.19155541360378264\n",
      "Batch 230,  loss: 0.20136860013008118\n",
      "Batch 235,  loss: 0.18677834570407867\n",
      "Batch 240,  loss: 0.20004386007785796\n",
      "Batch 245,  loss: 0.24100984036922454\n",
      "Batch 250,  loss: 0.1778235375881195\n",
      "Batch 255,  loss: 0.17295394837856293\n",
      "Batch 260,  loss: 0.19138556718826294\n",
      "Batch 265,  loss: 0.1348986506462097\n",
      "Batch 270,  loss: 0.17365774214267732\n",
      "Batch 275,  loss: 0.14996800273656846\n",
      "Batch 280,  loss: 0.16937122941017152\n",
      "Batch 285,  loss: 0.17191587686538695\n",
      "Batch 290,  loss: 0.1423657402396202\n",
      "Batch 295,  loss: 0.21001680493354796\n",
      "Batch 300,  loss: 0.1544609934091568\n",
      "Batch 305,  loss: 0.21225101947784425\n",
      "Batch 310,  loss: 0.17070485055446624\n",
      "Batch 315,  loss: 0.18390392065048217\n",
      "Batch 320,  loss: 0.18715596199035645\n",
      "Batch 325,  loss: 0.2071705162525177\n",
      "Batch 330,  loss: 0.20137544572353364\n",
      "Batch 335,  loss: 0.15769869983196258\n",
      "Batch 340,  loss: 0.2578846663236618\n",
      "Batch 345,  loss: 0.18527622520923615\n",
      "Batch 350,  loss: 0.16220428943634033\n",
      "Batch 355,  loss: 0.15469013005495072\n",
      "Batch 360,  loss: 0.15468741059303284\n",
      "Batch 365,  loss: 0.1900728926062584\n",
      "Batch 370,  loss: 0.13282448947429656\n",
      "Batch 375,  loss: 0.16641144454479218\n",
      "Batch 380,  loss: 0.1790095642209053\n",
      "Batch 385,  loss: 0.1372244730591774\n",
      "Batch 390,  loss: 0.20001210272312164\n",
      "Batch 395,  loss: 0.17176578044891358\n",
      "Batch 400,  loss: 0.14025591015815736\n",
      "Batch 405,  loss: 0.17455307245254517\n",
      "Batch 410,  loss: 0.15517458617687224\n",
      "Batch 415,  loss: 0.16766001731157304\n",
      "Batch 420,  loss: 0.18035558760166168\n",
      "Batch 425,  loss: 0.14251810908317566\n",
      "Batch 430,  loss: 0.16117151230573654\n",
      "Batch 435,  loss: 0.15382764488458633\n",
      "Batch 440,  loss: 0.14992564916610718\n",
      "Batch 445,  loss: 0.1414966180920601\n",
      "Batch 450,  loss: 0.19861584901809692\n",
      "Batch 455,  loss: 0.19032725989818572\n",
      "Batch 460,  loss: 0.17068488597869874\n",
      "Batch 465,  loss: 0.20179405808448792\n",
      "Batch 470,  loss: 0.18911561965942383\n",
      "Batch 475,  loss: 0.1518495887517929\n",
      "Batch 480,  loss: 0.21276915967464446\n",
      "Batch 485,  loss: 0.17511655390262604\n",
      "Batch 490,  loss: 0.17488197684288026\n",
      "Batch 495,  loss: 0.24949417412281036\n",
      "Batch 500,  loss: 0.18342678099870682\n",
      "Batch 505,  loss: 0.16762910783290863\n",
      "Batch 510,  loss: 0.16320383548736572\n",
      "Batch 515,  loss: 0.19509456753730775\n",
      "Batch 520,  loss: 0.1289534568786621\n",
      "Batch 525,  loss: 0.200144961476326\n",
      "Batch 530,  loss: 0.15609320104122162\n",
      "Batch 535,  loss: 0.128749880194664\n",
      "Batch 540,  loss: 0.2132483035326004\n",
      "Batch 545,  loss: 0.18642689883708954\n",
      "Batch 550,  loss: 0.1769179254770279\n",
      "Batch 555,  loss: 0.19217347502708435\n",
      "Batch 560,  loss: 0.19798271507024764\n",
      "Batch 565,  loss: 0.17518254816532136\n",
      "Batch 570,  loss: 0.14159861207008362\n",
      "Batch 575,  loss: 0.1725998267531395\n",
      "Batch 580,  loss: 0.1917822003364563\n",
      "Batch 585,  loss: 0.1842193126678467\n",
      "Batch 590,  loss: 0.1472407877445221\n",
      "Batch 595,  loss: 0.1723536431789398\n",
      "Batch 600,  loss: 0.21169947385787963\n",
      "Batch 605,  loss: 0.14739756435155868\n",
      "Batch 610,  loss: 0.2228219836950302\n",
      "Batch 615,  loss: 0.2088787242770195\n",
      "Batch 620,  loss: 0.18771125823259355\n",
      "Batch 625,  loss: 0.18611448109149933\n",
      "Batch 630,  loss: 0.18960972726345063\n",
      "Batch 635,  loss: 0.15645130723714828\n",
      "Batch 640,  loss: 0.18476659804582596\n",
      "Batch 645,  loss: 0.22586712539196013\n",
      "Batch 650,  loss: 0.2177708387374878\n",
      "Batch 655,  loss: 0.13277194201946257\n",
      "Batch 660,  loss: 0.16605569422245026\n",
      "Batch 665,  loss: 0.17355250418186188\n",
      "Batch 670,  loss: 0.17346589565277098\n",
      "Batch 675,  loss: 0.17155976891517638\n",
      "Batch 680,  loss: 0.24788883626461028\n",
      "Batch 685,  loss: 0.16286391913890838\n",
      "Batch 690,  loss: 0.1978260338306427\n",
      "Batch 695,  loss: 0.15437932908535004\n",
      "Batch 700,  loss: 0.18990648090839385\n",
      "Batch 705,  loss: 0.19120485782623292\n",
      "Batch 710,  loss: 0.13353707790374755\n",
      "Batch 715,  loss: 0.21902027130126953\n",
      "Batch 720,  loss: 0.22502115070819856\n",
      "Batch 725,  loss: 0.1961096927523613\n",
      "Batch 730,  loss: 0.14458419978618622\n",
      "Batch 735,  loss: 0.18538890182971954\n",
      "Batch 740,  loss: 0.18167030215263366\n",
      "Batch 745,  loss: 0.21346572637557984\n",
      "Batch 750,  loss: 0.19336827844381332\n",
      "Batch 755,  loss: 0.14691732823848724\n",
      "Batch 760,  loss: 0.15312288403511048\n",
      "Batch 765,  loss: 0.1974451422691345\n",
      "Batch 770,  loss: 0.17733185291290282\n",
      "Batch 775,  loss: 0.20937927365303038\n",
      "Batch 780,  loss: 0.19202982783317565\n",
      "Batch 785,  loss: 0.17792699933052064\n",
      "Batch 790,  loss: 0.189905521273613\n",
      "Batch 795,  loss: 0.1885443240404129\n",
      "Batch 800,  loss: 0.17059336304664613\n",
      "Batch 805,  loss: 0.14296877086162568\n",
      "Batch 810,  loss: 0.15835194885730744\n",
      "Batch 815,  loss: 0.17586441338062286\n",
      "Batch 820,  loss: 0.18676879107952118\n",
      "Batch 825,  loss: 0.20229871273040773\n",
      "Batch 830,  loss: 0.13204023838043213\n",
      "Batch 835,  loss: 0.1990156352519989\n",
      "Batch 840,  loss: 0.19188071191310882\n",
      "Batch 845,  loss: 0.16893505454063415\n",
      "Batch 850,  loss: 0.18467153161764144\n",
      "Batch 855,  loss: 0.15544606000185013\n",
      "Batch 860,  loss: 0.16828059107065202\n",
      "Batch 865,  loss: 0.18731766194105148\n",
      "Batch 870,  loss: 0.1784638226032257\n",
      "Batch 875,  loss: 0.16499971151351928\n",
      "Batch 880,  loss: 0.13291824907064437\n",
      "Batch 885,  loss: 0.1666811466217041\n",
      "Batch 890,  loss: 0.16530055105686187\n",
      "Batch 895,  loss: 0.157820862531662\n",
      "Batch 900,  loss: 0.24251697063446045\n",
      "Batch 905,  loss: 0.1894106537103653\n",
      "Batch 910,  loss: 0.1840873673558235\n",
      "Batch 915,  loss: 0.16956217736005783\n",
      "Batch 920,  loss: 0.16740725338459014\n",
      "Batch 925,  loss: 0.18377077728509902\n",
      "Batch 930,  loss: 0.20173000991344453\n",
      "Batch 935,  loss: 0.167391736805439\n",
      "Batch 940,  loss: 0.23334522545337677\n",
      "Batch 945,  loss: 0.1800595223903656\n",
      "Batch 950,  loss: 0.18564495742321013\n",
      "Batch 955,  loss: 0.2114173799753189\n",
      "Batch 960,  loss: 0.17229219377040864\n",
      "Batch 965,  loss: 0.15558636486530303\n",
      "Batch 970,  loss: 0.18503798693418502\n",
      "Batch 975,  loss: 0.17959485352039337\n",
      "Batch 980,  loss: 0.1886881709098816\n",
      "Batch 985,  loss: 0.18643526136875152\n",
      "Batch 990,  loss: 0.15374147295951843\n",
      "Batch 995,  loss: 0.16827016770839692\n",
      "Batch 1000,  loss: 0.15417293906211854\n",
      "Batch 1005,  loss: 0.18829544484615326\n",
      "Batch 1010,  loss: 0.17690641433000565\n",
      "Batch 1015,  loss: 0.2062601327896118\n",
      "Batch 1020,  loss: 0.16777912825345992\n",
      "Batch 1025,  loss: 0.1440393805503845\n",
      "Batch 1030,  loss: 0.15596267133951186\n",
      "Batch 1035,  loss: 0.16479988545179367\n",
      "Batch 1040,  loss: 0.21060875952243804\n",
      "Batch 1045,  loss: 0.18301718831062316\n",
      "Batch 1050,  loss: 0.17653251588344573\n",
      "Batch 1055,  loss: 0.15731174349784852\n",
      "Batch 1060,  loss: 0.20690280348062515\n",
      "Batch 1065,  loss: 0.1374804437160492\n",
      "Batch 1070,  loss: 0.14662856459617615\n",
      "Batch 1075,  loss: 0.1767264723777771\n",
      "Batch 1080,  loss: 0.18534432500600814\n",
      "Batch 1085,  loss: 0.21359959840774537\n",
      "Batch 1090,  loss: 0.16720970273017882\n",
      "Batch 1095,  loss: 0.19870888739824294\n",
      "Batch 1100,  loss: 0.18742435574531555\n",
      "Batch 1105,  loss: 0.162079855799675\n",
      "Batch 1110,  loss: 0.18082510381937028\n",
      "Batch 1115,  loss: 0.1881456583738327\n",
      "Batch 1120,  loss: 0.19835953414440155\n",
      "Batch 1125,  loss: 0.15892022252082824\n",
      "Batch 1130,  loss: 0.16772631108760833\n",
      "Batch 1135,  loss: 0.17688489109277725\n",
      "Batch 1140,  loss: 0.1734231650829315\n",
      "Batch 1145,  loss: 0.20623927116394042\n",
      "Batch 1150,  loss: 0.1961607187986374\n",
      "Batch 1155,  loss: 0.15476502776145934\n",
      "Batch 1160,  loss: 0.15503469854593277\n",
      "Batch 1165,  loss: 0.16604937613010406\n",
      "Batch 1170,  loss: 0.22036106288433074\n",
      "Batch 1175,  loss: 0.19064247757196426\n",
      "Batch 1180,  loss: 0.16694090366363526\n",
      "Batch 1185,  loss: 0.16853534877300264\n",
      "Batch 1190,  loss: 0.1306306391954422\n",
      "Batch 1195,  loss: 0.19915909469127654\n",
      "Batch 1200,  loss: 0.1833016484975815\n",
      "Batch 1205,  loss: 0.1858913540840149\n",
      "Batch 1210,  loss: 0.1946125239133835\n",
      "Batch 1215,  loss: 0.15846610367298125\n",
      "Batch 1220,  loss: 0.15089562833309172\n",
      "Batch 1225,  loss: 0.1229006215929985\n",
      "Batch 1230,  loss: 0.1877347022294998\n",
      "Batch 1235,  loss: 0.18697290420532225\n",
      "Batch 1240,  loss: 0.1767866089940071\n",
      "Batch 1245,  loss: 0.12275417447090149\n",
      "Batch 1250,  loss: 0.2197491466999054\n",
      "Batch 1255,  loss: 0.19863414764404297\n",
      "Batch 1260,  loss: 0.15707551687955856\n",
      "Batch 1265,  loss: 0.17551958560943604\n",
      "Batch 1270,  loss: 0.17737798094749452\n",
      "Batch 1275,  loss: 0.1624582901597023\n",
      "Batch 1280,  loss: 0.17571785748004914\n",
      "Batch 1285,  loss: 0.1745762676000595\n",
      "Batch 1290,  loss: 0.23646503686904907\n",
      "Batch 1295,  loss: 0.18458424806594848\n",
      "Batch 1300,  loss: 0.1966276854276657\n",
      "Batch 1305,  loss: 0.16018233001232146\n",
      "Batch 1310,  loss: 0.16727278083562852\n",
      "Batch 1315,  loss: 0.2179398149251938\n",
      "Batch 1320,  loss: 0.18033088892698287\n",
      "Batch 1325,  loss: 0.21278911232948303\n",
      "Batch 1330,  loss: 0.17875089049339293\n",
      "Batch 1335,  loss: 0.2449325829744339\n",
      "Batch 1340,  loss: 0.1508965849876404\n",
      "Batch 1345,  loss: 0.1696817934513092\n",
      "Batch 1350,  loss: 0.1308347374200821\n",
      "Batch 1355,  loss: 0.15410311222076417\n",
      "Batch 1360,  loss: 0.24699523746967317\n",
      "Batch 1365,  loss: 0.19258669316768645\n",
      "Batch 1370,  loss: 0.15471153259277343\n",
      "Batch 1375,  loss: 0.1744493216276169\n",
      "Batch 1380,  loss: 0.1765639901161194\n",
      "Batch 1385,  loss: 0.13620046079158782\n",
      "Batch 1390,  loss: 0.18509330451488495\n",
      "Batch 1395,  loss: 0.22610852122306824\n",
      "Batch 1400,  loss: 0.1614968240261078\n",
      "Batch 1405,  loss: 0.19874571561813353\n",
      "Batch 1410,  loss: 0.18061716258525848\n",
      "Batch 1415,  loss: 0.1588571473956108\n",
      "Batch 1420,  loss: 0.21526328921318055\n",
      "Batch 1425,  loss: 0.15837303698062896\n",
      "Batch 1430,  loss: 0.16688347160816192\n",
      "Batch 1435,  loss: 0.1983553946018219\n",
      "Batch 1440,  loss: 0.21284184753894805\n",
      "Batch 1445,  loss: 0.16206721365451812\n",
      "Batch 1450,  loss: 0.20466732680797578\n",
      "Batch 1455,  loss: 0.1579361617565155\n",
      "Batch 1460,  loss: 0.1854136824607849\n",
      "Batch 1465,  loss: 0.24030499458312987\n",
      "Batch 1470,  loss: 0.18043981790542601\n",
      "Batch 1475,  loss: 0.26430373191833495\n",
      "Batch 1480,  loss: 0.18906785249710084\n",
      "Batch 1485,  loss: 0.17213278114795685\n",
      "Batch 1490,  loss: 0.16165515035390854\n",
      "Batch 1495,  loss: 0.1661680296063423\n",
      "Batch 1500,  loss: 0.19780127108097076\n",
      "Batch 1505,  loss: 0.13223282992839813\n",
      "Batch 1510,  loss: 0.1344711184501648\n",
      "Batch 1515,  loss: 0.17389279901981353\n",
      "Batch 1520,  loss: 0.20069184452295302\n",
      "Batch 1525,  loss: 0.19611373245716096\n",
      "Batch 1530,  loss: 0.17392568141222\n",
      "Batch 1535,  loss: 0.15202624648809432\n",
      "Batch 1540,  loss: 0.15894707590341567\n",
      "Batch 1545,  loss: 0.18005017340183258\n",
      "Batch 1550,  loss: 0.14494653344154357\n",
      "Batch 1555,  loss: 0.13593339473009108\n",
      "Batch 1560,  loss: 0.1809741109609604\n",
      "Batch 1565,  loss: 0.17717955708503724\n",
      "Batch 1570,  loss: 0.18492539823055268\n",
      "Batch 1575,  loss: 0.15334588438272476\n",
      "Batch 1580,  loss: 0.18867810368537902\n",
      "Batch 1585,  loss: 0.2450135201215744\n",
      "Batch 1590,  loss: 0.19439176917076112\n",
      "Batch 1595,  loss: 0.17155715823173523\n",
      "Batch 1600,  loss: 0.16585147827863694\n",
      "Batch 1605,  loss: 0.14974479824304582\n",
      "Batch 1610,  loss: 0.14589285850524902\n",
      "Batch 1615,  loss: 0.16144878417253494\n",
      "Batch 1620,  loss: 0.16019266545772554\n",
      "Batch 1625,  loss: 0.18013688921928406\n",
      "Batch 1630,  loss: 0.20750248730182647\n",
      "Batch 1635,  loss: 0.2094906449317932\n",
      "Batch 1640,  loss: 0.20446999371051788\n",
      "Batch 1645,  loss: 0.16915315985679627\n",
      "Batch 1650,  loss: 0.2051861584186554\n",
      "Batch 1655,  loss: 0.1503770798444748\n",
      "Batch 1660,  loss: 0.1615433692932129\n",
      "Batch 1665,  loss: 0.16550627797842027\n",
      "Batch 1670,  loss: 0.13940248787403106\n",
      "Batch 1675,  loss: 0.1505842074751854\n",
      "Batch 1680,  loss: 0.20944616198539734\n",
      "Batch 1685,  loss: 0.21617081463336946\n",
      "Batch 1690,  loss: 0.21026575416326523\n",
      "Batch 1695,  loss: 0.16610046327114106\n",
      "Batch 1700,  loss: 0.17055667340755462\n",
      "Batch 1705,  loss: 0.19125746488571166\n",
      "Batch 1710,  loss: 0.18606634736061095\n",
      "Batch 1715,  loss: 0.18168485462665557\n",
      "Batch 1720,  loss: 0.17561698257923125\n",
      "Batch 1725,  loss: 0.18646662533283234\n",
      "Batch 1730,  loss: 0.21768229305744172\n",
      "Batch 1735,  loss: 0.15381495654582977\n",
      "Batch 1740,  loss: 0.19525960683822632\n",
      "Batch 1745,  loss: 0.17018423676490785\n",
      "Batch 1750,  loss: 0.19330033361911775\n",
      "Batch 1755,  loss: 0.1971384197473526\n",
      "Batch 1760,  loss: 0.12665688395500183\n",
      "Batch 1765,  loss: 0.18015700280666352\n",
      "Batch 1770,  loss: 0.16068852543830872\n",
      "Batch 1775,  loss: 0.22987047731876373\n",
      "Batch 1780,  loss: 0.20347710847854614\n",
      "Batch 1785,  loss: 0.23357968628406525\n",
      "Batch 1790,  loss: 0.21504070460796357\n",
      "Batch 1795,  loss: 0.20633068084716796\n",
      "Batch 1800,  loss: 0.16864781081676483\n",
      "Batch 1805,  loss: 0.20111246705055236\n",
      "Batch 1810,  loss: 0.19597740173339845\n",
      "Batch 1815,  loss: 0.22984883487224578\n",
      "Batch 1820,  loss: 0.18989717662334443\n",
      "Batch 1825,  loss: 0.17286517918109895\n",
      "Batch 1830,  loss: 0.19253296554088592\n",
      "Batch 1835,  loss: 0.1996362954378128\n",
      "Batch 1840,  loss: 0.1830550879240036\n",
      "Batch 1845,  loss: 0.1788268893957138\n",
      "Batch 1850,  loss: 0.16535884737968445\n",
      "Batch 1855,  loss: 0.13760726153850555\n",
      "Batch 1860,  loss: 0.1456274390220642\n",
      "Batch 1865,  loss: 0.1419288069009781\n",
      "Batch 1870,  loss: 0.1808852344751358\n",
      "Batch 1875,  loss: 0.1730767548084259\n",
      "Batch 1880,  loss: 0.17786029875278472\n",
      "Batch 1885,  loss: 0.14712992012500764\n",
      "Batch 1890,  loss: 0.19167089760303496\n",
      "Batch 1895,  loss: 0.2072497308254242\n",
      "Batch 1900,  loss: 0.1929360419511795\n",
      "Batch 1905,  loss: 0.17377075105905532\n",
      "Batch 1910,  loss: 0.16448026299476623\n",
      "Batch 1915,  loss: 0.18794351816177368\n",
      "Batch 1920,  loss: 0.19659028351306915\n",
      "Batch 1925,  loss: 0.17248515486717225\n",
      "Batch 1930,  loss: 0.14356318712234498\n",
      "Batch 1935,  loss: 0.20602653920650482\n",
      "Batch 1940,  loss: 0.14865854978561402\n",
      "Batch 1945,  loss: 0.17229930460453033\n",
      "Batch 1950,  loss: 0.2111461341381073\n",
      "Batch 1955,  loss: 0.15353567600250245\n",
      "Batch 1960,  loss: 0.23392814695835112\n",
      "Batch 1965,  loss: 0.1370012119412422\n",
      "Batch 1970,  loss: 0.2025571882724762\n",
      "Batch 1975,  loss: 0.16051121652126313\n",
      "Batch 1980,  loss: 0.19636159837245942\n",
      "Batch 1985,  loss: 0.16176465004682541\n",
      "Batch 1990,  loss: 0.1566975474357605\n",
      "Batch 1995,  loss: 0.19566227197647096\n",
      "Batch 2000,  loss: 0.1527446061372757\n",
      "Batch 2005,  loss: 0.20740584880113602\n",
      "Batch 2010,  loss: 0.21622426211833953\n",
      "Batch 2015,  loss: 0.15182927250862122\n",
      "Batch 2020,  loss: 0.13744909763336183\n",
      "Batch 2025,  loss: 0.19758786857128144\n",
      "Batch 2030,  loss: 0.16494676023721694\n",
      "Batch 2035,  loss: 0.1995948374271393\n",
      "Batch 2040,  loss: 0.17156186401844026\n",
      "Batch 2045,  loss: 0.23173809051513672\n",
      "Batch 2050,  loss: 0.19862657487392427\n",
      "Batch 2055,  loss: 0.20969513058662415\n",
      "Batch 2060,  loss: 0.17483640015125274\n",
      "Batch 2065,  loss: 0.18337638974189757\n",
      "Batch 2070,  loss: 0.2154153347015381\n",
      "Batch 2075,  loss: 0.1635676607489586\n",
      "Batch 2080,  loss: 0.14636874496936797\n",
      "Batch 2085,  loss: 0.1997431129217148\n",
      "Batch 2090,  loss: 0.21578529179096223\n",
      "Batch 2095,  loss: 0.13080991059541702\n",
      "Batch 2100,  loss: 0.1894198477268219\n",
      "Batch 2105,  loss: 0.21752333343029023\n",
      "Batch 2110,  loss: 0.1652682602405548\n",
      "Batch 2115,  loss: 0.12444307506084443\n",
      "Batch 2120,  loss: 0.1864977717399597\n",
      "Batch 2125,  loss: 0.17461255192756653\n",
      "Batch 2130,  loss: 0.2005656361579895\n",
      "Batch 2135,  loss: 0.1768009603023529\n",
      "Batch 2140,  loss: 0.17048183977603912\n",
      "Batch 2145,  loss: 0.16738847643136978\n",
      "Batch 2150,  loss: 0.15777018666267395\n",
      "Batch 2155,  loss: 0.17345272302627562\n",
      "Batch 2160,  loss: 0.18530104160308838\n",
      "Batch 2165,  loss: 0.14956863820552826\n",
      "Batch 2170,  loss: 0.17375194132328034\n",
      "Batch 2175,  loss: 0.2066534698009491\n",
      "Batch 2180,  loss: 0.25233928561210633\n",
      "Batch 2185,  loss: 0.139474755525589\n",
      "Batch 2190,  loss: 0.17342582941055298\n",
      "Batch 2195,  loss: 0.14583779871463776\n",
      "Batch 2200,  loss: 0.18720283210277558\n",
      "Batch 2205,  loss: 0.1883605897426605\n",
      "Batch 2210,  loss: 0.18979777693748473\n",
      "Batch 2215,  loss: 0.18180357813835143\n",
      "Batch 2220,  loss: 0.1457266926765442\n",
      "Batch 2225,  loss: 0.16672716438770294\n",
      "Batch 2230,  loss: 0.15464126467704772\n",
      "Batch 2235,  loss: 0.18775232434272765\n",
      "Batch 2240,  loss: 0.14596304595470427\n",
      "Batch 2245,  loss: 0.14676098227500917\n",
      "Batch 2250,  loss: 0.1807653546333313\n",
      "Batch 2255,  loss: 0.1720288336277008\n",
      "Batch 2260,  loss: 0.14748426377773285\n",
      "Batch 2265,  loss: 0.22262876927852632\n",
      "Batch 2270,  loss: 0.13803930282592775\n",
      "Batch 2275,  loss: 0.18143963813781738\n",
      "Batch 2280,  loss: 0.1778012216091156\n",
      "Batch 2285,  loss: 0.17262911200523376\n",
      "Batch 2290,  loss: 0.1534450203180313\n",
      "Batch 2295,  loss: 0.1975573182106018\n",
      "Batch 2300,  loss: 0.1656351000070572\n",
      "Batch 2305,  loss: 0.17205170840024947\n",
      "Batch 2310,  loss: 0.1294270411133766\n",
      "Batch 2315,  loss: 0.19313411116600038\n",
      "Batch 2320,  loss: 0.1950155794620514\n",
      "Batch 2325,  loss: 0.16140906810760497\n",
      "Batch 2330,  loss: 0.1903702586889267\n",
      "Batch 2335,  loss: 0.168188413977623\n",
      "Batch 2340,  loss: 0.18403567969799042\n",
      "Batch 2345,  loss: 0.16952179968357087\n",
      "Batch 2350,  loss: 0.18144101202487944\n",
      "Batch 2355,  loss: 0.18419962525367736\n",
      "Batch 2360,  loss: 0.14203589111566545\n",
      "Batch 2365,  loss: 0.17695510983467103\n",
      "Batch 2370,  loss: 0.15154634565114974\n",
      "Batch 2375,  loss: 0.17811486423015593\n",
      "Batch 2380,  loss: 0.16934265494346618\n",
      "Batch 2385,  loss: 0.17915936261415483\n",
      "Batch 2390,  loss: 0.16268500685691833\n",
      "Batch 2395,  loss: 0.1676050454378128\n",
      "Batch 2400,  loss: 0.1925113469362259\n",
      "Batch 2405,  loss: 0.17138227224349975\n",
      "Batch 2410,  loss: 0.1456035017967224\n",
      "Batch 2415,  loss: 0.17144836038351058\n",
      "Batch 2420,  loss: 0.17872883081436158\n",
      "Batch 2425,  loss: 0.1661834180355072\n",
      "Batch 2430,  loss: 0.16662364900112153\n",
      "Batch 2435,  loss: 0.16217479705810547\n",
      "Batch 2440,  loss: 0.19581398963928223\n",
      "Batch 2445,  loss: 0.1423201784491539\n",
      "Batch 2450,  loss: 0.19790565669536592\n",
      "Batch 2455,  loss: 0.19096864759922028\n",
      "Batch 2460,  loss: 0.17415531426668168\n",
      "Batch 2465,  loss: 0.12607213407754897\n",
      "Batch 2470,  loss: 0.11862425059080124\n",
      "Batch 2475,  loss: 0.19757616519927979\n",
      "Batch 2480,  loss: 0.19682191014289857\n",
      "Batch 2485,  loss: 0.1632044106721878\n",
      "Batch 2490,  loss: 0.20926171839237212\n",
      "Batch 2495,  loss: 0.16350004822015762\n",
      "Batch 2500,  loss: 0.18883779346942903\n",
      "Batch 2505,  loss: 0.19867521226406099\n",
      "Batch 2510,  loss: 0.22077990770339967\n",
      "Batch 2515,  loss: 0.19495953619480133\n",
      "Batch 2520,  loss: 0.24865957498550414\n",
      "Batch 2525,  loss: 0.16083515286445618\n",
      "Batch 2530,  loss: 0.19844281673431396\n",
      "Batch 2535,  loss: 0.1803571581840515\n",
      "Batch 2540,  loss: 0.18503325879573823\n",
      "Batch 2545,  loss: 0.15222619771957396\n",
      "Batch 2550,  loss: 0.17763262391090393\n",
      "Batch 2555,  loss: 0.19310874491930008\n",
      "Batch 2560,  loss: 0.16697753667831422\n",
      "Batch 2565,  loss: 0.17753566205501556\n",
      "Batch 2570,  loss: 0.16701282411813737\n",
      "Batch 2575,  loss: 0.17944397330284118\n",
      "Batch 2580,  loss: 0.1571194976568222\n",
      "Batch 2585,  loss: 0.1925170511007309\n",
      "Batch 2590,  loss: 0.1830800712108612\n",
      "Batch 2595,  loss: 0.17462661266326904\n",
      "Batch 2600,  loss: 0.24320245981216432\n",
      "Batch 2605,  loss: 0.19482350647449492\n",
      "Batch 2610,  loss: 0.20516558289527892\n",
      "Batch 2615,  loss: 0.175831937789917\n",
      "Batch 2620,  loss: 0.20192080438137056\n",
      "Batch 2625,  loss: 0.14823607057332994\n",
      "Batch 2630,  loss: 0.22891200184822083\n",
      "Batch 2635,  loss: 0.18128953576087953\n",
      "Batch 2640,  loss: 0.20145007073879242\n",
      "Batch 2645,  loss: 0.18471271991729737\n",
      "Batch 2650,  loss: 0.14638668149709702\n",
      "Batch 2655,  loss: 0.19134874641895294\n",
      "Batch 2660,  loss: 0.16370275020599365\n",
      "Batch 2665,  loss: 0.20175906121730805\n",
      "Batch 2670,  loss: 0.1614617168903351\n",
      "Batch 2675,  loss: 0.17727818787097932\n",
      "Batch 2680,  loss: 0.19395928382873534\n",
      "Batch 2685,  loss: 0.2051795929670334\n",
      "Batch 2690,  loss: 0.16058435738086702\n",
      "Batch 2695,  loss: 0.17212315946817397\n",
      "Batch 2700,  loss: 0.22795917093753815\n",
      "Batch 2705,  loss: 0.20058707594871522\n",
      "Batch 2710,  loss: 0.2105569839477539\n",
      "Batch 2715,  loss: 0.17727323472499848\n",
      "Batch 2720,  loss: 0.1828770399093628\n",
      "Batch 2725,  loss: 0.19460029006004334\n",
      "Batch 2730,  loss: 0.1935531049966812\n",
      "Batch 2735,  loss: 0.1747327357530594\n",
      "Batch 2740,  loss: 0.19141474068164827\n",
      "Batch 2745,  loss: 0.1743026465177536\n",
      "Batch 2750,  loss: 0.21421589851379394\n",
      "Batch 2755,  loss: 0.24068976640701295\n",
      "Batch 2760,  loss: 0.16184911429882048\n",
      "Batch 2765,  loss: 0.15520247220993041\n",
      "Batch 2770,  loss: 0.23236990571022034\n",
      "LOSS train 0.23236990571022034. Validation loss: 0.1722915022213581 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 16:\n",
      "Batch 5,  loss: 0.1883789300918579\n",
      "Batch 10,  loss: 0.20407474786043167\n",
      "Batch 15,  loss: 0.23881462216377258\n",
      "Batch 20,  loss: 0.18730807900428773\n",
      "Batch 25,  loss: 0.16971199512481688\n",
      "Batch 30,  loss: 0.13412297070026397\n",
      "Batch 35,  loss: 0.21539998948574066\n",
      "Batch 40,  loss: 0.19515152275562286\n",
      "Batch 45,  loss: 0.15928345918655396\n",
      "Batch 50,  loss: 0.17356509268283843\n",
      "Batch 55,  loss: 0.17686948776245118\n",
      "Batch 60,  loss: 0.21846227645874022\n",
      "Batch 65,  loss: 0.1691935330629349\n",
      "Batch 70,  loss: 0.19447335004806518\n",
      "Batch 75,  loss: 0.20027278363704681\n",
      "Batch 80,  loss: 0.16901959627866744\n",
      "Batch 85,  loss: 0.16740135550498964\n",
      "Batch 90,  loss: 0.255283510684967\n",
      "Batch 95,  loss: 0.21979132294654846\n",
      "Batch 100,  loss: 0.2090659499168396\n",
      "Batch 105,  loss: 0.1602056547999382\n",
      "Batch 110,  loss: 0.15452198088169097\n",
      "Batch 115,  loss: 0.18959133327007294\n",
      "Batch 120,  loss: 0.18188272565603256\n",
      "Batch 125,  loss: 0.19352841675281524\n",
      "Batch 130,  loss: 0.135359525680542\n",
      "Batch 135,  loss: 0.1559544876217842\n",
      "Batch 140,  loss: 0.16263870596885682\n",
      "Batch 145,  loss: 0.1666974887251854\n",
      "Batch 150,  loss: 0.16810895204544068\n",
      "Batch 155,  loss: 0.15795691609382628\n",
      "Batch 160,  loss: 0.2096935212612152\n",
      "Batch 165,  loss: 0.17361160814762117\n",
      "Batch 170,  loss: 0.15456701517105104\n",
      "Batch 175,  loss: 0.2527173638343811\n",
      "Batch 180,  loss: 0.17487905621528627\n",
      "Batch 185,  loss: 0.20064765214920044\n",
      "Batch 190,  loss: 0.1882999360561371\n",
      "Batch 195,  loss: 0.19954626113176346\n",
      "Batch 200,  loss: 0.18939482867717744\n",
      "Batch 205,  loss: 0.19931579530239105\n",
      "Batch 210,  loss: 0.19184016585350036\n",
      "Batch 215,  loss: 0.17004842162132264\n",
      "Batch 220,  loss: 0.16003368496894838\n",
      "Batch 225,  loss: 0.21689088344573976\n",
      "Batch 230,  loss: 0.22244250476360322\n",
      "Batch 235,  loss: 0.14595677852630615\n",
      "Batch 240,  loss: 0.16322871446609497\n",
      "Batch 245,  loss: 0.20889900326728822\n",
      "Batch 250,  loss: 0.18081214427947997\n",
      "Batch 255,  loss: 0.19588237404823303\n",
      "Batch 260,  loss: 0.20544271171092987\n",
      "Batch 265,  loss: 0.2185042232275009\n",
      "Batch 270,  loss: 0.15768246054649354\n",
      "Batch 275,  loss: 0.19461770355701447\n",
      "Batch 280,  loss: 0.20691475570201873\n",
      "Batch 285,  loss: 0.148871710896492\n",
      "Batch 290,  loss: 0.1548781543970108\n",
      "Batch 295,  loss: 0.19386348128318787\n",
      "Batch 300,  loss: 0.15844842791557312\n",
      "Batch 305,  loss: 0.1447898656129837\n",
      "Batch 310,  loss: 0.14342063367366792\n",
      "Batch 315,  loss: 0.15218127518892288\n",
      "Batch 320,  loss: 0.15344893485307692\n",
      "Batch 325,  loss: 0.14917762130498885\n",
      "Batch 330,  loss: 0.1865850180387497\n",
      "Batch 335,  loss: 0.1555274322628975\n",
      "Batch 340,  loss: 0.17849804759025573\n",
      "Batch 345,  loss: 0.18670002222061158\n",
      "Batch 350,  loss: 0.19616950005292894\n",
      "Batch 355,  loss: 0.20590856969356536\n",
      "Batch 360,  loss: 0.1645277261734009\n",
      "Batch 365,  loss: 0.17050265967845918\n",
      "Batch 370,  loss: 0.19389876425266267\n",
      "Batch 375,  loss: 0.17433315515518188\n",
      "Batch 380,  loss: 0.18599144667387008\n",
      "Batch 385,  loss: 0.1577206552028656\n",
      "Batch 390,  loss: 0.1762317016720772\n",
      "Batch 395,  loss: 0.16007506251335143\n",
      "Batch 400,  loss: 0.15002564191818238\n",
      "Batch 405,  loss: 0.1500387743115425\n",
      "Batch 410,  loss: 0.18685521185398102\n",
      "Batch 415,  loss: 0.16000003069639207\n",
      "Batch 420,  loss: 0.1781182199716568\n",
      "Batch 425,  loss: 0.2265823543071747\n",
      "Batch 430,  loss: 0.19632042944431305\n",
      "Batch 435,  loss: 0.16353992223739625\n",
      "Batch 440,  loss: 0.17187348902225494\n",
      "Batch 445,  loss: 0.16005183905363082\n",
      "Batch 450,  loss: 0.19857662320137023\n",
      "Batch 455,  loss: 0.1824120342731476\n",
      "Batch 460,  loss: 0.13932449519634246\n",
      "Batch 465,  loss: 0.19736265242099763\n",
      "Batch 470,  loss: 0.17662177085876465\n",
      "Batch 475,  loss: 0.16824280172586442\n",
      "Batch 480,  loss: 0.14761163741350175\n",
      "Batch 485,  loss: 0.17934761345386505\n",
      "Batch 490,  loss: 0.17920106649398804\n",
      "Batch 495,  loss: 0.1789226710796356\n",
      "Batch 500,  loss: 0.16776042878627778\n",
      "Batch 505,  loss: 0.15068454146385193\n",
      "Batch 510,  loss: 0.19256847798824311\n",
      "Batch 515,  loss: 0.2014806792140007\n",
      "Batch 520,  loss: 0.1558764472603798\n",
      "Batch 525,  loss: 0.19951819479465485\n",
      "Batch 530,  loss: 0.16078612506389617\n",
      "Batch 535,  loss: 0.16316215097904205\n",
      "Batch 540,  loss: 0.17386814653873445\n",
      "Batch 545,  loss: 0.17887955904006958\n",
      "Batch 550,  loss: 0.1796271324157715\n",
      "Batch 555,  loss: 0.18131494522094727\n",
      "Batch 560,  loss: 0.16769388914108277\n",
      "Batch 565,  loss: 0.1663560152053833\n",
      "Batch 570,  loss: 0.14194742143154143\n",
      "Batch 575,  loss: 0.16918070912361144\n",
      "Batch 580,  loss: 0.18187262415885924\n",
      "Batch 585,  loss: 0.20656318068504334\n",
      "Batch 590,  loss: 0.1823413223028183\n",
      "Batch 595,  loss: 0.17233753800392151\n",
      "Batch 600,  loss: 0.13641471564769744\n",
      "Batch 605,  loss: 0.16257408857345582\n",
      "Batch 610,  loss: 0.1564645677804947\n",
      "Batch 615,  loss: 0.1806959331035614\n",
      "Batch 620,  loss: 0.1987566888332367\n",
      "Batch 625,  loss: 0.163798588514328\n",
      "Batch 630,  loss: 0.1582698106765747\n",
      "Batch 635,  loss: 0.17482191622257232\n",
      "Batch 640,  loss: 0.1427379697561264\n",
      "Batch 645,  loss: 0.16643185019493104\n",
      "Batch 650,  loss: 0.16654235273599624\n",
      "Batch 655,  loss: 0.21191756427288055\n",
      "Batch 660,  loss: 0.14177505075931549\n",
      "Batch 665,  loss: 0.13993779867887496\n",
      "Batch 670,  loss: 0.17308852672576905\n",
      "Batch 675,  loss: 0.16895836293697358\n",
      "Batch 680,  loss: 0.15407092571258546\n",
      "Batch 685,  loss: 0.14846578538417815\n",
      "Batch 690,  loss: 0.1759267270565033\n",
      "Batch 695,  loss: 0.14128673821687698\n",
      "Batch 700,  loss: 0.17897297739982604\n",
      "Batch 705,  loss: 0.16987192034721374\n",
      "Batch 710,  loss: 0.1634410172700882\n",
      "Batch 715,  loss: 0.21310227513313293\n",
      "Batch 720,  loss: 0.1801815390586853\n",
      "Batch 725,  loss: 0.21381158828735353\n",
      "Batch 730,  loss: 0.1767591953277588\n",
      "Batch 735,  loss: 0.17922683358192443\n",
      "Batch 740,  loss: 0.18886927664279937\n",
      "Batch 745,  loss: 0.2022333562374115\n",
      "Batch 750,  loss: 0.19865615665912628\n",
      "Batch 755,  loss: 0.19250627607107162\n",
      "Batch 760,  loss: 0.166882786154747\n",
      "Batch 765,  loss: 0.1654092401266098\n",
      "Batch 770,  loss: 0.1934542864561081\n",
      "Batch 775,  loss: 0.15408977270126342\n",
      "Batch 780,  loss: 0.1513489305973053\n",
      "Batch 785,  loss: 0.1811201497912407\n",
      "Batch 790,  loss: 0.19051468074321748\n",
      "Batch 795,  loss: 0.16393974125385286\n",
      "Batch 800,  loss: 0.17052924931049346\n",
      "Batch 805,  loss: 0.18127697706222534\n",
      "Batch 810,  loss: 0.19276441931724547\n",
      "Batch 815,  loss: 0.18310690224170684\n",
      "Batch 820,  loss: 0.17921751737594604\n",
      "Batch 825,  loss: 0.20400288105010986\n",
      "Batch 830,  loss: 0.14857374280691146\n",
      "Batch 835,  loss: 0.19167208075523376\n",
      "Batch 840,  loss: 0.19382140040397644\n",
      "Batch 845,  loss: 0.16874246001243592\n",
      "Batch 850,  loss: 0.15800858438014984\n",
      "Batch 855,  loss: 0.1870324581861496\n",
      "Batch 860,  loss: 0.16483529508113862\n",
      "Batch 865,  loss: 0.12919958233833312\n",
      "Batch 870,  loss: 0.19186744093894958\n",
      "Batch 875,  loss: 0.16528896987438202\n",
      "Batch 880,  loss: 0.1954505905508995\n",
      "Batch 885,  loss: 0.19036725163459778\n",
      "Batch 890,  loss: 0.15065103769302368\n",
      "Batch 895,  loss: 0.22982154786586761\n",
      "Batch 900,  loss: 0.19346053302288055\n",
      "Batch 905,  loss: 0.18604701161384582\n",
      "Batch 910,  loss: 0.1637225091457367\n",
      "Batch 915,  loss: 0.15403065979480743\n",
      "Batch 920,  loss: 0.18502855002880098\n",
      "Batch 925,  loss: 0.1221693903207779\n",
      "Batch 930,  loss: 0.18344354033470153\n",
      "Batch 935,  loss: 0.18553715646266938\n",
      "Batch 940,  loss: 0.1761291354894638\n",
      "Batch 945,  loss: 0.14167650789022446\n",
      "Batch 950,  loss: 0.17752874195575713\n",
      "Batch 955,  loss: 0.16022222191095353\n",
      "Batch 960,  loss: 0.13945091962814332\n",
      "Batch 965,  loss: 0.19684658646583558\n",
      "Batch 970,  loss: 0.15983300805091857\n",
      "Batch 975,  loss: 0.14408934861421585\n",
      "Batch 980,  loss: 0.21712150275707245\n",
      "Batch 985,  loss: 0.1582596242427826\n",
      "Batch 990,  loss: 0.19288738667964936\n",
      "Batch 995,  loss: 0.1600762724876404\n",
      "Batch 1000,  loss: 0.2110999584197998\n",
      "Batch 1005,  loss: 0.18991787731647491\n",
      "Batch 1010,  loss: 0.1625589907169342\n",
      "Batch 1015,  loss: 0.192834734916687\n",
      "Batch 1020,  loss: 0.17303755283355712\n",
      "Batch 1025,  loss: 0.13912152945995332\n",
      "Batch 1030,  loss: 0.20094294846057892\n",
      "Batch 1035,  loss: 0.17113647162914275\n",
      "Batch 1040,  loss: 0.24136958718299867\n",
      "Batch 1045,  loss: 0.1698415145277977\n",
      "Batch 1050,  loss: 0.15733764171600342\n",
      "Batch 1055,  loss: 0.18120672702789306\n",
      "Batch 1060,  loss: 0.20137522518634796\n",
      "Batch 1065,  loss: 0.16800978481769563\n",
      "Batch 1070,  loss: 0.15283922106027603\n",
      "Batch 1075,  loss: 0.18750426769256592\n",
      "Batch 1080,  loss: 0.15092176645994188\n",
      "Batch 1085,  loss: 0.23286717236042023\n",
      "Batch 1090,  loss: 0.1752232789993286\n",
      "Batch 1095,  loss: 0.20905357599258423\n",
      "Batch 1100,  loss: 0.19572373628616332\n",
      "Batch 1105,  loss: 0.17205469608306884\n",
      "Batch 1110,  loss: 0.16193108558654784\n",
      "Batch 1115,  loss: 0.15783266723155975\n",
      "Batch 1120,  loss: 0.19179787933826448\n",
      "Batch 1125,  loss: 0.15662372708320618\n",
      "Batch 1130,  loss: 0.19666161835193635\n",
      "Batch 1135,  loss: 0.16658263504505158\n",
      "Batch 1140,  loss: 0.15876902937889098\n",
      "Batch 1145,  loss: 0.1983827233314514\n",
      "Batch 1150,  loss: 0.22622235417366027\n",
      "Batch 1155,  loss: 0.17586311101913452\n",
      "Batch 1160,  loss: 0.20705095380544664\n",
      "Batch 1165,  loss: 0.16493644714355468\n",
      "Batch 1170,  loss: 0.20640534162521362\n",
      "Batch 1175,  loss: 0.12482745200395584\n",
      "Batch 1180,  loss: 0.2008794665336609\n",
      "Batch 1185,  loss: 0.16369247138500215\n",
      "Batch 1190,  loss: 0.169769224524498\n",
      "Batch 1195,  loss: 0.17757435142993927\n",
      "Batch 1200,  loss: 0.1566842883825302\n",
      "Batch 1205,  loss: 0.18417089581489562\n",
      "Batch 1210,  loss: 0.17622096389532088\n",
      "Batch 1215,  loss: 0.15668977200984954\n",
      "Batch 1220,  loss: 0.19735405147075652\n",
      "Batch 1225,  loss: 0.17868448346853255\n",
      "Batch 1230,  loss: 0.17897261083126068\n",
      "Batch 1235,  loss: 0.14689195454120635\n",
      "Batch 1240,  loss: 0.25843422412872313\n",
      "Batch 1245,  loss: 0.16896197497844695\n",
      "Batch 1250,  loss: 0.1765369564294815\n",
      "Batch 1255,  loss: 0.2229920119047165\n",
      "Batch 1260,  loss: 0.19599660336971284\n",
      "Batch 1265,  loss: 0.17152952402830124\n",
      "Batch 1270,  loss: 0.14982334971427919\n",
      "Batch 1275,  loss: 0.16124520152807237\n",
      "Batch 1280,  loss: 0.18306469917297363\n",
      "Batch 1285,  loss: 0.19706752598285676\n",
      "Batch 1290,  loss: 0.1789635732769966\n",
      "Batch 1295,  loss: 0.1818121090531349\n",
      "Batch 1300,  loss: 0.1516444981098175\n",
      "Batch 1305,  loss: 0.21456916332244874\n",
      "Batch 1310,  loss: 0.17717946469783782\n",
      "Batch 1315,  loss: 0.18626191318035126\n",
      "Batch 1320,  loss: 0.16989135444164277\n",
      "Batch 1325,  loss: 0.20528817623853685\n",
      "Batch 1330,  loss: 0.1916837751865387\n",
      "Batch 1335,  loss: 0.18522550463676452\n",
      "Batch 1340,  loss: 0.23432491421699525\n",
      "Batch 1345,  loss: 0.14533576220273972\n",
      "Batch 1350,  loss: 0.20994971692562103\n",
      "Batch 1355,  loss: 0.1682429254055023\n",
      "Batch 1360,  loss: 0.1634848654270172\n",
      "Batch 1365,  loss: 0.18621175736188889\n",
      "Batch 1370,  loss: 0.1907939776778221\n",
      "Batch 1375,  loss: 0.13111567497253418\n",
      "Batch 1380,  loss: 0.14948116540908812\n",
      "Batch 1385,  loss: 0.18001553118228913\n",
      "Batch 1390,  loss: 0.16288293451070784\n",
      "Batch 1395,  loss: 0.18402570486068726\n",
      "Batch 1400,  loss: 0.16658473908901214\n",
      "Batch 1405,  loss: 0.19255106449127196\n",
      "Batch 1410,  loss: 0.16935769021511077\n",
      "Batch 1415,  loss: 0.11675835400819778\n",
      "Batch 1420,  loss: 0.17788615226745605\n",
      "Batch 1425,  loss: 0.14280658662319184\n",
      "Batch 1430,  loss: 0.16707807630300522\n",
      "Batch 1435,  loss: 0.1802665114402771\n",
      "Batch 1440,  loss: 0.16648759245872496\n",
      "Batch 1445,  loss: 0.16524204313755037\n",
      "Batch 1450,  loss: 0.21349234879016876\n",
      "Batch 1455,  loss: 0.17378698587417601\n",
      "Batch 1460,  loss: 0.1204909935593605\n",
      "Batch 1465,  loss: 0.18656814098358154\n",
      "Batch 1470,  loss: 0.17516924440860748\n",
      "Batch 1475,  loss: 0.16522724628448487\n",
      "Batch 1480,  loss: 0.20214900076389314\n",
      "Batch 1485,  loss: 0.17036897987127303\n",
      "Batch 1490,  loss: 0.16795871257781983\n",
      "Batch 1495,  loss: 0.17968396842479706\n",
      "Batch 1500,  loss: 0.1671275869011879\n",
      "Batch 1505,  loss: 0.17154791057109833\n",
      "Batch 1510,  loss: 0.21002449095249176\n",
      "Batch 1515,  loss: 0.1721754252910614\n",
      "Batch 1520,  loss: 0.18181732594966887\n",
      "Batch 1525,  loss: 0.17585451304912567\n",
      "Batch 1530,  loss: 0.17769189476966857\n",
      "Batch 1535,  loss: 0.16250346302986146\n",
      "Batch 1540,  loss: 0.1877093255519867\n",
      "Batch 1545,  loss: 0.16437545269727707\n",
      "Batch 1550,  loss: 0.22296499013900756\n",
      "Batch 1555,  loss: 0.17133711278438568\n",
      "Batch 1560,  loss: 0.1829317569732666\n",
      "Batch 1565,  loss: 0.19681065678596496\n",
      "Batch 1570,  loss: 0.18429015278816224\n",
      "Batch 1575,  loss: 0.19135463535785674\n",
      "Batch 1580,  loss: 0.15753270387649537\n",
      "Batch 1585,  loss: 0.19527807235717773\n",
      "Batch 1590,  loss: 0.20665022730827332\n",
      "Batch 1595,  loss: 0.16546201705932617\n",
      "Batch 1600,  loss: 0.19108495712280274\n",
      "Batch 1605,  loss: 0.17158716768026352\n",
      "Batch 1610,  loss: 0.21075732111930848\n",
      "Batch 1615,  loss: 0.1614811196923256\n",
      "Batch 1620,  loss: 0.159572097659111\n",
      "Batch 1625,  loss: 0.172518053650856\n",
      "Batch 1630,  loss: 0.20095951855182648\n",
      "Batch 1635,  loss: 0.2137628376483917\n",
      "Batch 1640,  loss: 0.19026134610176088\n",
      "Batch 1645,  loss: 0.16051473915576936\n",
      "Batch 1650,  loss: 0.1461619734764099\n",
      "Batch 1655,  loss: 0.2003112703561783\n",
      "Batch 1660,  loss: 0.2036060482263565\n",
      "Batch 1665,  loss: 0.1763020634651184\n",
      "Batch 1670,  loss: 0.1523977354168892\n",
      "Batch 1675,  loss: 0.1519884705543518\n",
      "Batch 1680,  loss: 0.17127295732498168\n",
      "Batch 1685,  loss: 0.1732887238264084\n",
      "Batch 1690,  loss: 0.17800097167491913\n",
      "Batch 1695,  loss: 0.1689622789621353\n",
      "Batch 1700,  loss: 0.14989716112613677\n",
      "Batch 1705,  loss: 0.15824607014656067\n",
      "Batch 1710,  loss: 0.18402999639511108\n",
      "Batch 1715,  loss: 0.18809268176555632\n",
      "Batch 1720,  loss: 0.1826375037431717\n",
      "Batch 1725,  loss: 0.18764880895614625\n",
      "Batch 1730,  loss: 0.20349062979221344\n",
      "Batch 1735,  loss: 0.21957059502601622\n",
      "Batch 1740,  loss: 0.14674482345581055\n",
      "Batch 1745,  loss: 0.19085303246974944\n",
      "Batch 1750,  loss: 0.1984206646680832\n",
      "Batch 1755,  loss: 0.14191290140151977\n",
      "Batch 1760,  loss: 0.22154139280319213\n",
      "Batch 1765,  loss: 0.21413518935441972\n",
      "Batch 1770,  loss: 0.24166062772274016\n",
      "Batch 1775,  loss: 0.22324368953704835\n",
      "Batch 1780,  loss: 0.15419127345085143\n",
      "Batch 1785,  loss: 0.22781290709972382\n",
      "Batch 1790,  loss: 0.16069243848323822\n",
      "Batch 1795,  loss: 0.14892130643129348\n",
      "Batch 1800,  loss: 0.14192816913127898\n",
      "Batch 1805,  loss: 0.1772134631872177\n",
      "Batch 1810,  loss: 0.17210699617862701\n",
      "Batch 1815,  loss: 0.19547134041786193\n",
      "Batch 1820,  loss: 0.2683289125561714\n",
      "Batch 1825,  loss: 0.1895831912755966\n",
      "Batch 1830,  loss: 0.16232965588569642\n",
      "Batch 1835,  loss: 0.15183963775634765\n",
      "Batch 1840,  loss: 0.15249942243099213\n",
      "Batch 1845,  loss: 0.14134219884872437\n",
      "Batch 1850,  loss: 0.20448152124881744\n",
      "Batch 1855,  loss: 0.19580834805965425\n",
      "Batch 1860,  loss: 0.19697439074516296\n",
      "Batch 1865,  loss: 0.17302198708057404\n",
      "Batch 1870,  loss: 0.2081926017999649\n",
      "Batch 1875,  loss: 0.1559978485107422\n",
      "Batch 1880,  loss: 0.2050999015569687\n",
      "Batch 1885,  loss: 0.17104771137237548\n",
      "Batch 1890,  loss: 0.18807097822427749\n",
      "Batch 1895,  loss: 0.2201461374759674\n",
      "Batch 1900,  loss: 0.17725095450878142\n",
      "Batch 1905,  loss: 0.13609060347080232\n",
      "Batch 1910,  loss: 0.19073976427316666\n",
      "Batch 1915,  loss: 0.22774769961833954\n",
      "Batch 1920,  loss: 0.17551090717315673\n",
      "Batch 1925,  loss: 0.17047130614519118\n",
      "Batch 1930,  loss: 0.16160454601049423\n",
      "Batch 1935,  loss: 0.15625662803649903\n",
      "Batch 1940,  loss: 0.14940255731344224\n",
      "Batch 1945,  loss: 0.17651114910840987\n",
      "Batch 1950,  loss: 0.19702331125736236\n",
      "Batch 1955,  loss: 0.15197354406118393\n",
      "Batch 1960,  loss: 0.14978356957435607\n",
      "Batch 1965,  loss: 0.15582760870456697\n",
      "Batch 1970,  loss: 0.18939775824546815\n",
      "Batch 1975,  loss: 0.190780171751976\n",
      "Batch 1980,  loss: 0.19097877740859986\n",
      "Batch 1985,  loss: 0.1673303723335266\n",
      "Batch 1990,  loss: 0.15479089319705963\n",
      "Batch 1995,  loss: 0.16137820184230806\n",
      "Batch 2000,  loss: 0.1732555001974106\n",
      "Batch 2005,  loss: 0.19971117675304412\n",
      "Batch 2010,  loss: 0.14520553052425383\n",
      "Batch 2015,  loss: 0.169638429582119\n",
      "Batch 2020,  loss: 0.20719520151615142\n",
      "Batch 2025,  loss: 0.1732645183801651\n",
      "Batch 2030,  loss: 0.19308849573135375\n",
      "Batch 2035,  loss: 0.20633980333805085\n",
      "Batch 2040,  loss: 0.17433913946151733\n",
      "Batch 2045,  loss: 0.18405321538448333\n",
      "Batch 2050,  loss: 0.17794844061136245\n",
      "Batch 2055,  loss: 0.1413065880537033\n",
      "Batch 2060,  loss: 0.1694491297006607\n",
      "Batch 2065,  loss: 0.1851219803094864\n",
      "Batch 2070,  loss: 0.18475775122642518\n",
      "Batch 2075,  loss: 0.1660168081521988\n",
      "Batch 2080,  loss: 0.1857629805803299\n",
      "Batch 2085,  loss: 0.19092320799827575\n",
      "Batch 2090,  loss: 0.19064070880413056\n",
      "Batch 2095,  loss: 0.21500295400619507\n",
      "Batch 2100,  loss: 0.182518869638443\n",
      "Batch 2105,  loss: 0.1343250721693039\n",
      "Batch 2110,  loss: 0.1546122685074806\n",
      "Batch 2115,  loss: 0.17030851244926454\n",
      "Batch 2120,  loss: 0.1636965572834015\n",
      "Batch 2125,  loss: 0.18799482882022858\n",
      "Batch 2130,  loss: 0.15065434873104094\n",
      "Batch 2135,  loss: 0.1644134745001793\n",
      "Batch 2140,  loss: 0.17532163262367248\n",
      "Batch 2145,  loss: 0.23501282632350923\n",
      "Batch 2150,  loss: 0.18723604679107667\n",
      "Batch 2155,  loss: 0.21201477944850922\n",
      "Batch 2160,  loss: 0.18242928385734558\n",
      "Batch 2165,  loss: 0.1886797606945038\n",
      "Batch 2170,  loss: 0.1860940486192703\n",
      "Batch 2175,  loss: 0.19539364874362947\n",
      "Batch 2180,  loss: 0.17813850045204163\n",
      "Batch 2185,  loss: 0.14563050419092177\n",
      "Batch 2190,  loss: 0.16462513506412507\n",
      "Batch 2195,  loss: 0.15725527703762054\n",
      "Batch 2200,  loss: 0.12911667227745055\n",
      "Batch 2205,  loss: 0.15479397177696227\n",
      "Batch 2210,  loss: 0.13056182861328125\n",
      "Batch 2215,  loss: 0.23013916015625\n",
      "Batch 2220,  loss: 0.17305348813533783\n",
      "Batch 2225,  loss: 0.15321507602930068\n",
      "Batch 2230,  loss: 0.1806771844625473\n",
      "Batch 2235,  loss: 0.1787978082895279\n",
      "Batch 2240,  loss: 0.1968967944383621\n",
      "Batch 2245,  loss: 0.16082073748111725\n",
      "Batch 2250,  loss: 0.18851694762706755\n",
      "Batch 2255,  loss: 0.17128641605377198\n",
      "Batch 2260,  loss: 0.18512167632579804\n",
      "Batch 2265,  loss: 0.1546245038509369\n",
      "Batch 2270,  loss: 0.1368757501244545\n",
      "Batch 2275,  loss: 0.1391218438744545\n",
      "Batch 2280,  loss: 0.1481405660510063\n",
      "Batch 2285,  loss: 0.20934716165065764\n",
      "Batch 2290,  loss: 0.192340749502182\n",
      "Batch 2295,  loss: 0.1669303596019745\n",
      "Batch 2300,  loss: 0.1681936949491501\n",
      "Batch 2305,  loss: 0.19178945124149321\n",
      "Batch 2310,  loss: 0.16859785616397857\n",
      "Batch 2315,  loss: 0.16060225963592528\n",
      "Batch 2320,  loss: 0.20939919650554656\n",
      "Batch 2325,  loss: 0.15452782809734344\n",
      "Batch 2330,  loss: 0.19376603364944459\n",
      "Batch 2335,  loss: 0.20378482043743135\n",
      "Batch 2340,  loss: 0.22987929880619049\n",
      "Batch 2345,  loss: 0.19287109076976777\n",
      "Batch 2350,  loss: 0.16215604841709136\n",
      "Batch 2355,  loss: 0.1623397797346115\n",
      "Batch 2360,  loss: 0.17030930668115615\n",
      "Batch 2365,  loss: 0.14633288234472275\n",
      "Batch 2370,  loss: 0.1946232795715332\n",
      "Batch 2375,  loss: 0.18547578752040864\n",
      "Batch 2380,  loss: 0.17987895160913467\n",
      "Batch 2385,  loss: 0.17882843017578126\n",
      "Batch 2390,  loss: 0.2183518350124359\n",
      "Batch 2395,  loss: 0.22289384603500367\n",
      "Batch 2400,  loss: 0.15201369524002076\n",
      "Batch 2405,  loss: 0.1466327890753746\n",
      "Batch 2410,  loss: 0.15333903431892396\n",
      "Batch 2415,  loss: 0.175116828083992\n",
      "Batch 2420,  loss: 0.1922587051987648\n",
      "Batch 2425,  loss: 0.14181484878063202\n",
      "Batch 2430,  loss: 0.1480947494506836\n",
      "Batch 2435,  loss: 0.18278028666973115\n",
      "Batch 2440,  loss: 0.15593304932117463\n",
      "Batch 2445,  loss: 0.17183295786380767\n",
      "Batch 2450,  loss: 0.14580171853303908\n",
      "Batch 2455,  loss: 0.1356671467423439\n",
      "Batch 2460,  loss: 0.15668214857578278\n",
      "Batch 2465,  loss: 0.15332877337932588\n",
      "Batch 2470,  loss: 0.1909751683473587\n",
      "Batch 2475,  loss: 0.19326309561729432\n",
      "Batch 2480,  loss: 0.17414150834083558\n",
      "Batch 2485,  loss: 0.1508359730243683\n",
      "Batch 2490,  loss: 0.21036160588264466\n",
      "Batch 2495,  loss: 0.17210501730442046\n",
      "Batch 2500,  loss: 0.1794113725423813\n",
      "Batch 2505,  loss: 0.16934385895729065\n",
      "Batch 2510,  loss: 0.18102700412273406\n",
      "Batch 2515,  loss: 0.15704576373100282\n",
      "Batch 2520,  loss: 0.18839170336723327\n",
      "Batch 2525,  loss: 0.20969806909561156\n",
      "Batch 2530,  loss: 0.20505830645561218\n",
      "Batch 2535,  loss: 0.18874939084053038\n",
      "Batch 2540,  loss: 0.19851488918066024\n",
      "Batch 2545,  loss: 0.21298136115074157\n",
      "Batch 2550,  loss: 0.19053445458412172\n",
      "Batch 2555,  loss: 0.1622290015220642\n",
      "Batch 2560,  loss: 0.20917820930480957\n",
      "Batch 2565,  loss: 0.16063622534275054\n",
      "Batch 2570,  loss: 0.18511396050453185\n",
      "Batch 2575,  loss: 0.15704168975353242\n",
      "Batch 2580,  loss: 0.19668341279029847\n",
      "Batch 2585,  loss: 0.17284136414527893\n",
      "Batch 2590,  loss: 0.2157404065132141\n",
      "Batch 2595,  loss: 0.1535005420446396\n",
      "Batch 2600,  loss: 0.20605165511369705\n",
      "Batch 2605,  loss: 0.19610570073127748\n",
      "Batch 2610,  loss: 0.2150200217962265\n",
      "Batch 2615,  loss: 0.2060152918100357\n",
      "Batch 2620,  loss: 0.1665292739868164\n",
      "Batch 2625,  loss: 0.1507412701845169\n",
      "Batch 2630,  loss: 0.1893689215183258\n",
      "Batch 2635,  loss: 0.18626387119293214\n",
      "Batch 2640,  loss: 0.16177752315998079\n",
      "Batch 2645,  loss: 0.15939972847700118\n",
      "Batch 2650,  loss: 0.18320204615592955\n",
      "Batch 2655,  loss: 0.17649682462215424\n",
      "Batch 2660,  loss: 0.23709596693515778\n",
      "Batch 2665,  loss: 0.17321590185165406\n",
      "Batch 2670,  loss: 0.16080162823200225\n",
      "Batch 2675,  loss: 0.16872908622026445\n",
      "Batch 2680,  loss: 0.2403359144926071\n",
      "Batch 2685,  loss: 0.20550216734409332\n",
      "Batch 2690,  loss: 0.17760855555534363\n",
      "Batch 2695,  loss: 0.15273042321205138\n",
      "Batch 2700,  loss: 0.1525007203221321\n",
      "Batch 2705,  loss: 0.1598675072193146\n",
      "Batch 2710,  loss: 0.18897721469402312\n",
      "Batch 2715,  loss: 0.18157214522361756\n",
      "Batch 2720,  loss: 0.21269806623458862\n",
      "Batch 2725,  loss: 0.17148130238056183\n",
      "Batch 2730,  loss: 0.17960298359394072\n",
      "Batch 2735,  loss: 0.20951433777809142\n",
      "Batch 2740,  loss: 0.19119793176651\n",
      "Batch 2745,  loss: 0.18673374652862548\n",
      "Batch 2750,  loss: 0.1652284622192383\n",
      "Batch 2755,  loss: 0.16669483184814454\n",
      "Batch 2760,  loss: 0.18773559629917144\n",
      "Batch 2765,  loss: 0.2038464367389679\n",
      "Batch 2770,  loss: 0.19122271239757538\n",
      "LOSS train 0.19122271239757538. Validation loss: 0.17752419349358037 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 17:\n",
      "Batch 5,  loss: 0.17786040306091308\n",
      "Batch 10,  loss: 0.2333226978778839\n",
      "Batch 15,  loss: 0.19718265533447266\n",
      "Batch 20,  loss: 0.15440205186605455\n",
      "Batch 25,  loss: 0.15551718473434448\n",
      "Batch 30,  loss: 0.158955317735672\n",
      "Batch 35,  loss: 0.15516749918460845\n",
      "Batch 40,  loss: 0.19346211850643158\n",
      "Batch 45,  loss: 0.15238352119922638\n",
      "Batch 50,  loss: 0.20078559815883637\n",
      "Batch 55,  loss: 0.16884689331054686\n",
      "Batch 60,  loss: 0.19167517721652985\n",
      "Batch 65,  loss: 0.18801016509532928\n",
      "Batch 70,  loss: 0.1424034669995308\n",
      "Batch 75,  loss: 0.1715135931968689\n",
      "Batch 80,  loss: 0.23737162947654725\n",
      "Batch 85,  loss: 0.1802184134721756\n",
      "Batch 90,  loss: 0.19018937200307845\n",
      "Batch 95,  loss: 0.1698276787996292\n",
      "Batch 100,  loss: 0.15737296640872955\n",
      "Batch 105,  loss: 0.18635376989841462\n",
      "Batch 110,  loss: 0.16679427921772003\n",
      "Batch 115,  loss: 0.18054235279560088\n",
      "Batch 120,  loss: 0.1364917814731598\n",
      "Batch 125,  loss: 0.17235096544027328\n",
      "Batch 130,  loss: 0.15492548048496246\n",
      "Batch 135,  loss: 0.16772416830062867\n",
      "Batch 140,  loss: 0.20140888094902037\n",
      "Batch 145,  loss: 0.2153586447238922\n",
      "Batch 150,  loss: 0.16094236671924592\n",
      "Batch 155,  loss: 0.1755223274230957\n",
      "Batch 160,  loss: 0.15664842128753662\n",
      "Batch 165,  loss: 0.16436643600463868\n",
      "Batch 170,  loss: 0.19708326011896132\n",
      "Batch 175,  loss: 0.1574835002422333\n",
      "Batch 180,  loss: 0.18147241026163102\n",
      "Batch 185,  loss: 0.16072700023651124\n",
      "Batch 190,  loss: 0.16869206130504608\n",
      "Batch 195,  loss: 0.19241181313991546\n",
      "Batch 200,  loss: 0.17945227921009063\n",
      "Batch 205,  loss: 0.14828475564718246\n",
      "Batch 210,  loss: 0.17271711826324462\n",
      "Batch 215,  loss: 0.21627010703086852\n",
      "Batch 220,  loss: 0.21707508862018585\n",
      "Batch 225,  loss: 0.21709567606449126\n",
      "Batch 230,  loss: 0.151486399769783\n",
      "Batch 235,  loss: 0.2115959793329239\n",
      "Batch 240,  loss: 0.15733665376901626\n",
      "Batch 245,  loss: 0.1780959278345108\n",
      "Batch 250,  loss: 0.16971125155687333\n",
      "Batch 255,  loss: 0.19954148232936858\n",
      "Batch 260,  loss: 0.13180712163448333\n",
      "Batch 265,  loss: 0.19044314622879027\n",
      "Batch 270,  loss: 0.15070977061986923\n",
      "Batch 275,  loss: 0.1615267962217331\n",
      "Batch 280,  loss: 0.15468689799308777\n",
      "Batch 285,  loss: 0.16895572394132613\n",
      "Batch 290,  loss: 0.20091758370399476\n",
      "Batch 295,  loss: 0.1365148603916168\n",
      "Batch 300,  loss: 0.15367026329040528\n",
      "Batch 305,  loss: 0.21299008429050445\n",
      "Batch 310,  loss: 0.18351692259311675\n",
      "Batch 315,  loss: 0.20792126655578613\n",
      "Batch 320,  loss: 0.21496957838535308\n",
      "Batch 325,  loss: 0.17949597239494325\n",
      "Batch 330,  loss: 0.145626962184906\n",
      "Batch 335,  loss: 0.13528805524110793\n",
      "Batch 340,  loss: 0.15114973485469818\n",
      "Batch 345,  loss: 0.15867068767547607\n",
      "Batch 350,  loss: 0.18811098337173462\n",
      "Batch 355,  loss: 0.1914491981267929\n",
      "Batch 360,  loss: 0.18012478649616243\n",
      "Batch 365,  loss: 0.16742131263017654\n",
      "Batch 370,  loss: 0.2203732967376709\n",
      "Batch 375,  loss: 0.1397940769791603\n",
      "Batch 380,  loss: 0.1861193895339966\n",
      "Batch 385,  loss: 0.163791623711586\n",
      "Batch 390,  loss: 0.1607260912656784\n",
      "Batch 395,  loss: 0.14413683414459227\n",
      "Batch 400,  loss: 0.1593677282333374\n",
      "Batch 405,  loss: 0.17558827102184296\n",
      "Batch 410,  loss: 0.18557920455932617\n",
      "Batch 415,  loss: 0.18941091895103454\n",
      "Batch 420,  loss: 0.20744937658309937\n",
      "Batch 425,  loss: 0.1594205230474472\n",
      "Batch 430,  loss: 0.1834479585289955\n",
      "Batch 435,  loss: 0.10846354514360428\n",
      "Batch 440,  loss: 0.14801271259784698\n",
      "Batch 445,  loss: 0.18189023584127426\n",
      "Batch 450,  loss: 0.1782202273607254\n",
      "Batch 455,  loss: 0.16584553718566894\n",
      "Batch 460,  loss: 0.2117367684841156\n",
      "Batch 465,  loss: 0.14719143509864807\n",
      "Batch 470,  loss: 0.17329679131507875\n",
      "Batch 475,  loss: 0.16932787299156188\n",
      "Batch 480,  loss: 0.1368871323764324\n",
      "Batch 485,  loss: 0.16285552978515624\n",
      "Batch 490,  loss: 0.1679968923330307\n",
      "Batch 495,  loss: 0.15947945266962052\n",
      "Batch 500,  loss: 0.1460049569606781\n",
      "Batch 505,  loss: 0.17839743494987487\n",
      "Batch 510,  loss: 0.1925426423549652\n",
      "Batch 515,  loss: 0.14129601120948793\n",
      "Batch 520,  loss: 0.20463770031929016\n",
      "Batch 525,  loss: 0.2071968287229538\n",
      "Batch 530,  loss: 0.17875145971775055\n",
      "Batch 535,  loss: 0.1756138026714325\n",
      "Batch 540,  loss: 0.16118521392345428\n",
      "Batch 545,  loss: 0.18899933099746705\n",
      "Batch 550,  loss: 0.21626968383789064\n",
      "Batch 555,  loss: 0.17506120949983597\n",
      "Batch 560,  loss: 0.1649949699640274\n",
      "Batch 565,  loss: 0.14156024307012557\n",
      "Batch 570,  loss: 0.21062341034412385\n",
      "Batch 575,  loss: 0.166633802652359\n",
      "Batch 580,  loss: 0.14858504980802537\n",
      "Batch 585,  loss: 0.13145259916782379\n",
      "Batch 590,  loss: 0.19096578657627106\n",
      "Batch 595,  loss: 0.1472818970680237\n",
      "Batch 600,  loss: 0.21378217935562133\n",
      "Batch 605,  loss: 0.1788865476846695\n",
      "Batch 610,  loss: 0.18849001973867416\n",
      "Batch 615,  loss: 0.16667315661907195\n",
      "Batch 620,  loss: 0.15510732531547547\n",
      "Batch 625,  loss: 0.13939189910888672\n",
      "Batch 630,  loss: 0.1777763158082962\n",
      "Batch 635,  loss: 0.14731690138578415\n",
      "Batch 640,  loss: 0.1876714050769806\n",
      "Batch 645,  loss: 0.15780077427625655\n",
      "Batch 650,  loss: 0.21083480417728423\n",
      "Batch 655,  loss: 0.20990356504917146\n",
      "Batch 660,  loss: 0.16354794949293136\n",
      "Batch 665,  loss: 0.194102481007576\n",
      "Batch 670,  loss: 0.19331459403038026\n",
      "Batch 675,  loss: 0.18172102868556977\n",
      "Batch 680,  loss: 0.21085298657417298\n",
      "Batch 685,  loss: 0.17735190093517303\n",
      "Batch 690,  loss: 0.16430607736110686\n",
      "Batch 695,  loss: 0.1879030168056488\n",
      "Batch 700,  loss: 0.1554206132888794\n",
      "Batch 705,  loss: 0.17965297102928163\n",
      "Batch 710,  loss: 0.1665555089712143\n",
      "Batch 715,  loss: 0.14373815953731536\n",
      "Batch 720,  loss: 0.1562941089272499\n",
      "Batch 725,  loss: 0.18816162049770355\n",
      "Batch 730,  loss: 0.18232434391975402\n",
      "Batch 735,  loss: 0.17418307811021805\n",
      "Batch 740,  loss: 0.18803652226924897\n",
      "Batch 745,  loss: 0.17493477165699006\n",
      "Batch 750,  loss: 0.18839490711688994\n",
      "Batch 755,  loss: 0.20356098115444182\n",
      "Batch 760,  loss: 0.20127575397491454\n",
      "Batch 765,  loss: 0.16916157007217408\n",
      "Batch 770,  loss: 0.17211572527885438\n",
      "Batch 775,  loss: 0.17290691137313843\n",
      "Batch 780,  loss: 0.182822647690773\n",
      "Batch 785,  loss: 0.1778457298874855\n",
      "Batch 790,  loss: 0.2384267508983612\n",
      "Batch 795,  loss: 0.1862485721707344\n",
      "Batch 800,  loss: 0.18623134195804597\n",
      "Batch 805,  loss: 0.1700278028845787\n",
      "Batch 810,  loss: 0.1760757803916931\n",
      "Batch 815,  loss: 0.19138179421424867\n",
      "Batch 820,  loss: 0.17624693214893342\n",
      "Batch 825,  loss: 0.20411401987075806\n",
      "Batch 830,  loss: 0.1699497014284134\n",
      "Batch 835,  loss: 0.17666183412075043\n",
      "Batch 840,  loss: 0.18058420419692994\n",
      "Batch 845,  loss: 0.16538096070289612\n",
      "Batch 850,  loss: 0.20101652443408966\n",
      "Batch 855,  loss: 0.2079305112361908\n",
      "Batch 860,  loss: 0.1867611050605774\n",
      "Batch 865,  loss: 0.15037587583065032\n",
      "Batch 870,  loss: 0.18244166076183319\n",
      "Batch 875,  loss: 0.16874715834856033\n",
      "Batch 880,  loss: 0.16173646003007888\n",
      "Batch 885,  loss: 0.17207829356193544\n",
      "Batch 890,  loss: 0.16774094849824905\n",
      "Batch 895,  loss: 0.15853185951709747\n",
      "Batch 900,  loss: 0.18155862092971803\n",
      "Batch 905,  loss: 0.1602090120315552\n",
      "Batch 910,  loss: 0.16812308877706528\n",
      "Batch 915,  loss: 0.15366372019052504\n",
      "Batch 920,  loss: 0.20144106745719909\n",
      "Batch 925,  loss: 0.2168993353843689\n",
      "Batch 930,  loss: 0.20986916422843932\n",
      "Batch 935,  loss: 0.19251474738121033\n",
      "Batch 940,  loss: 0.18904503881931306\n",
      "Batch 945,  loss: 0.1367361679673195\n",
      "Batch 950,  loss: 0.11828902959823609\n",
      "Batch 955,  loss: 0.20332602858543397\n",
      "Batch 960,  loss: 0.191570845246315\n",
      "Batch 965,  loss: 0.17767581045627595\n",
      "Batch 970,  loss: 0.15369583368301393\n",
      "Batch 975,  loss: 0.2169831156730652\n",
      "Batch 980,  loss: 0.22427084147930146\n",
      "Batch 985,  loss: 0.2489743113517761\n",
      "Batch 990,  loss: 0.1781073585152626\n",
      "Batch 995,  loss: 0.16419738680124282\n",
      "Batch 1000,  loss: 0.1533445805311203\n",
      "Batch 1005,  loss: 0.1931520789861679\n",
      "Batch 1010,  loss: 0.13924876153469085\n",
      "Batch 1015,  loss: 0.17926545441150665\n",
      "Batch 1020,  loss: 0.14756953716278076\n",
      "Batch 1025,  loss: 0.15461848080158233\n",
      "Batch 1030,  loss: 0.20498934388160706\n",
      "Batch 1035,  loss: 0.19750625193119048\n",
      "Batch 1040,  loss: 0.15894728899002075\n",
      "Batch 1045,  loss: 0.18932801187038423\n",
      "Batch 1050,  loss: 0.1576263964176178\n",
      "Batch 1055,  loss: 0.21973905265331267\n",
      "Batch 1060,  loss: 0.17725893557071687\n",
      "Batch 1065,  loss: 0.12775264978408812\n",
      "Batch 1070,  loss: 0.1329132080078125\n",
      "Batch 1075,  loss: 0.22241357564926148\n",
      "Batch 1080,  loss: 0.1574718177318573\n",
      "Batch 1085,  loss: 0.1820679634809494\n",
      "Batch 1090,  loss: 0.16862532496452332\n",
      "Batch 1095,  loss: 0.15083830058574677\n",
      "Batch 1100,  loss: 0.19761362969875335\n",
      "Batch 1105,  loss: 0.16504034250974656\n",
      "Batch 1110,  loss: 0.23662994801998138\n",
      "Batch 1115,  loss: 0.16917891502380372\n",
      "Batch 1120,  loss: 0.15377856492996217\n",
      "Batch 1125,  loss: 0.17167778462171554\n",
      "Batch 1130,  loss: 0.15215203762054444\n",
      "Batch 1135,  loss: 0.19555142968893052\n",
      "Batch 1140,  loss: 0.17347197532653807\n",
      "Batch 1145,  loss: 0.20661754608154298\n",
      "Batch 1150,  loss: 0.18174821138381958\n",
      "Batch 1155,  loss: 0.16107999086380004\n",
      "Batch 1160,  loss: 0.1798262983560562\n",
      "Batch 1165,  loss: 0.17977795898914337\n",
      "Batch 1170,  loss: 0.18247274458408355\n",
      "Batch 1175,  loss: 0.1372389480471611\n",
      "Batch 1180,  loss: 0.1824834793806076\n",
      "Batch 1185,  loss: 0.16985119134187698\n",
      "Batch 1190,  loss: 0.20120332837104798\n",
      "Batch 1195,  loss: 0.16919426321983339\n",
      "Batch 1200,  loss: 0.15696867406368256\n",
      "Batch 1205,  loss: 0.18583106696605683\n",
      "Batch 1210,  loss: 0.17011684477329253\n",
      "Batch 1215,  loss: 0.13812145441770554\n",
      "Batch 1220,  loss: 0.17959669828414918\n",
      "Batch 1225,  loss: 0.17394658029079438\n",
      "Batch 1230,  loss: 0.15850197970867158\n",
      "Batch 1235,  loss: 0.1592705577611923\n",
      "Batch 1240,  loss: 0.12690932154655457\n",
      "Batch 1245,  loss: 0.1578580766916275\n",
      "Batch 1250,  loss: 0.1901894688606262\n",
      "Batch 1255,  loss: 0.20794273614883424\n",
      "Batch 1260,  loss: 0.12590642422437667\n",
      "Batch 1265,  loss: 0.15806289464235307\n",
      "Batch 1270,  loss: 0.188343346118927\n",
      "Batch 1275,  loss: 0.13136590272188187\n",
      "Batch 1280,  loss: 0.17515619695186616\n",
      "Batch 1285,  loss: 0.16025327146053314\n",
      "Batch 1290,  loss: 0.17397527098655702\n",
      "Batch 1295,  loss: 0.16935084462165834\n",
      "Batch 1300,  loss: 0.19570122361183168\n",
      "Batch 1305,  loss: 0.18168675899505615\n",
      "Batch 1310,  loss: 0.19732144773006438\n",
      "Batch 1315,  loss: 0.17104423940181732\n",
      "Batch 1320,  loss: 0.1877364844083786\n",
      "Batch 1325,  loss: 0.13308971226215363\n",
      "Batch 1330,  loss: 0.19953529834747313\n",
      "Batch 1335,  loss: 0.14942678362131118\n",
      "Batch 1340,  loss: 0.19019808769226074\n",
      "Batch 1345,  loss: 0.1366082102060318\n",
      "Batch 1350,  loss: 0.2038394182920456\n",
      "Batch 1355,  loss: 0.15315095633268355\n",
      "Batch 1360,  loss: 0.16615902334451677\n",
      "Batch 1365,  loss: 0.19160135388374328\n",
      "Batch 1370,  loss: 0.20477201491594316\n",
      "Batch 1375,  loss: 0.17495769560337066\n",
      "Batch 1380,  loss: 0.1818505734205246\n",
      "Batch 1385,  loss: 0.15680915266275405\n",
      "Batch 1390,  loss: 0.22910070568323135\n",
      "Batch 1395,  loss: 0.24685556888580323\n",
      "Batch 1400,  loss: 0.19163722097873687\n",
      "Batch 1405,  loss: 0.16216663420200347\n",
      "Batch 1410,  loss: 0.15532214045524598\n",
      "Batch 1415,  loss: 0.2181633621454239\n",
      "Batch 1420,  loss: 0.2279263198375702\n",
      "Batch 1425,  loss: 0.1628182888031006\n",
      "Batch 1430,  loss: 0.18955449163913726\n",
      "Batch 1435,  loss: 0.16405248939990996\n",
      "Batch 1440,  loss: 0.1992896556854248\n",
      "Batch 1445,  loss: 0.15554868578910827\n",
      "Batch 1450,  loss: 0.18816344439983368\n",
      "Batch 1455,  loss: 0.21761000156402588\n",
      "Batch 1460,  loss: 0.15298159122467042\n",
      "Batch 1465,  loss: 0.18381742537021636\n",
      "Batch 1470,  loss: 0.14345706403255462\n",
      "Batch 1475,  loss: 0.18308986127376556\n",
      "Batch 1480,  loss: 0.14762579798698425\n",
      "Batch 1485,  loss: 0.19657761752605438\n",
      "Batch 1490,  loss: 0.21233336329460145\n",
      "Batch 1495,  loss: 0.1597466289997101\n",
      "Batch 1500,  loss: 0.1834272712469101\n",
      "Batch 1505,  loss: 0.1431744948029518\n",
      "Batch 1510,  loss: 0.16400524973869324\n",
      "Batch 1515,  loss: 0.1670937031507492\n",
      "Batch 1520,  loss: 0.17637520879507065\n",
      "Batch 1525,  loss: 0.15872464776039125\n",
      "Batch 1530,  loss: 0.20285889208316804\n",
      "Batch 1535,  loss: 0.15647176653146744\n",
      "Batch 1540,  loss: 0.18570770025253297\n",
      "Batch 1545,  loss: 0.1645220249891281\n",
      "Batch 1550,  loss: 0.19200490713119506\n",
      "Batch 1555,  loss: 0.19368370175361632\n",
      "Batch 1560,  loss: 0.1722678944468498\n",
      "Batch 1565,  loss: 0.21920179724693298\n",
      "Batch 1570,  loss: 0.17310051918029784\n",
      "Batch 1575,  loss: 0.15784215033054352\n",
      "Batch 1580,  loss: 0.17329223155975343\n",
      "Batch 1585,  loss: 0.22285155951976776\n",
      "Batch 1590,  loss: 0.19330924451351167\n",
      "Batch 1595,  loss: 0.13328950703144074\n",
      "Batch 1600,  loss: 0.150966776907444\n",
      "Batch 1605,  loss: 0.14395490437746047\n",
      "Batch 1610,  loss: 0.14798444807529448\n",
      "Batch 1615,  loss: 0.15500186383724213\n",
      "Batch 1620,  loss: 0.13776974529027938\n",
      "Batch 1625,  loss: 0.1456444412469864\n",
      "Batch 1630,  loss: 0.15666724145412445\n",
      "Batch 1635,  loss: 0.20277314484119416\n",
      "Batch 1640,  loss: 0.2091197907924652\n",
      "Batch 1645,  loss: 0.16999383866786957\n",
      "Batch 1650,  loss: 0.13159238398075104\n",
      "Batch 1655,  loss: 0.16805404424667358\n",
      "Batch 1660,  loss: 0.16154012680053711\n",
      "Batch 1665,  loss: 0.16667400002479554\n",
      "Batch 1670,  loss: 0.16767183244228362\n",
      "Batch 1675,  loss: 0.1953733280301094\n",
      "Batch 1680,  loss: 0.1846563845872879\n",
      "Batch 1685,  loss: 0.1521466851234436\n",
      "Batch 1690,  loss: 0.16962264478206635\n",
      "Batch 1695,  loss: 0.17673790603876113\n",
      "Batch 1700,  loss: 0.16186920702457427\n",
      "Batch 1705,  loss: 0.2318929463624954\n",
      "Batch 1710,  loss: 0.19467918276786805\n",
      "Batch 1715,  loss: 0.1999563455581665\n",
      "Batch 1720,  loss: 0.19267552495002746\n",
      "Batch 1725,  loss: 0.16563267409801483\n",
      "Batch 1730,  loss: 0.1750166267156601\n",
      "Batch 1735,  loss: 0.14204711765050887\n",
      "Batch 1740,  loss: 0.16744423508644105\n",
      "Batch 1745,  loss: 0.1547464281320572\n",
      "Batch 1750,  loss: 0.163090480864048\n",
      "Batch 1755,  loss: 0.17604176104068756\n",
      "Batch 1760,  loss: 0.13399804532527923\n",
      "Batch 1765,  loss: 0.19048474431037904\n",
      "Batch 1770,  loss: 0.1459360271692276\n",
      "Batch 1775,  loss: 0.173269584774971\n",
      "Batch 1780,  loss: 0.14477447867393495\n",
      "Batch 1785,  loss: 0.20173795223236085\n",
      "Batch 1790,  loss: 0.17043355703353882\n",
      "Batch 1795,  loss: 0.2041979819536209\n",
      "Batch 1800,  loss: 0.1598094403743744\n",
      "Batch 1805,  loss: 0.15589758157730102\n",
      "Batch 1810,  loss: 0.15674970299005508\n",
      "Batch 1815,  loss: 0.18171727061271667\n",
      "Batch 1820,  loss: 0.19846488684415817\n",
      "Batch 1825,  loss: 0.14863502979278564\n",
      "Batch 1830,  loss: 0.20095081627368927\n",
      "Batch 1835,  loss: 0.1495463252067566\n",
      "Batch 1840,  loss: 0.1718999743461609\n",
      "Batch 1845,  loss: 0.15665368139743804\n",
      "Batch 1850,  loss: 0.15705746859312059\n",
      "Batch 1855,  loss: 0.23675151467323302\n",
      "Batch 1860,  loss: 0.14352622479200364\n",
      "Batch 1865,  loss: 0.1937186375260353\n",
      "Batch 1870,  loss: 0.17061097919940948\n",
      "Batch 1875,  loss: 0.19799671471118926\n",
      "Batch 1880,  loss: 0.19186481982469558\n",
      "Batch 1885,  loss: 0.18083026707172395\n",
      "Batch 1890,  loss: 0.13512841016054153\n",
      "Batch 1895,  loss: 0.1575264811515808\n",
      "Batch 1900,  loss: 0.14212839156389237\n",
      "Batch 1905,  loss: 0.16756727695465087\n",
      "Batch 1910,  loss: 0.20700180679559707\n",
      "Batch 1915,  loss: 0.1616984188556671\n",
      "Batch 1920,  loss: 0.13291468620300292\n",
      "Batch 1925,  loss: 0.17638179361820222\n",
      "Batch 1930,  loss: 0.17614082992076874\n",
      "Batch 1935,  loss: 0.17180319726467133\n",
      "Batch 1940,  loss: 0.21496719717979432\n",
      "Batch 1945,  loss: 0.2020985886454582\n",
      "Batch 1950,  loss: 0.16932365894317628\n",
      "Batch 1955,  loss: 0.17196420431137086\n",
      "Batch 1960,  loss: 0.23120590448379516\n",
      "Batch 1965,  loss: 0.15775791108608245\n",
      "Batch 1970,  loss: 0.1530611991882324\n",
      "Batch 1975,  loss: 0.20545809268951415\n",
      "Batch 1980,  loss: 0.1640894293785095\n",
      "Batch 1985,  loss: 0.19012166261672975\n",
      "Batch 1990,  loss: 0.16285027414560319\n",
      "Batch 1995,  loss: 0.1602581560611725\n",
      "Batch 2000,  loss: 0.16463289707899093\n",
      "Batch 2005,  loss: 0.16104302704334258\n",
      "Batch 2010,  loss: 0.20531371831893921\n",
      "Batch 2015,  loss: 0.18825983107089997\n",
      "Batch 2020,  loss: 0.18569700419902802\n",
      "Batch 2025,  loss: 0.13108748495578765\n",
      "Batch 2030,  loss: 0.17586084604263305\n",
      "Batch 2035,  loss: 0.17140716016292573\n",
      "Batch 2040,  loss: 0.17851054519414902\n",
      "Batch 2045,  loss: 0.21924599707126619\n",
      "Batch 2050,  loss: 0.16112030446529388\n",
      "Batch 2055,  loss: 0.16692828238010407\n",
      "Batch 2060,  loss: 0.16459790766239166\n",
      "Batch 2065,  loss: 0.20231659710407257\n",
      "Batch 2070,  loss: 0.22174238562583923\n",
      "Batch 2075,  loss: 0.17008359730243683\n",
      "Batch 2080,  loss: 0.1759940892457962\n",
      "Batch 2085,  loss: 0.22571369409561157\n",
      "Batch 2090,  loss: 0.1918785199522972\n",
      "Batch 2095,  loss: 0.2071271777153015\n",
      "Batch 2100,  loss: 0.1922753170132637\n",
      "Batch 2105,  loss: 0.1414145976305008\n",
      "Batch 2110,  loss: 0.18102365583181382\n",
      "Batch 2115,  loss: 0.14272791743278504\n",
      "Batch 2120,  loss: 0.1774309277534485\n",
      "Batch 2125,  loss: 0.16987268924713134\n",
      "Batch 2130,  loss: 0.14559632092714309\n",
      "Batch 2135,  loss: 0.14915130138397217\n",
      "Batch 2140,  loss: 0.16725813448429108\n",
      "Batch 2145,  loss: 0.19580929577350617\n",
      "Batch 2150,  loss: 0.1422460690140724\n",
      "Batch 2155,  loss: 0.1525435909628868\n",
      "Batch 2160,  loss: 0.1615844786167145\n",
      "Batch 2165,  loss: 0.22976788878440857\n",
      "Batch 2170,  loss: 0.1658905953168869\n",
      "Batch 2175,  loss: 0.16376859545707703\n",
      "Batch 2180,  loss: 0.19016332924365997\n",
      "Batch 2185,  loss: 0.19983381927013397\n",
      "Batch 2190,  loss: 0.20369347035884858\n",
      "Batch 2195,  loss: 0.21805291175842284\n",
      "Batch 2200,  loss: 0.2113116756081581\n",
      "Batch 2205,  loss: 0.17316153198480605\n",
      "Batch 2210,  loss: 0.1484740048646927\n",
      "Batch 2215,  loss: 0.13882769495248795\n",
      "Batch 2220,  loss: 0.15489390641450881\n",
      "Batch 2225,  loss: 0.17480918765068054\n",
      "Batch 2230,  loss: 0.16871093809604645\n",
      "Batch 2235,  loss: 0.1560463309288025\n",
      "Batch 2240,  loss: 0.25369605123996736\n",
      "Batch 2245,  loss: 0.17508610785007478\n",
      "Batch 2250,  loss: 0.19563202261924745\n",
      "Batch 2255,  loss: 0.21418380588293076\n",
      "Batch 2260,  loss: 0.16055974662303923\n",
      "Batch 2265,  loss: 0.16834817230701446\n",
      "Batch 2270,  loss: 0.18712586164474487\n",
      "Batch 2275,  loss: 0.18069634735584258\n",
      "Batch 2280,  loss: 0.14987242817878724\n",
      "Batch 2285,  loss: 0.1919422209262848\n",
      "Batch 2290,  loss: 0.19716881811618805\n",
      "Batch 2295,  loss: 0.2121301144361496\n",
      "Batch 2300,  loss: 0.19795748293399812\n",
      "Batch 2305,  loss: 0.15225793719291686\n",
      "Batch 2310,  loss: 0.1851739376783371\n",
      "Batch 2315,  loss: 0.14433104395866395\n",
      "Batch 2320,  loss: 0.15582916587591172\n",
      "Batch 2325,  loss: 0.1755475163459778\n",
      "Batch 2330,  loss: 0.16079220920801163\n",
      "Batch 2335,  loss: 0.16282833814620973\n",
      "Batch 2340,  loss: 0.17305726408958436\n",
      "Batch 2345,  loss: 0.1782458394765854\n",
      "Batch 2350,  loss: 0.22976410388946533\n",
      "Batch 2355,  loss: 0.1957648664712906\n",
      "Batch 2360,  loss: 0.20686987936496734\n",
      "Batch 2365,  loss: 0.16916486322879792\n",
      "Batch 2370,  loss: 0.1434822529554367\n",
      "Batch 2375,  loss: 0.17316453754901887\n",
      "Batch 2380,  loss: 0.19276825487613677\n",
      "Batch 2385,  loss: 0.17549864947795868\n",
      "Batch 2390,  loss: 0.16015740633010864\n",
      "Batch 2395,  loss: 0.1951005846261978\n",
      "Batch 2400,  loss: 0.1353137657046318\n",
      "Batch 2405,  loss: 0.17265709340572358\n",
      "Batch 2410,  loss: 0.2159956932067871\n",
      "Batch 2415,  loss: 0.1659439131617546\n",
      "Batch 2420,  loss: 0.1815534383058548\n",
      "Batch 2425,  loss: 0.18030039370059966\n",
      "Batch 2430,  loss: 0.18291905522346497\n",
      "Batch 2435,  loss: 0.18847343027591706\n",
      "Batch 2440,  loss: 0.170451121032238\n",
      "Batch 2445,  loss: 0.22177510261535643\n",
      "Batch 2450,  loss: 0.1369499683380127\n",
      "Batch 2455,  loss: 0.14948560744524003\n",
      "Batch 2460,  loss: 0.20373513400554658\n",
      "Batch 2465,  loss: 0.1735190898180008\n",
      "Batch 2470,  loss: 0.16069830656051637\n",
      "Batch 2475,  loss: 0.2504464864730835\n",
      "Batch 2480,  loss: 0.2102280706167221\n",
      "Batch 2485,  loss: 0.20016815066337584\n",
      "Batch 2490,  loss: 0.15242032557725907\n",
      "Batch 2495,  loss: 0.1455724745988846\n",
      "Batch 2500,  loss: 0.16390929520130157\n",
      "Batch 2505,  loss: 0.210686594247818\n",
      "Batch 2510,  loss: 0.14433826506137848\n",
      "Batch 2515,  loss: 0.18617017269134523\n",
      "Batch 2520,  loss: 0.19919536411762237\n",
      "Batch 2525,  loss: 0.20144761800765992\n",
      "Batch 2530,  loss: 0.15824211835861207\n",
      "Batch 2535,  loss: 0.17283861041069032\n",
      "Batch 2540,  loss: 0.23578513860702516\n",
      "Batch 2545,  loss: 0.12741221338510514\n",
      "Batch 2550,  loss: 0.1567044660449028\n",
      "Batch 2555,  loss: 0.21681838035583495\n",
      "Batch 2560,  loss: 0.1464392811059952\n",
      "Batch 2565,  loss: 0.1675192594528198\n",
      "Batch 2570,  loss: 0.20720551162958145\n",
      "Batch 2575,  loss: 0.1854359209537506\n",
      "Batch 2580,  loss: 0.18445006310939788\n",
      "Batch 2585,  loss: 0.1673562467098236\n",
      "Batch 2590,  loss: 0.18266039788722993\n",
      "Batch 2595,  loss: 0.19084653556346892\n",
      "Batch 2600,  loss: 0.1621489942073822\n",
      "Batch 2605,  loss: 0.20976539552211762\n",
      "Batch 2610,  loss: 0.15323765575885773\n",
      "Batch 2615,  loss: 0.1981113761663437\n",
      "Batch 2620,  loss: 0.16441482901573182\n",
      "Batch 2625,  loss: 0.14655176997184755\n",
      "Batch 2630,  loss: 0.16447081863880159\n",
      "Batch 2635,  loss: 0.16695138812065125\n",
      "Batch 2640,  loss: 0.1634308308362961\n",
      "Batch 2645,  loss: 0.18759032487869262\n",
      "Batch 2650,  loss: 0.14855294972658156\n",
      "Batch 2655,  loss: 0.23320261836051942\n",
      "Batch 2660,  loss: 0.18596796691417694\n",
      "Batch 2665,  loss: 0.17723744213581086\n",
      "Batch 2670,  loss: 0.1591240480542183\n",
      "Batch 2675,  loss: 0.15811725556850434\n",
      "Batch 2680,  loss: 0.15665092766284944\n",
      "Batch 2685,  loss: 0.18965977430343628\n",
      "Batch 2690,  loss: 0.21695330142974853\n",
      "Batch 2695,  loss: 0.15036217868328094\n",
      "Batch 2700,  loss: 0.1647206336259842\n",
      "Batch 2705,  loss: 0.20573989003896714\n",
      "Batch 2710,  loss: 0.15968666672706605\n",
      "Batch 2715,  loss: 0.16561706960201264\n",
      "Batch 2720,  loss: 0.15179348587989808\n",
      "Batch 2725,  loss: 0.20197519063949584\n",
      "Batch 2730,  loss: 0.18298125267028809\n",
      "Batch 2735,  loss: 0.19086663722991942\n",
      "Batch 2740,  loss: 0.19367800354957582\n",
      "Batch 2745,  loss: 0.17269041389226913\n",
      "Batch 2750,  loss: 0.17707529962062835\n",
      "Batch 2755,  loss: 0.17952632606029512\n",
      "Batch 2760,  loss: 0.17003833502531052\n",
      "Batch 2765,  loss: 0.18059717416763305\n",
      "Batch 2770,  loss: 0.20542958080768586\n",
      "LOSS train 0.20542958080768586. Validation loss: 0.1614164223532296 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 18:\n",
      "Batch 5,  loss: 0.1685417264699936\n",
      "Batch 10,  loss: 0.20018551945686341\n",
      "Batch 15,  loss: 0.19315942227840424\n",
      "Batch 20,  loss: 0.17368268370628356\n",
      "Batch 25,  loss: 0.1644926220178604\n",
      "Batch 30,  loss: 0.16753003150224685\n",
      "Batch 35,  loss: 0.17157977670431138\n",
      "Batch 40,  loss: 0.19210328459739684\n",
      "Batch 45,  loss: 0.14248926639556886\n",
      "Batch 50,  loss: 0.20251991152763366\n",
      "Batch 55,  loss: 0.15018065869808198\n",
      "Batch 60,  loss: 0.14932893514633178\n",
      "Batch 65,  loss: 0.18159670233726502\n",
      "Batch 70,  loss: 0.16322894096374513\n",
      "Batch 75,  loss: 0.13465773761272432\n",
      "Batch 80,  loss: 0.18789080381393433\n",
      "Batch 85,  loss: 0.18667952418327333\n",
      "Batch 90,  loss: 0.13494229614734649\n",
      "Batch 95,  loss: 0.17715557515621186\n",
      "Batch 100,  loss: 0.1964147001504898\n",
      "Batch 105,  loss: 0.19711067974567414\n",
      "Batch 110,  loss: 0.20010242760181426\n",
      "Batch 115,  loss: 0.1442606806755066\n",
      "Batch 120,  loss: 0.19020704925060272\n",
      "Batch 125,  loss: 0.19181728065013887\n",
      "Batch 130,  loss: 0.12752317935228347\n",
      "Batch 135,  loss: 0.19434188306331635\n",
      "Batch 140,  loss: 0.1858375370502472\n",
      "Batch 145,  loss: 0.15473177433013915\n",
      "Batch 150,  loss: 0.15302745401859283\n",
      "Batch 155,  loss: 0.19383397102355956\n",
      "Batch 160,  loss: 0.15668152570724486\n",
      "Batch 165,  loss: 0.1673896223306656\n",
      "Batch 170,  loss: 0.1618381232023239\n",
      "Batch 175,  loss: 0.18617793768644333\n",
      "Batch 180,  loss: 0.221891850233078\n",
      "Batch 185,  loss: 0.16104242205619812\n",
      "Batch 190,  loss: 0.15157860815525054\n",
      "Batch 195,  loss: 0.18320510387420655\n",
      "Batch 200,  loss: 0.17570771872997284\n",
      "Batch 205,  loss: 0.15714185535907746\n",
      "Batch 210,  loss: 0.17127215266227722\n",
      "Batch 215,  loss: 0.18789331316947938\n",
      "Batch 220,  loss: 0.16926583349704744\n",
      "Batch 225,  loss: 0.15753598809242247\n",
      "Batch 230,  loss: 0.163600917160511\n",
      "Batch 235,  loss: 0.16406027376651763\n",
      "Batch 240,  loss: 0.173871012032032\n",
      "Batch 245,  loss: 0.17236053049564362\n",
      "Batch 250,  loss: 0.22295932173728944\n",
      "Batch 255,  loss: 0.16655004173517227\n",
      "Batch 260,  loss: 0.17433422803878784\n",
      "Batch 265,  loss: 0.1812722608447075\n",
      "Batch 270,  loss: 0.18216781914234162\n",
      "Batch 275,  loss: 0.15497359931468963\n",
      "Batch 280,  loss: 0.2108363002538681\n",
      "Batch 285,  loss: 0.18835982978343963\n",
      "Batch 290,  loss: 0.16588488817214966\n",
      "Batch 295,  loss: 0.14873412549495696\n",
      "Batch 300,  loss: 0.1757612109184265\n",
      "Batch 305,  loss: 0.21119412779808044\n",
      "Batch 310,  loss: 0.18086625039577484\n",
      "Batch 315,  loss: 0.20544822216033937\n",
      "Batch 320,  loss: 0.1506112515926361\n",
      "Batch 325,  loss: 0.23916781842708587\n",
      "Batch 330,  loss: 0.15861066728830336\n",
      "Batch 335,  loss: 0.1812032490968704\n",
      "Batch 340,  loss: 0.18470633327960967\n",
      "Batch 345,  loss: 0.15895503163337707\n",
      "Batch 350,  loss: 0.1594969540834427\n",
      "Batch 355,  loss: 0.19521964192390442\n",
      "Batch 360,  loss: 0.19206264913082122\n",
      "Batch 365,  loss: 0.21407006680965424\n",
      "Batch 370,  loss: 0.156084281206131\n",
      "Batch 375,  loss: 0.18536839187145232\n",
      "Batch 380,  loss: 0.20655413269996642\n",
      "Batch 385,  loss: 0.15832898914813995\n",
      "Batch 390,  loss: 0.15009224712848662\n",
      "Batch 395,  loss: 0.2004072666168213\n",
      "Batch 400,  loss: 0.17367581129074097\n",
      "Batch 405,  loss: 0.1593289315700531\n",
      "Batch 410,  loss: 0.18425384163856506\n",
      "Batch 415,  loss: 0.14426704198122026\n",
      "Batch 420,  loss: 0.16315275132656099\n",
      "Batch 425,  loss: 0.17867473661899566\n",
      "Batch 430,  loss: 0.17628662288188934\n",
      "Batch 435,  loss: 0.16805262267589569\n",
      "Batch 440,  loss: 0.17040070593357087\n",
      "Batch 445,  loss: 0.14257772862911225\n",
      "Batch 450,  loss: 0.1533668041229248\n",
      "Batch 455,  loss: 0.1800156831741333\n",
      "Batch 460,  loss: 0.1406702220439911\n",
      "Batch 465,  loss: 0.15639653354883193\n",
      "Batch 470,  loss: 0.18533044159412385\n",
      "Batch 475,  loss: 0.15878387093544005\n",
      "Batch 480,  loss: 0.16221911758184432\n",
      "Batch 485,  loss: 0.1663202464580536\n",
      "Batch 490,  loss: 0.19200905859470369\n",
      "Batch 495,  loss: 0.16367563903331755\n",
      "Batch 500,  loss: 0.17675656974315643\n",
      "Batch 505,  loss: 0.1822242945432663\n",
      "Batch 510,  loss: 0.14687686860561372\n",
      "Batch 515,  loss: 0.19746296405792235\n",
      "Batch 520,  loss: 0.2006823480129242\n",
      "Batch 525,  loss: 0.1736256092786789\n",
      "Batch 530,  loss: 0.16115351021289825\n",
      "Batch 535,  loss: 0.15640764981508254\n",
      "Batch 540,  loss: 0.1653905287384987\n",
      "Batch 545,  loss: 0.14751769006252288\n",
      "Batch 550,  loss: 0.14649620652198792\n",
      "Batch 555,  loss: 0.15935856401920317\n",
      "Batch 560,  loss: 0.2215340942144394\n",
      "Batch 565,  loss: 0.18289841264486312\n",
      "Batch 570,  loss: 0.2260560631752014\n",
      "Batch 575,  loss: 0.1790362387895584\n",
      "Batch 580,  loss: 0.17301586866378785\n",
      "Batch 585,  loss: 0.204007488489151\n",
      "Batch 590,  loss: 0.18421258330345153\n",
      "Batch 595,  loss: 0.15336983203887938\n",
      "Batch 600,  loss: 0.23797659277915956\n",
      "Batch 605,  loss: 0.15086568742990494\n",
      "Batch 610,  loss: 0.1586870864033699\n",
      "Batch 615,  loss: 0.18699455708265306\n",
      "Batch 620,  loss: 0.21919542849063872\n",
      "Batch 625,  loss: 0.18829265832901002\n",
      "Batch 630,  loss: 0.16576583683490753\n",
      "Batch 635,  loss: 0.20696036517620087\n",
      "Batch 640,  loss: 0.17158959805965424\n",
      "Batch 645,  loss: 0.17123527824878693\n",
      "Batch 650,  loss: 0.1744203507900238\n",
      "Batch 655,  loss: 0.17916531711816788\n",
      "Batch 660,  loss: 0.23284270167350768\n",
      "Batch 665,  loss: 0.17281956672668458\n",
      "Batch 670,  loss: 0.2044612944126129\n",
      "Batch 675,  loss: 0.1660159021615982\n",
      "Batch 680,  loss: 0.16140994131565095\n",
      "Batch 685,  loss: 0.1716485232114792\n",
      "Batch 690,  loss: 0.16441404521465303\n",
      "Batch 695,  loss: 0.16583881676197051\n",
      "Batch 700,  loss: 0.15760663747787476\n",
      "Batch 705,  loss: 0.2020224153995514\n",
      "Batch 710,  loss: 0.1677284747362137\n",
      "Batch 715,  loss: 0.17603763639926912\n",
      "Batch 720,  loss: 0.15367235243320465\n",
      "Batch 725,  loss: 0.18317118287086487\n",
      "Batch 730,  loss: 0.1708059638738632\n",
      "Batch 735,  loss: 0.1640864849090576\n",
      "Batch 740,  loss: 0.2271072655916214\n",
      "Batch 745,  loss: 0.15491545498371123\n",
      "Batch 750,  loss: 0.17366744577884674\n",
      "Batch 755,  loss: 0.17335468232631684\n",
      "Batch 760,  loss: 0.14939115941524506\n",
      "Batch 765,  loss: 0.15542077720165254\n",
      "Batch 770,  loss: 0.16905349791049956\n",
      "Batch 775,  loss: 0.18148001730442048\n",
      "Batch 780,  loss: 0.1656959503889084\n",
      "Batch 785,  loss: 0.22180504500865936\n",
      "Batch 790,  loss: 0.12560874670743943\n",
      "Batch 795,  loss: 0.15787285268306733\n",
      "Batch 800,  loss: 0.17749310731887818\n",
      "Batch 805,  loss: 0.20348477363586426\n",
      "Batch 810,  loss: 0.15202628076076508\n",
      "Batch 815,  loss: 0.17915008068084717\n",
      "Batch 820,  loss: 0.15849791020154952\n",
      "Batch 825,  loss: 0.16207274347543715\n",
      "Batch 830,  loss: 0.13483441472053528\n",
      "Batch 835,  loss: 0.1529028296470642\n",
      "Batch 840,  loss: 0.16373851895332336\n",
      "Batch 845,  loss: 0.16563972234725952\n",
      "Batch 850,  loss: 0.16466534733772278\n",
      "Batch 855,  loss: 0.19052773714065552\n",
      "Batch 860,  loss: 0.14998592883348466\n",
      "Batch 865,  loss: 0.1793621927499771\n",
      "Batch 870,  loss: 0.1480820968747139\n",
      "Batch 875,  loss: 0.17699920535087585\n",
      "Batch 880,  loss: 0.1937105894088745\n",
      "Batch 885,  loss: 0.20086710155010223\n",
      "Batch 890,  loss: 0.17886962890625\n",
      "Batch 895,  loss: 0.20521736443042754\n",
      "Batch 900,  loss: 0.1747763127088547\n",
      "Batch 905,  loss: 0.16400784850120545\n",
      "Batch 910,  loss: 0.1877447098493576\n",
      "Batch 915,  loss: 0.14314844459295273\n",
      "Batch 920,  loss: 0.16659601628780366\n",
      "Batch 925,  loss: 0.17921435534954072\n",
      "Batch 930,  loss: 0.1753257155418396\n",
      "Batch 935,  loss: 0.1625327944755554\n",
      "Batch 940,  loss: 0.16484017670154572\n",
      "Batch 945,  loss: 0.15710261166095735\n",
      "Batch 950,  loss: 0.14810483455657958\n",
      "Batch 955,  loss: 0.1883646219968796\n",
      "Batch 960,  loss: 0.1596078783273697\n",
      "Batch 965,  loss: 0.22474235892295838\n",
      "Batch 970,  loss: 0.23316690027713777\n",
      "Batch 975,  loss: 0.18623399436473848\n",
      "Batch 980,  loss: 0.19565752148628235\n",
      "Batch 985,  loss: 0.19351617991924286\n",
      "Batch 990,  loss: 0.1813513845205307\n",
      "Batch 995,  loss: 0.14337283074855806\n",
      "Batch 1000,  loss: 0.12112950831651688\n",
      "Batch 1005,  loss: 0.13692664355039597\n",
      "Batch 1010,  loss: 0.1443550169467926\n",
      "Batch 1015,  loss: 0.1876628041267395\n",
      "Batch 1020,  loss: 0.13651283085346222\n",
      "Batch 1025,  loss: 0.15732307732105255\n",
      "Batch 1030,  loss: 0.16289347559213638\n",
      "Batch 1035,  loss: 0.16184980571269988\n",
      "Batch 1040,  loss: 0.19634988009929658\n",
      "Batch 1045,  loss: 0.19329022467136384\n",
      "Batch 1050,  loss: 0.16812447011470794\n",
      "Batch 1055,  loss: 0.16237941533327102\n",
      "Batch 1060,  loss: 0.13928597718477248\n",
      "Batch 1065,  loss: 0.2026916652917862\n",
      "Batch 1070,  loss: 0.14470090121030807\n",
      "Batch 1075,  loss: 0.1948060154914856\n",
      "Batch 1080,  loss: 0.20599769949913024\n",
      "Batch 1085,  loss: 0.18503401279449463\n",
      "Batch 1090,  loss: 0.15289647579193116\n",
      "Batch 1095,  loss: 0.2104976326227188\n",
      "Batch 1100,  loss: 0.15630588829517364\n",
      "Batch 1105,  loss: 0.1636149764060974\n",
      "Batch 1110,  loss: 0.18528708219528198\n",
      "Batch 1115,  loss: 0.16168699264526368\n",
      "Batch 1120,  loss: 0.18811876475811004\n",
      "Batch 1125,  loss: 0.15561355352401735\n",
      "Batch 1130,  loss: 0.1652846097946167\n",
      "Batch 1135,  loss: 0.17569979876279831\n",
      "Batch 1140,  loss: 0.17884030640125276\n",
      "Batch 1145,  loss: 0.22643323242664337\n",
      "Batch 1150,  loss: 0.1688561648130417\n",
      "Batch 1155,  loss: 0.19592553973197938\n",
      "Batch 1160,  loss: 0.15032729804515838\n",
      "Batch 1165,  loss: 0.18417275249958037\n",
      "Batch 1170,  loss: 0.1886383444070816\n",
      "Batch 1175,  loss: 0.1668404072523117\n",
      "Batch 1180,  loss: 0.19586034417152404\n",
      "Batch 1185,  loss: 0.18726563453674316\n",
      "Batch 1190,  loss: 0.19947879910469055\n",
      "Batch 1195,  loss: 0.17853321135044098\n",
      "Batch 1200,  loss: 0.17224543988704683\n",
      "Batch 1205,  loss: 0.25586656033992766\n",
      "Batch 1210,  loss: 0.18751721680164338\n",
      "Batch 1215,  loss: 0.18737094700336457\n",
      "Batch 1220,  loss: 0.1568957969546318\n",
      "Batch 1225,  loss: 0.21475054919719697\n",
      "Batch 1230,  loss: 0.1571356475353241\n",
      "Batch 1235,  loss: 0.1760673403739929\n",
      "Batch 1240,  loss: 0.14762349128723146\n",
      "Batch 1245,  loss: 0.14368576556444168\n",
      "Batch 1250,  loss: 0.1525721490383148\n",
      "Batch 1255,  loss: 0.1332438677549362\n",
      "Batch 1260,  loss: 0.18393328189849853\n",
      "Batch 1265,  loss: 0.16964115351438522\n",
      "Batch 1270,  loss: 0.17136301696300507\n",
      "Batch 1275,  loss: 0.16576169133186341\n",
      "Batch 1280,  loss: 0.18326641321182252\n",
      "Batch 1285,  loss: 0.19051391780376434\n",
      "Batch 1290,  loss: 0.21202267408370973\n",
      "Batch 1295,  loss: 0.13363877385854722\n",
      "Batch 1300,  loss: 0.13495426177978515\n",
      "Batch 1305,  loss: 0.19608187973499297\n",
      "Batch 1310,  loss: 0.1412879079580307\n",
      "Batch 1315,  loss: 0.15921957790851593\n",
      "Batch 1320,  loss: 0.15985269844532013\n",
      "Batch 1325,  loss: 0.14704829156398774\n",
      "Batch 1330,  loss: 0.13574400991201402\n",
      "Batch 1335,  loss: 0.16706996262073517\n",
      "Batch 1340,  loss: 0.16958731412887573\n",
      "Batch 1345,  loss: 0.1829669952392578\n",
      "Batch 1350,  loss: 0.15785633772611618\n",
      "Batch 1355,  loss: 0.17690632939338685\n",
      "Batch 1360,  loss: 0.1690505862236023\n",
      "Batch 1365,  loss: 0.18610163033008575\n",
      "Batch 1370,  loss: 0.1823904484510422\n",
      "Batch 1375,  loss: 0.21517808437347413\n",
      "Batch 1380,  loss: 0.15394337177276612\n",
      "Batch 1385,  loss: 0.16943956017494202\n",
      "Batch 1390,  loss: 0.16643806397914887\n",
      "Batch 1395,  loss: 0.15603557378053665\n",
      "Batch 1400,  loss: 0.1692618027329445\n",
      "Batch 1405,  loss: 0.16780976057052613\n",
      "Batch 1410,  loss: 0.15120496451854706\n",
      "Batch 1415,  loss: 0.2038058429956436\n",
      "Batch 1420,  loss: 0.14368399381637573\n",
      "Batch 1425,  loss: 0.16467446386814116\n",
      "Batch 1430,  loss: 0.1707222580909729\n",
      "Batch 1435,  loss: 0.1508256822824478\n",
      "Batch 1440,  loss: 0.22771382927894593\n",
      "Batch 1445,  loss: 0.12541415095329284\n",
      "Batch 1450,  loss: 0.17224173843860627\n",
      "Batch 1455,  loss: 0.19522231221199035\n",
      "Batch 1460,  loss: 0.17956340610980986\n",
      "Batch 1465,  loss: 0.16599652916193008\n",
      "Batch 1470,  loss: 0.15198513567447663\n",
      "Batch 1475,  loss: 0.19082603454589844\n",
      "Batch 1480,  loss: 0.131436288356781\n",
      "Batch 1485,  loss: 0.16558684706687926\n",
      "Batch 1490,  loss: 0.16572897136211395\n",
      "Batch 1495,  loss: 0.14855870604515076\n",
      "Batch 1500,  loss: 0.22402306497097016\n",
      "Batch 1505,  loss: 0.2058247745037079\n",
      "Batch 1510,  loss: 0.15679520219564438\n",
      "Batch 1515,  loss: 0.24968738555908204\n",
      "Batch 1520,  loss: 0.1726268857717514\n",
      "Batch 1525,  loss: 0.1472238302230835\n",
      "Batch 1530,  loss: 0.14595087617635727\n",
      "Batch 1535,  loss: 0.1368291586637497\n",
      "Batch 1540,  loss: 0.15993277579545975\n",
      "Batch 1545,  loss: 0.18957023322582245\n",
      "Batch 1550,  loss: 0.19741891622543334\n",
      "Batch 1555,  loss: 0.14735714346170425\n",
      "Batch 1560,  loss: 0.2087739646434784\n",
      "Batch 1565,  loss: 0.16795699447393417\n",
      "Batch 1570,  loss: 0.2195487916469574\n",
      "Batch 1575,  loss: 0.14888980984687805\n",
      "Batch 1580,  loss: 0.19731622338294982\n",
      "Batch 1585,  loss: 0.1568517804145813\n",
      "Batch 1590,  loss: 0.16166920959949493\n",
      "Batch 1595,  loss: 0.20824896693229675\n",
      "Batch 1600,  loss: 0.14886744022369386\n",
      "Batch 1605,  loss: 0.16709140837192535\n",
      "Batch 1610,  loss: 0.18545859456062316\n",
      "Batch 1615,  loss: 0.2266526460647583\n",
      "Batch 1620,  loss: 0.24796757102012634\n",
      "Batch 1625,  loss: 0.18148830235004426\n",
      "Batch 1630,  loss: 0.1765325963497162\n",
      "Batch 1635,  loss: 0.16554612517356873\n",
      "Batch 1640,  loss: 0.16796770989894866\n",
      "Batch 1645,  loss: 0.15703653842210769\n",
      "Batch 1650,  loss: 0.19093902111053468\n",
      "Batch 1655,  loss: 0.1811620980501175\n",
      "Batch 1660,  loss: 0.17025405764579774\n",
      "Batch 1665,  loss: 0.15353589355945588\n",
      "Batch 1670,  loss: 0.18179236352443695\n",
      "Batch 1675,  loss: 0.19075149297714233\n",
      "Batch 1680,  loss: 0.17878342568874359\n",
      "Batch 1685,  loss: 0.16684752702713013\n",
      "Batch 1690,  loss: 0.1778899371623993\n",
      "Batch 1695,  loss: 0.20490371882915498\n",
      "Batch 1700,  loss: 0.20259115993976592\n",
      "Batch 1705,  loss: 0.1852343738079071\n",
      "Batch 1710,  loss: 0.1597046434879303\n",
      "Batch 1715,  loss: 0.15960437059402466\n",
      "Batch 1720,  loss: 0.19559107422828675\n",
      "Batch 1725,  loss: 0.24310593605041503\n",
      "Batch 1730,  loss: 0.205340239405632\n",
      "Batch 1735,  loss: 0.1476459801197052\n",
      "Batch 1740,  loss: 0.22804152071475983\n",
      "Batch 1745,  loss: 0.20107246041297913\n",
      "Batch 1750,  loss: 0.16494925171136857\n",
      "Batch 1755,  loss: 0.15057624727487565\n",
      "Batch 1760,  loss: 0.19811183214187622\n",
      "Batch 1765,  loss: 0.22729598879814147\n",
      "Batch 1770,  loss: 0.17117931544780732\n",
      "Batch 1775,  loss: 0.12997767478227615\n",
      "Batch 1780,  loss: 0.15018932819366454\n",
      "Batch 1785,  loss: 0.16443712413311004\n",
      "Batch 1790,  loss: 0.18925048410892487\n",
      "Batch 1795,  loss: 0.18412646055221557\n",
      "Batch 1800,  loss: 0.21796624660491942\n",
      "Batch 1805,  loss: 0.15758931934833526\n",
      "Batch 1810,  loss: 0.17159641087055205\n",
      "Batch 1815,  loss: 0.1818518429994583\n",
      "Batch 1820,  loss: 0.15334030687808992\n",
      "Batch 1825,  loss: 0.19450852870941163\n",
      "Batch 1830,  loss: 0.160111603140831\n",
      "Batch 1835,  loss: 0.18101712465286254\n",
      "Batch 1840,  loss: 0.15989806950092317\n",
      "Batch 1845,  loss: 0.1240359365940094\n",
      "Batch 1850,  loss: 0.18532335758209229\n",
      "Batch 1855,  loss: 0.19665433764457702\n",
      "Batch 1860,  loss: 0.19713775515556337\n",
      "Batch 1865,  loss: 0.16179811656475068\n",
      "Batch 1870,  loss: 0.18630681931972504\n",
      "Batch 1875,  loss: 0.15405207574367524\n",
      "Batch 1880,  loss: 0.1797875240445137\n",
      "Batch 1885,  loss: 0.14606767743825913\n",
      "Batch 1890,  loss: 0.2276979446411133\n",
      "Batch 1895,  loss: 0.1877980947494507\n",
      "Batch 1900,  loss: 0.15832397639751433\n",
      "Batch 1905,  loss: 0.1574525147676468\n",
      "Batch 1910,  loss: 0.14000928848981858\n",
      "Batch 1915,  loss: 0.19341602325439453\n",
      "Batch 1920,  loss: 0.20888289213180541\n",
      "Batch 1925,  loss: 0.15548136830329895\n",
      "Batch 1930,  loss: 0.14534655213356018\n",
      "Batch 1935,  loss: 0.1636658638715744\n",
      "Batch 1940,  loss: 0.17367396354675294\n",
      "Batch 1945,  loss: 0.15008483827114105\n",
      "Batch 1950,  loss: 0.23471357822418212\n",
      "Batch 1955,  loss: 0.16363545805215834\n",
      "Batch 1960,  loss: 0.17192595452070236\n",
      "Batch 1965,  loss: 0.20411506444215774\n",
      "Batch 1970,  loss: 0.18059016168117523\n",
      "Batch 1975,  loss: 0.16348775327205659\n",
      "Batch 1980,  loss: 0.17067385017871856\n",
      "Batch 1985,  loss: 0.16127171814441682\n",
      "Batch 1990,  loss: 0.15031459480524062\n",
      "Batch 1995,  loss: 0.20027938783168792\n",
      "Batch 2000,  loss: 0.1552659973502159\n",
      "Batch 2005,  loss: 0.17742347419261933\n",
      "Batch 2010,  loss: 0.14365728199481964\n",
      "Batch 2015,  loss: 0.16072725057601928\n",
      "Batch 2020,  loss: 0.174088454246521\n",
      "Batch 2025,  loss: 0.16089147925376893\n",
      "Batch 2030,  loss: 0.15262234807014466\n",
      "Batch 2035,  loss: 0.1881041020154953\n",
      "Batch 2040,  loss: 0.1983891934156418\n",
      "Batch 2045,  loss: 0.20789601802825927\n",
      "Batch 2050,  loss: 0.1946377635002136\n",
      "Batch 2055,  loss: 0.17268285304307937\n",
      "Batch 2060,  loss: 0.2152095228433609\n",
      "Batch 2065,  loss: 0.2094045788049698\n",
      "Batch 2070,  loss: 0.15201397836208344\n",
      "Batch 2075,  loss: 0.21179097890853882\n",
      "Batch 2080,  loss: 0.17320075929164885\n",
      "Batch 2085,  loss: 0.19416923820972443\n",
      "Batch 2090,  loss: 0.16816367208957672\n",
      "Batch 2095,  loss: 0.14096954464912415\n",
      "Batch 2100,  loss: 0.14398974180221558\n",
      "Batch 2105,  loss: 0.20151847898960112\n",
      "Batch 2110,  loss: 0.16820619106292725\n",
      "Batch 2115,  loss: 0.1403939038515091\n",
      "Batch 2120,  loss: 0.14847565591335296\n",
      "Batch 2125,  loss: 0.22332731187343596\n",
      "Batch 2130,  loss: 0.1940808653831482\n",
      "Batch 2135,  loss: 0.16544745564460756\n",
      "Batch 2140,  loss: 0.17119463086128234\n",
      "Batch 2145,  loss: 0.19729859232902527\n",
      "Batch 2150,  loss: 0.18515646755695342\n",
      "Batch 2155,  loss: 0.20570102334022522\n",
      "Batch 2160,  loss: 0.18820685744285584\n",
      "Batch 2165,  loss: 0.15214299708604812\n",
      "Batch 2170,  loss: 0.20506047904491426\n",
      "Batch 2175,  loss: 0.21637722849845886\n",
      "Batch 2180,  loss: 0.19611711502075196\n",
      "Batch 2185,  loss: 0.18486025631427766\n",
      "Batch 2190,  loss: 0.16575819849967957\n",
      "Batch 2195,  loss: 0.20819445848464965\n",
      "Batch 2200,  loss: 0.2009807363152504\n",
      "Batch 2205,  loss: 0.16832008063793183\n",
      "Batch 2210,  loss: 0.17438601851463317\n",
      "Batch 2215,  loss: 0.174557164311409\n",
      "Batch 2220,  loss: 0.2283947706222534\n",
      "Batch 2225,  loss: 0.23055908977985382\n",
      "Batch 2230,  loss: 0.18266534805297852\n",
      "Batch 2235,  loss: 0.19553641080856324\n",
      "Batch 2240,  loss: 0.25172044038772584\n",
      "Batch 2245,  loss: 0.15361520946025847\n",
      "Batch 2250,  loss: 0.1839648425579071\n",
      "Batch 2255,  loss: 0.19354299902915956\n",
      "Batch 2260,  loss: 0.24080257415771483\n",
      "Batch 2265,  loss: 0.18573883771896363\n",
      "Batch 2270,  loss: 0.15431496649980544\n",
      "Batch 2275,  loss: 0.14752072095870972\n",
      "Batch 2280,  loss: 0.13027148842811584\n",
      "Batch 2285,  loss: 0.16031647920608522\n",
      "Batch 2290,  loss: 0.17684333622455597\n",
      "Batch 2295,  loss: 0.1512869715690613\n",
      "Batch 2300,  loss: 0.19071345627307892\n",
      "Batch 2305,  loss: 0.1552590847015381\n",
      "Batch 2310,  loss: 0.15478623211383818\n",
      "Batch 2315,  loss: 0.14159636199474335\n",
      "Batch 2320,  loss: 0.19397374391555786\n",
      "Batch 2325,  loss: 0.12791628539562225\n",
      "Batch 2330,  loss: 0.14484156668186188\n",
      "Batch 2335,  loss: 0.17691931426525115\n",
      "Batch 2340,  loss: 0.16744644790887833\n",
      "Batch 2345,  loss: 0.18006874322891236\n",
      "Batch 2350,  loss: 0.2293030798435211\n",
      "Batch 2355,  loss: 0.16852351129055024\n",
      "Batch 2360,  loss: 0.1250418394804001\n",
      "Batch 2365,  loss: 0.14319822192192078\n",
      "Batch 2370,  loss: 0.2077322095632553\n",
      "Batch 2375,  loss: 0.19026907980442048\n",
      "Batch 2380,  loss: 0.16181905567646027\n",
      "Batch 2385,  loss: 0.19521737694740296\n",
      "Batch 2390,  loss: 0.14874030500650406\n",
      "Batch 2395,  loss: 0.11988604664802552\n",
      "Batch 2400,  loss: 0.17761709690093994\n",
      "Batch 2405,  loss: 0.15760028958320618\n",
      "Batch 2410,  loss: 0.1539863795042038\n",
      "Batch 2415,  loss: 0.14279988706111907\n",
      "Batch 2420,  loss: 0.18578455746173858\n",
      "Batch 2425,  loss: 0.1918739229440689\n",
      "Batch 2430,  loss: 0.14804547280073166\n",
      "Batch 2435,  loss: 0.16677665263414382\n",
      "Batch 2440,  loss: 0.1697876513004303\n",
      "Batch 2445,  loss: 0.17300551235675812\n",
      "Batch 2450,  loss: 0.17593312561511992\n",
      "Batch 2455,  loss: 0.14720627367496492\n",
      "Batch 2460,  loss: 0.1704319089651108\n",
      "Batch 2465,  loss: 0.12840030789375306\n",
      "Batch 2470,  loss: 0.1974142700433731\n",
      "Batch 2475,  loss: 0.23866347074508668\n",
      "Batch 2480,  loss: 0.19251919984817506\n",
      "Batch 2485,  loss: 0.1840284138917923\n",
      "Batch 2490,  loss: 0.16712902188301088\n",
      "Batch 2495,  loss: 0.16746949255466462\n",
      "Batch 2500,  loss: 0.17446371912956238\n",
      "Batch 2505,  loss: 0.19186957478523253\n",
      "Batch 2510,  loss: 0.17283571511507034\n",
      "Batch 2515,  loss: 0.17551021575927733\n",
      "Batch 2520,  loss: 0.22631718814373017\n",
      "Batch 2525,  loss: 0.15484445691108703\n",
      "Batch 2530,  loss: 0.18646342009305955\n",
      "Batch 2535,  loss: 0.17938878685235976\n",
      "Batch 2540,  loss: 0.15334367156028747\n",
      "Batch 2545,  loss: 0.16270793080329896\n",
      "Batch 2550,  loss: 0.17938470244407653\n",
      "Batch 2555,  loss: 0.1411446750164032\n",
      "Batch 2560,  loss: 0.1836351990699768\n",
      "Batch 2565,  loss: 0.16586515605449675\n",
      "Batch 2570,  loss: 0.11947801113128662\n",
      "Batch 2575,  loss: 0.18402500152587892\n",
      "Batch 2580,  loss: 0.1644641190767288\n",
      "Batch 2585,  loss: 0.14780595004558564\n",
      "Batch 2590,  loss: 0.16635884642601012\n",
      "Batch 2595,  loss: 0.17200713455677033\n",
      "Batch 2600,  loss: 0.16193414181470872\n",
      "Batch 2605,  loss: 0.15226098150014877\n",
      "Batch 2610,  loss: 0.18530917763710023\n",
      "Batch 2615,  loss: 0.17255623191595076\n",
      "Batch 2620,  loss: 0.24930243492126464\n",
      "Batch 2625,  loss: 0.13799485862255095\n",
      "Batch 2630,  loss: 0.23539021015167236\n",
      "Batch 2635,  loss: 0.15999385565519333\n",
      "Batch 2640,  loss: 0.15041631162166597\n",
      "Batch 2645,  loss: 0.17943300008773805\n",
      "Batch 2650,  loss: 0.16335899233818055\n",
      "Batch 2655,  loss: 0.19852475821971893\n",
      "Batch 2660,  loss: 0.16916981637477874\n",
      "Batch 2665,  loss: 0.13770895153284074\n",
      "Batch 2670,  loss: 0.13506733477115632\n",
      "Batch 2675,  loss: 0.15505203008651733\n",
      "Batch 2680,  loss: 0.1508308917284012\n",
      "Batch 2685,  loss: 0.155085289478302\n",
      "Batch 2690,  loss: 0.1475171387195587\n",
      "Batch 2695,  loss: 0.1792699784040451\n",
      "Batch 2700,  loss: 0.14556460231542587\n",
      "Batch 2705,  loss: 0.18757632970809937\n",
      "Batch 2710,  loss: 0.19091725945472718\n",
      "Batch 2715,  loss: 0.178661772608757\n",
      "Batch 2720,  loss: 0.19443272948265075\n",
      "Batch 2725,  loss: 0.18191588819026946\n",
      "Batch 2730,  loss: 0.12245836853981018\n",
      "Batch 2735,  loss: 0.18641234040260315\n",
      "Batch 2740,  loss: 0.15593688189983368\n",
      "Batch 2745,  loss: 0.14996798783540727\n",
      "Batch 2750,  loss: 0.16470858007669448\n",
      "Batch 2755,  loss: 0.171147945523262\n",
      "Batch 2760,  loss: 0.13395911753177642\n",
      "Batch 2765,  loss: 0.20008100271224977\n",
      "Batch 2770,  loss: 0.1795497715473175\n",
      "LOSS train 0.1795497715473175. Validation loss: 0.16686389129263934 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 19:\n",
      "Batch 5,  loss: 0.21641216427087784\n",
      "Batch 10,  loss: 0.21270522624254226\n",
      "Batch 15,  loss: 0.17940581291913987\n",
      "Batch 20,  loss: 0.1804560825228691\n",
      "Batch 25,  loss: 0.20652461051940918\n",
      "Batch 30,  loss: 0.18163211941719054\n",
      "Batch 35,  loss: 0.15122487694025039\n",
      "Batch 40,  loss: 0.19456364214420319\n",
      "Batch 45,  loss: 0.16976408362388612\n",
      "Batch 50,  loss: 0.16897776126861572\n",
      "Batch 55,  loss: 0.19845774471759797\n",
      "Batch 60,  loss: 0.12449822127819062\n",
      "Batch 65,  loss: 0.14650557935237885\n",
      "Batch 70,  loss: 0.15076266825199128\n",
      "Batch 75,  loss: 0.18571489155292512\n",
      "Batch 80,  loss: 0.14885919988155366\n",
      "Batch 85,  loss: 0.16584791094064713\n",
      "Batch 90,  loss: 0.16876181960105896\n",
      "Batch 95,  loss: 0.1771872967481613\n",
      "Batch 100,  loss: 0.1898756057024002\n",
      "Batch 105,  loss: 0.18437444418668747\n",
      "Batch 110,  loss: 0.2030368596315384\n",
      "Batch 115,  loss: 0.20830931961536409\n",
      "Batch 120,  loss: 0.14058952033519745\n",
      "Batch 125,  loss: 0.18716372549533844\n",
      "Batch 130,  loss: 0.12605027258396148\n",
      "Batch 135,  loss: 0.2015537679195404\n",
      "Batch 140,  loss: 0.1840946078300476\n",
      "Batch 145,  loss: 0.18897743821144103\n",
      "Batch 150,  loss: 0.2247324436903\n",
      "Batch 155,  loss: 0.16187156736850739\n",
      "Batch 160,  loss: 0.21318225264549256\n",
      "Batch 165,  loss: 0.1757625788450241\n",
      "Batch 170,  loss: 0.1798834189772606\n",
      "Batch 175,  loss: 0.1286294773221016\n",
      "Batch 180,  loss: 0.15237500965595246\n",
      "Batch 185,  loss: 0.1458882659673691\n",
      "Batch 190,  loss: 0.14232825636863708\n",
      "Batch 195,  loss: 0.15109143704175948\n",
      "Batch 200,  loss: 0.15260535776615142\n",
      "Batch 205,  loss: 0.1757422298192978\n",
      "Batch 210,  loss: 0.1422579914331436\n",
      "Batch 215,  loss: 0.18756809681653977\n",
      "Batch 220,  loss: 0.19060854166746138\n",
      "Batch 225,  loss: 0.17457000613212587\n",
      "Batch 230,  loss: 0.1905508428812027\n",
      "Batch 235,  loss: 0.1591326966881752\n",
      "Batch 240,  loss: 0.14824663400650023\n",
      "Batch 245,  loss: 0.1413791447877884\n",
      "Batch 250,  loss: 0.16166381537914276\n",
      "Batch 255,  loss: 0.1591905489563942\n",
      "Batch 260,  loss: 0.13543673753738403\n",
      "Batch 265,  loss: 0.13245408087968827\n",
      "Batch 270,  loss: 0.17993074059486389\n",
      "Batch 275,  loss: 0.1324163168668747\n",
      "Batch 280,  loss: 0.17919971346855162\n",
      "Batch 285,  loss: 0.15905336439609527\n",
      "Batch 290,  loss: 0.1694045513868332\n",
      "Batch 295,  loss: 0.205383238196373\n",
      "Batch 300,  loss: 0.176990108191967\n",
      "Batch 305,  loss: 0.15907403379678725\n",
      "Batch 310,  loss: 0.15213632583618164\n",
      "Batch 315,  loss: 0.16942943930625914\n",
      "Batch 320,  loss: 0.23216392993927001\n",
      "Batch 325,  loss: 0.13901186883449554\n",
      "Batch 330,  loss: 0.17836568951606752\n",
      "Batch 335,  loss: 0.16245157420635223\n",
      "Batch 340,  loss: 0.13548892587423325\n",
      "Batch 345,  loss: 0.17690280377864837\n",
      "Batch 350,  loss: 0.15407320559024812\n",
      "Batch 355,  loss: 0.12172516584396362\n",
      "Batch 360,  loss: 0.17585214972496033\n",
      "Batch 365,  loss: 0.1640646919608116\n",
      "Batch 370,  loss: 0.1799578458070755\n",
      "Batch 375,  loss: 0.1599822074174881\n",
      "Batch 380,  loss: 0.1873968780040741\n",
      "Batch 385,  loss: 0.19816286563873292\n",
      "Batch 390,  loss: 0.17566996514797212\n",
      "Batch 395,  loss: 0.15826793909072875\n",
      "Batch 400,  loss: 0.1756690427660942\n",
      "Batch 405,  loss: 0.1454707533121109\n",
      "Batch 410,  loss: 0.21161620318889618\n",
      "Batch 415,  loss: 0.20009881407022476\n",
      "Batch 420,  loss: 0.16676820814609528\n",
      "Batch 425,  loss: 0.17583001852035524\n",
      "Batch 430,  loss: 0.1464875489473343\n",
      "Batch 435,  loss: 0.15582308769226075\n",
      "Batch 440,  loss: 0.19849941432476043\n",
      "Batch 445,  loss: 0.17935972511768342\n",
      "Batch 450,  loss: 0.13921629190444945\n",
      "Batch 455,  loss: 0.23247204422950746\n",
      "Batch 460,  loss: 0.166191703081131\n",
      "Batch 465,  loss: 0.1224213570356369\n",
      "Batch 470,  loss: 0.15626788437366484\n",
      "Batch 475,  loss: 0.17031277269124984\n",
      "Batch 480,  loss: 0.19530733674764633\n",
      "Batch 485,  loss: 0.16765012294054032\n",
      "Batch 490,  loss: 0.1675458461046219\n",
      "Batch 495,  loss: 0.2178643137216568\n",
      "Batch 500,  loss: 0.18153197765350343\n",
      "Batch 505,  loss: 0.15753548145294188\n",
      "Batch 510,  loss: 0.15917703211307527\n",
      "Batch 515,  loss: 0.1481156289577484\n",
      "Batch 520,  loss: 0.16975927352905273\n",
      "Batch 525,  loss: 0.14801816940307616\n",
      "Batch 530,  loss: 0.1668435126543045\n",
      "Batch 535,  loss: 0.15435884594917298\n",
      "Batch 540,  loss: 0.13645191192626954\n",
      "Batch 545,  loss: 0.19966570138931275\n",
      "Batch 550,  loss: 0.1563822954893112\n",
      "Batch 555,  loss: 0.18221558928489684\n",
      "Batch 560,  loss: 0.1594369739294052\n",
      "Batch 565,  loss: 0.21879065036773682\n",
      "Batch 570,  loss: 0.1746375858783722\n",
      "Batch 575,  loss: 0.13801372796297073\n",
      "Batch 580,  loss: 0.1743822231888771\n",
      "Batch 585,  loss: 0.14125990569591523\n",
      "Batch 590,  loss: 0.16455289125442504\n",
      "Batch 595,  loss: 0.1751156508922577\n",
      "Batch 600,  loss: 0.14216588139533998\n",
      "Batch 605,  loss: 0.18255559206008912\n",
      "Batch 610,  loss: 0.17126708030700682\n",
      "Batch 615,  loss: 0.1843679815530777\n",
      "Batch 620,  loss: 0.17075753211975098\n",
      "Batch 625,  loss: 0.15634064972400666\n",
      "Batch 630,  loss: 0.1904384523630142\n",
      "Batch 635,  loss: 0.19624877274036406\n",
      "Batch 640,  loss: 0.17781513929367065\n",
      "Batch 645,  loss: 0.17529054284095763\n",
      "Batch 650,  loss: 0.13994928300380707\n",
      "Batch 655,  loss: 0.17212574779987336\n",
      "Batch 660,  loss: 0.1788572996854782\n",
      "Batch 665,  loss: 0.15020815432071685\n",
      "Batch 670,  loss: 0.204660964012146\n",
      "Batch 675,  loss: 0.19233000427484512\n",
      "Batch 680,  loss: 0.17134890854358673\n",
      "Batch 685,  loss: 0.2124800056219101\n",
      "Batch 690,  loss: 0.17651002407073973\n",
      "Batch 695,  loss: 0.14938725978136064\n",
      "Batch 700,  loss: 0.1915499597787857\n",
      "Batch 705,  loss: 0.25380312502384184\n",
      "Batch 710,  loss: 0.14948179125785827\n",
      "Batch 715,  loss: 0.20350025445222855\n",
      "Batch 720,  loss: 0.17706723511219025\n",
      "Batch 725,  loss: 0.16655293554067613\n",
      "Batch 730,  loss: 0.23927558958530426\n",
      "Batch 735,  loss: 0.22368883192539216\n",
      "Batch 740,  loss: 0.15038199126720428\n",
      "Batch 745,  loss: 0.1705583930015564\n",
      "Batch 750,  loss: 0.19265887141227722\n",
      "Batch 755,  loss: 0.17005324363708496\n",
      "Batch 760,  loss: 0.16022713482379913\n",
      "Batch 765,  loss: 0.20217209458351135\n",
      "Batch 770,  loss: 0.16650405377149582\n",
      "Batch 775,  loss: 0.15685506612062455\n",
      "Batch 780,  loss: 0.14931101053953172\n",
      "Batch 785,  loss: 0.14634040892124175\n",
      "Batch 790,  loss: 0.12608897984027861\n",
      "Batch 795,  loss: 0.1611540883779526\n",
      "Batch 800,  loss: 0.18525383919477462\n",
      "Batch 805,  loss: 0.15140887200832367\n",
      "Batch 810,  loss: 0.18895926028490068\n",
      "Batch 815,  loss: 0.20442264676094055\n",
      "Batch 820,  loss: 0.1773802876472473\n",
      "Batch 825,  loss: 0.19413978308439256\n",
      "Batch 830,  loss: 0.18889296650886536\n",
      "Batch 835,  loss: 0.17940460741519929\n",
      "Batch 840,  loss: 0.17228003442287446\n",
      "Batch 845,  loss: 0.17497336864471436\n",
      "Batch 850,  loss: 0.19844075441360473\n",
      "Batch 855,  loss: 0.14177675247192384\n",
      "Batch 860,  loss: 0.17784058749675752\n",
      "Batch 865,  loss: 0.18499949276447297\n",
      "Batch 870,  loss: 0.13821687996387483\n",
      "Batch 875,  loss: 0.14690787941217423\n",
      "Batch 880,  loss: 0.20207489430904388\n",
      "Batch 885,  loss: 0.20626036524772645\n",
      "Batch 890,  loss: 0.19546101689338685\n",
      "Batch 895,  loss: 0.1909219115972519\n",
      "Batch 900,  loss: 0.17195065468549728\n",
      "Batch 905,  loss: 0.17441100776195526\n",
      "Batch 910,  loss: 0.13694462180137634\n",
      "Batch 915,  loss: 0.2071049392223358\n",
      "Batch 920,  loss: 0.14341916739940644\n",
      "Batch 925,  loss: 0.22470256984233855\n",
      "Batch 930,  loss: 0.1683310389518738\n",
      "Batch 935,  loss: 0.1797281950712204\n",
      "Batch 940,  loss: 0.22001957297325134\n",
      "Batch 945,  loss: 0.15629417896270753\n",
      "Batch 950,  loss: 0.14401667416095734\n",
      "Batch 955,  loss: 0.1795550435781479\n",
      "Batch 960,  loss: 0.1494166761636734\n",
      "Batch 965,  loss: 0.1630365028977394\n",
      "Batch 970,  loss: 0.16451883614063262\n",
      "Batch 975,  loss: 0.15041855126619338\n",
      "Batch 980,  loss: 0.15931584537029267\n",
      "Batch 985,  loss: 0.14589348137378694\n",
      "Batch 990,  loss: 0.18853312730789185\n",
      "Batch 995,  loss: 0.16916435360908508\n",
      "Batch 1000,  loss: 0.1636892229318619\n",
      "Batch 1005,  loss: 0.17115130722522737\n",
      "Batch 1010,  loss: 0.1700306549668312\n",
      "Batch 1015,  loss: 0.17151883095502854\n",
      "Batch 1020,  loss: 0.16797128915786744\n",
      "Batch 1025,  loss: 0.15070367902517318\n",
      "Batch 1030,  loss: 0.1700459435582161\n",
      "Batch 1035,  loss: 0.17557432651519775\n",
      "Batch 1040,  loss: 0.24919612407684327\n",
      "Batch 1045,  loss: 0.12548168897628784\n",
      "Batch 1050,  loss: 0.18338948488235474\n",
      "Batch 1055,  loss: 0.1650862604379654\n",
      "Batch 1060,  loss: 0.15448021590709687\n",
      "Batch 1065,  loss: 0.19150867760181428\n",
      "Batch 1070,  loss: 0.13857850581407546\n",
      "Batch 1075,  loss: 0.15698860287666322\n",
      "Batch 1080,  loss: 0.16585947573184967\n",
      "Batch 1085,  loss: 0.1780272662639618\n",
      "Batch 1090,  loss: 0.20182740092277526\n",
      "Batch 1095,  loss: 0.1500403493642807\n",
      "Batch 1100,  loss: 0.16496811658143998\n",
      "Batch 1105,  loss: 0.21272721290588378\n",
      "Batch 1110,  loss: 0.21686356365680695\n",
      "Batch 1115,  loss: 0.1815275490283966\n",
      "Batch 1120,  loss: 0.16988151967525483\n",
      "Batch 1125,  loss: 0.17660488486289977\n",
      "Batch 1130,  loss: 0.16928322613239288\n",
      "Batch 1135,  loss: 0.1593090832233429\n",
      "Batch 1140,  loss: 0.25313117504119875\n",
      "Batch 1145,  loss: 0.22033447921276092\n",
      "Batch 1150,  loss: 0.1617618277668953\n",
      "Batch 1155,  loss: 0.1809931591153145\n",
      "Batch 1160,  loss: 0.1980684995651245\n",
      "Batch 1165,  loss: 0.13227662146091462\n",
      "Batch 1170,  loss: 0.19576771855354308\n",
      "Batch 1175,  loss: 0.18298116326332092\n",
      "Batch 1180,  loss: 0.15320539474487305\n",
      "Batch 1185,  loss: 0.153726527094841\n",
      "Batch 1190,  loss: 0.231485116481781\n",
      "Batch 1195,  loss: 0.1651249796152115\n",
      "Batch 1200,  loss: 0.15489615201950074\n",
      "Batch 1205,  loss: 0.1678536206483841\n",
      "Batch 1210,  loss: 0.15642265677452089\n",
      "Batch 1215,  loss: 0.14480268359184265\n",
      "Batch 1220,  loss: 0.19192614555358886\n",
      "Batch 1225,  loss: 0.14561784863471985\n",
      "Batch 1230,  loss: 0.1355367824435234\n",
      "Batch 1235,  loss: 0.1504376173019409\n",
      "Batch 1240,  loss: 0.14947321265935898\n",
      "Batch 1245,  loss: 0.15515224784612655\n",
      "Batch 1250,  loss: 0.14188268929719924\n",
      "Batch 1255,  loss: 0.14111080169677734\n",
      "Batch 1260,  loss: 0.15134216248989105\n",
      "Batch 1265,  loss: 0.1703587979078293\n",
      "Batch 1270,  loss: 0.13879483938217163\n",
      "Batch 1275,  loss: 0.16908083260059356\n",
      "Batch 1280,  loss: 0.1506419599056244\n",
      "Batch 1285,  loss: 0.1690148890018463\n",
      "Batch 1290,  loss: 0.1815885066986084\n",
      "Batch 1295,  loss: 0.16854010224342347\n",
      "Batch 1300,  loss: 0.17280230820178985\n",
      "Batch 1305,  loss: 0.19456686824560165\n",
      "Batch 1310,  loss: 0.21332298815250397\n",
      "Batch 1315,  loss: 0.2040899306535721\n",
      "Batch 1320,  loss: 0.20171457827091216\n",
      "Batch 1325,  loss: 0.14633050560951233\n",
      "Batch 1330,  loss: 0.15160728693008424\n",
      "Batch 1335,  loss: 0.16502247750759125\n",
      "Batch 1340,  loss: 0.15735458731651306\n",
      "Batch 1345,  loss: 0.16735986471176148\n",
      "Batch 1350,  loss: 0.13265036046504974\n",
      "Batch 1355,  loss: 0.21027892231941223\n",
      "Batch 1360,  loss: 0.19021278917789458\n",
      "Batch 1365,  loss: 0.16596194505691528\n",
      "Batch 1370,  loss: 0.2150888115167618\n",
      "Batch 1375,  loss: 0.12551773190498353\n",
      "Batch 1380,  loss: 0.19498027265071868\n",
      "Batch 1385,  loss: 0.15652463734149932\n",
      "Batch 1390,  loss: 0.18177397400140763\n",
      "Batch 1395,  loss: 0.1811019241809845\n",
      "Batch 1400,  loss: 0.19638836085796357\n",
      "Batch 1405,  loss: 0.18496030271053315\n",
      "Batch 1410,  loss: 0.17464927434921265\n",
      "Batch 1415,  loss: 0.1421806365251541\n",
      "Batch 1420,  loss: 0.25232931673526765\n",
      "Batch 1425,  loss: 0.1990090161561966\n",
      "Batch 1430,  loss: 0.14160102754831314\n",
      "Batch 1435,  loss: 0.1751389116048813\n",
      "Batch 1440,  loss: 0.16588285863399505\n",
      "Batch 1445,  loss: 0.17699458599090576\n",
      "Batch 1450,  loss: 0.2156514436006546\n",
      "Batch 1455,  loss: 0.2058826729655266\n",
      "Batch 1460,  loss: 0.17949092090129853\n",
      "Batch 1465,  loss: 0.1757691591978073\n",
      "Batch 1470,  loss: 0.20407373905181886\n",
      "Batch 1475,  loss: 0.17530068457126619\n",
      "Batch 1480,  loss: 0.12888670861721038\n",
      "Batch 1485,  loss: 0.16536483466625213\n",
      "Batch 1490,  loss: 0.14021424651145936\n",
      "Batch 1495,  loss: 0.17703697681427003\n",
      "Batch 1500,  loss: 0.1667339563369751\n",
      "Batch 1505,  loss: 0.21450853645801543\n",
      "Batch 1510,  loss: 0.19006020724773406\n",
      "Batch 1515,  loss: 0.17455187886953355\n",
      "Batch 1520,  loss: 0.1812162920832634\n",
      "Batch 1525,  loss: 0.17964657098054887\n",
      "Batch 1530,  loss: 0.17794403433799744\n",
      "Batch 1535,  loss: 0.15543718934059142\n",
      "Batch 1540,  loss: 0.16530290246009827\n",
      "Batch 1545,  loss: 0.16214731335639954\n",
      "Batch 1550,  loss: 0.20376031696796418\n",
      "Batch 1555,  loss: 0.17337960749864578\n",
      "Batch 1560,  loss: 0.15468603670597075\n",
      "Batch 1565,  loss: 0.16117033511400222\n",
      "Batch 1570,  loss: 0.1516784220933914\n",
      "Batch 1575,  loss: 0.13567904531955718\n",
      "Batch 1580,  loss: 0.20243612825870513\n",
      "Batch 1585,  loss: 0.1756158009171486\n",
      "Batch 1590,  loss: 0.20115693509578705\n",
      "Batch 1595,  loss: 0.17598387598991394\n",
      "Batch 1600,  loss: 0.1425352931022644\n",
      "Batch 1605,  loss: 0.1592527449131012\n",
      "Batch 1610,  loss: 0.13812150359153746\n",
      "Batch 1615,  loss: 0.1830274671316147\n",
      "Batch 1620,  loss: 0.12989941835403443\n",
      "Batch 1625,  loss: 0.16695918440818786\n",
      "Batch 1630,  loss: 0.16332228034734725\n",
      "Batch 1635,  loss: 0.15199901759624482\n",
      "Batch 1640,  loss: 0.20224908292293547\n",
      "Batch 1645,  loss: 0.17558524906635284\n",
      "Batch 1650,  loss: 0.15150286853313447\n",
      "Batch 1655,  loss: 0.20938446521759033\n",
      "Batch 1660,  loss: 0.17727765887975694\n",
      "Batch 1665,  loss: 0.19086897671222686\n",
      "Batch 1670,  loss: 0.16656690537929536\n",
      "Batch 1675,  loss: 0.24192289710044862\n",
      "Batch 1680,  loss: 0.16614651530981064\n",
      "Batch 1685,  loss: 0.18187157213687896\n",
      "Batch 1690,  loss: 0.18673163056373596\n",
      "Batch 1695,  loss: 0.15679043531417847\n",
      "Batch 1700,  loss: 0.20795686095952987\n",
      "Batch 1705,  loss: 0.24540510177612304\n",
      "Batch 1710,  loss: 0.19042885005474092\n",
      "Batch 1715,  loss: 0.19308814406394958\n",
      "Batch 1720,  loss: 0.17589212357997894\n",
      "Batch 1725,  loss: 0.17875868678092957\n",
      "Batch 1730,  loss: 0.18232218623161317\n",
      "Batch 1735,  loss: 0.1534888908267021\n",
      "Batch 1740,  loss: 0.18387105613946914\n",
      "Batch 1745,  loss: 0.18450243771076202\n",
      "Batch 1750,  loss: 0.14773397147655487\n",
      "Batch 1755,  loss: 0.18150440454483033\n",
      "Batch 1760,  loss: 0.14318918883800508\n",
      "Batch 1765,  loss: 0.160796557366848\n",
      "Batch 1770,  loss: 0.17690480947494508\n",
      "Batch 1775,  loss: 0.15595348477363585\n",
      "Batch 1780,  loss: 0.1428369700908661\n",
      "Batch 1785,  loss: 0.16269921660423278\n",
      "Batch 1790,  loss: 0.2008159950375557\n",
      "Batch 1795,  loss: 0.1762459695339203\n",
      "Batch 1800,  loss: 0.18071656823158264\n",
      "Batch 1805,  loss: 0.17966101169586182\n",
      "Batch 1810,  loss: 0.18326470255851746\n",
      "Batch 1815,  loss: 0.1849078804254532\n",
      "Batch 1820,  loss: 0.1540567696094513\n",
      "Batch 1825,  loss: 0.14079252779483795\n",
      "Batch 1830,  loss: 0.150750070810318\n",
      "Batch 1835,  loss: 0.16774440705776214\n",
      "Batch 1840,  loss: 0.21001358032226564\n",
      "Batch 1845,  loss: 0.20608406960964204\n",
      "Batch 1850,  loss: 0.1589356392621994\n",
      "Batch 1855,  loss: 0.11404595226049423\n",
      "Batch 1860,  loss: 0.1894838899374008\n",
      "Batch 1865,  loss: 0.1680736869573593\n",
      "Batch 1870,  loss: 0.1917004704475403\n",
      "Batch 1875,  loss: 0.1753520131111145\n",
      "Batch 1880,  loss: 0.16359293460845947\n",
      "Batch 1885,  loss: 0.15719854831695557\n",
      "Batch 1890,  loss: 0.1394353598356247\n",
      "Batch 1895,  loss: 0.11838275790214539\n",
      "Batch 1900,  loss: 0.1844463050365448\n",
      "Batch 1905,  loss: 0.14753677994012832\n",
      "Batch 1910,  loss: 0.17011482119560242\n",
      "Batch 1915,  loss: 0.18094628751277925\n",
      "Batch 1920,  loss: 0.16869941353797913\n",
      "Batch 1925,  loss: 0.17338240295648574\n",
      "Batch 1930,  loss: 0.19255958497524261\n",
      "Batch 1935,  loss: 0.15932826101779937\n",
      "Batch 1940,  loss: 0.1392581731081009\n",
      "Batch 1945,  loss: 0.14476175904273986\n",
      "Batch 1950,  loss: 0.19988672137260438\n",
      "Batch 1955,  loss: 0.19952842891216277\n",
      "Batch 1960,  loss: 0.18922645449638367\n",
      "Batch 1965,  loss: 0.17628541588783264\n",
      "Batch 1970,  loss: 0.13034123331308364\n",
      "Batch 1975,  loss: 0.1860979601740837\n",
      "Batch 1980,  loss: 0.19110090732574464\n",
      "Batch 1985,  loss: 0.1442887604236603\n",
      "Batch 1990,  loss: 0.15749874860048294\n",
      "Batch 1995,  loss: 0.18630716800689698\n",
      "Batch 2000,  loss: 0.18775021135807038\n",
      "Batch 2005,  loss: 0.18386618196964263\n",
      "Batch 2010,  loss: 0.1494506776332855\n",
      "Batch 2015,  loss: 0.14564842432737352\n",
      "Batch 2020,  loss: 0.1504916489124298\n",
      "Batch 2025,  loss: 0.20053194165229798\n",
      "Batch 2030,  loss: 0.1719195932149887\n",
      "Batch 2035,  loss: 0.16347275376319886\n",
      "Batch 2040,  loss: 0.1611461490392685\n",
      "Batch 2045,  loss: 0.1805170774459839\n",
      "Batch 2050,  loss: 0.160418501496315\n",
      "Batch 2055,  loss: 0.14152103364467622\n",
      "Batch 2060,  loss: 0.1811741828918457\n",
      "Batch 2065,  loss: 0.23410137444734574\n",
      "Batch 2070,  loss: 0.16112883388996124\n",
      "Batch 2075,  loss: 0.15956251472234725\n",
      "Batch 2080,  loss: 0.13949162662029266\n",
      "Batch 2085,  loss: 0.15724026411771774\n",
      "Batch 2090,  loss: 0.17898877263069152\n",
      "Batch 2095,  loss: 0.16156858652830125\n",
      "Batch 2100,  loss: 0.1911207139492035\n",
      "Batch 2105,  loss: 0.17159971296787263\n",
      "Batch 2110,  loss: 0.1662647619843483\n",
      "Batch 2115,  loss: 0.15445881485939025\n",
      "Batch 2120,  loss: 0.19283553063869477\n",
      "Batch 2125,  loss: 0.15256282389163972\n",
      "Batch 2130,  loss: 0.15045225173234938\n",
      "Batch 2135,  loss: 0.16544950604438782\n",
      "Batch 2140,  loss: 0.1583400160074234\n",
      "Batch 2145,  loss: 0.15138427615165712\n",
      "Batch 2150,  loss: 0.18737855106592177\n",
      "Batch 2155,  loss: 0.2039890855550766\n",
      "Batch 2160,  loss: 0.2343256562948227\n",
      "Batch 2165,  loss: 0.1730799615383148\n",
      "Batch 2170,  loss: 0.16737951040267945\n",
      "Batch 2175,  loss: 0.18616905212402343\n",
      "Batch 2180,  loss: 0.18097715675830842\n",
      "Batch 2185,  loss: 0.15773779898881912\n",
      "Batch 2190,  loss: 0.2097413033246994\n",
      "Batch 2195,  loss: 0.11938835382461548\n",
      "Batch 2200,  loss: 0.1759905159473419\n",
      "Batch 2205,  loss: 0.20668874979019164\n",
      "Batch 2210,  loss: 0.1974654972553253\n",
      "Batch 2215,  loss: 0.17749909907579423\n",
      "Batch 2220,  loss: 0.12475906610488892\n",
      "Batch 2225,  loss: 0.19216777086257936\n",
      "Batch 2230,  loss: 0.22709205746650696\n",
      "Batch 2235,  loss: 0.17459233105182648\n",
      "Batch 2240,  loss: 0.1782112181186676\n",
      "Batch 2245,  loss: 0.13147099316120148\n",
      "Batch 2250,  loss: 0.1401897192001343\n",
      "Batch 2255,  loss: 0.17038373351097108\n",
      "Batch 2260,  loss: 0.18356038630008698\n",
      "Batch 2265,  loss: 0.18884640336036682\n",
      "Batch 2270,  loss: 0.1739341765642166\n",
      "Batch 2275,  loss: 0.11822818666696548\n",
      "Batch 2280,  loss: 0.18820574581623079\n",
      "Batch 2285,  loss: 0.2372973531484604\n",
      "Batch 2290,  loss: 0.16420809626579286\n",
      "Batch 2295,  loss: 0.17958842366933822\n",
      "Batch 2300,  loss: 0.1910319834947586\n",
      "Batch 2305,  loss: 0.1465184599161148\n",
      "Batch 2310,  loss: 0.15232308804988862\n",
      "Batch 2315,  loss: 0.17760152369737625\n",
      "Batch 2320,  loss: 0.1943627879023552\n",
      "Batch 2325,  loss: 0.15927801728248597\n",
      "Batch 2330,  loss: 0.22207297682762145\n",
      "Batch 2335,  loss: 0.16160788238048554\n",
      "Batch 2340,  loss: 0.17934065759181977\n",
      "Batch 2345,  loss: 0.20500072240829467\n",
      "Batch 2350,  loss: 0.1381093144416809\n",
      "Batch 2355,  loss: 0.1883938044309616\n",
      "Batch 2360,  loss: 0.18688815385103225\n",
      "Batch 2365,  loss: 0.217282634973526\n",
      "Batch 2370,  loss: 0.15051301717758178\n",
      "Batch 2375,  loss: 0.17513245046138765\n",
      "Batch 2380,  loss: 0.1694483757019043\n",
      "Batch 2385,  loss: 0.20004430413246155\n",
      "Batch 2390,  loss: 0.18310255110263823\n",
      "Batch 2395,  loss: 0.18559047281742097\n",
      "Batch 2400,  loss: 0.1274909108877182\n",
      "Batch 2405,  loss: 0.167381888628006\n",
      "Batch 2410,  loss: 0.17668849229812622\n",
      "Batch 2415,  loss: 0.18150450438261032\n",
      "Batch 2420,  loss: 0.17015012502670288\n",
      "Batch 2425,  loss: 0.16349832266569136\n",
      "Batch 2430,  loss: 0.22797201722860336\n",
      "Batch 2435,  loss: 0.17782881557941438\n",
      "Batch 2440,  loss: 0.14290613532066346\n",
      "Batch 2445,  loss: 0.15589962899684906\n",
      "Batch 2450,  loss: 0.18289467692375183\n",
      "Batch 2455,  loss: 0.21001092791557313\n",
      "Batch 2460,  loss: 0.14306317865848542\n",
      "Batch 2465,  loss: 0.12645020186901093\n",
      "Batch 2470,  loss: 0.21651616096496581\n",
      "Batch 2475,  loss: 0.148120154440403\n",
      "Batch 2480,  loss: 0.18277995586395263\n",
      "Batch 2485,  loss: 0.13892751485109328\n",
      "Batch 2490,  loss: 0.1895480751991272\n",
      "Batch 2495,  loss: 0.19967693835496902\n",
      "Batch 2500,  loss: 0.17339395582675934\n",
      "Batch 2505,  loss: 0.17482113987207412\n",
      "Batch 2510,  loss: 0.17162700295448302\n",
      "Batch 2515,  loss: 0.2326503574848175\n",
      "Batch 2520,  loss: 0.19028021693229674\n",
      "Batch 2525,  loss: 0.1349344551563263\n",
      "Batch 2530,  loss: 0.1336922451853752\n",
      "Batch 2535,  loss: 0.177011838555336\n",
      "Batch 2540,  loss: 0.21416075527668\n",
      "Batch 2545,  loss: 0.14893966019153596\n",
      "Batch 2550,  loss: 0.16627439856529236\n",
      "Batch 2555,  loss: 0.24053095281124115\n",
      "Batch 2560,  loss: 0.17225737869739532\n",
      "Batch 2565,  loss: 0.1844438672065735\n",
      "Batch 2570,  loss: 0.17213949263095857\n",
      "Batch 2575,  loss: 0.1533744752407074\n",
      "Batch 2580,  loss: 0.16840187460184097\n",
      "Batch 2585,  loss: 0.20115672945976257\n",
      "Batch 2590,  loss: 0.16076109409332276\n",
      "Batch 2595,  loss: 0.13492845445871354\n",
      "Batch 2600,  loss: 0.17688899040222167\n",
      "Batch 2605,  loss: 0.18985294699668884\n",
      "Batch 2610,  loss: 0.19414424002170563\n",
      "Batch 2615,  loss: 0.17893292903900146\n",
      "Batch 2620,  loss: 0.15369083881378173\n",
      "Batch 2625,  loss: 0.1414755553007126\n",
      "Batch 2630,  loss: 0.14795246869325637\n",
      "Batch 2635,  loss: 0.15758540183305741\n",
      "Batch 2640,  loss: 0.1916935384273529\n",
      "Batch 2645,  loss: 0.17042771279811858\n",
      "Batch 2650,  loss: 0.14731334447860717\n",
      "Batch 2655,  loss: 0.17686749398708343\n",
      "Batch 2660,  loss: 0.1983841836452484\n",
      "Batch 2665,  loss: 0.1484060376882553\n",
      "Batch 2670,  loss: 0.13863804042339326\n",
      "Batch 2675,  loss: 0.15447267889976501\n",
      "Batch 2680,  loss: 0.15519119799137115\n",
      "Batch 2685,  loss: 0.17450851798057557\n",
      "Batch 2690,  loss: 0.21465732157230377\n",
      "Batch 2695,  loss: 0.18862296640872955\n",
      "Batch 2700,  loss: 0.14039247930049897\n",
      "Batch 2705,  loss: 0.15666552931070327\n",
      "Batch 2710,  loss: 0.17327948212623595\n",
      "Batch 2715,  loss: 0.20722075700759887\n",
      "Batch 2720,  loss: 0.16975111067295073\n",
      "Batch 2725,  loss: 0.14860005378723146\n",
      "Batch 2730,  loss: 0.1618153840303421\n",
      "Batch 2735,  loss: 0.20052766799926758\n",
      "Batch 2740,  loss: 0.16152941882610322\n",
      "Batch 2745,  loss: 0.1584938198328018\n",
      "Batch 2750,  loss: 0.16573377549648285\n",
      "Batch 2755,  loss: 0.17972835898399353\n",
      "Batch 2760,  loss: 0.1827334940433502\n",
      "Batch 2765,  loss: 0.1339755803346634\n",
      "Batch 2770,  loss: 0.15957525968551636\n",
      "LOSS train 0.15957525968551636. Validation loss: 0.1659085054381716 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 20:\n",
      "Batch 5,  loss: 0.16257558465003968\n",
      "Batch 10,  loss: 0.2014622688293457\n",
      "Batch 15,  loss: 0.1898236244916916\n",
      "Batch 20,  loss: 0.16525295078754426\n",
      "Batch 25,  loss: 0.13538229763507842\n",
      "Batch 30,  loss: 0.14749657809734346\n",
      "Batch 35,  loss: 0.19599225223064423\n",
      "Batch 40,  loss: 0.19544720649719238\n",
      "Batch 45,  loss: 0.2313726842403412\n",
      "Batch 50,  loss: 0.1504741206765175\n",
      "Batch 55,  loss: 0.15211591124534607\n",
      "Batch 60,  loss: 0.15329329967498778\n",
      "Batch 65,  loss: 0.15018699765205384\n",
      "Batch 70,  loss: 0.1969480484724045\n",
      "Batch 75,  loss: 0.16651330888271332\n",
      "Batch 80,  loss: 0.14878193140029908\n",
      "Batch 85,  loss: 0.1636499285697937\n",
      "Batch 90,  loss: 0.1833073914051056\n",
      "Batch 95,  loss: 0.1421508550643921\n",
      "Batch 100,  loss: 0.16858592480421067\n",
      "Batch 105,  loss: 0.1481352835893631\n",
      "Batch 110,  loss: 0.18473172187805176\n",
      "Batch 115,  loss: 0.19210711419582366\n",
      "Batch 120,  loss: 0.19219217598438262\n",
      "Batch 125,  loss: 0.20236510038375854\n",
      "Batch 130,  loss: 0.19327459186315538\n",
      "Batch 135,  loss: 0.17348724454641343\n",
      "Batch 140,  loss: 0.14645857363939285\n",
      "Batch 145,  loss: 0.1576034426689148\n",
      "Batch 150,  loss: 0.17209005653858184\n",
      "Batch 155,  loss: 0.16497504115104675\n",
      "Batch 160,  loss: 0.17687548100948333\n",
      "Batch 165,  loss: 0.1733219563961029\n",
      "Batch 170,  loss: 0.15568283647298814\n",
      "Batch 175,  loss: 0.14983539581298827\n",
      "Batch 180,  loss: 0.18451609015464782\n",
      "Batch 185,  loss: 0.1662314146757126\n",
      "Batch 190,  loss: 0.2001946747303009\n",
      "Batch 195,  loss: 0.2041858911514282\n",
      "Batch 200,  loss: 0.14689042717218398\n",
      "Batch 205,  loss: 0.18673067837953566\n",
      "Batch 210,  loss: 0.1717577189207077\n",
      "Batch 215,  loss: 0.1842509090900421\n",
      "Batch 220,  loss: 0.1724128931760788\n",
      "Batch 225,  loss: 0.22080055475234986\n",
      "Batch 230,  loss: 0.18085407018661498\n",
      "Batch 235,  loss: 0.20635332465171813\n",
      "Batch 240,  loss: 0.1363112971186638\n",
      "Batch 245,  loss: 0.17678338885307313\n",
      "Batch 250,  loss: 0.17131664752960205\n",
      "Batch 255,  loss: 0.15227468311786652\n",
      "Batch 260,  loss: 0.15943096876144408\n",
      "Batch 265,  loss: 0.15815902948379518\n",
      "Batch 270,  loss: 0.15835598707199097\n",
      "Batch 275,  loss: 0.17566548138856888\n",
      "Batch 280,  loss: 0.13376958668231964\n",
      "Batch 285,  loss: 0.20737614929676057\n",
      "Batch 290,  loss: 0.24981351792812348\n",
      "Batch 295,  loss: 0.14386411160230636\n",
      "Batch 300,  loss: 0.20328312814235688\n",
      "Batch 305,  loss: 0.16780076324939727\n",
      "Batch 310,  loss: 0.2162321150302887\n",
      "Batch 315,  loss: 0.20505529046058654\n",
      "Batch 320,  loss: 0.16684140264987946\n",
      "Batch 325,  loss: 0.16563602685928344\n",
      "Batch 330,  loss: 0.1521553561091423\n",
      "Batch 335,  loss: 0.15429390370845794\n",
      "Batch 340,  loss: 0.1393620789051056\n",
      "Batch 345,  loss: 0.1522922247648239\n",
      "Batch 350,  loss: 0.20405078530311585\n",
      "Batch 355,  loss: 0.19834063798189164\n",
      "Batch 360,  loss: 0.18733726143836976\n",
      "Batch 365,  loss: 0.25495379865169526\n",
      "Batch 370,  loss: 0.1810372531414032\n",
      "Batch 375,  loss: 0.15826852917671203\n",
      "Batch 380,  loss: 0.1717464655637741\n",
      "Batch 385,  loss: 0.15691778361797332\n",
      "Batch 390,  loss: 0.18966963291168212\n",
      "Batch 395,  loss: 0.17559707313776016\n",
      "Batch 400,  loss: 0.1611013799905777\n",
      "Batch 405,  loss: 0.16192234456539153\n",
      "Batch 410,  loss: 0.18169969469308853\n",
      "Batch 415,  loss: 0.15745024681091307\n",
      "Batch 420,  loss: 0.15315211713314056\n",
      "Batch 425,  loss: 0.17132038474082947\n",
      "Batch 430,  loss: 0.16726866364479065\n",
      "Batch 435,  loss: 0.1691458210349083\n",
      "Batch 440,  loss: 0.16936168670654297\n",
      "Batch 445,  loss: 0.1876158148050308\n",
      "Batch 450,  loss: 0.1617383062839508\n",
      "Batch 455,  loss: 0.14749362617731093\n",
      "Batch 460,  loss: 0.13198832869529725\n",
      "Batch 465,  loss: 0.17460630983114242\n",
      "Batch 470,  loss: 0.15826283246278763\n",
      "Batch 475,  loss: 0.17105310559272766\n",
      "Batch 480,  loss: 0.16070803105831147\n",
      "Batch 485,  loss: 0.19418926537036896\n",
      "Batch 490,  loss: 0.20211630463600158\n",
      "Batch 495,  loss: 0.1905500680208206\n",
      "Batch 500,  loss: 0.15868267863988877\n",
      "Batch 505,  loss: 0.1624100089073181\n",
      "Batch 510,  loss: 0.16313101649284362\n",
      "Batch 515,  loss: 0.14646666944026948\n",
      "Batch 520,  loss: 0.14926617443561555\n",
      "Batch 525,  loss: 0.171972593665123\n",
      "Batch 530,  loss: 0.24816786348819733\n",
      "Batch 535,  loss: 0.19111317098140718\n",
      "Batch 540,  loss: 0.152423694729805\n",
      "Batch 545,  loss: 0.14619233310222626\n",
      "Batch 550,  loss: 0.16013869643211365\n",
      "Batch 555,  loss: 0.1868720293045044\n",
      "Batch 560,  loss: 0.15512735843658448\n",
      "Batch 565,  loss: 0.19164025485515596\n",
      "Batch 570,  loss: 0.2887246608734131\n",
      "Batch 575,  loss: 0.17827727198600768\n",
      "Batch 580,  loss: 0.1826496183872223\n",
      "Batch 585,  loss: 0.16588728427886962\n",
      "Batch 590,  loss: 0.16224154233932495\n",
      "Batch 595,  loss: 0.17347003817558287\n",
      "Batch 600,  loss: 0.2294376701116562\n",
      "Batch 605,  loss: 0.1844550520181656\n",
      "Batch 610,  loss: 0.1471084773540497\n",
      "Batch 615,  loss: 0.1598551869392395\n",
      "Batch 620,  loss: 0.1638966679573059\n",
      "Batch 625,  loss: 0.1816756993532181\n",
      "Batch 630,  loss: 0.15633865743875502\n",
      "Batch 635,  loss: 0.20898271203041077\n",
      "Batch 640,  loss: 0.15461345613002778\n",
      "Batch 645,  loss: 0.16760976016521453\n",
      "Batch 650,  loss: 0.14855410307645797\n",
      "Batch 655,  loss: 0.17993415296077728\n",
      "Batch 660,  loss: 0.14828709363937378\n",
      "Batch 665,  loss: 0.18319595158100127\n",
      "Batch 670,  loss: 0.16644413471221925\n",
      "Batch 675,  loss: 0.21387978196144103\n",
      "Batch 680,  loss: 0.16073658764362336\n",
      "Batch 685,  loss: 0.1556982934474945\n",
      "Batch 690,  loss: 0.17286626398563384\n",
      "Batch 695,  loss: 0.14091525822877884\n",
      "Batch 700,  loss: 0.14433110356330872\n",
      "Batch 705,  loss: 0.16672928780317306\n",
      "Batch 710,  loss: 0.15845376998186111\n",
      "Batch 715,  loss: 0.19824141263961792\n",
      "Batch 720,  loss: 0.16608892381191254\n",
      "Batch 725,  loss: 0.190124049782753\n",
      "Batch 730,  loss: 0.12751999795436858\n",
      "Batch 735,  loss: 0.14567969739437103\n",
      "Batch 740,  loss: 0.15926388055086135\n",
      "Batch 745,  loss: 0.12130572199821472\n",
      "Batch 750,  loss: 0.1709655851125717\n",
      "Batch 755,  loss: 0.17609213143587113\n",
      "Batch 760,  loss: 0.2058439552783966\n",
      "Batch 765,  loss: 0.15160281360149383\n",
      "Batch 770,  loss: 0.16148182153701782\n",
      "Batch 775,  loss: 0.15070854127407074\n",
      "Batch 780,  loss: 0.1585708498954773\n",
      "Batch 785,  loss: 0.169877290725708\n",
      "Batch 790,  loss: 0.17722138017416\n",
      "Batch 795,  loss: 0.2046130567789078\n",
      "Batch 800,  loss: 0.2086076870560646\n",
      "Batch 805,  loss: 0.19670692682266236\n",
      "Batch 810,  loss: 0.15823348015546798\n",
      "Batch 815,  loss: 0.1788521885871887\n",
      "Batch 820,  loss: 0.1714714825153351\n",
      "Batch 825,  loss: 0.16485776454210282\n",
      "Batch 830,  loss: 0.1620054453611374\n",
      "Batch 835,  loss: 0.16378603577613832\n",
      "Batch 840,  loss: 0.15744456350803376\n",
      "Batch 845,  loss: 0.15322493016719818\n",
      "Batch 850,  loss: 0.17578685581684111\n",
      "Batch 855,  loss: 0.1379820764064789\n",
      "Batch 860,  loss: 0.14718296974897385\n",
      "Batch 865,  loss: 0.16561562418937684\n",
      "Batch 870,  loss: 0.14095257520675658\n",
      "Batch 875,  loss: 0.16266175955533982\n",
      "Batch 880,  loss: 0.1644149899482727\n",
      "Batch 885,  loss: 0.1968709111213684\n",
      "Batch 890,  loss: 0.1464322179555893\n",
      "Batch 895,  loss: 0.1304265782237053\n",
      "Batch 900,  loss: 0.17074279934167863\n",
      "Batch 905,  loss: 0.17861698269844056\n",
      "Batch 910,  loss: 0.16381973922252654\n",
      "Batch 915,  loss: 0.1536095544695854\n",
      "Batch 920,  loss: 0.17165250182151795\n",
      "Batch 925,  loss: 0.181864595413208\n",
      "Batch 930,  loss: 0.1594746857881546\n",
      "Batch 935,  loss: 0.1770906537771225\n",
      "Batch 940,  loss: 0.17109331637620925\n",
      "Batch 945,  loss: 0.16413194686174393\n",
      "Batch 950,  loss: 0.2121548354625702\n",
      "Batch 955,  loss: 0.15281904935836793\n",
      "Batch 960,  loss: 0.19205842316150665\n",
      "Batch 965,  loss: 0.1862598866224289\n",
      "Batch 970,  loss: 0.14980090260505677\n",
      "Batch 975,  loss: 0.20142728686332703\n",
      "Batch 980,  loss: 0.148106387257576\n",
      "Batch 985,  loss: 0.16707004308700563\n",
      "Batch 990,  loss: 0.14513547271490096\n",
      "Batch 995,  loss: 0.1983938544988632\n",
      "Batch 1000,  loss: 0.1573692098259926\n",
      "Batch 1005,  loss: 0.14941913187503814\n",
      "Batch 1010,  loss: 0.21869518458843232\n",
      "Batch 1015,  loss: 0.1494959384202957\n",
      "Batch 1020,  loss: 0.16720809936523437\n",
      "Batch 1025,  loss: 0.1912837117910385\n",
      "Batch 1030,  loss: 0.18933668583631516\n",
      "Batch 1035,  loss: 0.20886346995830535\n",
      "Batch 1040,  loss: 0.1647248834371567\n",
      "Batch 1045,  loss: 0.13876565992832185\n",
      "Batch 1050,  loss: 0.16138240545988083\n",
      "Batch 1055,  loss: 0.15956589281558992\n",
      "Batch 1060,  loss: 0.14048646986484528\n",
      "Batch 1065,  loss: 0.17940110862255096\n",
      "Batch 1070,  loss: 0.21873475909233092\n",
      "Batch 1075,  loss: 0.1559583842754364\n",
      "Batch 1080,  loss: 0.13800100982189178\n",
      "Batch 1085,  loss: 0.18914845138788222\n",
      "Batch 1090,  loss: 0.2099778950214386\n",
      "Batch 1095,  loss: 0.1856444925069809\n",
      "Batch 1100,  loss: 0.19038815200328826\n",
      "Batch 1105,  loss: 0.1350218713283539\n",
      "Batch 1110,  loss: 0.15180962085723876\n",
      "Batch 1115,  loss: 0.16755273044109345\n",
      "Batch 1120,  loss: 0.19965529143810273\n",
      "Batch 1125,  loss: 0.1881642907857895\n",
      "Batch 1130,  loss: 0.15761846005916597\n",
      "Batch 1135,  loss: 0.1643608421087265\n",
      "Batch 1140,  loss: 0.20267808735370635\n",
      "Batch 1145,  loss: 0.1887042373418808\n",
      "Batch 1150,  loss: 0.15477897226810455\n",
      "Batch 1155,  loss: 0.15634491741657258\n",
      "Batch 1160,  loss: 0.15592082738876342\n",
      "Batch 1165,  loss: 0.16753858029842378\n",
      "Batch 1170,  loss: 0.15757086575031282\n",
      "Batch 1175,  loss: 0.183244925737381\n",
      "Batch 1180,  loss: 0.23117755651473998\n",
      "Batch 1185,  loss: 0.1863079473376274\n",
      "Batch 1190,  loss: 0.18789512813091278\n",
      "Batch 1195,  loss: 0.17790716886520386\n",
      "Batch 1200,  loss: 0.16121673583984375\n",
      "Batch 1205,  loss: 0.1784047693014145\n",
      "Batch 1210,  loss: 0.17766830325126648\n",
      "Batch 1215,  loss: 0.17554117143154144\n",
      "Batch 1220,  loss: 0.16742319464683533\n",
      "Batch 1225,  loss: 0.14333200752735137\n",
      "Batch 1230,  loss: 0.17943825125694274\n",
      "Batch 1235,  loss: 0.23035219311714172\n",
      "Batch 1240,  loss: 0.21206190586090087\n",
      "Batch 1245,  loss: 0.15607552230358124\n",
      "Batch 1250,  loss: 0.14428784251213073\n",
      "Batch 1255,  loss: 0.20608043074607849\n",
      "Batch 1260,  loss: 0.17390563786029817\n",
      "Batch 1265,  loss: 0.1347251534461975\n",
      "Batch 1270,  loss: 0.1791734054684639\n",
      "Batch 1275,  loss: 0.14879602789878846\n",
      "Batch 1280,  loss: 0.18640277087688445\n",
      "Batch 1285,  loss: 0.17879915982484818\n",
      "Batch 1290,  loss: 0.206546813249588\n",
      "Batch 1295,  loss: 0.16578105986118316\n",
      "Batch 1300,  loss: 0.15852585136890412\n",
      "Batch 1305,  loss: 0.14776515662670137\n",
      "Batch 1310,  loss: 0.15158821046352386\n",
      "Batch 1315,  loss: 0.18524520993232726\n",
      "Batch 1320,  loss: 0.146853443980217\n",
      "Batch 1325,  loss: 0.1555759146809578\n",
      "Batch 1330,  loss: 0.1778301328420639\n",
      "Batch 1335,  loss: 0.18529748916625977\n",
      "Batch 1340,  loss: 0.1685411214828491\n",
      "Batch 1345,  loss: 0.18314635753631592\n",
      "Batch 1350,  loss: 0.200936421751976\n",
      "Batch 1355,  loss: 0.1422875329852104\n",
      "Batch 1360,  loss: 0.1735559582710266\n",
      "Batch 1365,  loss: 0.17581128776073457\n",
      "Batch 1370,  loss: 0.19182045757770538\n",
      "Batch 1375,  loss: 0.1928372859954834\n",
      "Batch 1380,  loss: 0.13767094016075135\n",
      "Batch 1385,  loss: 0.15264977812767028\n",
      "Batch 1390,  loss: 0.18977243900299073\n",
      "Batch 1395,  loss: 0.16636627316474914\n",
      "Batch 1400,  loss: 0.1445384293794632\n",
      "Batch 1405,  loss: 0.1533989578485489\n",
      "Batch 1410,  loss: 0.1702224165201187\n",
      "Batch 1415,  loss: 0.17902185916900634\n",
      "Batch 1420,  loss: 0.17335070967674254\n",
      "Batch 1425,  loss: 0.1749395400285721\n",
      "Batch 1430,  loss: 0.14868732094764708\n",
      "Batch 1435,  loss: 0.13859099596738816\n",
      "Batch 1440,  loss: 0.22361265122890472\n",
      "Batch 1445,  loss: 0.16653610169887542\n",
      "Batch 1450,  loss: 0.14843189418315889\n",
      "Batch 1455,  loss: 0.209349924325943\n",
      "Batch 1460,  loss: 0.17596344649791718\n",
      "Batch 1465,  loss: 0.195733380317688\n",
      "Batch 1470,  loss: 0.20673724561929702\n",
      "Batch 1475,  loss: 0.20691479593515397\n",
      "Batch 1480,  loss: 0.16233607530593872\n",
      "Batch 1485,  loss: 0.13372356593608856\n",
      "Batch 1490,  loss: 0.19344041049480437\n",
      "Batch 1495,  loss: 0.1869807720184326\n",
      "Batch 1500,  loss: 0.1604306235909462\n",
      "Batch 1505,  loss: 0.11484145373106003\n",
      "Batch 1510,  loss: 0.16389988958835602\n",
      "Batch 1515,  loss: 0.17457445561885834\n",
      "Batch 1520,  loss: 0.16104499101638795\n",
      "Batch 1525,  loss: 0.22055533528327942\n",
      "Batch 1530,  loss: 0.15454185754060745\n",
      "Batch 1535,  loss: 0.1657704383134842\n",
      "Batch 1540,  loss: 0.18852103054523467\n",
      "Batch 1545,  loss: 0.14997321367263794\n",
      "Batch 1550,  loss: 0.18239865005016326\n",
      "Batch 1555,  loss: 0.20117666721343994\n",
      "Batch 1560,  loss: 0.1606052875518799\n",
      "Batch 1565,  loss: 0.1548950493335724\n",
      "Batch 1570,  loss: 0.15722982585430145\n",
      "Batch 1575,  loss: 0.15744127035140992\n",
      "Batch 1580,  loss: 0.16826913952827455\n",
      "Batch 1585,  loss: 0.2375475287437439\n",
      "Batch 1590,  loss: 0.17517402172088622\n",
      "Batch 1595,  loss: 0.202360862493515\n",
      "Batch 1600,  loss: 0.1559600591659546\n",
      "Batch 1605,  loss: 0.13189607262611389\n",
      "Batch 1610,  loss: 0.14987617880105972\n",
      "Batch 1615,  loss: 0.20829952359199524\n",
      "Batch 1620,  loss: 0.17613011002540588\n",
      "Batch 1625,  loss: 0.14718773812055588\n",
      "Batch 1630,  loss: 0.13120374381542205\n",
      "Batch 1635,  loss: 0.1709091603755951\n",
      "Batch 1640,  loss: 0.16788262128829956\n",
      "Batch 1645,  loss: 0.15549804419279098\n",
      "Batch 1650,  loss: 0.1820461392402649\n",
      "Batch 1655,  loss: 0.16230445802211763\n",
      "Batch 1660,  loss: 0.21325408220291137\n",
      "Batch 1665,  loss: 0.17880277931690217\n",
      "Batch 1670,  loss: 0.156831032037735\n",
      "Batch 1675,  loss: 0.13100482970476152\n",
      "Batch 1680,  loss: 0.15559411346912383\n",
      "Batch 1685,  loss: 0.13280561268329621\n",
      "Batch 1690,  loss: 0.15573275685310364\n",
      "Batch 1695,  loss: 0.16626957356929778\n",
      "Batch 1700,  loss: 0.15069920420646668\n",
      "Batch 1705,  loss: 0.15697318464517593\n",
      "Batch 1710,  loss: 0.20919327139854432\n",
      "Batch 1715,  loss: 0.1777452141046524\n",
      "Batch 1720,  loss: 0.1678588420152664\n",
      "Batch 1725,  loss: 0.21303207874298097\n",
      "Batch 1730,  loss: 0.16509430408477782\n",
      "Batch 1735,  loss: 0.13430675715208054\n",
      "Batch 1740,  loss: 0.11272335350513459\n",
      "Batch 1745,  loss: 0.15019713938236237\n",
      "Batch 1750,  loss: 0.234238600730896\n",
      "Batch 1755,  loss: 0.13648149222135544\n",
      "Batch 1760,  loss: 0.17338015139102936\n",
      "Batch 1765,  loss: 0.13455166220664977\n",
      "Batch 1770,  loss: 0.19015123844146728\n",
      "Batch 1775,  loss: 0.15353810042142868\n",
      "Batch 1780,  loss: 0.15952969789505006\n",
      "Batch 1785,  loss: 0.148530013859272\n",
      "Batch 1790,  loss: 0.17466081380844117\n",
      "Batch 1795,  loss: 0.17135832011699675\n",
      "Batch 1800,  loss: 0.2215714633464813\n",
      "Batch 1805,  loss: 0.16055552661418915\n",
      "Batch 1810,  loss: 0.19717091619968413\n",
      "Batch 1815,  loss: 0.1403678447008133\n",
      "Batch 1820,  loss: 0.17214007973670958\n",
      "Batch 1825,  loss: 0.17426915168762208\n",
      "Batch 1830,  loss: 0.15978819727897645\n",
      "Batch 1835,  loss: 0.16868262588977814\n",
      "Batch 1840,  loss: 0.1837661623954773\n",
      "Batch 1845,  loss: 0.16035747677087783\n",
      "Batch 1850,  loss: 0.1415826588869095\n",
      "Batch 1855,  loss: 0.1856738030910492\n",
      "Batch 1860,  loss: 0.18419967591762543\n",
      "Batch 1865,  loss: 0.15167016834020614\n",
      "Batch 1870,  loss: 0.1374589681625366\n",
      "Batch 1875,  loss: 0.17774288952350617\n",
      "Batch 1880,  loss: 0.14211885184049605\n",
      "Batch 1885,  loss: 0.152397021651268\n",
      "Batch 1890,  loss: 0.16669323444366455\n",
      "Batch 1895,  loss: 0.20691274106502533\n",
      "Batch 1900,  loss: 0.21738236546516418\n",
      "Batch 1905,  loss: 0.18085492253303528\n",
      "Batch 1910,  loss: 0.16268931627273558\n",
      "Batch 1915,  loss: 0.1931667611002922\n",
      "Batch 1920,  loss: 0.17625496983528138\n",
      "Batch 1925,  loss: 0.16934792846441268\n",
      "Batch 1930,  loss: 0.16714536249637604\n",
      "Batch 1935,  loss: 0.17374615967273713\n",
      "Batch 1940,  loss: 0.18055123090744019\n",
      "Batch 1945,  loss: 0.16281767785549164\n",
      "Batch 1950,  loss: 0.1526345655322075\n",
      "Batch 1955,  loss: 0.19169214069843293\n",
      "Batch 1960,  loss: 0.21620673239231109\n",
      "Batch 1965,  loss: 0.16599812507629394\n",
      "Batch 1970,  loss: 0.18834602534770967\n",
      "Batch 1975,  loss: 0.171042799949646\n",
      "Batch 1980,  loss: 0.18467509746551514\n",
      "Batch 1985,  loss: 0.13917387425899505\n",
      "Batch 1990,  loss: 0.13439535200595856\n",
      "Batch 1995,  loss: 0.1708376944065094\n",
      "Batch 2000,  loss: 0.13658704459667206\n",
      "Batch 2005,  loss: 0.16323463767766952\n",
      "Batch 2010,  loss: 0.1491633638739586\n",
      "Batch 2015,  loss: 0.20535964369773865\n",
      "Batch 2020,  loss: 0.1767915368080139\n",
      "Batch 2025,  loss: 0.18593813478946686\n",
      "Batch 2030,  loss: 0.2009010136127472\n",
      "Batch 2035,  loss: 0.15462746024131774\n",
      "Batch 2040,  loss: 0.13506267368793487\n",
      "Batch 2045,  loss: 0.23469798862934113\n",
      "Batch 2050,  loss: 0.15498841404914857\n",
      "Batch 2055,  loss: 0.17914434671401977\n",
      "Batch 2060,  loss: 0.17689518332481385\n",
      "Batch 2065,  loss: 0.22238937318325042\n",
      "Batch 2070,  loss: 0.1207838550209999\n",
      "Batch 2075,  loss: 0.17131535410881044\n",
      "Batch 2080,  loss: 0.13249375224113463\n",
      "Batch 2085,  loss: 0.24030665457248687\n",
      "Batch 2090,  loss: 0.19953216314315797\n",
      "Batch 2095,  loss: 0.1610896348953247\n",
      "Batch 2100,  loss: 0.1599373161792755\n",
      "Batch 2105,  loss: 0.15274859070777894\n",
      "Batch 2110,  loss: 0.15311729311943054\n",
      "Batch 2115,  loss: 0.18267773389816283\n",
      "Batch 2120,  loss: 0.15698513388633728\n",
      "Batch 2125,  loss: 0.17206381559371947\n",
      "Batch 2130,  loss: 0.1941158205270767\n",
      "Batch 2135,  loss: 0.18789085298776625\n",
      "Batch 2140,  loss: 0.15831592977046965\n",
      "Batch 2145,  loss: 0.13903380930423737\n",
      "Batch 2150,  loss: 0.1724175125360489\n",
      "Batch 2155,  loss: 0.22646810710430146\n",
      "Batch 2160,  loss: 0.1581060767173767\n",
      "Batch 2165,  loss: 0.1681223288178444\n",
      "Batch 2170,  loss: 0.1826953411102295\n",
      "Batch 2175,  loss: 0.1761177361011505\n",
      "Batch 2180,  loss: 0.1421726882457733\n",
      "Batch 2185,  loss: 0.1894811600446701\n",
      "Batch 2190,  loss: 0.1548439159989357\n",
      "Batch 2195,  loss: 0.22467198073863984\n",
      "Batch 2200,  loss: 0.13073497712612153\n",
      "Batch 2205,  loss: 0.1687546193599701\n",
      "Batch 2210,  loss: 0.15694318115711212\n",
      "Batch 2215,  loss: 0.16631257981061937\n",
      "Batch 2220,  loss: 0.21170118749141692\n",
      "Batch 2225,  loss: 0.1924219995737076\n",
      "Batch 2230,  loss: 0.16580302715301515\n",
      "Batch 2235,  loss: 0.18081924170255662\n",
      "Batch 2240,  loss: 0.19862670302391053\n",
      "Batch 2245,  loss: 0.1663681223988533\n",
      "Batch 2250,  loss: 0.16313255727291107\n",
      "Batch 2255,  loss: 0.15772935301065444\n",
      "Batch 2260,  loss: 0.17948596626520158\n",
      "Batch 2265,  loss: 0.14959049522876738\n",
      "Batch 2270,  loss: 0.16248036175966263\n",
      "Batch 2275,  loss: 0.19915314316749572\n",
      "Batch 2280,  loss: 0.13032861202955245\n",
      "Batch 2285,  loss: 0.20509153306484224\n",
      "Batch 2290,  loss: 0.18084039092063903\n",
      "Batch 2295,  loss: 0.14253822565078736\n",
      "Batch 2300,  loss: 0.23371862769126892\n",
      "Batch 2305,  loss: 0.17242024838924408\n",
      "Batch 2310,  loss: 0.19148240983486176\n",
      "Batch 2315,  loss: 0.17892524600028992\n",
      "Batch 2320,  loss: 0.1924000382423401\n",
      "Batch 2325,  loss: 0.162161622941494\n",
      "Batch 2330,  loss: 0.18248483836650847\n",
      "Batch 2335,  loss: 0.13752560913562775\n",
      "Batch 2340,  loss: 0.16608139872550964\n",
      "Batch 2345,  loss: 0.16982629597187043\n",
      "Batch 2350,  loss: 0.16766207814216613\n",
      "Batch 2355,  loss: 0.15214448571205139\n",
      "Batch 2360,  loss: 0.1388248860836029\n",
      "Batch 2365,  loss: 0.18293408751487733\n",
      "Batch 2370,  loss: 0.22322871237993241\n",
      "Batch 2375,  loss: 0.15802884101867676\n",
      "Batch 2380,  loss: 0.18550444543361663\n",
      "Batch 2385,  loss: 0.15944069921970366\n",
      "Batch 2390,  loss: 0.17227449417114257\n",
      "Batch 2395,  loss: 0.1609627217054367\n",
      "Batch 2400,  loss: 0.17696327567100525\n",
      "Batch 2405,  loss: 0.1603179842233658\n",
      "Batch 2410,  loss: 0.1781758815050125\n",
      "Batch 2415,  loss: 0.23672115802764893\n",
      "Batch 2420,  loss: 0.1931436538696289\n",
      "Batch 2425,  loss: 0.18216926455497742\n",
      "Batch 2430,  loss: 0.19965855181217193\n",
      "Batch 2435,  loss: 0.16908954381942748\n",
      "Batch 2440,  loss: 0.16566012650728226\n",
      "Batch 2445,  loss: 0.17961282879114152\n",
      "Batch 2450,  loss: 0.1580004721879959\n",
      "Batch 2455,  loss: 0.1941425621509552\n",
      "Batch 2460,  loss: 0.16643638610839845\n",
      "Batch 2465,  loss: 0.15351193249225617\n",
      "Batch 2470,  loss: 0.18879860490560532\n",
      "Batch 2475,  loss: 0.14365075379610062\n",
      "Batch 2480,  loss: 0.17854450941085814\n",
      "Batch 2485,  loss: 0.1358791321516037\n",
      "Batch 2490,  loss: 0.1406099498271942\n",
      "Batch 2495,  loss: 0.15630808770656585\n",
      "Batch 2500,  loss: 0.20563015937805176\n",
      "Batch 2505,  loss: 0.1734011083841324\n",
      "Batch 2510,  loss: 0.14252615869045257\n",
      "Batch 2515,  loss: 0.19028583467006682\n",
      "Batch 2520,  loss: 0.1419643670320511\n",
      "Batch 2525,  loss: 0.1856971949338913\n",
      "Batch 2530,  loss: 0.15031381249427794\n",
      "Batch 2535,  loss: 0.15146385580301286\n",
      "Batch 2540,  loss: 0.14163710474967955\n",
      "Batch 2545,  loss: 0.13295416682958602\n",
      "Batch 2550,  loss: 0.1875939965248108\n",
      "Batch 2555,  loss: 0.20710912346839905\n",
      "Batch 2560,  loss: 0.1456185594201088\n",
      "Batch 2565,  loss: 0.1356615647673607\n",
      "Batch 2570,  loss: 0.14721742272377014\n",
      "Batch 2575,  loss: 0.1956601321697235\n",
      "Batch 2580,  loss: 0.17763587683439255\n",
      "Batch 2585,  loss: 0.1750216156244278\n",
      "Batch 2590,  loss: 0.16828757524490356\n",
      "Batch 2595,  loss: 0.13399194180965424\n",
      "Batch 2600,  loss: 0.1732061356306076\n",
      "Batch 2605,  loss: 0.1559573382139206\n",
      "Batch 2610,  loss: 0.18007710725069045\n",
      "Batch 2615,  loss: 0.169313882291317\n",
      "Batch 2620,  loss: 0.19604031145572662\n",
      "Batch 2625,  loss: 0.14564681947231292\n",
      "Batch 2630,  loss: 0.1484317272901535\n",
      "Batch 2635,  loss: 0.17743599265813828\n",
      "Batch 2640,  loss: 0.16342178285121917\n",
      "Batch 2645,  loss: 0.18580179810523986\n",
      "Batch 2650,  loss: 0.1509401649236679\n",
      "Batch 2655,  loss: 0.15731585770845413\n",
      "Batch 2660,  loss: 0.20632233023643493\n",
      "Batch 2665,  loss: 0.16227131485939025\n",
      "Batch 2670,  loss: 0.11552217751741409\n",
      "Batch 2675,  loss: 0.1784963548183441\n",
      "Batch 2680,  loss: 0.18043927997350692\n",
      "Batch 2685,  loss: 0.2066475734114647\n",
      "Batch 2690,  loss: 0.11714060604572296\n",
      "Batch 2695,  loss: 0.19471823424100876\n",
      "Batch 2700,  loss: 0.2255926877260208\n",
      "Batch 2705,  loss: 0.13135323524475098\n",
      "Batch 2710,  loss: 0.17270218431949616\n",
      "Batch 2715,  loss: 0.16708791255950928\n",
      "Batch 2720,  loss: 0.1620323985815048\n",
      "Batch 2725,  loss: 0.1377396211028099\n",
      "Batch 2730,  loss: 0.14396119564771653\n",
      "Batch 2735,  loss: 0.16383111774921416\n",
      "Batch 2740,  loss: 0.1903795063495636\n",
      "Batch 2745,  loss: 0.17045403122901917\n",
      "Batch 2750,  loss: 0.15569999814033508\n",
      "Batch 2755,  loss: 0.1723097950220108\n",
      "Batch 2760,  loss: 0.18036367297172545\n",
      "Batch 2765,  loss: 0.17767751812934876\n",
      "Batch 2770,  loss: 0.17047979831695556\n",
      "LOSS train 0.17047979831695556. Validation loss: 0.18911147914801 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 21:\n",
      "Batch 5,  loss: 0.16295695602893828\n",
      "Batch 10,  loss: 0.17454727739095688\n",
      "Batch 15,  loss: 0.20372349619865418\n",
      "Batch 20,  loss: 0.17655296623706818\n",
      "Batch 25,  loss: 0.1643358588218689\n",
      "Batch 30,  loss: 0.18055233657360076\n",
      "Batch 35,  loss: 0.1745053634047508\n",
      "Batch 40,  loss: 0.11720669865608216\n",
      "Batch 45,  loss: 0.19719924926757812\n",
      "Batch 50,  loss: 0.13556597828865052\n",
      "Batch 55,  loss: 0.14137671291828155\n",
      "Batch 60,  loss: 0.19734806418418885\n",
      "Batch 65,  loss: 0.16737701296806334\n",
      "Batch 70,  loss: 0.1462147504091263\n",
      "Batch 75,  loss: 0.17306671142578126\n",
      "Batch 80,  loss: 0.14336951076984406\n",
      "Batch 85,  loss: 0.15341313779354096\n",
      "Batch 90,  loss: 0.18134828209877013\n",
      "Batch 95,  loss: 0.21373486518859863\n",
      "Batch 100,  loss: 0.21768364906311036\n",
      "Batch 105,  loss: 0.19826803207397461\n",
      "Batch 110,  loss: 0.13054505586624146\n",
      "Batch 115,  loss: 0.16015902459621428\n",
      "Batch 120,  loss: 0.1830386683344841\n",
      "Batch 125,  loss: 0.1613248646259308\n",
      "Batch 130,  loss: 0.17552798092365265\n",
      "Batch 135,  loss: 0.15127082020044327\n",
      "Batch 140,  loss: 0.16876036822795867\n",
      "Batch 145,  loss: 0.18732119500637054\n",
      "Batch 150,  loss: 0.16230080127716065\n",
      "Batch 155,  loss: 0.15277497321367264\n",
      "Batch 160,  loss: 0.1533738359808922\n",
      "Batch 165,  loss: 0.15872810333967208\n",
      "Batch 170,  loss: 0.18754283487796783\n",
      "Batch 175,  loss: 0.1286788746714592\n",
      "Batch 180,  loss: 0.19679608345031738\n",
      "Batch 185,  loss: 0.2070151150226593\n",
      "Batch 190,  loss: 0.1790609836578369\n",
      "Batch 195,  loss: 0.16576142162084578\n",
      "Batch 200,  loss: 0.148879511654377\n",
      "Batch 205,  loss: 0.1473998546600342\n",
      "Batch 210,  loss: 0.16048489212989808\n",
      "Batch 215,  loss: 0.14007253646850587\n",
      "Batch 220,  loss: 0.16674709022045137\n",
      "Batch 225,  loss: 0.17376787066459656\n",
      "Batch 230,  loss: 0.1856379270553589\n",
      "Batch 235,  loss: 0.13917230814695358\n",
      "Batch 240,  loss: 0.16552695780992507\n",
      "Batch 245,  loss: 0.1663697198033333\n",
      "Batch 250,  loss: 0.1823524832725525\n",
      "Batch 255,  loss: 0.1749550312757492\n",
      "Batch 260,  loss: 0.2455233007669449\n",
      "Batch 265,  loss: 0.22589224874973296\n",
      "Batch 270,  loss: 0.1425698459148407\n",
      "Batch 275,  loss: 0.16929701268672942\n",
      "Batch 280,  loss: 0.14331397265195847\n",
      "Batch 285,  loss: 0.16473053097724916\n",
      "Batch 290,  loss: 0.1717741847038269\n",
      "Batch 295,  loss: 0.18679267764091492\n",
      "Batch 300,  loss: 0.16219441890716552\n",
      "Batch 305,  loss: 0.14293779134750367\n",
      "Batch 310,  loss: 0.16971466988325118\n",
      "Batch 315,  loss: 0.14108458459377288\n",
      "Batch 320,  loss: 0.1265472799539566\n",
      "Batch 325,  loss: 0.16789113879203796\n",
      "Batch 330,  loss: 0.20507676303386688\n",
      "Batch 335,  loss: 0.1472010299563408\n",
      "Batch 340,  loss: 0.18452869951725007\n",
      "Batch 345,  loss: 0.20401939153671264\n",
      "Batch 350,  loss: 0.1581876829266548\n",
      "Batch 355,  loss: 0.15733534395694732\n",
      "Batch 360,  loss: 0.14626311957836152\n",
      "Batch 365,  loss: 0.18626678586006165\n",
      "Batch 370,  loss: 0.17876966297626495\n",
      "Batch 375,  loss: 0.17095268666744232\n",
      "Batch 380,  loss: 0.14815801978111268\n",
      "Batch 385,  loss: 0.1427045315504074\n",
      "Batch 390,  loss: 0.18265116214752197\n",
      "Batch 395,  loss: 0.12563934028148652\n",
      "Batch 400,  loss: 0.12973728477954866\n",
      "Batch 405,  loss: 0.19105870723724366\n",
      "Batch 410,  loss: 0.13982804864645004\n",
      "Batch 415,  loss: 0.17790269255638122\n",
      "Batch 420,  loss: 0.16168675422668458\n",
      "Batch 425,  loss: 0.14164827167987823\n",
      "Batch 430,  loss: 0.16850927770137786\n",
      "Batch 435,  loss: 0.17101181149482728\n",
      "Batch 440,  loss: 0.12066220939159393\n",
      "Batch 445,  loss: 0.20315189361572267\n",
      "Batch 450,  loss: 0.15538054406642915\n",
      "Batch 455,  loss: 0.1838105082511902\n",
      "Batch 460,  loss: 0.18549841940402984\n",
      "Batch 465,  loss: 0.1762655794620514\n",
      "Batch 470,  loss: 0.18793123066425324\n",
      "Batch 475,  loss: 0.15424336045980452\n",
      "Batch 480,  loss: 0.17603919357061387\n",
      "Batch 485,  loss: 0.1625571459531784\n",
      "Batch 490,  loss: 0.20928216278553008\n",
      "Batch 495,  loss: 0.16432369500398636\n",
      "Batch 500,  loss: 0.17345186322927475\n",
      "Batch 505,  loss: 0.1256316587328911\n",
      "Batch 510,  loss: 0.1639149308204651\n",
      "Batch 515,  loss: 0.17323419749736785\n",
      "Batch 520,  loss: 0.14047948867082596\n",
      "Batch 525,  loss: 0.1681894302368164\n",
      "Batch 530,  loss: 0.1444390520453453\n",
      "Batch 535,  loss: 0.1462073355913162\n",
      "Batch 540,  loss: 0.17391344904899597\n",
      "Batch 545,  loss: 0.1721187174320221\n",
      "Batch 550,  loss: 0.14242681115865707\n",
      "Batch 555,  loss: 0.1882063090801239\n",
      "Batch 560,  loss: 0.15501990914344788\n",
      "Batch 565,  loss: 0.15358531177043916\n",
      "Batch 570,  loss: 0.14031309336423875\n",
      "Batch 575,  loss: 0.1463036298751831\n",
      "Batch 580,  loss: 0.21485479772090912\n",
      "Batch 585,  loss: 0.12781353294849396\n",
      "Batch 590,  loss: 0.19255410730838776\n",
      "Batch 595,  loss: 0.17758693397045136\n",
      "Batch 600,  loss: 0.20799998939037323\n",
      "Batch 605,  loss: 0.14055217057466507\n",
      "Batch 610,  loss: 0.16297512501478195\n",
      "Batch 615,  loss: 0.18673276007175446\n",
      "Batch 620,  loss: 0.17494336366653443\n",
      "Batch 625,  loss: 0.16137655079364777\n",
      "Batch 630,  loss: 0.20553354620933534\n",
      "Batch 635,  loss: 0.14907779097557067\n",
      "Batch 640,  loss: 0.1492309346795082\n",
      "Batch 645,  loss: 0.17629415094852446\n",
      "Batch 650,  loss: 0.1438573732972145\n",
      "Batch 655,  loss: 0.2073331743478775\n",
      "Batch 660,  loss: 0.1908005565404892\n",
      "Batch 665,  loss: 0.16177614778280258\n",
      "Batch 670,  loss: 0.21150450706481932\n",
      "Batch 675,  loss: 0.18573869913816451\n",
      "Batch 680,  loss: 0.18089784383773805\n",
      "Batch 685,  loss: 0.1369308277964592\n",
      "Batch 690,  loss: 0.1644233226776123\n",
      "Batch 695,  loss: 0.17539646923542024\n",
      "Batch 700,  loss: 0.18469587564468384\n",
      "Batch 705,  loss: 0.12707734405994414\n",
      "Batch 710,  loss: 0.17275973558425903\n",
      "Batch 715,  loss: 0.21617036163806916\n",
      "Batch 720,  loss: 0.18960204124450683\n",
      "Batch 725,  loss: 0.15593834817409516\n",
      "Batch 730,  loss: 0.15348412990570068\n",
      "Batch 735,  loss: 0.17294711619615555\n",
      "Batch 740,  loss: 0.21869902908802033\n",
      "Batch 745,  loss: 0.18275438547134398\n",
      "Batch 750,  loss: 0.11598521173000335\n",
      "Batch 755,  loss: 0.17843893468379973\n",
      "Batch 760,  loss: 0.23013525009155272\n",
      "Batch 765,  loss: 0.14902227222919465\n",
      "Batch 770,  loss: 0.1522882476449013\n",
      "Batch 775,  loss: 0.15912383198738098\n",
      "Batch 780,  loss: 0.12322447150945663\n",
      "Batch 785,  loss: 0.1823491707444191\n",
      "Batch 790,  loss: 0.21515757143497466\n",
      "Batch 795,  loss: 0.15474174320697784\n",
      "Batch 800,  loss: 0.14497110098600388\n",
      "Batch 805,  loss: 0.15736341923475267\n",
      "Batch 810,  loss: 0.19675928056240083\n",
      "Batch 815,  loss: 0.17750500440597533\n",
      "Batch 820,  loss: 0.16970837712287903\n",
      "Batch 825,  loss: 0.1383364275097847\n",
      "Batch 830,  loss: 0.19351021349430084\n",
      "Batch 835,  loss: 0.17448054254055023\n",
      "Batch 840,  loss: 0.16957179605960845\n",
      "Batch 845,  loss: 0.19164976477622986\n",
      "Batch 850,  loss: 0.15115379095077514\n",
      "Batch 855,  loss: 0.13521353900432587\n",
      "Batch 860,  loss: 0.19626975059509277\n",
      "Batch 865,  loss: 0.1807350307703018\n",
      "Batch 870,  loss: 0.15961234867572785\n",
      "Batch 875,  loss: 0.1453268736600876\n",
      "Batch 880,  loss: 0.1662990480661392\n",
      "Batch 885,  loss: 0.170350182056427\n",
      "Batch 890,  loss: 0.16860397756099701\n",
      "Batch 895,  loss: 0.13930549323558808\n",
      "Batch 900,  loss: 0.16952071487903594\n",
      "Batch 905,  loss: 0.15832310616970063\n",
      "Batch 910,  loss: 0.16892276108264923\n",
      "Batch 915,  loss: 0.16129970252513887\n",
      "Batch 920,  loss: 0.1773039385676384\n",
      "Batch 925,  loss: 0.15783064663410187\n",
      "Batch 930,  loss: 0.13202562034130097\n",
      "Batch 935,  loss: 0.18134293109178543\n",
      "Batch 940,  loss: 0.14167357385158538\n",
      "Batch 945,  loss: 0.1380106121301651\n",
      "Batch 950,  loss: 0.2142369657754898\n",
      "Batch 955,  loss: 0.217936372756958\n",
      "Batch 960,  loss: 0.13484315127134322\n",
      "Batch 965,  loss: 0.15693373382091522\n",
      "Batch 970,  loss: 0.16650731414556502\n",
      "Batch 975,  loss: 0.20294826328754426\n",
      "Batch 980,  loss: 0.1675535261631012\n",
      "Batch 985,  loss: 0.19308891892433167\n",
      "Batch 990,  loss: 0.18284654915332793\n",
      "Batch 995,  loss: 0.20851629376411437\n",
      "Batch 1000,  loss: 0.144497749209404\n",
      "Batch 1005,  loss: 0.15054913163185119\n",
      "Batch 1010,  loss: 0.19345453679561614\n",
      "Batch 1015,  loss: 0.17710529267787933\n",
      "Batch 1020,  loss: 0.22116791009902953\n",
      "Batch 1025,  loss: 0.16841146498918533\n",
      "Batch 1030,  loss: 0.13746320456266403\n",
      "Batch 1035,  loss: 0.17409393787384034\n",
      "Batch 1040,  loss: 0.16568895429372787\n",
      "Batch 1045,  loss: 0.15173633694648742\n",
      "Batch 1050,  loss: 0.1336604103446007\n",
      "Batch 1055,  loss: 0.176435387134552\n",
      "Batch 1060,  loss: 0.20217648446559905\n",
      "Batch 1065,  loss: 0.14474928081035615\n",
      "Batch 1070,  loss: 0.2014040768146515\n",
      "Batch 1075,  loss: 0.17917194664478303\n",
      "Batch 1080,  loss: 0.1660250872373581\n",
      "Batch 1085,  loss: 0.19072663486003877\n",
      "Batch 1090,  loss: 0.19352903068065644\n",
      "Batch 1095,  loss: 0.16131221055984496\n",
      "Batch 1100,  loss: 0.17649625539779662\n",
      "Batch 1105,  loss: 0.18770332336425782\n",
      "Batch 1110,  loss: 0.15874949097633362\n",
      "Batch 1115,  loss: 0.19260961711406707\n",
      "Batch 1120,  loss: 0.17719174921512604\n",
      "Batch 1125,  loss: 0.16337611973285676\n",
      "Batch 1130,  loss: 0.1942916989326477\n",
      "Batch 1135,  loss: 0.21015455722808837\n",
      "Batch 1140,  loss: 0.12403537333011627\n",
      "Batch 1145,  loss: 0.14169951975345613\n",
      "Batch 1150,  loss: 0.17455873191356658\n",
      "Batch 1155,  loss: 0.15313308238983153\n",
      "Batch 1160,  loss: 0.1503376141190529\n",
      "Batch 1165,  loss: 0.18344614803791046\n",
      "Batch 1170,  loss: 0.19830788373947145\n",
      "Batch 1175,  loss: 0.1557943969964981\n",
      "Batch 1180,  loss: 0.1613193243741989\n",
      "Batch 1185,  loss: 0.17164969742298125\n",
      "Batch 1190,  loss: 0.16821466982364655\n",
      "Batch 1195,  loss: 0.1829819142818451\n",
      "Batch 1200,  loss: 0.17538870871067047\n",
      "Batch 1205,  loss: 0.20467065572738646\n",
      "Batch 1210,  loss: 0.16292524933815003\n",
      "Batch 1215,  loss: 0.1662502646446228\n",
      "Batch 1220,  loss: 0.15234674513339996\n",
      "Batch 1225,  loss: 0.1611539050936699\n",
      "Batch 1230,  loss: 0.12316281199455262\n",
      "Batch 1235,  loss: 0.17374944239854812\n",
      "Batch 1240,  loss: 0.16008260846138\n",
      "Batch 1245,  loss: 0.13291341066360474\n",
      "Batch 1250,  loss: 0.18838935792446138\n",
      "Batch 1255,  loss: 0.16501190066337584\n",
      "Batch 1260,  loss: 0.20938099920749664\n",
      "Batch 1265,  loss: 0.13142043501138687\n",
      "Batch 1270,  loss: 0.16977468729019166\n",
      "Batch 1275,  loss: 0.18828934729099273\n",
      "Batch 1280,  loss: 0.15416765213012695\n",
      "Batch 1285,  loss: 0.19390024691820146\n",
      "Batch 1290,  loss: 0.1434722363948822\n",
      "Batch 1295,  loss: 0.1541102945804596\n",
      "Batch 1300,  loss: 0.16320479959249495\n",
      "Batch 1305,  loss: 0.2225046843290329\n",
      "Batch 1310,  loss: 0.12425179183483123\n",
      "Batch 1315,  loss: 0.244000580906868\n",
      "Batch 1320,  loss: 0.1380407154560089\n",
      "Batch 1325,  loss: 0.18180011510848998\n",
      "Batch 1330,  loss: 0.16965435147285463\n",
      "Batch 1335,  loss: 0.22396597564220427\n",
      "Batch 1340,  loss: 0.1658344954252243\n",
      "Batch 1345,  loss: 0.15368865728378295\n",
      "Batch 1350,  loss: 0.1983465775847435\n",
      "Batch 1355,  loss: 0.21094391047954558\n",
      "Batch 1360,  loss: 0.16917490512132644\n",
      "Batch 1365,  loss: 0.16417478024959564\n",
      "Batch 1370,  loss: 0.16091635525226594\n",
      "Batch 1375,  loss: 0.18820394873619078\n",
      "Batch 1380,  loss: 0.17560609579086303\n",
      "Batch 1385,  loss: 0.18299186527729033\n",
      "Batch 1390,  loss: 0.15140778720378875\n",
      "Batch 1395,  loss: 0.16341568827629088\n",
      "Batch 1400,  loss: 0.13301538974046706\n",
      "Batch 1405,  loss: 0.18991459608078004\n",
      "Batch 1410,  loss: 0.15124317407608032\n",
      "Batch 1415,  loss: 0.1606105625629425\n",
      "Batch 1420,  loss: 0.13919058442115784\n",
      "Batch 1425,  loss: 0.1729472368955612\n",
      "Batch 1430,  loss: 0.16533724665641786\n",
      "Batch 1435,  loss: 0.1496140480041504\n",
      "Batch 1440,  loss: 0.15664226412773133\n",
      "Batch 1445,  loss: 0.16077936291694642\n",
      "Batch 1450,  loss: 0.16132570505142213\n",
      "Batch 1455,  loss: 0.13378717452287675\n",
      "Batch 1460,  loss: 0.13802167922258377\n",
      "Batch 1465,  loss: 0.1748172014951706\n",
      "Batch 1470,  loss: 0.1605750411748886\n",
      "Batch 1475,  loss: 0.17838147282600403\n",
      "Batch 1480,  loss: 0.19888471066951752\n",
      "Batch 1485,  loss: 0.1941845566034317\n",
      "Batch 1490,  loss: 0.18554426431655885\n",
      "Batch 1495,  loss: 0.16345818042755128\n",
      "Batch 1500,  loss: 0.14638107717037202\n",
      "Batch 1505,  loss: 0.15171175301074982\n",
      "Batch 1510,  loss: 0.1875603199005127\n",
      "Batch 1515,  loss: 0.2092031478881836\n",
      "Batch 1520,  loss: 0.15092849135398864\n",
      "Batch 1525,  loss: 0.16526237577199937\n",
      "Batch 1530,  loss: 0.13601864129304886\n",
      "Batch 1535,  loss: 0.16985796242952347\n",
      "Batch 1540,  loss: 0.15831224918365477\n",
      "Batch 1545,  loss: 0.1660478115081787\n",
      "Batch 1550,  loss: 0.21840773671865463\n",
      "Batch 1555,  loss: 0.18302458822727202\n",
      "Batch 1560,  loss: 0.1434931844472885\n",
      "Batch 1565,  loss: 0.17055799663066865\n",
      "Batch 1570,  loss: 0.15900121331214906\n",
      "Batch 1575,  loss: 0.15728001296520233\n",
      "Batch 1580,  loss: 0.14629798829555513\n",
      "Batch 1585,  loss: 0.21887941509485245\n",
      "Batch 1590,  loss: 0.11647461503744125\n",
      "Batch 1595,  loss: 0.17691146433353425\n",
      "Batch 1600,  loss: 0.17276451587677003\n",
      "Batch 1605,  loss: 0.18100351989269256\n",
      "Batch 1610,  loss: 0.1404403790831566\n",
      "Batch 1615,  loss: 0.20021811425685881\n",
      "Batch 1620,  loss: 0.13630678802728652\n",
      "Batch 1625,  loss: 0.16757086515426636\n",
      "Batch 1630,  loss: 0.14357760846614837\n",
      "Batch 1635,  loss: 0.1602093309164047\n",
      "Batch 1640,  loss: 0.14713214784860612\n",
      "Batch 1645,  loss: 0.16112527549266814\n",
      "Batch 1650,  loss: 0.16191490590572358\n",
      "Batch 1655,  loss: 0.19775618314743043\n",
      "Batch 1660,  loss: 0.16153258979320526\n",
      "Batch 1665,  loss: 0.1702248454093933\n",
      "Batch 1670,  loss: 0.17561013996601105\n",
      "Batch 1675,  loss: 0.14118826240301133\n",
      "Batch 1680,  loss: 0.1935460537672043\n",
      "Batch 1685,  loss: 0.15670729279518128\n",
      "Batch 1690,  loss: 0.11758385598659515\n",
      "Batch 1695,  loss: 0.17794739305973054\n",
      "Batch 1700,  loss: 0.14341780543327332\n",
      "Batch 1705,  loss: 0.1940195769071579\n",
      "Batch 1710,  loss: 0.16232044398784637\n",
      "Batch 1715,  loss: 0.13352464735507966\n",
      "Batch 1720,  loss: 0.16098838448524475\n",
      "Batch 1725,  loss: 0.13691911548376084\n",
      "Batch 1730,  loss: 0.1483801633119583\n",
      "Batch 1735,  loss: 0.1635492652654648\n",
      "Batch 1740,  loss: 0.15515827536582946\n",
      "Batch 1745,  loss: 0.19551202952861785\n",
      "Batch 1750,  loss: 0.21454134583473206\n",
      "Batch 1755,  loss: 0.12044289708137512\n",
      "Batch 1760,  loss: 0.20819375813007354\n",
      "Batch 1765,  loss: 0.1607702538371086\n",
      "Batch 1770,  loss: 0.2001276955008507\n",
      "Batch 1775,  loss: 0.16880401968955994\n",
      "Batch 1780,  loss: 0.20633416324853898\n",
      "Batch 1785,  loss: 0.16293320059776306\n",
      "Batch 1790,  loss: 0.1793278306722641\n",
      "Batch 1795,  loss: 0.18691689968109132\n",
      "Batch 1800,  loss: 0.19334484338760377\n",
      "Batch 1805,  loss: 0.11313072144985199\n",
      "Batch 1810,  loss: 0.19377095103263856\n",
      "Batch 1815,  loss: 0.1752383068203926\n",
      "Batch 1820,  loss: 0.18061486184597014\n",
      "Batch 1825,  loss: 0.21402393281459808\n",
      "Batch 1830,  loss: 0.16992118656635286\n",
      "Batch 1835,  loss: 0.1716700553894043\n",
      "Batch 1840,  loss: 0.14400493055582048\n",
      "Batch 1845,  loss: 0.1557942658662796\n",
      "Batch 1850,  loss: 0.16306237876415253\n",
      "Batch 1855,  loss: 0.15528010427951813\n",
      "Batch 1860,  loss: 0.154620897769928\n",
      "Batch 1865,  loss: 0.18588111400604249\n",
      "Batch 1870,  loss: 0.19642865657806396\n",
      "Batch 1875,  loss: 0.1829166054725647\n",
      "Batch 1880,  loss: 0.1748334586620331\n",
      "Batch 1885,  loss: 0.18250370174646377\n",
      "Batch 1890,  loss: 0.21082769334316254\n",
      "Batch 1895,  loss: 0.15182788372039796\n",
      "Batch 1900,  loss: 0.18191484808921815\n",
      "Batch 1905,  loss: 0.17028212249279023\n",
      "Batch 1910,  loss: 0.14984452426433564\n",
      "Batch 1915,  loss: 0.181461837887764\n",
      "Batch 1920,  loss: 0.15737414062023164\n",
      "Batch 1925,  loss: 0.1662122294306755\n",
      "Batch 1930,  loss: 0.17690171599388121\n",
      "Batch 1935,  loss: 0.15721183866262436\n",
      "Batch 1940,  loss: 0.153120693564415\n",
      "Batch 1945,  loss: 0.17940255403518676\n",
      "Batch 1950,  loss: 0.2334467351436615\n",
      "Batch 1955,  loss: 0.17043964564800262\n",
      "Batch 1960,  loss: 0.15116558074951172\n",
      "Batch 1965,  loss: 0.24245228469371796\n",
      "Batch 1970,  loss: 0.157764208316803\n",
      "Batch 1975,  loss: 0.14072140157222748\n",
      "Batch 1980,  loss: 0.17656200677156447\n",
      "Batch 1985,  loss: 0.16028417646884918\n",
      "Batch 1990,  loss: 0.1937730133533478\n",
      "Batch 1995,  loss: 0.18389370143413544\n",
      "Batch 2000,  loss: 0.20942992269992827\n",
      "Batch 2005,  loss: 0.1478365182876587\n",
      "Batch 2010,  loss: 0.16857468485832214\n",
      "Batch 2015,  loss: 0.18374695181846618\n",
      "Batch 2020,  loss: 0.15901644378900529\n",
      "Batch 2025,  loss: 0.15356432944536208\n",
      "Batch 2030,  loss: 0.14675131291151047\n",
      "Batch 2035,  loss: 0.19068149030208587\n",
      "Batch 2040,  loss: 0.18568047881126404\n",
      "Batch 2045,  loss: 0.20373686850070954\n",
      "Batch 2050,  loss: 0.18467580378055573\n",
      "Batch 2055,  loss: 0.1819564700126648\n",
      "Batch 2060,  loss: 0.17366407662630082\n",
      "Batch 2065,  loss: 0.17846296429634095\n",
      "Batch 2070,  loss: 0.1580972909927368\n",
      "Batch 2075,  loss: 0.13700595051050185\n",
      "Batch 2080,  loss: 0.16638793796300888\n",
      "Batch 2085,  loss: 0.17651403397321702\n",
      "Batch 2090,  loss: 0.1701629340648651\n",
      "Batch 2095,  loss: 0.1943986728787422\n",
      "Batch 2100,  loss: 0.21869755983352662\n",
      "Batch 2105,  loss: 0.21641672551631927\n",
      "Batch 2110,  loss: 0.1361812338232994\n",
      "Batch 2115,  loss: 0.17535336017608644\n",
      "Batch 2120,  loss: 0.15976809114217758\n",
      "Batch 2125,  loss: 0.19816676080226897\n",
      "Batch 2130,  loss: 0.1531735837459564\n",
      "Batch 2135,  loss: 0.20110780298709868\n",
      "Batch 2140,  loss: 0.1639828860759735\n",
      "Batch 2145,  loss: 0.15780164301395416\n",
      "Batch 2150,  loss: 0.18171679973602295\n",
      "Batch 2155,  loss: 0.17199448645114898\n",
      "Batch 2160,  loss: 0.14451337605714798\n",
      "Batch 2165,  loss: 0.1453977718949318\n",
      "Batch 2170,  loss: 0.18940330445766448\n",
      "Batch 2175,  loss: 0.1472246065735817\n",
      "Batch 2180,  loss: 0.17911303043365479\n",
      "Batch 2185,  loss: 0.22613604962825776\n",
      "Batch 2190,  loss: 0.17504094243049623\n",
      "Batch 2195,  loss: 0.13751286119222642\n",
      "Batch 2200,  loss: 0.14540569931268693\n",
      "Batch 2205,  loss: 0.1736379712820053\n",
      "Batch 2210,  loss: 0.158608078956604\n",
      "Batch 2215,  loss: 0.15656844675540924\n",
      "Batch 2220,  loss: 0.18131693154573442\n",
      "Batch 2225,  loss: 0.1480566754937172\n",
      "Batch 2230,  loss: 0.160507670044899\n",
      "Batch 2235,  loss: 0.1444193184375763\n",
      "Batch 2240,  loss: 0.1747869670391083\n",
      "Batch 2245,  loss: 0.22160932421684265\n",
      "Batch 2250,  loss: 0.182149076461792\n",
      "Batch 2255,  loss: 0.16295499503612518\n",
      "Batch 2260,  loss: 0.1652681976556778\n",
      "Batch 2265,  loss: 0.19773324728012084\n",
      "Batch 2270,  loss: 0.17699886858463287\n",
      "Batch 2275,  loss: 0.13384469002485275\n",
      "Batch 2280,  loss: 0.14740174412727355\n",
      "Batch 2285,  loss: 0.21368831098079683\n",
      "Batch 2290,  loss: 0.17965812981128693\n",
      "Batch 2295,  loss: 0.16664567291736604\n",
      "Batch 2300,  loss: 0.19126131385564804\n",
      "Batch 2305,  loss: 0.16110454648733138\n",
      "Batch 2310,  loss: 0.21650956869125365\n",
      "Batch 2315,  loss: 0.1481696844100952\n",
      "Batch 2320,  loss: 0.19309128671884537\n",
      "Batch 2325,  loss: 0.16204863488674165\n",
      "Batch 2330,  loss: 0.20169728696346284\n",
      "Batch 2335,  loss: 0.16426823139190674\n",
      "Batch 2340,  loss: 0.2049688369035721\n",
      "Batch 2345,  loss: 0.161221843957901\n",
      "Batch 2350,  loss: 0.20172042548656463\n",
      "Batch 2355,  loss: 0.17259475588798523\n",
      "Batch 2360,  loss: 0.15901877880096435\n",
      "Batch 2365,  loss: 0.15657373368740082\n",
      "Batch 2370,  loss: 0.17752696126699447\n",
      "Batch 2375,  loss: 0.16854445338249208\n",
      "Batch 2380,  loss: 0.18346595168113708\n",
      "Batch 2385,  loss: 0.15066453367471694\n",
      "Batch 2390,  loss: 0.15922630429267884\n",
      "Batch 2395,  loss: 0.17208935171365738\n",
      "Batch 2400,  loss: 0.140385702252388\n",
      "Batch 2405,  loss: 0.18167699873447418\n",
      "Batch 2410,  loss: 0.16659194231033325\n",
      "Batch 2415,  loss: 0.16841885447502136\n",
      "Batch 2420,  loss: 0.13489139825105667\n",
      "Batch 2425,  loss: 0.17495442032814026\n",
      "Batch 2430,  loss: 0.14417564272880554\n",
      "Batch 2435,  loss: 0.19774700701236725\n",
      "Batch 2440,  loss: 0.17097168564796447\n",
      "Batch 2445,  loss: 0.19369924068450928\n",
      "Batch 2450,  loss: 0.1322167232632637\n",
      "Batch 2455,  loss: 0.17407774329185485\n",
      "Batch 2460,  loss: 0.16551789939403533\n",
      "Batch 2465,  loss: 0.20237543433904648\n",
      "Batch 2470,  loss: 0.15721465945243834\n",
      "Batch 2475,  loss: 0.19873612821102143\n",
      "Batch 2480,  loss: 0.13981359601020812\n",
      "Batch 2485,  loss: 0.1834447205066681\n",
      "Batch 2490,  loss: 0.21770403385162354\n",
      "Batch 2495,  loss: 0.16347037851810456\n",
      "Batch 2500,  loss: 0.18303581923246384\n",
      "Batch 2505,  loss: 0.20240953862667083\n",
      "Batch 2510,  loss: 0.15623151659965515\n",
      "Batch 2515,  loss: 0.16557707488536835\n",
      "Batch 2520,  loss: 0.17790945768356323\n",
      "Batch 2525,  loss: 0.15904432237148286\n",
      "Batch 2530,  loss: 0.17855069935321807\n",
      "Batch 2535,  loss: 0.1832870662212372\n",
      "Batch 2540,  loss: 0.17070319950580598\n",
      "Batch 2545,  loss: 0.19784844517707825\n",
      "Batch 2550,  loss: 0.17799730151891707\n",
      "Batch 2555,  loss: 0.17355011999607087\n",
      "Batch 2560,  loss: 0.18753808438777925\n",
      "Batch 2565,  loss: 0.19419161081314087\n",
      "Batch 2570,  loss: 0.22404754757881165\n",
      "Batch 2575,  loss: 0.17731736600399017\n",
      "Batch 2580,  loss: 0.17244525551795958\n",
      "Batch 2585,  loss: 0.14087509363889694\n",
      "Batch 2590,  loss: 0.20205460488796234\n",
      "Batch 2595,  loss: 0.15528935343027114\n",
      "Batch 2600,  loss: 0.1871781438589096\n",
      "Batch 2605,  loss: 0.19188299179077148\n",
      "Batch 2610,  loss: 0.1683739736676216\n",
      "Batch 2615,  loss: 0.16012799590826035\n",
      "Batch 2620,  loss: 0.14194354712963103\n",
      "Batch 2625,  loss: 0.17650668323040009\n",
      "Batch 2630,  loss: 0.18688985109329223\n",
      "Batch 2635,  loss: 0.19464919567108155\n",
      "Batch 2640,  loss: 0.18851207792758942\n",
      "Batch 2645,  loss: 0.13866598904132843\n",
      "Batch 2650,  loss: 0.18699811398983002\n",
      "Batch 2655,  loss: 0.1676946461200714\n",
      "Batch 2660,  loss: 0.1446728453040123\n",
      "Batch 2665,  loss: 0.17118376791477202\n",
      "Batch 2670,  loss: 0.1420397639274597\n",
      "Batch 2675,  loss: 0.15732736587524415\n",
      "Batch 2680,  loss: 0.15736873000860213\n",
      "Batch 2685,  loss: 0.16747798919677734\n",
      "Batch 2690,  loss: 0.1687469482421875\n",
      "Batch 2695,  loss: 0.1678302615880966\n",
      "Batch 2700,  loss: 0.15518012940883635\n",
      "Batch 2705,  loss: 0.14883902072906494\n",
      "Batch 2710,  loss: 0.15509272813796998\n",
      "Batch 2715,  loss: 0.1241712063550949\n",
      "Batch 2720,  loss: 0.1604494869709015\n",
      "Batch 2725,  loss: 0.1719558447599411\n",
      "Batch 2730,  loss: 0.14317850768566132\n",
      "Batch 2735,  loss: 0.1505717307329178\n",
      "Batch 2740,  loss: 0.15678776800632477\n",
      "Batch 2745,  loss: 0.1638549566268921\n",
      "Batch 2750,  loss: 0.15723492801189423\n",
      "Batch 2755,  loss: 0.1518234059214592\n",
      "Batch 2760,  loss: 0.19407352507114412\n",
      "Batch 2765,  loss: 0.14510111659765243\n",
      "Batch 2770,  loss: 0.13104133903980256\n",
      "LOSS train 0.13104133903980256. Validation loss: 0.16758701371813745 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 22:\n",
      "Batch 5,  loss: 0.18948978781700135\n",
      "Batch 10,  loss: 0.14397553354501724\n",
      "Batch 15,  loss: 0.16057352721691132\n",
      "Batch 20,  loss: 0.18779980689287185\n",
      "Batch 25,  loss: 0.16594817340373993\n",
      "Batch 30,  loss: 0.14241641461849214\n",
      "Batch 35,  loss: 0.15365299135446547\n",
      "Batch 40,  loss: 0.18766669929027557\n",
      "Batch 45,  loss: 0.18166554272174834\n",
      "Batch 50,  loss: 0.17185227274894715\n",
      "Batch 55,  loss: 0.1494571805000305\n",
      "Batch 60,  loss: 0.16674579679965973\n",
      "Batch 65,  loss: 0.1834128588438034\n",
      "Batch 70,  loss: 0.16351457685232162\n",
      "Batch 75,  loss: 0.17794946432113648\n",
      "Batch 80,  loss: 0.1650832861661911\n",
      "Batch 85,  loss: 0.14089388400316238\n",
      "Batch 90,  loss: 0.15537543892860411\n",
      "Batch 95,  loss: 0.1954965353012085\n",
      "Batch 100,  loss: 0.1729851633310318\n",
      "Batch 105,  loss: 0.1502457469701767\n",
      "Batch 110,  loss: 0.17612810730934142\n",
      "Batch 115,  loss: 0.20133854299783707\n",
      "Batch 120,  loss: 0.20088847875595092\n",
      "Batch 125,  loss: 0.2048242211341858\n",
      "Batch 130,  loss: 0.17124074697494507\n",
      "Batch 135,  loss: 0.21190055906772615\n",
      "Batch 140,  loss: 0.13779035210609436\n",
      "Batch 145,  loss: 0.18279043734073638\n",
      "Batch 150,  loss: 0.14009381383657454\n",
      "Batch 155,  loss: 0.17626375555992127\n",
      "Batch 160,  loss: 0.20282334983348846\n",
      "Batch 165,  loss: 0.19694537073373794\n",
      "Batch 170,  loss: 0.1841079592704773\n",
      "Batch 175,  loss: 0.1905869036912918\n",
      "Batch 180,  loss: 0.1740120217204094\n",
      "Batch 185,  loss: 0.14540378153324127\n",
      "Batch 190,  loss: 0.12364558428525925\n",
      "Batch 195,  loss: 0.1307055026292801\n",
      "Batch 200,  loss: 0.17181507200002671\n",
      "Batch 205,  loss: 0.23091790378093718\n",
      "Batch 210,  loss: 0.20674133002758027\n",
      "Batch 215,  loss: 0.13769639432430267\n",
      "Batch 220,  loss: 0.1549980103969574\n",
      "Batch 225,  loss: 0.18128736317157745\n",
      "Batch 230,  loss: 0.1844850957393646\n",
      "Batch 235,  loss: 0.15848512351512908\n",
      "Batch 240,  loss: 0.1333084985613823\n",
      "Batch 245,  loss: 0.1453011840581894\n",
      "Batch 250,  loss: 0.18576180189847946\n",
      "Batch 255,  loss: 0.1491394817829132\n",
      "Batch 260,  loss: 0.1383485823869705\n",
      "Batch 265,  loss: 0.16855134963989257\n",
      "Batch 270,  loss: 0.244493705034256\n",
      "Batch 275,  loss: 0.16344002783298492\n",
      "Batch 280,  loss: 0.21793994009494783\n",
      "Batch 285,  loss: 0.19216637015342714\n",
      "Batch 290,  loss: 0.16814517378807067\n",
      "Batch 295,  loss: 0.1443193033337593\n",
      "Batch 300,  loss: 0.13097010403871537\n",
      "Batch 305,  loss: 0.15007957220077514\n",
      "Batch 310,  loss: 0.12716939002275468\n",
      "Batch 315,  loss: 0.14874534755945207\n",
      "Batch 320,  loss: 0.15328799039125443\n",
      "Batch 325,  loss: 0.17555320262908936\n",
      "Batch 330,  loss: 0.11379583030939103\n",
      "Batch 335,  loss: 0.18569236993789673\n",
      "Batch 340,  loss: 0.17596042156219482\n",
      "Batch 345,  loss: 0.19357654750347136\n",
      "Batch 350,  loss: 0.16937661170959473\n",
      "Batch 355,  loss: 0.1675182670354843\n",
      "Batch 360,  loss: 0.1402840495109558\n",
      "Batch 365,  loss: 0.20782550275325776\n",
      "Batch 370,  loss: 0.17868546545505523\n",
      "Batch 375,  loss: 0.16192325055599213\n",
      "Batch 380,  loss: 0.13001516610383987\n",
      "Batch 385,  loss: 0.15324885845184327\n",
      "Batch 390,  loss: 0.1600585624575615\n",
      "Batch 395,  loss: 0.22277947515249252\n",
      "Batch 400,  loss: 0.1561003640294075\n",
      "Batch 405,  loss: 0.16243706047534942\n",
      "Batch 410,  loss: 0.2055017352104187\n",
      "Batch 415,  loss: 0.15258157551288604\n",
      "Batch 420,  loss: 0.18613449931144715\n",
      "Batch 425,  loss: 0.13396716117858887\n",
      "Batch 430,  loss: 0.2541577637195587\n",
      "Batch 435,  loss: 0.14814117699861526\n",
      "Batch 440,  loss: 0.16645205169916152\n",
      "Batch 445,  loss: 0.13614371716976165\n",
      "Batch 450,  loss: 0.11896329075098037\n",
      "Batch 455,  loss: 0.14248809963464737\n",
      "Batch 460,  loss: 0.18210891485214234\n",
      "Batch 465,  loss: 0.17831784188747407\n",
      "Batch 470,  loss: 0.18298718631267546\n",
      "Batch 475,  loss: 0.1958620846271515\n",
      "Batch 480,  loss: 0.11492289155721665\n",
      "Batch 485,  loss: 0.1670835793018341\n",
      "Batch 490,  loss: 0.1644849419593811\n",
      "Batch 495,  loss: 0.19222067445516586\n",
      "Batch 500,  loss: 0.2083317905664444\n",
      "Batch 505,  loss: 0.17010174691677094\n",
      "Batch 510,  loss: 0.15895556956529616\n",
      "Batch 515,  loss: 0.17352948635816573\n",
      "Batch 520,  loss: 0.16856148540973664\n",
      "Batch 525,  loss: 0.14159667789936065\n",
      "Batch 530,  loss: 0.1717902362346649\n",
      "Batch 535,  loss: 0.14219296127557754\n",
      "Batch 540,  loss: 0.1556113988161087\n",
      "Batch 545,  loss: 0.1612570568919182\n",
      "Batch 550,  loss: 0.19843416213989257\n",
      "Batch 555,  loss: 0.14094638228416442\n",
      "Batch 560,  loss: 0.19163092970848083\n",
      "Batch 565,  loss: 0.12268984615802765\n",
      "Batch 570,  loss: 0.2177642911672592\n",
      "Batch 575,  loss: 0.2075422525405884\n",
      "Batch 580,  loss: 0.13602712154388427\n",
      "Batch 585,  loss: 0.20260571241378783\n",
      "Batch 590,  loss: 0.1795753389596939\n",
      "Batch 595,  loss: 0.18339708149433137\n",
      "Batch 600,  loss: 0.16138807833194732\n",
      "Batch 605,  loss: 0.13654319047927857\n",
      "Batch 610,  loss: 0.18496010899543763\n",
      "Batch 615,  loss: 0.16783752739429475\n",
      "Batch 620,  loss: 0.18753063082695007\n",
      "Batch 625,  loss: 0.17494803220033645\n",
      "Batch 630,  loss: 0.2388305902481079\n",
      "Batch 635,  loss: 0.15158270299434662\n",
      "Batch 640,  loss: 0.18126691430807113\n",
      "Batch 645,  loss: 0.16551070511341096\n",
      "Batch 650,  loss: 0.1333271563053131\n",
      "Batch 655,  loss: 0.15136294364929198\n",
      "Batch 660,  loss: 0.1855836868286133\n",
      "Batch 665,  loss: 0.16940774619579316\n",
      "Batch 670,  loss: 0.131879460811615\n",
      "Batch 675,  loss: 0.17859655916690825\n",
      "Batch 680,  loss: 0.1468260556459427\n",
      "Batch 685,  loss: 0.19270907044410707\n",
      "Batch 690,  loss: 0.14275094866752625\n",
      "Batch 695,  loss: 0.17003410458564758\n",
      "Batch 700,  loss: 0.1444933995604515\n",
      "Batch 705,  loss: 0.22797753810882568\n",
      "Batch 710,  loss: 0.16352909356355666\n",
      "Batch 715,  loss: 0.13965402096509932\n",
      "Batch 720,  loss: 0.21994391679763795\n",
      "Batch 725,  loss: 0.1780218303203583\n",
      "Batch 730,  loss: 0.14841206669807433\n",
      "Batch 735,  loss: 0.13852248787879945\n",
      "Batch 740,  loss: 0.18476932346820832\n",
      "Batch 745,  loss: 0.15754239559173583\n",
      "Batch 750,  loss: 0.19046146869659425\n",
      "Batch 755,  loss: 0.13277970105409623\n",
      "Batch 760,  loss: 0.1573459655046463\n",
      "Batch 765,  loss: 0.18621835708618165\n",
      "Batch 770,  loss: 0.14363571256399155\n",
      "Batch 775,  loss: 0.15295957624912263\n",
      "Batch 780,  loss: 0.17309898436069487\n",
      "Batch 785,  loss: 0.17712795585393906\n",
      "Batch 790,  loss: 0.2136305958032608\n",
      "Batch 795,  loss: 0.15655846893787384\n",
      "Batch 800,  loss: 0.16618021726608276\n",
      "Batch 805,  loss: 0.2145561993122101\n",
      "Batch 810,  loss: 0.1840835139155388\n",
      "Batch 815,  loss: 0.1389251545071602\n",
      "Batch 820,  loss: 0.18741739690303802\n",
      "Batch 825,  loss: 0.17796674370765686\n",
      "Batch 830,  loss: 0.21494121253490447\n",
      "Batch 835,  loss: 0.17365858554840088\n",
      "Batch 840,  loss: 0.1462338998913765\n",
      "Batch 845,  loss: 0.14120824486017228\n",
      "Batch 850,  loss: 0.1655185788869858\n",
      "Batch 855,  loss: 0.13829888999462128\n",
      "Batch 860,  loss: 0.1435921758413315\n",
      "Batch 865,  loss: 0.15200715959072114\n",
      "Batch 870,  loss: 0.1439594805240631\n",
      "Batch 875,  loss: 0.16650554537773132\n",
      "Batch 880,  loss: 0.18048517107963563\n",
      "Batch 885,  loss: 0.21682600378990174\n",
      "Batch 890,  loss: 0.14975640028715134\n",
      "Batch 895,  loss: 0.17541069388389588\n",
      "Batch 900,  loss: 0.14949023127555847\n",
      "Batch 905,  loss: 0.19120033383369445\n",
      "Batch 910,  loss: 0.15651547014713288\n",
      "Batch 915,  loss: 0.19673991203308105\n",
      "Batch 920,  loss: 0.1407981649041176\n",
      "Batch 925,  loss: 0.17449957132339478\n",
      "Batch 930,  loss: 0.13045039921998977\n",
      "Batch 935,  loss: 0.15699997246265412\n",
      "Batch 940,  loss: 0.16290522515773773\n",
      "Batch 945,  loss: 0.1667388677597046\n",
      "Batch 950,  loss: 0.17540699541568755\n",
      "Batch 955,  loss: 0.15525991916656495\n",
      "Batch 960,  loss: 0.22841970324516297\n",
      "Batch 965,  loss: 0.18187781274318696\n",
      "Batch 970,  loss: 0.13299672305583954\n",
      "Batch 975,  loss: 0.19633912146091462\n",
      "Batch 980,  loss: 0.14375631958246232\n",
      "Batch 985,  loss: 0.17316017895936966\n",
      "Batch 990,  loss: 0.15690285265445708\n",
      "Batch 995,  loss: 0.1687130808830261\n",
      "Batch 1000,  loss: 0.1464780628681183\n",
      "Batch 1005,  loss: 0.15210846066474915\n",
      "Batch 1010,  loss: 0.19489000737667084\n",
      "Batch 1015,  loss: 0.18582317531108855\n",
      "Batch 1020,  loss: 0.1954597294330597\n",
      "Batch 1025,  loss: 0.14481616467237474\n",
      "Batch 1030,  loss: 0.13316625207662583\n",
      "Batch 1035,  loss: 0.21980373561382294\n",
      "Batch 1040,  loss: 0.1586685910820961\n",
      "Batch 1045,  loss: 0.15809637159109116\n",
      "Batch 1050,  loss: 0.16051010191440582\n",
      "Batch 1055,  loss: 0.11855451464653015\n",
      "Batch 1060,  loss: 0.1705957055091858\n",
      "Batch 1065,  loss: 0.1353692188858986\n",
      "Batch 1070,  loss: 0.16664123833179473\n",
      "Batch 1075,  loss: 0.1316557854413986\n",
      "Batch 1080,  loss: 0.22291404604911805\n",
      "Batch 1085,  loss: 0.14861513674259186\n",
      "Batch 1090,  loss: 0.16819774806499482\n",
      "Batch 1095,  loss: 0.15571670830249787\n",
      "Batch 1100,  loss: 0.15892782360315322\n",
      "Batch 1105,  loss: 0.14837424457073212\n",
      "Batch 1110,  loss: 0.1611711323261261\n",
      "Batch 1115,  loss: 0.18743428140878676\n",
      "Batch 1120,  loss: 0.1809478908777237\n",
      "Batch 1125,  loss: 0.16335814595222473\n",
      "Batch 1130,  loss: 0.20292648077011108\n",
      "Batch 1135,  loss: 0.19491470456123353\n",
      "Batch 1140,  loss: 0.19667449295520784\n",
      "Batch 1145,  loss: 0.20477404296398163\n",
      "Batch 1150,  loss: 0.16999851018190384\n",
      "Batch 1155,  loss: 0.19005100429058075\n",
      "Batch 1160,  loss: 0.17128746807575226\n",
      "Batch 1165,  loss: 0.1992361918091774\n",
      "Batch 1170,  loss: 0.17593807280063628\n",
      "Batch 1175,  loss: 0.1567020058631897\n",
      "Batch 1180,  loss: 0.14391789883375167\n",
      "Batch 1185,  loss: 0.14546851813793182\n",
      "Batch 1190,  loss: 0.1741342693567276\n",
      "Batch 1195,  loss: 0.19510634541511535\n",
      "Batch 1200,  loss: 0.13918984979391097\n",
      "Batch 1205,  loss: 0.13012887984514238\n",
      "Batch 1210,  loss: 0.1762287586927414\n",
      "Batch 1215,  loss: 0.17103484869003296\n",
      "Batch 1220,  loss: 0.2022528111934662\n",
      "Batch 1225,  loss: 0.14418581426143645\n",
      "Batch 1230,  loss: 0.15120832473039628\n",
      "Batch 1235,  loss: 0.22129650563001632\n",
      "Batch 1240,  loss: 0.17610302865505217\n",
      "Batch 1245,  loss: 0.19008907526731492\n",
      "Batch 1250,  loss: 0.1495416820049286\n",
      "Batch 1255,  loss: 0.1766826629638672\n",
      "Batch 1260,  loss: 0.2108699232339859\n",
      "Batch 1265,  loss: 0.17025412619113922\n",
      "Batch 1270,  loss: 0.12968548834323884\n",
      "Batch 1275,  loss: 0.2161615490913391\n",
      "Batch 1280,  loss: 0.1538768917322159\n",
      "Batch 1285,  loss: 0.21800418496131896\n",
      "Batch 1290,  loss: 0.1652448743581772\n",
      "Batch 1295,  loss: 0.1512930601835251\n",
      "Batch 1300,  loss: 0.18960571736097337\n",
      "Batch 1305,  loss: 0.1433350622653961\n",
      "Batch 1310,  loss: 0.1610679417848587\n",
      "Batch 1315,  loss: 0.17359951734542847\n",
      "Batch 1320,  loss: 0.14499873518943787\n",
      "Batch 1325,  loss: 0.17383589148521422\n",
      "Batch 1330,  loss: 0.1274091988801956\n",
      "Batch 1335,  loss: 0.1417780727148056\n",
      "Batch 1340,  loss: 0.18241050839424133\n",
      "Batch 1345,  loss: 0.19083437621593474\n",
      "Batch 1350,  loss: 0.19465922862291335\n",
      "Batch 1355,  loss: 0.15147200375795364\n",
      "Batch 1360,  loss: 0.15952170491218567\n",
      "Batch 1365,  loss: 0.18799850046634675\n",
      "Batch 1370,  loss: 0.13209339678287507\n",
      "Batch 1375,  loss: 0.157149101793766\n",
      "Batch 1380,  loss: 0.1641805425286293\n",
      "Batch 1385,  loss: 0.20294994115829468\n",
      "Batch 1390,  loss: 0.11008359342813492\n",
      "Batch 1395,  loss: 0.14882924407720566\n",
      "Batch 1400,  loss: 0.16859701722860337\n",
      "Batch 1405,  loss: 0.13921573758125305\n",
      "Batch 1410,  loss: 0.19154961854219438\n",
      "Batch 1415,  loss: 0.18389833867549896\n",
      "Batch 1420,  loss: 0.1670016184449196\n",
      "Batch 1425,  loss: 0.1594848483800888\n",
      "Batch 1430,  loss: 0.15643162205815314\n",
      "Batch 1435,  loss: 0.13382781594991683\n",
      "Batch 1440,  loss: 0.18466741740703582\n",
      "Batch 1445,  loss: 0.13027009665966033\n",
      "Batch 1450,  loss: 0.13760287463665008\n",
      "Batch 1455,  loss: 0.14375093579292297\n",
      "Batch 1460,  loss: 0.14261920303106307\n",
      "Batch 1465,  loss: 0.1955052763223648\n",
      "Batch 1470,  loss: 0.145347261428833\n",
      "Batch 1475,  loss: 0.2146686851978302\n",
      "Batch 1480,  loss: 0.2115519165992737\n",
      "Batch 1485,  loss: 0.15439150631427764\n",
      "Batch 1490,  loss: 0.19559279978275299\n",
      "Batch 1495,  loss: 0.16370200514793395\n",
      "Batch 1500,  loss: 0.1873646855354309\n",
      "Batch 1505,  loss: 0.15371789336204528\n",
      "Batch 1510,  loss: 0.1577872395515442\n",
      "Batch 1515,  loss: 0.1629262685775757\n",
      "Batch 1520,  loss: 0.14580240994691848\n",
      "Batch 1525,  loss: 0.1795437216758728\n",
      "Batch 1530,  loss: 0.15737438797950745\n",
      "Batch 1535,  loss: 0.18210862576961517\n",
      "Batch 1540,  loss: 0.1408746674656868\n",
      "Batch 1545,  loss: 0.15695105493068695\n",
      "Batch 1550,  loss: 0.19702610075473787\n",
      "Batch 1555,  loss: 0.13356538265943527\n",
      "Batch 1560,  loss: 0.155704165995121\n",
      "Batch 1565,  loss: 0.18205010518431664\n",
      "Batch 1570,  loss: 0.19337964355945586\n",
      "Batch 1575,  loss: 0.17825194001197814\n",
      "Batch 1580,  loss: 0.12228613048791885\n",
      "Batch 1585,  loss: 0.20713827908039092\n",
      "Batch 1590,  loss: 0.15536453425884247\n",
      "Batch 1595,  loss: 0.14331019967794417\n",
      "Batch 1600,  loss: 0.17079300284385682\n",
      "Batch 1605,  loss: 0.14892666935920715\n",
      "Batch 1610,  loss: 0.17908337265253066\n",
      "Batch 1615,  loss: 0.16023869514465333\n",
      "Batch 1620,  loss: 0.16742290258407594\n",
      "Batch 1625,  loss: 0.2014016330242157\n",
      "Batch 1630,  loss: 0.1710865914821625\n",
      "Batch 1635,  loss: 0.2123512417078018\n",
      "Batch 1640,  loss: 0.15863531678915024\n",
      "Batch 1645,  loss: 0.16512677520513536\n",
      "Batch 1650,  loss: 0.1588144302368164\n",
      "Batch 1655,  loss: 0.20680008232593536\n",
      "Batch 1660,  loss: 0.15301588475704192\n",
      "Batch 1665,  loss: 0.1540296584367752\n",
      "Batch 1670,  loss: 0.13937091678380967\n",
      "Batch 1675,  loss: 0.20249539017677307\n",
      "Batch 1680,  loss: 0.19836855232715606\n",
      "Batch 1685,  loss: 0.13187334835529327\n",
      "Batch 1690,  loss: 0.12770163118839264\n",
      "Batch 1695,  loss: 0.22525736391544343\n",
      "Batch 1700,  loss: 0.18589696884155274\n",
      "Batch 1705,  loss: 0.1746157079935074\n",
      "Batch 1710,  loss: 0.17401297390460968\n",
      "Batch 1715,  loss: 0.18916338980197905\n",
      "Batch 1720,  loss: 0.21383141875267028\n",
      "Batch 1725,  loss: 0.1525189161300659\n",
      "Batch 1730,  loss: 0.1971471220254898\n",
      "Batch 1735,  loss: 0.14902147948741912\n",
      "Batch 1740,  loss: 0.17377932071685792\n",
      "Batch 1745,  loss: 0.18210191428661346\n",
      "Batch 1750,  loss: 0.1752559795975685\n",
      "Batch 1755,  loss: 0.2170535922050476\n",
      "Batch 1760,  loss: 0.16831082999706268\n",
      "Batch 1765,  loss: 0.15656015574932097\n",
      "Batch 1770,  loss: 0.19065776467323303\n",
      "Batch 1775,  loss: 0.13085425198078154\n",
      "Batch 1780,  loss: 0.1779184192419052\n",
      "Batch 1785,  loss: 0.16908707618713378\n",
      "Batch 1790,  loss: 0.18450642228126526\n",
      "Batch 1795,  loss: 0.15629127919673919\n",
      "Batch 1800,  loss: 0.19167769849300384\n",
      "Batch 1805,  loss: 0.18221277594566346\n",
      "Batch 1810,  loss: 0.15593241751194\n",
      "Batch 1815,  loss: 0.1645740032196045\n",
      "Batch 1820,  loss: 0.16145175695419312\n",
      "Batch 1825,  loss: 0.16128987669944764\n",
      "Batch 1830,  loss: 0.17021421790122987\n",
      "Batch 1835,  loss: 0.16446920335292817\n",
      "Batch 1840,  loss: 0.17681384086608887\n",
      "Batch 1845,  loss: 0.1381077289581299\n",
      "Batch 1850,  loss: 0.13629592806100846\n",
      "Batch 1855,  loss: 0.19375220239162444\n",
      "Batch 1860,  loss: 0.1655573844909668\n",
      "Batch 1865,  loss: 0.1594596117734909\n",
      "Batch 1870,  loss: 0.15495658218860625\n",
      "Batch 1875,  loss: 0.18027113378047943\n",
      "Batch 1880,  loss: 0.1847478359937668\n",
      "Batch 1885,  loss: 0.14772602319717407\n",
      "Batch 1890,  loss: 0.16958414614200593\n",
      "Batch 1895,  loss: 0.14858680367469787\n",
      "Batch 1900,  loss: 0.13693420737981796\n",
      "Batch 1905,  loss: 0.15066002309322357\n",
      "Batch 1910,  loss: 0.1819458693265915\n",
      "Batch 1915,  loss: 0.16409476697444916\n",
      "Batch 1920,  loss: 0.15576874911785127\n",
      "Batch 1925,  loss: 0.14522575587034225\n",
      "Batch 1930,  loss: 0.15998345911502837\n",
      "Batch 1935,  loss: 0.1811947375535965\n",
      "Batch 1940,  loss: 0.19195001125335692\n",
      "Batch 1945,  loss: 0.17083594501018523\n",
      "Batch 1950,  loss: 0.13057741522789001\n",
      "Batch 1955,  loss: 0.12733108997344972\n",
      "Batch 1960,  loss: 0.16189038157463073\n",
      "Batch 1965,  loss: 0.19825674891471862\n",
      "Batch 1970,  loss: 0.15242241621017455\n",
      "Batch 1975,  loss: 0.1381859302520752\n",
      "Batch 1980,  loss: 0.21107274740934373\n",
      "Batch 1985,  loss: 0.14985601007938384\n",
      "Batch 1990,  loss: 0.17201557755470276\n",
      "Batch 1995,  loss: 0.19329432547092437\n",
      "Batch 2000,  loss: 0.17995304614305496\n",
      "Batch 2005,  loss: 0.15007042586803437\n",
      "Batch 2010,  loss: 0.15467246174812316\n",
      "Batch 2015,  loss: 0.11534596234560013\n",
      "Batch 2020,  loss: 0.19929092526435851\n",
      "Batch 2025,  loss: 0.14784812182188034\n",
      "Batch 2030,  loss: 0.14175000935792922\n",
      "Batch 2035,  loss: 0.15462875366210938\n",
      "Batch 2040,  loss: 0.1330495908856392\n",
      "Batch 2045,  loss: 0.15603585988283158\n",
      "Batch 2050,  loss: 0.1436552032828331\n",
      "Batch 2055,  loss: 0.1734016388654709\n",
      "Batch 2060,  loss: 0.15749820768833162\n",
      "Batch 2065,  loss: 0.13627552092075348\n",
      "Batch 2070,  loss: 0.1811099112033844\n",
      "Batch 2075,  loss: 0.15385644882917404\n",
      "Batch 2080,  loss: 0.13487051725387572\n",
      "Batch 2085,  loss: 0.21117416620254517\n",
      "Batch 2090,  loss: 0.150930018723011\n",
      "Batch 2095,  loss: 0.2062013790011406\n",
      "Batch 2100,  loss: 0.2169601172208786\n",
      "Batch 2105,  loss: 0.21788397133350373\n",
      "Batch 2110,  loss: 0.17947594821453094\n",
      "Batch 2115,  loss: 0.12588071078062057\n",
      "Batch 2120,  loss: 0.16105979681015015\n",
      "Batch 2125,  loss: 0.1882130831480026\n",
      "Batch 2130,  loss: 0.20983998030424117\n",
      "Batch 2135,  loss: 0.14776573777198793\n",
      "Batch 2140,  loss: 0.14026205688714982\n",
      "Batch 2145,  loss: 0.18985306918621064\n",
      "Batch 2150,  loss: 0.17938205003738403\n",
      "Batch 2155,  loss: 0.14721845984458923\n",
      "Batch 2160,  loss: 0.12863149493932724\n",
      "Batch 2165,  loss: 0.13887741565704345\n",
      "Batch 2170,  loss: 0.19713162779808044\n",
      "Batch 2175,  loss: 0.17398190796375274\n",
      "Batch 2180,  loss: 0.20173495411872863\n",
      "Batch 2185,  loss: 0.16404570639133453\n",
      "Batch 2190,  loss: 0.1654801994562149\n",
      "Batch 2195,  loss: 0.1743869110941887\n",
      "Batch 2200,  loss: 0.12312238663434982\n",
      "Batch 2205,  loss: 0.18654421269893645\n",
      "Batch 2210,  loss: 0.14919762313365936\n",
      "Batch 2215,  loss: 0.1902379035949707\n",
      "Batch 2220,  loss: 0.15836676955223083\n",
      "Batch 2225,  loss: 0.17955815196037292\n",
      "Batch 2230,  loss: 0.2430833101272583\n",
      "Batch 2235,  loss: 0.16563552618026733\n",
      "Batch 2240,  loss: 0.17308966517448426\n",
      "Batch 2245,  loss: 0.17030635476112366\n",
      "Batch 2250,  loss: 0.15606721192598344\n",
      "Batch 2255,  loss: 0.21589449942111968\n",
      "Batch 2260,  loss: 0.18717384487390518\n",
      "Batch 2265,  loss: 0.22634637951850892\n",
      "Batch 2270,  loss: 0.14751133024692537\n",
      "Batch 2275,  loss: 0.13094803392887117\n",
      "Batch 2280,  loss: 0.18369064927101136\n",
      "Batch 2285,  loss: 0.1574171870946884\n",
      "Batch 2290,  loss: 0.19289092421531678\n",
      "Batch 2295,  loss: 0.19907489120960237\n",
      "Batch 2300,  loss: 0.16381272971630095\n",
      "Batch 2305,  loss: 0.1400063157081604\n",
      "Batch 2310,  loss: 0.16257520616054535\n",
      "Batch 2315,  loss: 0.16077656149864197\n",
      "Batch 2320,  loss: 0.16139740943908693\n",
      "Batch 2325,  loss: 0.16281510293483734\n",
      "Batch 2330,  loss: 0.1931035801768303\n",
      "Batch 2335,  loss: 0.19698053896427153\n",
      "Batch 2340,  loss: 0.1883576214313507\n",
      "Batch 2345,  loss: 0.18163964301347732\n",
      "Batch 2350,  loss: 0.19067065566778182\n",
      "Batch 2355,  loss: 0.2037154585123062\n",
      "Batch 2360,  loss: 0.150248284637928\n",
      "Batch 2365,  loss: 0.16088116765022278\n",
      "Batch 2370,  loss: 0.17695055902004242\n",
      "Batch 2375,  loss: 0.19201138913631438\n",
      "Batch 2380,  loss: 0.1287777066230774\n",
      "Batch 2385,  loss: 0.19117820262908936\n",
      "Batch 2390,  loss: 0.18646207451820374\n",
      "Batch 2395,  loss: 0.1251738488674164\n",
      "Batch 2400,  loss: 0.16899046748876573\n",
      "Batch 2405,  loss: 0.16431443840265275\n",
      "Batch 2410,  loss: 0.15766699314117433\n",
      "Batch 2415,  loss: 0.21597540974617005\n",
      "Batch 2420,  loss: 0.2012111097574234\n",
      "Batch 2425,  loss: 0.1795122042298317\n",
      "Batch 2430,  loss: 0.15234901309013366\n",
      "Batch 2435,  loss: 0.1661614626646042\n",
      "Batch 2440,  loss: 0.14072296023368835\n",
      "Batch 2445,  loss: 0.18304366916418074\n",
      "Batch 2450,  loss: 0.1491523876786232\n",
      "Batch 2455,  loss: 0.1563820332288742\n",
      "Batch 2460,  loss: 0.12630708366632462\n",
      "Batch 2465,  loss: 0.15183919221162795\n",
      "Batch 2470,  loss: 0.15395234525203705\n",
      "Batch 2475,  loss: 0.16625799834728242\n",
      "Batch 2480,  loss: 0.15807842016220092\n",
      "Batch 2485,  loss: 0.169534569978714\n",
      "Batch 2490,  loss: 0.14787469208240508\n",
      "Batch 2495,  loss: 0.1931620180606842\n",
      "Batch 2500,  loss: 0.15582067370414734\n",
      "Batch 2505,  loss: 0.15204329788684845\n",
      "Batch 2510,  loss: 0.1406358778476715\n",
      "Batch 2515,  loss: 0.20392653048038484\n",
      "Batch 2520,  loss: 0.19467901289463044\n",
      "Batch 2525,  loss: 0.180584354698658\n",
      "Batch 2530,  loss: 0.15323029458522797\n",
      "Batch 2535,  loss: 0.14706864058971406\n",
      "Batch 2540,  loss: 0.15127542316913606\n",
      "Batch 2545,  loss: 0.13570794463157654\n",
      "Batch 2550,  loss: 0.19186532199382783\n",
      "Batch 2555,  loss: 0.18796591311693192\n",
      "Batch 2560,  loss: 0.1843131184577942\n",
      "Batch 2565,  loss: 0.16741399914026261\n",
      "Batch 2570,  loss: 0.16022901833057404\n",
      "Batch 2575,  loss: 0.1516200765967369\n",
      "Batch 2580,  loss: 0.11479226499795914\n",
      "Batch 2585,  loss: 0.2151058167219162\n",
      "Batch 2590,  loss: 0.15196304321289061\n",
      "Batch 2595,  loss: 0.16411827951669694\n",
      "Batch 2600,  loss: 0.21557332277297975\n",
      "Batch 2605,  loss: 0.20468003153800965\n",
      "Batch 2610,  loss: 0.16589232087135314\n",
      "Batch 2615,  loss: 0.12831954956054686\n",
      "Batch 2620,  loss: 0.13692553341388702\n",
      "Batch 2625,  loss: 0.14857357144355773\n",
      "Batch 2630,  loss: 0.16083896309137344\n",
      "Batch 2635,  loss: 0.1704043909907341\n",
      "Batch 2640,  loss: 0.15292589813470842\n",
      "Batch 2645,  loss: 0.16244138777256012\n",
      "Batch 2650,  loss: 0.1487748831510544\n",
      "Batch 2655,  loss: 0.17186692506074905\n",
      "Batch 2660,  loss: 0.13971458673477172\n",
      "Batch 2665,  loss: 0.16953330039978026\n",
      "Batch 2670,  loss: 0.16474489271640777\n",
      "Batch 2675,  loss: 0.1631637379527092\n",
      "Batch 2680,  loss: 0.16760696172714235\n",
      "Batch 2685,  loss: 0.1603389412164688\n",
      "Batch 2690,  loss: 0.17618148922920226\n",
      "Batch 2695,  loss: 0.22804129719734192\n",
      "Batch 2700,  loss: 0.16337321549654008\n",
      "Batch 2705,  loss: 0.18884755969047545\n",
      "Batch 2710,  loss: 0.14789435118436814\n",
      "Batch 2715,  loss: 0.12873246222734452\n",
      "Batch 2720,  loss: 0.17408813536167145\n",
      "Batch 2725,  loss: 0.17673459351062776\n",
      "Batch 2730,  loss: 0.14023648351430892\n",
      "Batch 2735,  loss: 0.18382700383663178\n",
      "Batch 2740,  loss: 0.22578816413879393\n",
      "Batch 2745,  loss: 0.16729941666126252\n",
      "Batch 2750,  loss: 0.1877707600593567\n",
      "Batch 2755,  loss: 0.15815051048994064\n",
      "Batch 2760,  loss: 0.18202556371688844\n",
      "Batch 2765,  loss: 0.18458082973957063\n",
      "Batch 2770,  loss: 0.14513039588928223\n",
      "LOSS train 0.14513039588928223. Validation loss: 0.16349322783708986 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 23:\n",
      "Batch 5,  loss: 0.20301568806171416\n",
      "Batch 10,  loss: 0.1834645003080368\n",
      "Batch 15,  loss: 0.16357387602329254\n",
      "Batch 20,  loss: 0.16810550093650817\n",
      "Batch 25,  loss: 0.11553703099489213\n",
      "Batch 30,  loss: 0.16266539096832275\n",
      "Batch 35,  loss: 0.15468167066574096\n",
      "Batch 40,  loss: 0.1781114876270294\n",
      "Batch 45,  loss: 0.15641015619039536\n",
      "Batch 50,  loss: 0.17062275856733322\n",
      "Batch 55,  loss: 0.14210808873176575\n",
      "Batch 60,  loss: 0.17871960550546645\n",
      "Batch 65,  loss: 0.1287437617778778\n",
      "Batch 70,  loss: 0.1772278815507889\n",
      "Batch 75,  loss: 0.14510838985443114\n",
      "Batch 80,  loss: 0.20107088088989258\n",
      "Batch 85,  loss: 0.17979002594947815\n",
      "Batch 90,  loss: 0.1274028465151787\n",
      "Batch 95,  loss: 0.162112495303154\n",
      "Batch 100,  loss: 0.14936104863882066\n",
      "Batch 105,  loss: 0.1482580319046974\n",
      "Batch 110,  loss: 0.17363171428442\n",
      "Batch 115,  loss: 0.1848958760499954\n",
      "Batch 120,  loss: 0.14861665815114974\n",
      "Batch 125,  loss: 0.21877619624137878\n",
      "Batch 130,  loss: 0.19589048624038696\n",
      "Batch 135,  loss: 0.242843297123909\n",
      "Batch 140,  loss: 0.15826352387666703\n",
      "Batch 145,  loss: 0.16259749829769135\n",
      "Batch 150,  loss: 0.16439070403575898\n",
      "Batch 155,  loss: 0.17594914734363556\n",
      "Batch 160,  loss: 0.15745028853416443\n",
      "Batch 165,  loss: 0.17760876417160035\n",
      "Batch 170,  loss: 0.12863595634698868\n",
      "Batch 175,  loss: 0.14047334343194962\n",
      "Batch 180,  loss: 0.18538513779640198\n",
      "Batch 185,  loss: 0.14286217093467712\n",
      "Batch 190,  loss: 0.16301027536392212\n",
      "Batch 195,  loss: 0.15529497861862182\n",
      "Batch 200,  loss: 0.14139440804719924\n",
      "Batch 205,  loss: 0.15049077272415162\n",
      "Batch 210,  loss: 0.16936541199684144\n",
      "Batch 215,  loss: 0.16335113644599913\n",
      "Batch 220,  loss: 0.14951995462179185\n",
      "Batch 225,  loss: 0.15651517659425734\n",
      "Batch 230,  loss: 0.16091272681951524\n",
      "Batch 235,  loss: 0.1651548594236374\n",
      "Batch 240,  loss: 0.1632021486759186\n",
      "Batch 245,  loss: 0.1419910967350006\n",
      "Batch 250,  loss: 0.16798013001680373\n",
      "Batch 255,  loss: 0.20694243907928467\n",
      "Batch 260,  loss: 0.15313046127557756\n",
      "Batch 265,  loss: 0.20038961470127106\n",
      "Batch 270,  loss: 0.17313313782215117\n",
      "Batch 275,  loss: 0.175360806286335\n",
      "Batch 280,  loss: 0.14234846383333205\n",
      "Batch 285,  loss: 0.16704495251178741\n",
      "Batch 290,  loss: 0.1496883749961853\n",
      "Batch 295,  loss: 0.13803558200597763\n",
      "Batch 300,  loss: 0.1504335507750511\n",
      "Batch 305,  loss: 0.16786790937185286\n",
      "Batch 310,  loss: 0.1920618787407875\n",
      "Batch 315,  loss: 0.1531560868024826\n",
      "Batch 320,  loss: 0.15844601690769194\n",
      "Batch 325,  loss: 0.14818537831306458\n",
      "Batch 330,  loss: 0.1343100056052208\n",
      "Batch 335,  loss: 0.15490728616714478\n",
      "Batch 340,  loss: 0.15897279381752014\n",
      "Batch 345,  loss: 0.13075532913208007\n",
      "Batch 350,  loss: 0.18281942307949067\n",
      "Batch 355,  loss: 0.16834711730480195\n",
      "Batch 360,  loss: 0.146038718521595\n",
      "Batch 365,  loss: 0.18376264572143555\n",
      "Batch 370,  loss: 0.1644163504242897\n",
      "Batch 375,  loss: 0.18608387112617492\n",
      "Batch 380,  loss: 0.15202786773443222\n",
      "Batch 385,  loss: 0.13818085938692093\n",
      "Batch 390,  loss: 0.15577893257141112\n",
      "Batch 395,  loss: 0.14482304751873015\n",
      "Batch 400,  loss: 0.16435494124889374\n",
      "Batch 405,  loss: 0.15848260521888732\n",
      "Batch 410,  loss: 0.22176264077425004\n",
      "Batch 415,  loss: 0.16316254436969757\n",
      "Batch 420,  loss: 0.14565746039152144\n",
      "Batch 425,  loss: 0.14349515736103058\n",
      "Batch 430,  loss: 0.1954899847507477\n",
      "Batch 435,  loss: 0.18770463168621063\n",
      "Batch 440,  loss: 0.18363125026226043\n",
      "Batch 445,  loss: 0.11552752554416656\n",
      "Batch 450,  loss: 0.19482173323631286\n",
      "Batch 455,  loss: 0.1954775035381317\n",
      "Batch 460,  loss: 0.1502092719078064\n",
      "Batch 465,  loss: 0.14576648473739623\n",
      "Batch 470,  loss: 0.15052207857370375\n",
      "Batch 475,  loss: 0.14523902535438538\n",
      "Batch 480,  loss: 0.13699089288711547\n",
      "Batch 485,  loss: 0.19518536627292632\n",
      "Batch 490,  loss: 0.13487826585769652\n",
      "Batch 495,  loss: 0.1895614504814148\n",
      "Batch 500,  loss: 0.17295235246419907\n",
      "Batch 505,  loss: 0.20644595324993134\n",
      "Batch 510,  loss: 0.16196370124816895\n",
      "Batch 515,  loss: 0.14724981784820557\n",
      "Batch 520,  loss: 0.17958040833473204\n",
      "Batch 525,  loss: 0.16402293145656585\n",
      "Batch 530,  loss: 0.17187452018260957\n",
      "Batch 535,  loss: 0.15609175860881805\n",
      "Batch 540,  loss: 0.15124132633209228\n",
      "Batch 545,  loss: 0.17200059890747071\n",
      "Batch 550,  loss: 0.16380041539669038\n",
      "Batch 555,  loss: 0.19999927878379822\n",
      "Batch 560,  loss: 0.15467021316289903\n",
      "Batch 565,  loss: 0.13813792020082474\n",
      "Batch 570,  loss: 0.1408016189932823\n",
      "Batch 575,  loss: 0.20111128687858582\n",
      "Batch 580,  loss: 0.14083377569913863\n",
      "Batch 585,  loss: 0.14758092015981675\n",
      "Batch 590,  loss: 0.1728547528386116\n",
      "Batch 595,  loss: 0.13713885396718978\n",
      "Batch 600,  loss: 0.13719631731510162\n",
      "Batch 605,  loss: 0.16550566852092743\n",
      "Batch 610,  loss: 0.1902856022119522\n",
      "Batch 615,  loss: 0.14115290939807892\n",
      "Batch 620,  loss: 0.18047442138195038\n",
      "Batch 625,  loss: 0.2066540777683258\n",
      "Batch 630,  loss: 0.1263173609972\n",
      "Batch 635,  loss: 0.2162384122610092\n",
      "Batch 640,  loss: 0.1677486330270767\n",
      "Batch 645,  loss: 0.13379729688167571\n",
      "Batch 650,  loss: 0.14577812254428862\n",
      "Batch 655,  loss: 0.15180556178092958\n",
      "Batch 660,  loss: 0.19200871884822845\n",
      "Batch 665,  loss: 0.18266991525888443\n",
      "Batch 670,  loss: 0.17485967874526978\n",
      "Batch 675,  loss: 0.18910238593816758\n",
      "Batch 680,  loss: 0.15805224776268006\n",
      "Batch 685,  loss: 0.17464019358158112\n",
      "Batch 690,  loss: 0.1638581395149231\n",
      "Batch 695,  loss: 0.19963428974151612\n",
      "Batch 700,  loss: 0.1751990497112274\n",
      "Batch 705,  loss: 0.17180530428886415\n",
      "Batch 710,  loss: 0.18636534512043\n",
      "Batch 715,  loss: 0.15878803730010987\n",
      "Batch 720,  loss: 0.19005816280841828\n",
      "Batch 725,  loss: 0.17226099371910095\n",
      "Batch 730,  loss: 0.144571952521801\n",
      "Batch 735,  loss: 0.17627822309732438\n",
      "Batch 740,  loss: 0.17924775779247284\n",
      "Batch 745,  loss: 0.13540713042020797\n",
      "Batch 750,  loss: 0.18930940628051757\n",
      "Batch 755,  loss: 0.1419869288802147\n",
      "Batch 760,  loss: 0.16375702023506164\n",
      "Batch 765,  loss: 0.1176365077495575\n",
      "Batch 770,  loss: 0.15976310074329375\n",
      "Batch 775,  loss: 0.19818633794784546\n",
      "Batch 780,  loss: 0.13876560926437378\n",
      "Batch 785,  loss: 0.12199386060237885\n",
      "Batch 790,  loss: 0.1807636260986328\n",
      "Batch 795,  loss: 0.16135531961917876\n",
      "Batch 800,  loss: 0.21908954232931138\n",
      "Batch 805,  loss: 0.17140989303588866\n",
      "Batch 810,  loss: 0.1918491780757904\n",
      "Batch 815,  loss: 0.12293237000703812\n",
      "Batch 820,  loss: 0.14612142145633697\n",
      "Batch 825,  loss: 0.15924381017684935\n",
      "Batch 830,  loss: 0.17178595662117005\n",
      "Batch 835,  loss: 0.14978980422019958\n",
      "Batch 840,  loss: 0.15140804648399353\n",
      "Batch 845,  loss: 0.18283694386482238\n",
      "Batch 850,  loss: 0.13811641931533813\n",
      "Batch 855,  loss: 0.152576807141304\n",
      "Batch 860,  loss: 0.20395196080207825\n",
      "Batch 865,  loss: 0.2018752723932266\n",
      "Batch 870,  loss: 0.17047515511512756\n",
      "Batch 875,  loss: 0.18265055269002914\n",
      "Batch 880,  loss: 0.1748798444867134\n",
      "Batch 885,  loss: 0.18693801164627075\n",
      "Batch 890,  loss: 0.11632500141859055\n",
      "Batch 895,  loss: 0.14876696616411209\n",
      "Batch 900,  loss: 0.19050511717796326\n",
      "Batch 905,  loss: 0.18024241626262666\n",
      "Batch 910,  loss: 0.1609708324074745\n",
      "Batch 915,  loss: 0.12579275369644166\n",
      "Batch 920,  loss: 0.1475329041481018\n",
      "Batch 925,  loss: 0.15275223851203917\n",
      "Batch 930,  loss: 0.150028994679451\n",
      "Batch 935,  loss: 0.1623198062181473\n",
      "Batch 940,  loss: 0.13858035802841187\n",
      "Batch 945,  loss: 0.1897977739572525\n",
      "Batch 950,  loss: 0.18717632293701172\n",
      "Batch 955,  loss: 0.1502862513065338\n",
      "Batch 960,  loss: 0.17319618165493011\n",
      "Batch 965,  loss: 0.16883707344532012\n",
      "Batch 970,  loss: 0.15686416923999785\n",
      "Batch 975,  loss: 0.14988427311182023\n",
      "Batch 980,  loss: 0.18739513903856278\n",
      "Batch 985,  loss: 0.15371154695749284\n",
      "Batch 990,  loss: 0.13332124203443527\n",
      "Batch 995,  loss: 0.2195828825235367\n",
      "Batch 1000,  loss: 0.14711526036262512\n",
      "Batch 1005,  loss: 0.19019430875778198\n",
      "Batch 1010,  loss: 0.12826706171035768\n",
      "Batch 1015,  loss: 0.19027695953845977\n",
      "Batch 1020,  loss: 0.19574854671955108\n",
      "Batch 1025,  loss: 0.18823327869176865\n",
      "Batch 1030,  loss: 0.14932952225208282\n",
      "Batch 1035,  loss: 0.19796192944049834\n",
      "Batch 1040,  loss: 0.15988589227199554\n",
      "Batch 1045,  loss: 0.16679012179374694\n",
      "Batch 1050,  loss: 0.18505025804042816\n",
      "Batch 1055,  loss: 0.17783803641796112\n",
      "Batch 1060,  loss: 0.13912082761526107\n",
      "Batch 1065,  loss: 0.17902376502752304\n",
      "Batch 1070,  loss: 0.17677030265331267\n",
      "Batch 1075,  loss: 0.1775545746088028\n",
      "Batch 1080,  loss: 0.16797513961791993\n",
      "Batch 1085,  loss: 0.23000326454639436\n",
      "Batch 1090,  loss: 0.22387094497680665\n",
      "Batch 1095,  loss: 0.11701389253139496\n",
      "Batch 1100,  loss: 0.17348008304834367\n",
      "Batch 1105,  loss: 0.1299224779009819\n",
      "Batch 1110,  loss: 0.1923880785703659\n",
      "Batch 1115,  loss: 0.15255849361419677\n",
      "Batch 1120,  loss: 0.13706914186477662\n",
      "Batch 1125,  loss: 0.1632300078868866\n",
      "Batch 1130,  loss: 0.14615233838558198\n",
      "Batch 1135,  loss: 0.15151010751724242\n",
      "Batch 1140,  loss: 0.19935239851474762\n",
      "Batch 1145,  loss: 0.1481127545237541\n",
      "Batch 1150,  loss: 0.18121320456266404\n",
      "Batch 1155,  loss: 0.13272578716278077\n",
      "Batch 1160,  loss: 0.1669560581445694\n",
      "Batch 1165,  loss: 0.19737998843193055\n",
      "Batch 1170,  loss: 0.21454420685768127\n",
      "Batch 1175,  loss: 0.20780754387378692\n",
      "Batch 1180,  loss: 0.15779446363449096\n",
      "Batch 1185,  loss: 0.22277696132659913\n",
      "Batch 1190,  loss: 0.1567297726869583\n",
      "Batch 1195,  loss: 0.1413838878273964\n",
      "Batch 1200,  loss: 0.18404185473918916\n",
      "Batch 1205,  loss: 0.1703239530324936\n",
      "Batch 1210,  loss: 0.14751549661159516\n",
      "Batch 1215,  loss: 0.19220964312553407\n",
      "Batch 1220,  loss: 0.18424250483512877\n",
      "Batch 1225,  loss: 0.1934904783964157\n",
      "Batch 1230,  loss: 0.14815940111875534\n",
      "Batch 1235,  loss: 0.16493725776672363\n",
      "Batch 1240,  loss: 0.17090273648500443\n",
      "Batch 1245,  loss: 0.1749384492635727\n",
      "Batch 1250,  loss: 0.178014275431633\n",
      "Batch 1255,  loss: 0.17862120866775513\n",
      "Batch 1260,  loss: 0.15355420410633086\n",
      "Batch 1265,  loss: 0.17272422313690186\n",
      "Batch 1270,  loss: 0.13811035454273224\n",
      "Batch 1275,  loss: 0.17016232311725615\n",
      "Batch 1280,  loss: 0.15030595511198044\n",
      "Batch 1285,  loss: 0.1453627049922943\n",
      "Batch 1290,  loss: 0.18913906216621398\n",
      "Batch 1295,  loss: 0.17689213752746583\n",
      "Batch 1300,  loss: 0.14140355885028838\n",
      "Batch 1305,  loss: 0.1211685597896576\n",
      "Batch 1310,  loss: 0.2087465927004814\n",
      "Batch 1315,  loss: 0.15756853222846984\n",
      "Batch 1320,  loss: 0.16664245426654817\n",
      "Batch 1325,  loss: 0.17074942886829375\n",
      "Batch 1330,  loss: 0.1921165555715561\n",
      "Batch 1335,  loss: 0.1674521952867508\n",
      "Batch 1340,  loss: 0.16839131265878676\n",
      "Batch 1345,  loss: 0.1946593552827835\n",
      "Batch 1350,  loss: 0.16257947385311128\n",
      "Batch 1355,  loss: 0.14069672524929047\n",
      "Batch 1360,  loss: 0.20601581335067748\n",
      "Batch 1365,  loss: 0.1606665939092636\n",
      "Batch 1370,  loss: 0.14553409665822983\n",
      "Batch 1375,  loss: 0.1772782936692238\n",
      "Batch 1380,  loss: 0.16376768797636032\n",
      "Batch 1385,  loss: 0.15003739595413207\n",
      "Batch 1390,  loss: 0.1404981419444084\n",
      "Batch 1395,  loss: 0.17215791046619416\n",
      "Batch 1400,  loss: 0.14795362800359727\n",
      "Batch 1405,  loss: 0.13885759115219115\n",
      "Batch 1410,  loss: 0.14293626248836516\n",
      "Batch 1415,  loss: 0.17541743516921998\n",
      "Batch 1420,  loss: 0.13777133524417878\n",
      "Batch 1425,  loss: 0.12706658840179444\n",
      "Batch 1430,  loss: 0.16530635803937913\n",
      "Batch 1435,  loss: 0.11718167662620545\n",
      "Batch 1440,  loss: 0.19284620881080627\n",
      "Batch 1445,  loss: 0.19189119040966035\n",
      "Batch 1450,  loss: 0.19187437891960143\n",
      "Batch 1455,  loss: 0.1473462089896202\n",
      "Batch 1460,  loss: 0.16547224670648575\n",
      "Batch 1465,  loss: 0.15338100790977477\n",
      "Batch 1470,  loss: 0.15076013505458832\n",
      "Batch 1475,  loss: 0.1309633105993271\n",
      "Batch 1480,  loss: 0.15858249813318254\n",
      "Batch 1485,  loss: 0.17118658721446992\n",
      "Batch 1490,  loss: 0.15379849821329117\n",
      "Batch 1495,  loss: 0.15752961486577988\n",
      "Batch 1500,  loss: 0.14306294471025466\n",
      "Batch 1505,  loss: 0.14751923084259033\n",
      "Batch 1510,  loss: 0.16312181055545807\n",
      "Batch 1515,  loss: 0.21995851397514343\n",
      "Batch 1520,  loss: 0.1998294472694397\n",
      "Batch 1525,  loss: 0.14024808406829833\n",
      "Batch 1530,  loss: 0.17948891818523408\n",
      "Batch 1535,  loss: 0.15107895135879518\n",
      "Batch 1540,  loss: 0.13385530412197114\n",
      "Batch 1545,  loss: 0.1449555993080139\n",
      "Batch 1550,  loss: 0.197812420129776\n",
      "Batch 1555,  loss: 0.22172966599464417\n",
      "Batch 1560,  loss: 0.18370505273342133\n",
      "Batch 1565,  loss: 0.1562773123383522\n",
      "Batch 1570,  loss: 0.17965826392173767\n",
      "Batch 1575,  loss: 0.15473536103963853\n",
      "Batch 1580,  loss: 0.15071651935577393\n",
      "Batch 1585,  loss: 0.14452641308307648\n",
      "Batch 1590,  loss: 0.17143514156341552\n",
      "Batch 1595,  loss: 0.18517932891845704\n",
      "Batch 1600,  loss: 0.16978228986263275\n",
      "Batch 1605,  loss: 0.19558065831661225\n",
      "Batch 1610,  loss: 0.1627138927578926\n",
      "Batch 1615,  loss: 0.1553306758403778\n",
      "Batch 1620,  loss: 0.17588284611701965\n",
      "Batch 1625,  loss: 0.19656698107719422\n",
      "Batch 1630,  loss: 0.14604028761386872\n",
      "Batch 1635,  loss: 0.18499508649110794\n",
      "Batch 1640,  loss: 0.19309649765491485\n",
      "Batch 1645,  loss: 0.1601278230547905\n",
      "Batch 1650,  loss: 0.14803368151187896\n",
      "Batch 1655,  loss: 0.17552025914192199\n",
      "Batch 1660,  loss: 0.1766616478562355\n",
      "Batch 1665,  loss: 0.15906890034675597\n",
      "Batch 1670,  loss: 0.1564176231622696\n",
      "Batch 1675,  loss: 0.18192526400089265\n",
      "Batch 1680,  loss: 0.17034777849912644\n",
      "Batch 1685,  loss: 0.18641951084136962\n",
      "Batch 1690,  loss: 0.16188099086284638\n",
      "Batch 1695,  loss: 0.21054586470127107\n",
      "Batch 1700,  loss: 0.17690775394439698\n",
      "Batch 1705,  loss: 0.19683263599872589\n",
      "Batch 1710,  loss: 0.1847127079963684\n",
      "Batch 1715,  loss: 0.1530402809381485\n",
      "Batch 1720,  loss: 0.17875059843063354\n",
      "Batch 1725,  loss: 0.1469055324792862\n",
      "Batch 1730,  loss: 0.16691599488258363\n",
      "Batch 1735,  loss: 0.16930228769779204\n",
      "Batch 1740,  loss: 0.10487845093011856\n",
      "Batch 1745,  loss: 0.15240821242332458\n",
      "Batch 1750,  loss: 0.18672824949026107\n",
      "Batch 1755,  loss: 0.1522013232111931\n",
      "Batch 1760,  loss: 0.1471303731203079\n",
      "Batch 1765,  loss: 0.16464600265026091\n",
      "Batch 1770,  loss: 0.18524637073278427\n",
      "Batch 1775,  loss: 0.20092312395572662\n",
      "Batch 1780,  loss: 0.1647622287273407\n",
      "Batch 1785,  loss: 0.16364509612321854\n",
      "Batch 1790,  loss: 0.1587577074766159\n",
      "Batch 1795,  loss: 0.14808995127677918\n",
      "Batch 1800,  loss: 0.1904132753610611\n",
      "Batch 1805,  loss: 0.15070659965276717\n",
      "Batch 1810,  loss: 0.14932140707969666\n",
      "Batch 1815,  loss: 0.20277722775936127\n",
      "Batch 1820,  loss: 0.14102806746959687\n",
      "Batch 1825,  loss: 0.15367359668016434\n",
      "Batch 1830,  loss: 0.17710170149803162\n",
      "Batch 1835,  loss: 0.16623497903347015\n",
      "Batch 1840,  loss: 0.20555693209171294\n",
      "Batch 1845,  loss: 0.1508351057767868\n",
      "Batch 1850,  loss: 0.15727909207344054\n",
      "Batch 1855,  loss: 0.13724958002567292\n",
      "Batch 1860,  loss: 0.15930616855621338\n",
      "Batch 1865,  loss: 0.14376720041036606\n",
      "Batch 1870,  loss: 0.176456281542778\n",
      "Batch 1875,  loss: 0.19528739601373674\n",
      "Batch 1880,  loss: 0.15208799988031388\n",
      "Batch 1885,  loss: 0.1604658454656601\n",
      "Batch 1890,  loss: 0.18639975786209106\n",
      "Batch 1895,  loss: 0.20163699984550476\n",
      "Batch 1900,  loss: 0.15682876259088516\n",
      "Batch 1905,  loss: 0.17495364099740982\n",
      "Batch 1910,  loss: 0.14271533787250518\n",
      "Batch 1915,  loss: 0.1770357072353363\n",
      "Batch 1920,  loss: 0.17601874172687532\n",
      "Batch 1925,  loss: 0.1298043578863144\n",
      "Batch 1930,  loss: 0.1781284272670746\n",
      "Batch 1935,  loss: 0.16122620105743407\n",
      "Batch 1940,  loss: 0.16730656623840331\n",
      "Batch 1945,  loss: 0.20444744527339936\n",
      "Batch 1950,  loss: 0.16493733525276183\n",
      "Batch 1955,  loss: 0.13258745521306992\n",
      "Batch 1960,  loss: 0.1872816801071167\n",
      "Batch 1965,  loss: 0.2296270877122879\n",
      "Batch 1970,  loss: 0.19306284785270691\n",
      "Batch 1975,  loss: 0.14383302330970765\n",
      "Batch 1980,  loss: 0.18461856245994568\n",
      "Batch 1985,  loss: 0.1795631468296051\n",
      "Batch 1990,  loss: 0.13274033218622208\n",
      "Batch 1995,  loss: 0.19601064622402192\n",
      "Batch 2000,  loss: 0.1978587031364441\n",
      "Batch 2005,  loss: 0.1756494253873825\n",
      "Batch 2010,  loss: 0.17813528031110765\n",
      "Batch 2015,  loss: 0.14475659430027008\n",
      "Batch 2020,  loss: 0.18988037705421448\n",
      "Batch 2025,  loss: 0.19687871932983397\n",
      "Batch 2030,  loss: 0.18063198029994965\n",
      "Batch 2035,  loss: 0.20936741828918456\n",
      "Batch 2040,  loss: 0.20724891126155853\n",
      "Batch 2045,  loss: 0.15951019823551177\n",
      "Batch 2050,  loss: 0.15946633219718934\n",
      "Batch 2055,  loss: 0.1443811312317848\n",
      "Batch 2060,  loss: 0.1620363712310791\n",
      "Batch 2065,  loss: 0.19166003167629242\n",
      "Batch 2070,  loss: 0.15593150854110718\n",
      "Batch 2075,  loss: 0.18077584207057953\n",
      "Batch 2080,  loss: 0.15460022091865538\n",
      "Batch 2085,  loss: 0.17847182750701904\n",
      "Batch 2090,  loss: 0.14494889676570893\n",
      "Batch 2095,  loss: 0.1772138774394989\n",
      "Batch 2100,  loss: 0.15154770463705064\n",
      "Batch 2105,  loss: 0.14084024280309676\n",
      "Batch 2110,  loss: 0.16532443463802338\n",
      "Batch 2115,  loss: 0.14306449592113496\n",
      "Batch 2120,  loss: 0.17220292389392852\n",
      "Batch 2125,  loss: 0.16659431904554367\n",
      "Batch 2130,  loss: 0.16334748268127441\n",
      "Batch 2135,  loss: 0.17691029757261276\n",
      "Batch 2140,  loss: 0.2059301480650902\n",
      "Batch 2145,  loss: 0.15294719040393828\n",
      "Batch 2150,  loss: 0.1448160156607628\n",
      "Batch 2155,  loss: 0.2290108919143677\n",
      "Batch 2160,  loss: 0.16642645746469498\n",
      "Batch 2165,  loss: 0.14996752589941026\n",
      "Batch 2170,  loss: 0.15987358689308168\n",
      "Batch 2175,  loss: 0.16332745254039766\n",
      "Batch 2180,  loss: 0.18961850106716155\n",
      "Batch 2185,  loss: 0.1628521829843521\n",
      "Batch 2190,  loss: 0.1424379304051399\n",
      "Batch 2195,  loss: 0.12988099157810212\n",
      "Batch 2200,  loss: 0.15446470379829408\n",
      "Batch 2205,  loss: 0.11601224839687348\n",
      "Batch 2210,  loss: 0.18791994750499724\n",
      "Batch 2215,  loss: 0.2018802732229233\n",
      "Batch 2220,  loss: 0.18978196531534194\n",
      "Batch 2225,  loss: 0.13715478777885437\n",
      "Batch 2230,  loss: 0.15358324348926544\n",
      "Batch 2235,  loss: 0.14604707956314086\n",
      "Batch 2240,  loss: 0.1390758976340294\n",
      "Batch 2245,  loss: 0.17228983342647552\n",
      "Batch 2250,  loss: 0.20324669480323793\n",
      "Batch 2255,  loss: 0.19519324898719786\n",
      "Batch 2260,  loss: 0.1327025681734085\n",
      "Batch 2265,  loss: 0.16972409784793854\n",
      "Batch 2270,  loss: 0.15541438162326812\n",
      "Batch 2275,  loss: 0.15091295540332794\n",
      "Batch 2280,  loss: 0.18589245676994323\n",
      "Batch 2285,  loss: 0.1729446217417717\n",
      "Batch 2290,  loss: 0.17106115818023682\n",
      "Batch 2295,  loss: 0.1578579217195511\n",
      "Batch 2300,  loss: 0.15539013743400573\n",
      "Batch 2305,  loss: 0.16666291803121566\n",
      "Batch 2310,  loss: 0.13246527314186096\n",
      "Batch 2315,  loss: 0.1443272352218628\n",
      "Batch 2320,  loss: 0.21756192147731782\n",
      "Batch 2325,  loss: 0.15414441674947738\n",
      "Batch 2330,  loss: 0.17290250808000565\n",
      "Batch 2335,  loss: 0.15085271000862122\n",
      "Batch 2340,  loss: 0.1907307982444763\n",
      "Batch 2345,  loss: 0.17726998627185822\n",
      "Batch 2350,  loss: 0.15275527834892272\n",
      "Batch 2355,  loss: 0.22090448141098024\n",
      "Batch 2360,  loss: 0.17283388078212739\n",
      "Batch 2365,  loss: 0.1478435665369034\n",
      "Batch 2370,  loss: 0.1993193060159683\n",
      "Batch 2375,  loss: 0.19800926744937897\n",
      "Batch 2380,  loss: 0.13971799612045288\n",
      "Batch 2385,  loss: 0.15369459241628647\n",
      "Batch 2390,  loss: 0.1922369956970215\n",
      "Batch 2395,  loss: 0.12641066759824754\n",
      "Batch 2400,  loss: 0.1772223562002182\n",
      "Batch 2405,  loss: 0.1756893128156662\n",
      "Batch 2410,  loss: 0.16222617626190186\n",
      "Batch 2415,  loss: 0.22196950167417526\n",
      "Batch 2420,  loss: 0.15270599126815795\n",
      "Batch 2425,  loss: 0.19691344797611238\n",
      "Batch 2430,  loss: 0.14414094388484955\n",
      "Batch 2435,  loss: 0.19522250592708587\n",
      "Batch 2440,  loss: 0.1197263777256012\n",
      "Batch 2445,  loss: 0.1411321610212326\n",
      "Batch 2450,  loss: 0.1504528656601906\n",
      "Batch 2455,  loss: 0.1325385645031929\n",
      "Batch 2460,  loss: 0.18901509046554565\n",
      "Batch 2465,  loss: 0.186876180768013\n",
      "Batch 2470,  loss: 0.1706514149904251\n",
      "Batch 2475,  loss: 0.1923814058303833\n",
      "Batch 2480,  loss: 0.19606557190418245\n",
      "Batch 2485,  loss: 0.16460272073745727\n",
      "Batch 2490,  loss: 0.1678985446691513\n",
      "Batch 2495,  loss: 0.231087127327919\n",
      "Batch 2500,  loss: 0.15674017369747162\n",
      "Batch 2505,  loss: 0.1436321407556534\n",
      "Batch 2510,  loss: 0.1661424770951271\n",
      "Batch 2515,  loss: 0.13017561584711074\n",
      "Batch 2520,  loss: 0.16787054985761643\n",
      "Batch 2525,  loss: 0.17093214392662048\n",
      "Batch 2530,  loss: 0.19118033051490785\n",
      "Batch 2535,  loss: 0.18064964562654495\n",
      "Batch 2540,  loss: 0.17775188237428666\n",
      "Batch 2545,  loss: 0.20690524876117705\n",
      "Batch 2550,  loss: 0.1740078419446945\n",
      "Batch 2555,  loss: 0.17006751894950867\n",
      "Batch 2560,  loss: 0.21521221697330475\n",
      "Batch 2565,  loss: 0.1517408534884453\n",
      "Batch 2570,  loss: 0.15346767157316207\n",
      "Batch 2575,  loss: 0.17111894935369493\n",
      "Batch 2580,  loss: 0.16621121019124985\n",
      "Batch 2585,  loss: 0.16475488990545273\n",
      "Batch 2590,  loss: 0.18920587003231049\n",
      "Batch 2595,  loss: 0.16003544628620148\n",
      "Batch 2600,  loss: 0.16321984380483628\n",
      "Batch 2605,  loss: 0.2244275063276291\n",
      "Batch 2610,  loss: 0.1705717623233795\n",
      "Batch 2615,  loss: 0.18172882497310638\n",
      "Batch 2620,  loss: 0.14266638904809953\n",
      "Batch 2625,  loss: 0.1423456221818924\n",
      "Batch 2630,  loss: 0.19619573652744293\n",
      "Batch 2635,  loss: 0.14358885437250138\n",
      "Batch 2640,  loss: 0.1510395884513855\n",
      "Batch 2645,  loss: 0.14124176800251007\n",
      "Batch 2650,  loss: 0.1564745157957077\n",
      "Batch 2655,  loss: 0.15996413230895995\n",
      "Batch 2660,  loss: 0.16705477237701416\n",
      "Batch 2665,  loss: 0.14845091700553895\n",
      "Batch 2670,  loss: 0.1428096890449524\n",
      "Batch 2675,  loss: 0.16209138035774232\n",
      "Batch 2680,  loss: 0.18589593172073365\n",
      "Batch 2685,  loss: 0.13148721903562546\n",
      "Batch 2690,  loss: 0.17851798832416535\n",
      "Batch 2695,  loss: 0.15796267688274385\n",
      "Batch 2700,  loss: 0.16028650403022765\n",
      "Batch 2705,  loss: 0.19234983921051024\n",
      "Batch 2710,  loss: 0.14421596974134446\n",
      "Batch 2715,  loss: 0.18788654506206512\n",
      "Batch 2720,  loss: 0.15289692133665084\n",
      "Batch 2725,  loss: 0.1584319517016411\n",
      "Batch 2730,  loss: 0.12438941448926925\n",
      "Batch 2735,  loss: 0.19079655408859253\n",
      "Batch 2740,  loss: 0.14673233032226562\n",
      "Batch 2745,  loss: 0.1313444584608078\n",
      "Batch 2750,  loss: 0.12682530879974366\n",
      "Batch 2755,  loss: 0.17459699213504792\n",
      "Batch 2760,  loss: 0.21811926364898682\n",
      "Batch 2765,  loss: 0.1991271674633026\n",
      "Batch 2770,  loss: 0.17184292674064636\n",
      "LOSS train 0.17184292674064636. Validation loss: 0.16047748389149394 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 24:\n",
      "Batch 5,  loss: 0.1761360287666321\n",
      "Batch 10,  loss: 0.13593968152999877\n",
      "Batch 15,  loss: 0.17667470276355743\n",
      "Batch 20,  loss: 0.1738746702671051\n",
      "Batch 25,  loss: 0.21500926315784455\n",
      "Batch 30,  loss: 0.18220856189727783\n",
      "Batch 35,  loss: 0.15216240286827087\n",
      "Batch 40,  loss: 0.141915163397789\n",
      "Batch 45,  loss: 0.15220213532447815\n",
      "Batch 50,  loss: 0.20591176748275758\n",
      "Batch 55,  loss: 0.2114310622215271\n",
      "Batch 60,  loss: 0.2210660383105278\n",
      "Batch 65,  loss: 0.17448831498622894\n",
      "Batch 70,  loss: 0.1528352454304695\n",
      "Batch 75,  loss: 0.1614545077085495\n",
      "Batch 80,  loss: 0.1277759239077568\n",
      "Batch 85,  loss: 0.22211917042732238\n",
      "Batch 90,  loss: 0.18973482251167298\n",
      "Batch 95,  loss: 0.18272676467895507\n",
      "Batch 100,  loss: 0.1671624332666397\n",
      "Batch 105,  loss: 0.16380694210529329\n",
      "Batch 110,  loss: 0.18013837039470673\n",
      "Batch 115,  loss: 0.15566213428974152\n",
      "Batch 120,  loss: 0.1828939884901047\n",
      "Batch 125,  loss: 0.18395060300827026\n",
      "Batch 130,  loss: 0.12818534225225447\n",
      "Batch 135,  loss: 0.17880282998085023\n",
      "Batch 140,  loss: 0.16881890892982482\n",
      "Batch 145,  loss: 0.147317373752594\n",
      "Batch 150,  loss: 0.14807816296815873\n",
      "Batch 155,  loss: 0.11907736957073212\n",
      "Batch 160,  loss: 0.16300761997699736\n",
      "Batch 165,  loss: 0.16815392374992372\n",
      "Batch 170,  loss: 0.1805932939052582\n",
      "Batch 175,  loss: 0.14352440536022187\n",
      "Batch 180,  loss: 0.12781294584274291\n",
      "Batch 185,  loss: 0.17416242957115174\n",
      "Batch 190,  loss: 0.15400069653987886\n",
      "Batch 195,  loss: 0.13030791133642197\n",
      "Batch 200,  loss: 0.16340610086917878\n",
      "Batch 205,  loss: 0.15338456630706787\n",
      "Batch 210,  loss: 0.17708866894245148\n",
      "Batch 215,  loss: 0.18565195202827453\n",
      "Batch 220,  loss: 0.16094586700201036\n",
      "Batch 225,  loss: 0.14758430421352386\n",
      "Batch 230,  loss: 0.12296458184719086\n",
      "Batch 235,  loss: 0.16192406713962554\n",
      "Batch 240,  loss: 0.17404697835445404\n",
      "Batch 245,  loss: 0.16459000408649443\n",
      "Batch 250,  loss: 0.15934395045042038\n",
      "Batch 255,  loss: 0.1460811287164688\n",
      "Batch 260,  loss: 0.13506068736314775\n",
      "Batch 265,  loss: 0.14731921255588531\n",
      "Batch 270,  loss: 0.12867322862148284\n",
      "Batch 275,  loss: 0.2001852035522461\n",
      "Batch 280,  loss: 0.14655158817768096\n",
      "Batch 285,  loss: 0.14927034974098205\n",
      "Batch 290,  loss: 0.17289953380823136\n",
      "Batch 295,  loss: 0.1667344778776169\n",
      "Batch 300,  loss: 0.16330230385065078\n",
      "Batch 305,  loss: 0.19184792339801787\n",
      "Batch 310,  loss: 0.18659846484661102\n",
      "Batch 315,  loss: 0.17534184753894805\n",
      "Batch 320,  loss: 0.13606804013252258\n",
      "Batch 325,  loss: 0.17401835322380066\n",
      "Batch 330,  loss: 0.1810409665107727\n",
      "Batch 335,  loss: 0.16075868010520936\n",
      "Batch 340,  loss: 0.18327150344848633\n",
      "Batch 345,  loss: 0.15645232200622558\n",
      "Batch 350,  loss: 0.1573777437210083\n",
      "Batch 355,  loss: 0.15393879115581513\n",
      "Batch 360,  loss: 0.1612030655145645\n",
      "Batch 365,  loss: 0.16404446065425873\n",
      "Batch 370,  loss: 0.13844265937805175\n",
      "Batch 375,  loss: 0.18188547492027282\n",
      "Batch 380,  loss: 0.15137567818164827\n",
      "Batch 385,  loss: 0.143764927983284\n",
      "Batch 390,  loss: 0.14344022572040557\n",
      "Batch 395,  loss: 0.19762416779994965\n",
      "Batch 400,  loss: 0.16427511721849442\n",
      "Batch 405,  loss: 0.1782011330127716\n",
      "Batch 410,  loss: 0.1349751442670822\n",
      "Batch 415,  loss: 0.16264132857322694\n",
      "Batch 420,  loss: 0.19522256553173065\n",
      "Batch 425,  loss: 0.16089149117469786\n",
      "Batch 430,  loss: 0.1671593651175499\n",
      "Batch 435,  loss: 0.14785025417804717\n",
      "Batch 440,  loss: 0.14633720219135285\n",
      "Batch 445,  loss: 0.15233689844608306\n",
      "Batch 450,  loss: 0.18636026382446289\n",
      "Batch 455,  loss: 0.1392226368188858\n",
      "Batch 460,  loss: 0.13844377398490906\n",
      "Batch 465,  loss: 0.2201178789138794\n",
      "Batch 470,  loss: 0.18068552613258362\n",
      "Batch 475,  loss: 0.15335156470537187\n",
      "Batch 480,  loss: 0.1578476309776306\n",
      "Batch 485,  loss: 0.24410865902900697\n",
      "Batch 490,  loss: 0.16916071474552155\n",
      "Batch 495,  loss: 0.1841926395893097\n",
      "Batch 500,  loss: 0.1719907760620117\n",
      "Batch 505,  loss: 0.19052546620368957\n",
      "Batch 510,  loss: 0.13537163585424422\n",
      "Batch 515,  loss: 0.15054586082696914\n",
      "Batch 520,  loss: 0.16951408088207245\n",
      "Batch 525,  loss: 0.17530256509780884\n",
      "Batch 530,  loss: 0.1502506762742996\n",
      "Batch 535,  loss: 0.15125663578510284\n",
      "Batch 540,  loss: 0.17726847231388093\n",
      "Batch 545,  loss: 0.17289042770862578\n",
      "Batch 550,  loss: 0.17346446514129638\n",
      "Batch 555,  loss: 0.18730044066905976\n",
      "Batch 560,  loss: 0.17527901977300644\n",
      "Batch 565,  loss: 0.13506677746772766\n",
      "Batch 570,  loss: 0.15000398457050323\n",
      "Batch 575,  loss: 0.16771962642669677\n",
      "Batch 580,  loss: 0.15423509180545808\n",
      "Batch 585,  loss: 0.18714609146118164\n",
      "Batch 590,  loss: 0.15114155560731887\n",
      "Batch 595,  loss: 0.15012844204902648\n",
      "Batch 600,  loss: 0.14299518316984178\n",
      "Batch 605,  loss: 0.160736608505249\n",
      "Batch 610,  loss: 0.19168537259101867\n",
      "Batch 615,  loss: 0.12231985628604888\n",
      "Batch 620,  loss: 0.13775139600038527\n",
      "Batch 625,  loss: 0.17260172665119172\n",
      "Batch 630,  loss: 0.17445591390132903\n",
      "Batch 635,  loss: 0.2241517037153244\n",
      "Batch 640,  loss: 0.1967228263616562\n",
      "Batch 645,  loss: 0.1472627639770508\n",
      "Batch 650,  loss: 0.1429651767015457\n",
      "Batch 655,  loss: 0.1720232516527176\n",
      "Batch 660,  loss: 0.1390835389494896\n",
      "Batch 665,  loss: 0.1588667780160904\n",
      "Batch 670,  loss: 0.20913975536823273\n",
      "Batch 675,  loss: 0.18752795159816743\n",
      "Batch 680,  loss: 0.180045385658741\n",
      "Batch 685,  loss: 0.17361646592617036\n",
      "Batch 690,  loss: 0.14876574873924256\n",
      "Batch 695,  loss: 0.14984526187181474\n",
      "Batch 700,  loss: 0.18448374271392823\n",
      "Batch 705,  loss: 0.20608134269714357\n",
      "Batch 710,  loss: 0.15918720960617067\n",
      "Batch 715,  loss: 0.16284762769937516\n",
      "Batch 720,  loss: 0.16426484286785126\n",
      "Batch 725,  loss: 0.1630213141441345\n",
      "Batch 730,  loss: 0.15953484177589417\n",
      "Batch 735,  loss: 0.2001662880182266\n",
      "Batch 740,  loss: 0.1767158180475235\n",
      "Batch 745,  loss: 0.1558055192232132\n",
      "Batch 750,  loss: 0.1384278029203415\n",
      "Batch 755,  loss: 0.1422431692481041\n",
      "Batch 760,  loss: 0.16216796338558198\n",
      "Batch 765,  loss: 0.16460808217525483\n",
      "Batch 770,  loss: 0.14672724902629852\n",
      "Batch 775,  loss: 0.18085246682167053\n",
      "Batch 780,  loss: 0.16743093430995942\n",
      "Batch 785,  loss: 0.20336203575134276\n",
      "Batch 790,  loss: 0.13258259743452072\n",
      "Batch 795,  loss: 0.15344349443912506\n",
      "Batch 800,  loss: 0.17036562860012056\n",
      "Batch 805,  loss: 0.15225454270839692\n",
      "Batch 810,  loss: 0.138270865380764\n",
      "Batch 815,  loss: 0.1408664032816887\n",
      "Batch 820,  loss: 0.15581443309783935\n",
      "Batch 825,  loss: 0.2115214228630066\n",
      "Batch 830,  loss: 0.1262206420302391\n",
      "Batch 835,  loss: 0.1636705368757248\n",
      "Batch 840,  loss: 0.20305399894714354\n",
      "Batch 845,  loss: 0.14508783370256423\n",
      "Batch 850,  loss: 0.1368545413017273\n",
      "Batch 855,  loss: 0.18717997372150422\n",
      "Batch 860,  loss: 0.20804132521152496\n",
      "Batch 865,  loss: 0.17431637048721313\n",
      "Batch 870,  loss: 0.2011124461889267\n",
      "Batch 875,  loss: 0.1372803419828415\n",
      "Batch 880,  loss: 0.21174920499324798\n",
      "Batch 885,  loss: 0.2109197348356247\n",
      "Batch 890,  loss: 0.15933481156826018\n",
      "Batch 895,  loss: 0.2013991579413414\n",
      "Batch 900,  loss: 0.18885124623775482\n",
      "Batch 905,  loss: 0.17053061127662658\n",
      "Batch 910,  loss: 0.177228382229805\n",
      "Batch 915,  loss: 0.149614317715168\n",
      "Batch 920,  loss: 0.17743294835090637\n",
      "Batch 925,  loss: 0.16189220249652864\n",
      "Batch 930,  loss: 0.30122526586055753\n",
      "Batch 935,  loss: 0.1434984549880028\n",
      "Batch 940,  loss: 0.1741909921169281\n",
      "Batch 945,  loss: 0.1809763491153717\n",
      "Batch 950,  loss: 0.13085561692714692\n",
      "Batch 955,  loss: 0.14859399497509002\n",
      "Batch 960,  loss: 0.16372356116771697\n",
      "Batch 965,  loss: 0.19092128574848174\n",
      "Batch 970,  loss: 0.16930311918258667\n",
      "Batch 975,  loss: 0.1885342627763748\n",
      "Batch 980,  loss: 0.173021899163723\n",
      "Batch 985,  loss: 0.12063938528299331\n",
      "Batch 990,  loss: 0.20804958045482635\n",
      "Batch 995,  loss: 0.16320506632328033\n",
      "Batch 1000,  loss: 0.19180526733398437\n",
      "Batch 1005,  loss: 0.16610188484191896\n",
      "Batch 1010,  loss: 0.19044771492481233\n",
      "Batch 1015,  loss: 0.15654935836791992\n",
      "Batch 1020,  loss: 0.15671632140874864\n",
      "Batch 1025,  loss: 0.17388354241847992\n",
      "Batch 1030,  loss: 0.17928739190101622\n",
      "Batch 1035,  loss: 0.1543642535805702\n",
      "Batch 1040,  loss: 0.15697542130947112\n",
      "Batch 1045,  loss: 0.16364206224679947\n",
      "Batch 1050,  loss: 0.1258278399705887\n",
      "Batch 1055,  loss: 0.17855322659015654\n",
      "Batch 1060,  loss: 0.1823967680335045\n",
      "Batch 1065,  loss: 0.18969893157482148\n",
      "Batch 1070,  loss: 0.15980028957128525\n",
      "Batch 1075,  loss: 0.19839700758457185\n",
      "Batch 1080,  loss: 0.20909444838762284\n",
      "Batch 1085,  loss: 0.1725538820028305\n",
      "Batch 1090,  loss: 0.15728093534708024\n",
      "Batch 1095,  loss: 0.2096998631954193\n",
      "Batch 1100,  loss: 0.18892868161201476\n",
      "Batch 1105,  loss: 0.1621176153421402\n",
      "Batch 1110,  loss: 0.1545435070991516\n",
      "Batch 1115,  loss: 0.1615886628627777\n",
      "Batch 1120,  loss: 0.18890798091888428\n",
      "Batch 1125,  loss: 0.21282847225666046\n",
      "Batch 1130,  loss: 0.11808036416769027\n",
      "Batch 1135,  loss: 0.16943232715129852\n",
      "Batch 1140,  loss: 0.15894400775432588\n",
      "Batch 1145,  loss: 0.16128964424133302\n",
      "Batch 1150,  loss: 0.2166579008102417\n",
      "Batch 1155,  loss: 0.149926994740963\n",
      "Batch 1160,  loss: 0.17168441116809846\n",
      "Batch 1165,  loss: 0.1529686465859413\n",
      "Batch 1170,  loss: 0.14552699029445648\n",
      "Batch 1175,  loss: 0.16051081717014312\n",
      "Batch 1180,  loss: 0.1498062640428543\n",
      "Batch 1185,  loss: 0.15980019569396972\n",
      "Batch 1190,  loss: 0.1788947254419327\n",
      "Batch 1195,  loss: 0.17248763144016266\n",
      "Batch 1200,  loss: 0.13311243951320648\n",
      "Batch 1205,  loss: 0.13493782579898833\n",
      "Batch 1210,  loss: 0.16557269394397736\n",
      "Batch 1215,  loss: 0.17880780696868898\n",
      "Batch 1220,  loss: 0.12641177624464034\n",
      "Batch 1225,  loss: 0.15577573776245118\n",
      "Batch 1230,  loss: 0.20287940502166749\n",
      "Batch 1235,  loss: 0.1681446313858032\n",
      "Batch 1240,  loss: 0.1346495509147644\n",
      "Batch 1245,  loss: 0.1652974843978882\n",
      "Batch 1250,  loss: 0.2147585153579712\n",
      "Batch 1255,  loss: 0.1585311084985733\n",
      "Batch 1260,  loss: 0.17015936672687532\n",
      "Batch 1265,  loss: 0.17257882952690123\n",
      "Batch 1270,  loss: 0.1834690272808075\n",
      "Batch 1275,  loss: 0.19700048863887787\n",
      "Batch 1280,  loss: 0.20709078907966613\n",
      "Batch 1285,  loss: 0.1811247080564499\n",
      "Batch 1290,  loss: 0.15710290670394897\n",
      "Batch 1295,  loss: 0.17511171400547026\n",
      "Batch 1300,  loss: 0.14571898877620698\n",
      "Batch 1305,  loss: 0.15052614808082582\n",
      "Batch 1310,  loss: 0.17869948595762253\n",
      "Batch 1315,  loss: 0.14740065932273866\n",
      "Batch 1320,  loss: 0.18620308637619018\n",
      "Batch 1325,  loss: 0.14398384392261504\n",
      "Batch 1330,  loss: 0.11955373734235764\n",
      "Batch 1335,  loss: 0.16007474511861802\n",
      "Batch 1340,  loss: 0.2012126624584198\n",
      "Batch 1345,  loss: 0.2534644931554794\n",
      "Batch 1350,  loss: 0.18956980407238005\n",
      "Batch 1355,  loss: 0.14166018962860108\n",
      "Batch 1360,  loss: 0.14571884870529175\n",
      "Batch 1365,  loss: 0.16579902172088623\n",
      "Batch 1370,  loss: 0.1584655299782753\n",
      "Batch 1375,  loss: 0.16673677563667297\n",
      "Batch 1380,  loss: 0.15055619329214096\n",
      "Batch 1385,  loss: 0.15738557428121566\n",
      "Batch 1390,  loss: 0.15457988977432252\n",
      "Batch 1395,  loss: 0.16423501670360566\n",
      "Batch 1400,  loss: 0.22394660860300064\n",
      "Batch 1405,  loss: 0.19374371469020843\n",
      "Batch 1410,  loss: 0.18849274516105652\n",
      "Batch 1415,  loss: 0.17516582012176513\n",
      "Batch 1420,  loss: 0.1568520799279213\n",
      "Batch 1425,  loss: 0.14118217527866364\n",
      "Batch 1430,  loss: 0.19945380389690398\n",
      "Batch 1435,  loss: 0.13178660869598388\n",
      "Batch 1440,  loss: 0.1832519143819809\n",
      "Batch 1445,  loss: 0.1641150966286659\n",
      "Batch 1450,  loss: 0.16244813352823256\n",
      "Batch 1455,  loss: 0.15594950318336487\n",
      "Batch 1460,  loss: 0.19731590747833253\n",
      "Batch 1465,  loss: 0.14165152460336686\n",
      "Batch 1470,  loss: 0.15931429713964462\n",
      "Batch 1475,  loss: 0.15760233700275422\n",
      "Batch 1480,  loss: 0.16427335292100906\n",
      "Batch 1485,  loss: 0.14401955157518387\n",
      "Batch 1490,  loss: 0.14502424448728563\n",
      "Batch 1495,  loss: 0.16128815710544586\n",
      "Batch 1500,  loss: 0.16496946811676025\n",
      "Batch 1505,  loss: 0.16889167726039886\n",
      "Batch 1510,  loss: 0.1903301239013672\n",
      "Batch 1515,  loss: 0.17643250674009323\n",
      "Batch 1520,  loss: 0.18069525361061095\n",
      "Batch 1525,  loss: 0.17115394175052642\n",
      "Batch 1530,  loss: 0.16549364030361174\n",
      "Batch 1535,  loss: 0.18342782855033873\n",
      "Batch 1540,  loss: 0.1458555728197098\n",
      "Batch 1545,  loss: 0.17274589836597443\n",
      "Batch 1550,  loss: 0.2074152410030365\n",
      "Batch 1555,  loss: 0.17203293591737748\n",
      "Batch 1560,  loss: 0.14586469382047654\n",
      "Batch 1565,  loss: 0.16338076442480087\n",
      "Batch 1570,  loss: 0.13729051351547242\n",
      "Batch 1575,  loss: 0.16251327693462372\n",
      "Batch 1580,  loss: 0.1568593740463257\n",
      "Batch 1585,  loss: 0.13204619586467742\n",
      "Batch 1590,  loss: 0.16640493422746658\n",
      "Batch 1595,  loss: 0.1663361370563507\n",
      "Batch 1600,  loss: 0.1525350272655487\n",
      "Batch 1605,  loss: 0.17579393088817596\n",
      "Batch 1610,  loss: 0.1453122690320015\n",
      "Batch 1615,  loss: 0.1485078066587448\n",
      "Batch 1620,  loss: 0.15017076283693315\n",
      "Batch 1625,  loss: 0.14927826225757598\n",
      "Batch 1630,  loss: 0.19449362456798552\n",
      "Batch 1635,  loss: 0.19115524590015412\n",
      "Batch 1640,  loss: 0.17007339894771575\n",
      "Batch 1645,  loss: 0.1576293647289276\n",
      "Batch 1650,  loss: 0.12393437325954437\n",
      "Batch 1655,  loss: 0.14570140689611435\n",
      "Batch 1660,  loss: 0.14263626635074617\n",
      "Batch 1665,  loss: 0.21958325207233428\n",
      "Batch 1670,  loss: 0.15474833250045777\n",
      "Batch 1675,  loss: 0.1650824084877968\n",
      "Batch 1680,  loss: 0.2030375063419342\n",
      "Batch 1685,  loss: 0.13404465913772584\n",
      "Batch 1690,  loss: 0.15105195343494415\n",
      "Batch 1695,  loss: 0.17518016397953035\n",
      "Batch 1700,  loss: 0.14561935961246492\n",
      "Batch 1705,  loss: 0.14047211408615112\n",
      "Batch 1710,  loss: 0.12488289326429367\n",
      "Batch 1715,  loss: 0.15870775729417802\n",
      "Batch 1720,  loss: 0.1724068894982338\n",
      "Batch 1725,  loss: 0.21713280379772187\n",
      "Batch 1730,  loss: 0.1352010414004326\n",
      "Batch 1735,  loss: 0.16391998380422593\n",
      "Batch 1740,  loss: 0.14627954363822937\n",
      "Batch 1745,  loss: 0.1707405388355255\n",
      "Batch 1750,  loss: 0.14494723975658416\n",
      "Batch 1755,  loss: 0.16493115574121475\n",
      "Batch 1760,  loss: 0.1659505248069763\n",
      "Batch 1765,  loss: 0.1323687508702278\n",
      "Batch 1770,  loss: 0.17729223221540452\n",
      "Batch 1775,  loss: 0.22411612272262574\n",
      "Batch 1780,  loss: 0.13807335048913955\n",
      "Batch 1785,  loss: 0.14008561223745347\n",
      "Batch 1790,  loss: 0.13683749735355377\n",
      "Batch 1795,  loss: 0.18513436913490294\n",
      "Batch 1800,  loss: 0.1471560075879097\n",
      "Batch 1805,  loss: 0.1460091084241867\n",
      "Batch 1810,  loss: 0.14848647117614747\n",
      "Batch 1815,  loss: 0.15870791524648667\n",
      "Batch 1820,  loss: 0.18320070803165436\n",
      "Batch 1825,  loss: 0.14873619377613068\n",
      "Batch 1830,  loss: 0.13940014094114303\n",
      "Batch 1835,  loss: 0.1476312905550003\n",
      "Batch 1840,  loss: 0.1314225748181343\n",
      "Batch 1845,  loss: 0.1512206107378006\n",
      "Batch 1850,  loss: 0.14667548835277558\n",
      "Batch 1855,  loss: 0.18214608132839202\n",
      "Batch 1860,  loss: 0.15326731353998185\n",
      "Batch 1865,  loss: 0.1455740749835968\n",
      "Batch 1870,  loss: 0.16070417165756226\n",
      "Batch 1875,  loss: 0.1734433352947235\n",
      "Batch 1880,  loss: 0.2563207924365997\n",
      "Batch 1885,  loss: 0.15425962209701538\n",
      "Batch 1890,  loss: 0.2306250512599945\n",
      "Batch 1895,  loss: 0.14399058222770691\n",
      "Batch 1900,  loss: 0.16080297231674195\n",
      "Batch 1905,  loss: 0.1378699392080307\n",
      "Batch 1910,  loss: 0.17469288855791093\n",
      "Batch 1915,  loss: 0.1235129937529564\n",
      "Batch 1920,  loss: 0.16891393363475798\n",
      "Batch 1925,  loss: 0.14828523695468904\n",
      "Batch 1930,  loss: 0.14775433540344238\n",
      "Batch 1935,  loss: 0.16526191532611847\n",
      "Batch 1940,  loss: 0.14003249406814575\n",
      "Batch 1945,  loss: 0.18441395461559296\n",
      "Batch 1950,  loss: 0.14603481888771058\n",
      "Batch 1955,  loss: 0.14274753183126448\n",
      "Batch 1960,  loss: 0.18342492282390593\n",
      "Batch 1965,  loss: 0.2002608835697174\n",
      "Batch 1970,  loss: 0.14629025161266326\n",
      "Batch 1975,  loss: 0.17502936720848083\n",
      "Batch 1980,  loss: 0.18483945429325105\n",
      "Batch 1985,  loss: 0.2112138569355011\n",
      "Batch 1990,  loss: 0.1506861448287964\n",
      "Batch 1995,  loss: 0.15290519148111342\n",
      "Batch 2000,  loss: 0.182399919629097\n",
      "Batch 2005,  loss: 0.19049835503101348\n",
      "Batch 2010,  loss: 0.16640160381793975\n",
      "Batch 2015,  loss: 0.1764104276895523\n",
      "Batch 2020,  loss: 0.16083788871765137\n",
      "Batch 2025,  loss: 0.18083831071853637\n",
      "Batch 2030,  loss: 0.19262125790119172\n",
      "Batch 2035,  loss: 0.15279819518327714\n",
      "Batch 2040,  loss: 0.11399138420820236\n",
      "Batch 2045,  loss: 0.16475421488285064\n",
      "Batch 2050,  loss: 0.16145857870578767\n",
      "Batch 2055,  loss: 0.16146437525749208\n",
      "Batch 2060,  loss: 0.18561725169420243\n",
      "Batch 2065,  loss: 0.15929343700408935\n",
      "Batch 2070,  loss: 0.1394892781972885\n",
      "Batch 2075,  loss: 0.1717900037765503\n",
      "Batch 2080,  loss: 0.14274144768714905\n",
      "Batch 2085,  loss: 0.1508329689502716\n",
      "Batch 2090,  loss: 0.13189118206501008\n",
      "Batch 2095,  loss: 0.1585441529750824\n",
      "Batch 2100,  loss: 0.22282715439796447\n",
      "Batch 2105,  loss: 0.16012890934944152\n",
      "Batch 2110,  loss: 0.16285445392131806\n",
      "Batch 2115,  loss: 0.1852810025215149\n",
      "Batch 2120,  loss: 0.17557636499404908\n",
      "Batch 2125,  loss: 0.1443544805049896\n",
      "Batch 2130,  loss: 0.16991072595119477\n",
      "Batch 2135,  loss: 0.15928139686584472\n",
      "Batch 2140,  loss: 0.18031226992607116\n",
      "Batch 2145,  loss: 0.1798841968178749\n",
      "Batch 2150,  loss: 0.13725969940423965\n",
      "Batch 2155,  loss: 0.14122166782617568\n",
      "Batch 2160,  loss: 0.2125103712081909\n",
      "Batch 2165,  loss: 0.13961123824119567\n",
      "Batch 2170,  loss: 0.16806384921073914\n",
      "Batch 2175,  loss: 0.15129876881837845\n",
      "Batch 2180,  loss: 0.15244853347539902\n",
      "Batch 2185,  loss: 0.15406554639339448\n",
      "Batch 2190,  loss: 0.1620588034391403\n",
      "Batch 2195,  loss: 0.18082317113876342\n",
      "Batch 2200,  loss: 0.17973161935806276\n",
      "Batch 2205,  loss: 0.1443842515349388\n",
      "Batch 2210,  loss: 0.19044351875782012\n",
      "Batch 2215,  loss: 0.13301257491111756\n",
      "Batch 2220,  loss: 0.16597504615783693\n",
      "Batch 2225,  loss: 0.17236152440309524\n",
      "Batch 2230,  loss: 0.1845990777015686\n",
      "Batch 2235,  loss: 0.1461415857076645\n",
      "Batch 2240,  loss: 0.18352219611406326\n",
      "Batch 2245,  loss: 0.18986034095287324\n",
      "Batch 2250,  loss: 0.17405883967876434\n",
      "Batch 2255,  loss: 0.19897107481956483\n",
      "Batch 2260,  loss: 0.22521076500415801\n",
      "Batch 2265,  loss: 0.16875153481960298\n",
      "Batch 2270,  loss: 0.1704484760761261\n",
      "Batch 2275,  loss: 0.1682366281747818\n",
      "Batch 2280,  loss: 0.1615281492471695\n",
      "Batch 2285,  loss: 0.16937282979488372\n",
      "Batch 2290,  loss: 0.1777731090784073\n",
      "Batch 2295,  loss: 0.18461913764476776\n",
      "Batch 2300,  loss: 0.22661187648773193\n",
      "Batch 2305,  loss: 0.15891017466783525\n",
      "Batch 2310,  loss: 0.16312469244003297\n",
      "Batch 2315,  loss: 0.1645620197057724\n",
      "Batch 2320,  loss: 0.16186420619487762\n",
      "Batch 2325,  loss: 0.14449402838945388\n",
      "Batch 2330,  loss: 0.18074970692396164\n",
      "Batch 2335,  loss: 0.1459597557783127\n",
      "Batch 2340,  loss: 0.14424234479665757\n",
      "Batch 2345,  loss: 0.14411961883306504\n",
      "Batch 2350,  loss: 0.15036929845809938\n",
      "Batch 2355,  loss: 0.17500229626893998\n",
      "Batch 2360,  loss: 0.19369370937347413\n",
      "Batch 2365,  loss: 0.16283558905124665\n",
      "Batch 2370,  loss: 0.1750151738524437\n",
      "Batch 2375,  loss: 0.1590611845254898\n",
      "Batch 2380,  loss: 0.1679060697555542\n",
      "Batch 2385,  loss: 0.18127519488334656\n",
      "Batch 2390,  loss: 0.12026183009147644\n",
      "Batch 2395,  loss: 0.1666967362165451\n",
      "Batch 2400,  loss: 0.18512830138206482\n",
      "Batch 2405,  loss: 0.17854395806789397\n",
      "Batch 2410,  loss: 0.16941570341587067\n",
      "Batch 2415,  loss: 0.16743250638246537\n",
      "Batch 2420,  loss: 0.18113969564437865\n",
      "Batch 2425,  loss: 0.12373712360858917\n",
      "Batch 2430,  loss: 0.14931166768074036\n",
      "Batch 2435,  loss: 0.1794442355632782\n",
      "Batch 2440,  loss: 0.13312159925699235\n",
      "Batch 2445,  loss: 0.15241710543632508\n",
      "Batch 2450,  loss: 0.1683242440223694\n",
      "Batch 2455,  loss: 0.16038554459810256\n",
      "Batch 2460,  loss: 0.17420122325420379\n",
      "Batch 2465,  loss: 0.1736488476395607\n",
      "Batch 2470,  loss: 0.1467983290553093\n",
      "Batch 2475,  loss: 0.16542534232139589\n",
      "Batch 2480,  loss: 0.12687655091285704\n",
      "Batch 2485,  loss: 0.15981273353099823\n",
      "Batch 2490,  loss: 0.17224508225917817\n",
      "Batch 2495,  loss: 0.1608596757054329\n",
      "Batch 2500,  loss: 0.17191149443387985\n",
      "Batch 2505,  loss: 0.16068755388259887\n",
      "Batch 2510,  loss: 0.19895922243595124\n",
      "Batch 2515,  loss: 0.17570032253861428\n",
      "Batch 2520,  loss: 0.13070226609706878\n",
      "Batch 2525,  loss: 0.15927456468343734\n",
      "Batch 2530,  loss: 0.1784418433904648\n",
      "Batch 2535,  loss: 0.13261090815067292\n",
      "Batch 2540,  loss: 0.16192277073860167\n",
      "Batch 2545,  loss: 0.12645224034786223\n",
      "Batch 2550,  loss: 0.180297788977623\n",
      "Batch 2555,  loss: 0.1351049304008484\n",
      "Batch 2560,  loss: 0.18208205997943877\n",
      "Batch 2565,  loss: 0.13492791950702668\n",
      "Batch 2570,  loss: 0.1912547916173935\n",
      "Batch 2575,  loss: 0.14206322580575942\n",
      "Batch 2580,  loss: 0.15906141698360443\n",
      "Batch 2585,  loss: 0.18367569148540497\n",
      "Batch 2590,  loss: 0.1297036111354828\n",
      "Batch 2595,  loss: 0.15891056954860688\n",
      "Batch 2600,  loss: 0.18596346229314803\n",
      "Batch 2605,  loss: 0.1627006232738495\n",
      "Batch 2610,  loss: 0.15931033492088317\n",
      "Batch 2615,  loss: 0.14873684346675872\n",
      "Batch 2620,  loss: 0.15935968607664108\n",
      "Batch 2625,  loss: 0.17630599439144135\n",
      "Batch 2630,  loss: 0.16666533499956132\n",
      "Batch 2635,  loss: 0.1967252090573311\n",
      "Batch 2640,  loss: 0.17950778901576997\n",
      "Batch 2645,  loss: 0.18212029933929444\n",
      "Batch 2650,  loss: 0.20597728192806244\n",
      "Batch 2655,  loss: 0.16968913078308107\n",
      "Batch 2660,  loss: 0.14887933135032655\n",
      "Batch 2665,  loss: 0.1703459620475769\n",
      "Batch 2670,  loss: 0.13543830960988998\n",
      "Batch 2675,  loss: 0.1550116077065468\n",
      "Batch 2680,  loss: 0.20249012112617493\n",
      "Batch 2685,  loss: 0.20891474187374115\n",
      "Batch 2690,  loss: 0.11916027963161469\n",
      "Batch 2695,  loss: 0.15615296363830566\n",
      "Batch 2700,  loss: 0.17342399954795837\n",
      "Batch 2705,  loss: 0.15944930911064148\n",
      "Batch 2710,  loss: 0.17348406016826629\n",
      "Batch 2715,  loss: 0.14604308903217317\n",
      "Batch 2720,  loss: 0.1419724002480507\n",
      "Batch 2725,  loss: 0.13905287086963652\n",
      "Batch 2730,  loss: 0.1777314841747284\n",
      "Batch 2735,  loss: 0.17761445045471191\n",
      "Batch 2740,  loss: 0.1557428538799286\n",
      "Batch 2745,  loss: 0.15771105587482454\n",
      "Batch 2750,  loss: 0.1693500891327858\n",
      "Batch 2755,  loss: 0.16808257699012757\n",
      "Batch 2760,  loss: 0.13268210738897324\n",
      "Batch 2765,  loss: 0.1661004453897476\n",
      "Batch 2770,  loss: 0.16474547684192659\n",
      "LOSS train 0.16474547684192659. Validation loss: 0.16173773407591163 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 25:\n",
      "Batch 5,  loss: 0.17511156499385833\n",
      "Batch 10,  loss: 0.15299152880907058\n",
      "Batch 15,  loss: 0.17769655883312224\n",
      "Batch 20,  loss: 0.19448167383670806\n",
      "Batch 25,  loss: 0.13370294868946075\n",
      "Batch 30,  loss: 0.16806296408176422\n",
      "Batch 35,  loss: 0.1614602953195572\n",
      "Batch 40,  loss: 0.17154764533042907\n",
      "Batch 45,  loss: 0.226444873213768\n",
      "Batch 50,  loss: 0.18847019374370574\n",
      "Batch 55,  loss: 0.14848467111587524\n",
      "Batch 60,  loss: 0.18964980244636537\n",
      "Batch 65,  loss: 0.1797273874282837\n",
      "Batch 70,  loss: 0.17736859768629074\n",
      "Batch 75,  loss: 0.15422510206699372\n",
      "Batch 80,  loss: 0.19592794626951218\n",
      "Batch 85,  loss: 0.21572158932685853\n",
      "Batch 90,  loss: 0.16380051523447037\n",
      "Batch 95,  loss: 0.1717865437269211\n",
      "Batch 100,  loss: 0.1990182012319565\n",
      "Batch 105,  loss: 0.16129110306501387\n",
      "Batch 110,  loss: 0.18999243080615996\n",
      "Batch 115,  loss: 0.19459387958049773\n",
      "Batch 120,  loss: 0.19395584464073182\n",
      "Batch 125,  loss: 0.18090709149837494\n",
      "Batch 130,  loss: 0.1768440544605255\n",
      "Batch 135,  loss: 0.1464799851179123\n",
      "Batch 140,  loss: 0.1374368354678154\n",
      "Batch 145,  loss: 0.19181268215179442\n",
      "Batch 150,  loss: 0.16796498596668244\n",
      "Batch 155,  loss: 0.13835863918066024\n",
      "Batch 160,  loss: 0.1804492235183716\n",
      "Batch 165,  loss: 0.1751646339893341\n",
      "Batch 170,  loss: 0.1921592116355896\n",
      "Batch 175,  loss: 0.14478932917118073\n",
      "Batch 180,  loss: 0.1678720533847809\n",
      "Batch 185,  loss: 0.1472740277647972\n",
      "Batch 190,  loss: 0.14767772257328032\n",
      "Batch 195,  loss: 0.14511752128601074\n",
      "Batch 200,  loss: 0.16100362241268157\n",
      "Batch 205,  loss: 0.14008063226938247\n",
      "Batch 210,  loss: 0.1549002006649971\n",
      "Batch 215,  loss: 0.1699792832136154\n",
      "Batch 220,  loss: 0.209909351170063\n",
      "Batch 225,  loss: 0.20006062388420104\n",
      "Batch 230,  loss: 0.17928068935871125\n",
      "Batch 235,  loss: 0.16142776906490325\n",
      "Batch 240,  loss: 0.13880891501903533\n",
      "Batch 245,  loss: 0.16317554116249083\n",
      "Batch 250,  loss: 0.21052909195423125\n",
      "Batch 255,  loss: 0.18770357072353364\n",
      "Batch 260,  loss: 0.15612053275108337\n",
      "Batch 265,  loss: 0.19976819455623626\n",
      "Batch 270,  loss: 0.1688738912343979\n",
      "Batch 275,  loss: 0.15422567427158357\n",
      "Batch 280,  loss: 0.14410934448242188\n",
      "Batch 285,  loss: 0.11894231736660003\n",
      "Batch 290,  loss: 0.1244104489684105\n",
      "Batch 295,  loss: 0.18297153115272521\n",
      "Batch 300,  loss: 0.1839727371931076\n",
      "Batch 305,  loss: 0.1636146366596222\n",
      "Batch 310,  loss: 0.16614325791597367\n",
      "Batch 315,  loss: 0.17204696238040923\n",
      "Batch 320,  loss: 0.2364983767271042\n",
      "Batch 325,  loss: 0.1423506498336792\n",
      "Batch 330,  loss: 0.1437262549996376\n",
      "Batch 335,  loss: 0.15920757055282592\n",
      "Batch 340,  loss: 0.16567076444625856\n",
      "Batch 345,  loss: 0.15385644584894181\n",
      "Batch 350,  loss: 0.1871549367904663\n",
      "Batch 355,  loss: 0.1697472631931305\n",
      "Batch 360,  loss: 0.22829068899154664\n",
      "Batch 365,  loss: 0.16839546710252762\n",
      "Batch 370,  loss: 0.20750927925109863\n",
      "Batch 375,  loss: 0.20941235423088073\n",
      "Batch 380,  loss: 0.1836940050125122\n",
      "Batch 385,  loss: 0.23342911154031754\n",
      "Batch 390,  loss: 0.14845311641693115\n",
      "Batch 395,  loss: 0.1903917133808136\n",
      "Batch 400,  loss: 0.1700570613145828\n",
      "Batch 405,  loss: 0.1806415632367134\n",
      "Batch 410,  loss: 0.15052364468574525\n",
      "Batch 415,  loss: 0.1837255299091339\n",
      "Batch 420,  loss: 0.16810031980276108\n",
      "Batch 425,  loss: 0.13814183473587036\n",
      "Batch 430,  loss: 0.13476209640502929\n",
      "Batch 435,  loss: 0.11773882210254669\n",
      "Batch 440,  loss: 0.13908893764019012\n",
      "Batch 445,  loss: 0.15759512633085251\n",
      "Batch 450,  loss: 0.16941803693771362\n",
      "Batch 455,  loss: 0.15174873620271684\n",
      "Batch 460,  loss: 0.14449240267276764\n",
      "Batch 465,  loss: 0.18944393396377562\n",
      "Batch 470,  loss: 0.22726736962795258\n",
      "Batch 475,  loss: 0.15364865958690643\n",
      "Batch 480,  loss: 0.18670958429574966\n",
      "Batch 485,  loss: 0.13595010638236998\n",
      "Batch 490,  loss: 0.1658237800002098\n",
      "Batch 495,  loss: 0.12726976573467255\n",
      "Batch 500,  loss: 0.1598688021302223\n",
      "Batch 505,  loss: 0.1688530385494232\n",
      "Batch 510,  loss: 0.17624636590480805\n",
      "Batch 515,  loss: 0.14877172112464904\n",
      "Batch 520,  loss: 0.134034264087677\n",
      "Batch 525,  loss: 0.18805043399333954\n",
      "Batch 530,  loss: 0.17598112523555756\n",
      "Batch 535,  loss: 0.14736692607402802\n",
      "Batch 540,  loss: 0.15425948649644852\n",
      "Batch 545,  loss: 0.2228294000029564\n",
      "Batch 550,  loss: 0.13875828087329864\n",
      "Batch 555,  loss: 0.15115906596183776\n",
      "Batch 560,  loss: 0.1555321604013443\n",
      "Batch 565,  loss: 0.1653358206152916\n",
      "Batch 570,  loss: 0.130942602455616\n",
      "Batch 575,  loss: 0.17047449946403503\n",
      "Batch 580,  loss: 0.19664980173110963\n",
      "Batch 585,  loss: 0.15428439527750015\n",
      "Batch 590,  loss: 0.14715474843978882\n",
      "Batch 595,  loss: 0.1409513920545578\n",
      "Batch 600,  loss: 0.14737004935741424\n",
      "Batch 605,  loss: 0.16983963847160338\n",
      "Batch 610,  loss: 0.15106023252010345\n",
      "Batch 615,  loss: 0.14882025271654128\n",
      "Batch 620,  loss: 0.16960075497627258\n",
      "Batch 625,  loss: 0.15407539904117584\n",
      "Batch 630,  loss: 0.17260044813156128\n",
      "Batch 635,  loss: 0.1577836185693741\n",
      "Batch 640,  loss: 0.18849601745605468\n",
      "Batch 645,  loss: 0.22919887602329253\n",
      "Batch 650,  loss: 0.1427269235253334\n",
      "Batch 655,  loss: 0.19125888496637344\n",
      "Batch 660,  loss: 0.1874876320362091\n",
      "Batch 665,  loss: 0.1648906350135803\n",
      "Batch 670,  loss: 0.14563632309436797\n",
      "Batch 675,  loss: 0.1547777459025383\n",
      "Batch 680,  loss: 0.19607825875282286\n",
      "Batch 685,  loss: 0.14316048920154573\n",
      "Batch 690,  loss: 0.18014862835407258\n",
      "Batch 695,  loss: 0.17031251192092894\n",
      "Batch 700,  loss: 0.1679535537958145\n",
      "Batch 705,  loss: 0.15198110193014144\n",
      "Batch 710,  loss: 0.25344171524047854\n",
      "Batch 715,  loss: 0.14837857186794282\n",
      "Batch 720,  loss: 0.13856552690267562\n",
      "Batch 725,  loss: 0.16172423660755159\n",
      "Batch 730,  loss: 0.13222183287143707\n",
      "Batch 735,  loss: 0.16484450697898864\n",
      "Batch 740,  loss: 0.17041075378656387\n",
      "Batch 745,  loss: 0.1301039382815361\n",
      "Batch 750,  loss: 0.19006026089191436\n",
      "Batch 755,  loss: 0.164039146900177\n",
      "Batch 760,  loss: 0.1978551983833313\n",
      "Batch 765,  loss: 0.21805750727653503\n",
      "Batch 770,  loss: 0.15141174644231797\n",
      "Batch 775,  loss: 0.20346497297286986\n",
      "Batch 780,  loss: 0.15490703880786896\n",
      "Batch 785,  loss: 0.1403825044631958\n",
      "Batch 790,  loss: 0.18827080130577087\n",
      "Batch 795,  loss: 0.18017394840717316\n",
      "Batch 800,  loss: 0.1638641357421875\n",
      "Batch 805,  loss: 0.18899403810501098\n",
      "Batch 810,  loss: 0.17760031968355178\n",
      "Batch 815,  loss: 0.1453053057193756\n",
      "Batch 820,  loss: 0.17309874594211577\n",
      "Batch 825,  loss: 0.14652691036462784\n",
      "Batch 830,  loss: 0.16462211906909943\n",
      "Batch 835,  loss: 0.16447535455226897\n",
      "Batch 840,  loss: 0.16275699734687804\n",
      "Batch 845,  loss: 0.15521581768989562\n",
      "Batch 850,  loss: 0.16795174181461334\n",
      "Batch 855,  loss: 0.13726406842470168\n",
      "Batch 860,  loss: 0.1266593337059021\n",
      "Batch 865,  loss: 0.15065160542726516\n",
      "Batch 870,  loss: 0.1732145994901657\n",
      "Batch 875,  loss: 0.1621036112308502\n",
      "Batch 880,  loss: 0.17201000452041626\n",
      "Batch 885,  loss: 0.1788153350353241\n",
      "Batch 890,  loss: 0.18716125637292863\n",
      "Batch 895,  loss: 0.1606311619281769\n",
      "Batch 900,  loss: 0.14642608612775804\n",
      "Batch 905,  loss: 0.2017001524567604\n",
      "Batch 910,  loss: 0.17020768523216248\n",
      "Batch 915,  loss: 0.14352820813655853\n",
      "Batch 920,  loss: 0.16878070384263993\n",
      "Batch 925,  loss: 0.16044434458017348\n",
      "Batch 930,  loss: 0.15575774163007736\n",
      "Batch 935,  loss: 0.18274774253368378\n",
      "Batch 940,  loss: 0.16926438361406326\n",
      "Batch 945,  loss: 0.15862010717391967\n",
      "Batch 950,  loss: 0.19259174466133117\n",
      "Batch 955,  loss: 0.18666185736656188\n",
      "Batch 960,  loss: 0.1781988725066185\n",
      "Batch 965,  loss: 0.17819247543811798\n",
      "Batch 970,  loss: 0.17703431248664855\n",
      "Batch 975,  loss: 0.17678192257881165\n",
      "Batch 980,  loss: 0.1891940265893936\n",
      "Batch 985,  loss: 0.14277507066726686\n",
      "Batch 990,  loss: 0.23377868235111238\n",
      "Batch 995,  loss: 0.1631218433380127\n",
      "Batch 1000,  loss: 0.17707454264163972\n",
      "Batch 1005,  loss: 0.16861455291509628\n",
      "Batch 1010,  loss: 0.14855623841285706\n",
      "Batch 1015,  loss: 0.16439693570137023\n",
      "Batch 1020,  loss: 0.14794980138540267\n",
      "Batch 1025,  loss: 0.1507620930671692\n",
      "Batch 1030,  loss: 0.15005056858062743\n",
      "Batch 1035,  loss: 0.13148145228624344\n",
      "Batch 1040,  loss: 0.13192204385995865\n",
      "Batch 1045,  loss: 0.11993652284145355\n",
      "Batch 1050,  loss: 0.14424578249454498\n",
      "Batch 1055,  loss: 0.15793495178222655\n",
      "Batch 1060,  loss: 0.17248610258102418\n",
      "Batch 1065,  loss: 0.1224187508225441\n",
      "Batch 1070,  loss: 0.15387364327907563\n",
      "Batch 1075,  loss: 0.18196935057640076\n",
      "Batch 1080,  loss: 0.21518274247646332\n",
      "Batch 1085,  loss: 0.19639921188354492\n",
      "Batch 1090,  loss: 0.17461274117231368\n",
      "Batch 1095,  loss: 0.21674493551254273\n",
      "Batch 1100,  loss: 0.09730101823806762\n",
      "Batch 1105,  loss: 0.12194666862487794\n",
      "Batch 1110,  loss: 0.1694493442773819\n",
      "Batch 1115,  loss: 0.11205142289400101\n",
      "Batch 1120,  loss: 0.1378496006131172\n",
      "Batch 1125,  loss: 0.19273057878017424\n",
      "Batch 1130,  loss: 0.14189439564943312\n",
      "Batch 1135,  loss: 0.18817162811756133\n",
      "Batch 1140,  loss: 0.14406286627054216\n",
      "Batch 1145,  loss: 0.16067825257778168\n",
      "Batch 1150,  loss: 0.1612695962190628\n",
      "Batch 1155,  loss: 0.18718969225883483\n",
      "Batch 1160,  loss: 0.15411353409290313\n",
      "Batch 1165,  loss: 0.13006934225559236\n",
      "Batch 1170,  loss: 0.17229344546794892\n",
      "Batch 1175,  loss: 0.11865741461515426\n",
      "Batch 1180,  loss: 0.17370678782463073\n",
      "Batch 1185,  loss: 0.15482382029294967\n",
      "Batch 1190,  loss: 0.1411062940955162\n",
      "Batch 1195,  loss: 0.15971314311027526\n",
      "Batch 1200,  loss: 0.15036243498325347\n",
      "Batch 1205,  loss: 0.165527606010437\n",
      "Batch 1210,  loss: 0.17559091746807098\n",
      "Batch 1215,  loss: 0.197079998254776\n",
      "Batch 1220,  loss: 0.1698793053627014\n",
      "Batch 1225,  loss: 0.15025076866149903\n",
      "Batch 1230,  loss: 0.14937229305505753\n",
      "Batch 1235,  loss: 0.13039652556180953\n",
      "Batch 1240,  loss: 0.1665937677025795\n",
      "Batch 1245,  loss: 0.14535439759492874\n",
      "Batch 1250,  loss: 0.19126254618167876\n",
      "Batch 1255,  loss: 0.14829362630844117\n",
      "Batch 1260,  loss: 0.1806056171655655\n",
      "Batch 1265,  loss: 0.14443425834178925\n",
      "Batch 1270,  loss: 0.21186022758483886\n",
      "Batch 1275,  loss: 0.16337388008832932\n",
      "Batch 1280,  loss: 0.12597346007823945\n",
      "Batch 1285,  loss: 0.18860508501529694\n",
      "Batch 1290,  loss: 0.15518361255526542\n",
      "Batch 1295,  loss: 0.12782395035028457\n",
      "Batch 1300,  loss: 0.15261511504650116\n",
      "Batch 1305,  loss: 0.13200747668743135\n",
      "Batch 1310,  loss: 0.14289335608482362\n",
      "Batch 1315,  loss: 0.17600631415843965\n",
      "Batch 1320,  loss: 0.1777210146188736\n",
      "Batch 1325,  loss: 0.14334555268287658\n",
      "Batch 1330,  loss: 0.13747648298740386\n",
      "Batch 1335,  loss: 0.15834150612354278\n",
      "Batch 1340,  loss: 0.14489029347896576\n",
      "Batch 1345,  loss: 0.157202784717083\n",
      "Batch 1350,  loss: 0.17590038180351258\n",
      "Batch 1355,  loss: 0.18610546886920928\n",
      "Batch 1360,  loss: 0.1299286365509033\n",
      "Batch 1365,  loss: 0.15293060839176179\n",
      "Batch 1370,  loss: 0.1554270327091217\n",
      "Batch 1375,  loss: 0.16135592609643937\n",
      "Batch 1380,  loss: 0.17399127185344695\n",
      "Batch 1385,  loss: 0.17967430353164673\n",
      "Batch 1390,  loss: 0.1739462822675705\n",
      "Batch 1395,  loss: 0.18114914298057555\n",
      "Batch 1400,  loss: 0.1528897151350975\n",
      "Batch 1405,  loss: 0.19524608552455902\n",
      "Batch 1410,  loss: 0.1935276210308075\n",
      "Batch 1415,  loss: 0.18616228699684143\n",
      "Batch 1420,  loss: 0.16344229280948638\n",
      "Batch 1425,  loss: 0.1819198966026306\n",
      "Batch 1430,  loss: 0.15666455030441284\n",
      "Batch 1435,  loss: 0.1620395451784134\n",
      "Batch 1440,  loss: 0.17981481850147246\n",
      "Batch 1445,  loss: 0.12729349881410598\n",
      "Batch 1450,  loss: 0.14719821512699127\n",
      "Batch 1455,  loss: 0.12318606972694397\n",
      "Batch 1460,  loss: 0.1788691133260727\n",
      "Batch 1465,  loss: 0.15638516694307328\n",
      "Batch 1470,  loss: 0.23110132217407225\n",
      "Batch 1475,  loss: 0.13914087414741516\n",
      "Batch 1480,  loss: 0.1818367063999176\n",
      "Batch 1485,  loss: 0.1544908031821251\n",
      "Batch 1490,  loss: 0.15230142176151276\n",
      "Batch 1495,  loss: 0.15990395843982697\n",
      "Batch 1500,  loss: 0.15205801725387574\n",
      "Batch 1505,  loss: 0.12037791311740875\n",
      "Batch 1510,  loss: 0.1387529417872429\n",
      "Batch 1515,  loss: 0.1946355387568474\n",
      "Batch 1520,  loss: 0.12125787138938904\n",
      "Batch 1525,  loss: 0.1435551956295967\n",
      "Batch 1530,  loss: 0.14507260918617249\n",
      "Batch 1535,  loss: 0.13095176219940186\n",
      "Batch 1540,  loss: 0.17363894134759902\n",
      "Batch 1545,  loss: 0.22371853590011598\n",
      "Batch 1550,  loss: 0.1282803311944008\n",
      "Batch 1555,  loss: 0.17194409668445587\n",
      "Batch 1560,  loss: 0.20084562301635742\n",
      "Batch 1565,  loss: 0.19794344007968903\n",
      "Batch 1570,  loss: 0.14780676662921904\n",
      "Batch 1575,  loss: 0.16577226519584656\n",
      "Batch 1580,  loss: 0.18161782324314119\n",
      "Batch 1585,  loss: 0.16063769161701202\n",
      "Batch 1590,  loss: 0.1451054871082306\n",
      "Batch 1595,  loss: 0.1720190942287445\n",
      "Batch 1600,  loss: 0.17721424698829652\n",
      "Batch 1605,  loss: 0.16031833589076996\n",
      "Batch 1610,  loss: 0.16111499071121216\n",
      "Batch 1615,  loss: 0.10163962095975876\n",
      "Batch 1620,  loss: 0.1657174050807953\n",
      "Batch 1625,  loss: 0.21970567107200623\n",
      "Batch 1630,  loss: 0.22014859169721604\n",
      "Batch 1635,  loss: 0.17113529443740844\n",
      "Batch 1640,  loss: 0.20699395835399628\n",
      "Batch 1645,  loss: 0.16870782971382142\n",
      "Batch 1650,  loss: 0.19408543407917023\n",
      "Batch 1655,  loss: 0.1563084602355957\n",
      "Batch 1660,  loss: 0.21681498885154724\n",
      "Batch 1665,  loss: 0.14786864966154098\n",
      "Batch 1670,  loss: 0.1551814466714859\n",
      "Batch 1675,  loss: 0.14545857906341553\n",
      "Batch 1680,  loss: 0.174147567152977\n",
      "Batch 1685,  loss: 0.1659283921122551\n",
      "Batch 1690,  loss: 0.15062377154827117\n",
      "Batch 1695,  loss: 0.16865460872650145\n",
      "Batch 1700,  loss: 0.1868073582649231\n",
      "Batch 1705,  loss: 0.2597375392913818\n",
      "Batch 1710,  loss: 0.13062765449285507\n",
      "Batch 1715,  loss: 0.16819681525230407\n",
      "Batch 1720,  loss: 0.20691935122013091\n",
      "Batch 1725,  loss: 0.12474522292613983\n",
      "Batch 1730,  loss: 0.1653848797082901\n",
      "Batch 1735,  loss: 0.184617018699646\n",
      "Batch 1740,  loss: 0.17020178437232972\n",
      "Batch 1745,  loss: 0.11297039985656739\n",
      "Batch 1750,  loss: 0.18001769483089447\n",
      "Batch 1755,  loss: 0.18371343314647676\n",
      "Batch 1760,  loss: 0.18912376463413239\n",
      "Batch 1765,  loss: 0.11362514346837997\n",
      "Batch 1770,  loss: 0.21702181696891784\n",
      "Batch 1775,  loss: 0.16837480217218398\n",
      "Batch 1780,  loss: 0.16354027688503264\n",
      "Batch 1785,  loss: 0.18057380020618438\n",
      "Batch 1790,  loss: 0.15095169246196746\n",
      "Batch 1795,  loss: 0.17878248989582063\n",
      "Batch 1800,  loss: 0.16750003695487975\n",
      "Batch 1805,  loss: 0.1375153675675392\n",
      "Batch 1810,  loss: 0.14396339058876037\n",
      "Batch 1815,  loss: 0.17331946194171904\n",
      "Batch 1820,  loss: 0.13312262147665024\n",
      "Batch 1825,  loss: 0.16258845329284669\n",
      "Batch 1830,  loss: 0.13617664575576782\n",
      "Batch 1835,  loss: 0.17712805271148682\n",
      "Batch 1840,  loss: 0.16990549862384796\n",
      "Batch 1845,  loss: 0.16318509578704835\n",
      "Batch 1850,  loss: 0.1616242915391922\n",
      "Batch 1855,  loss: 0.13028670847415924\n",
      "Batch 1860,  loss: 0.15869772136211396\n",
      "Batch 1865,  loss: 0.18472400903701783\n",
      "Batch 1870,  loss: 0.15081675350666046\n",
      "Batch 1875,  loss: 0.22686460614204407\n",
      "Batch 1880,  loss: 0.19294657409191132\n",
      "Batch 1885,  loss: 0.20354360342025757\n",
      "Batch 1890,  loss: 0.17251980006694795\n",
      "Batch 1895,  loss: 0.15369062423706054\n",
      "Batch 1900,  loss: 0.1504932850599289\n",
      "Batch 1905,  loss: 0.15865181088447572\n",
      "Batch 1910,  loss: 0.2200684130191803\n",
      "Batch 1915,  loss: 0.1574811488389969\n",
      "Batch 1920,  loss: 0.15934595763683318\n",
      "Batch 1925,  loss: 0.16539891362190245\n",
      "Batch 1930,  loss: 0.15730027109384537\n",
      "Batch 1935,  loss: 0.16882530152797698\n",
      "Batch 1940,  loss: 0.15690793842077255\n",
      "Batch 1945,  loss: 0.12512232810258866\n",
      "Batch 1950,  loss: 0.1524336516857147\n",
      "Batch 1955,  loss: 0.17346669733524323\n",
      "Batch 1960,  loss: 0.1919343203306198\n",
      "Batch 1965,  loss: 0.1506710946559906\n",
      "Batch 1970,  loss: 0.13290351927280425\n",
      "Batch 1975,  loss: 0.16419419050216674\n",
      "Batch 1980,  loss: 0.1437989741563797\n",
      "Batch 1985,  loss: 0.17576027512550355\n",
      "Batch 1990,  loss: 0.1786312773823738\n",
      "Batch 1995,  loss: 0.20259954631328583\n",
      "Batch 2000,  loss: 0.16157956868410112\n",
      "Batch 2005,  loss: 0.15657367408275605\n",
      "Batch 2010,  loss: 0.15822670757770538\n",
      "Batch 2015,  loss: 0.18751133978366852\n",
      "Batch 2020,  loss: 0.18648894429206847\n",
      "Batch 2025,  loss: 0.17198331505060196\n",
      "Batch 2030,  loss: 0.13803344815969468\n",
      "Batch 2035,  loss: 0.12710123062133788\n",
      "Batch 2040,  loss: 0.14222718477249147\n",
      "Batch 2045,  loss: 0.167165407538414\n",
      "Batch 2050,  loss: 0.16247261464595794\n",
      "Batch 2055,  loss: 0.13953781127929688\n",
      "Batch 2060,  loss: 0.1428294748067856\n",
      "Batch 2065,  loss: 0.15369216352701187\n",
      "Batch 2070,  loss: 0.1692911595106125\n",
      "Batch 2075,  loss: 0.18500271439552307\n",
      "Batch 2080,  loss: 0.1600620925426483\n",
      "Batch 2085,  loss: 0.14542853385210036\n",
      "Batch 2090,  loss: 0.23731200098991395\n",
      "Batch 2095,  loss: 0.14332853257656097\n",
      "Batch 2100,  loss: 0.16721807718276976\n",
      "Batch 2105,  loss: 0.16544928252696992\n",
      "Batch 2110,  loss: 0.18994369208812714\n",
      "Batch 2115,  loss: 0.15982482582330704\n",
      "Batch 2120,  loss: 0.15058032125234605\n",
      "Batch 2125,  loss: 0.18448178470134735\n",
      "Batch 2130,  loss: 0.1274331822991371\n",
      "Batch 2135,  loss: 0.19179177284240723\n",
      "Batch 2140,  loss: 0.2136303961277008\n",
      "Batch 2145,  loss: 0.15155106484889985\n",
      "Batch 2150,  loss: 0.14969744086265563\n",
      "Batch 2155,  loss: 0.17387807965278626\n",
      "Batch 2160,  loss: 0.14911389648914336\n",
      "Batch 2165,  loss: 0.13947615176439285\n",
      "Batch 2170,  loss: 0.1598415344953537\n",
      "Batch 2175,  loss: 0.15506542026996611\n",
      "Batch 2180,  loss: 0.16179605275392533\n",
      "Batch 2185,  loss: 0.19805567264556884\n",
      "Batch 2190,  loss: 0.2010296642780304\n",
      "Batch 2195,  loss: 0.14041839987039567\n",
      "Batch 2200,  loss: 0.15638220608234404\n",
      "Batch 2205,  loss: 0.17880272269248962\n",
      "Batch 2210,  loss: 0.14887891411781312\n",
      "Batch 2215,  loss: 0.1400996759533882\n",
      "Batch 2220,  loss: 0.1735268235206604\n",
      "Batch 2225,  loss: 0.13531213104724885\n",
      "Batch 2230,  loss: 0.15360909104347228\n",
      "Batch 2235,  loss: 0.1995210736989975\n",
      "Batch 2240,  loss: 0.1893100768327713\n",
      "Batch 2245,  loss: 0.18075641393661498\n",
      "Batch 2250,  loss: 0.13246670961380005\n",
      "Batch 2255,  loss: 0.17036379426717757\n",
      "Batch 2260,  loss: 0.1263459324836731\n",
      "Batch 2265,  loss: 0.1632871448993683\n",
      "Batch 2270,  loss: 0.15683129876852037\n",
      "Batch 2275,  loss: 0.16371879875659942\n",
      "Batch 2280,  loss: 0.17142826020717622\n",
      "Batch 2285,  loss: 0.16734884977340697\n",
      "Batch 2290,  loss: 0.1528022438287735\n",
      "Batch 2295,  loss: 0.1661502778530121\n",
      "Batch 2300,  loss: 0.16182701289653778\n",
      "Batch 2305,  loss: 0.18428976982831954\n",
      "Batch 2310,  loss: 0.17227007895708085\n",
      "Batch 2315,  loss: 0.13575909584760665\n",
      "Batch 2320,  loss: 0.16621833741664888\n",
      "Batch 2325,  loss: 0.2192552626132965\n",
      "Batch 2330,  loss: 0.16378221213817595\n",
      "Batch 2335,  loss: 0.17147139310836793\n",
      "Batch 2340,  loss: 0.24787608683109283\n",
      "Batch 2345,  loss: 0.13869437873363494\n",
      "Batch 2350,  loss: 0.15698766112327575\n",
      "Batch 2355,  loss: 0.14486086666584014\n",
      "Batch 2360,  loss: 0.1252992644906044\n",
      "Batch 2365,  loss: 0.21528297364711763\n",
      "Batch 2370,  loss: 0.13806337267160415\n",
      "Batch 2375,  loss: 0.14423150271177293\n",
      "Batch 2380,  loss: 0.1480892464518547\n",
      "Batch 2385,  loss: 0.17966432869434357\n",
      "Batch 2390,  loss: 0.19886773824691772\n",
      "Batch 2395,  loss: 0.14385389983654023\n",
      "Batch 2400,  loss: 0.16688561141490937\n",
      "Batch 2405,  loss: 0.16610508859157563\n",
      "Batch 2410,  loss: 0.13353621661663057\n",
      "Batch 2415,  loss: 0.1557927429676056\n",
      "Batch 2420,  loss: 0.19522695243358612\n",
      "Batch 2425,  loss: 0.19557687044143676\n",
      "Batch 2430,  loss: 0.15375718027353286\n",
      "Batch 2435,  loss: 0.15596758276224137\n",
      "Batch 2440,  loss: 0.15058353394269944\n",
      "Batch 2445,  loss: 0.18108610063791275\n",
      "Batch 2450,  loss: 0.22637895345687867\n",
      "Batch 2455,  loss: 0.14278181344270707\n",
      "Batch 2460,  loss: 0.13615306913852693\n",
      "Batch 2465,  loss: 0.16760438978672026\n",
      "Batch 2470,  loss: 0.17351922988891602\n",
      "Batch 2475,  loss: 0.14217260330915452\n",
      "Batch 2480,  loss: 0.13751368522644042\n",
      "Batch 2485,  loss: 0.17170465886592864\n",
      "Batch 2490,  loss: 0.20012687742710114\n",
      "Batch 2495,  loss: 0.1913167804479599\n",
      "Batch 2500,  loss: 0.16483273804187776\n",
      "Batch 2505,  loss: 0.15392646789550782\n",
      "Batch 2510,  loss: 0.17985186874866485\n",
      "Batch 2515,  loss: 0.12465697377920151\n",
      "Batch 2520,  loss: 0.18600561320781708\n",
      "Batch 2525,  loss: 0.16478623151779176\n",
      "Batch 2530,  loss: 0.12817959040403365\n",
      "Batch 2535,  loss: 0.18165259957313537\n",
      "Batch 2540,  loss: 0.18732020854949952\n",
      "Batch 2545,  loss: 0.17823701500892639\n",
      "Batch 2550,  loss: 0.19945042878389357\n",
      "Batch 2555,  loss: 0.16042251586914064\n",
      "Batch 2560,  loss: 0.1476265698671341\n",
      "Batch 2565,  loss: 0.14338158220052719\n",
      "Batch 2570,  loss: 0.16221895217895507\n",
      "Batch 2575,  loss: 0.2005952328443527\n",
      "Batch 2580,  loss: 0.17197740077972412\n",
      "Batch 2585,  loss: 0.16214870363473893\n",
      "Batch 2590,  loss: 0.13947555422782898\n",
      "Batch 2595,  loss: 0.16040213257074357\n",
      "Batch 2600,  loss: 0.16666944324970245\n",
      "Batch 2605,  loss: 0.14645805805921555\n",
      "Batch 2610,  loss: 0.12043022215366364\n",
      "Batch 2615,  loss: 0.1440524622797966\n",
      "Batch 2620,  loss: 0.14490166008472444\n",
      "Batch 2625,  loss: 0.14209390580654144\n",
      "Batch 2630,  loss: 0.15921701788902282\n",
      "Batch 2635,  loss: 0.15370117574930192\n",
      "Batch 2640,  loss: 0.13817810118198395\n",
      "Batch 2645,  loss: 0.17606761455535888\n",
      "Batch 2650,  loss: 0.1431313931941986\n",
      "Batch 2655,  loss: 0.1387317568063736\n",
      "Batch 2660,  loss: 0.20526669621467591\n",
      "Batch 2665,  loss: 0.1525757372379303\n",
      "Batch 2670,  loss: 0.1552893340587616\n",
      "Batch 2675,  loss: 0.14450633972883226\n",
      "Batch 2680,  loss: 0.12120118886232376\n",
      "Batch 2685,  loss: 0.13785738050937651\n",
      "Batch 2690,  loss: 0.15927640795707704\n",
      "Batch 2695,  loss: 0.1483166590332985\n",
      "Batch 2700,  loss: 0.17466025650501252\n",
      "Batch 2705,  loss: 0.21657333374023438\n",
      "Batch 2710,  loss: 0.1278726190328598\n",
      "Batch 2715,  loss: 0.16584445238113404\n",
      "Batch 2720,  loss: 0.16125490069389342\n",
      "Batch 2725,  loss: 0.16046817898750304\n",
      "Batch 2730,  loss: 0.18828876316547394\n",
      "Batch 2735,  loss: 0.1466760978102684\n",
      "Batch 2740,  loss: 0.1647024855017662\n",
      "Batch 2745,  loss: 0.19159730076789855\n",
      "Batch 2750,  loss: 0.14582798779010772\n",
      "Batch 2755,  loss: 0.22048765420913696\n",
      "Batch 2760,  loss: 0.19107696264982224\n",
      "Batch 2765,  loss: 0.15564721524715425\n",
      "Batch 2770,  loss: 0.15487535446882247\n",
      "LOSS train 0.15487535446882247. Validation loss: 0.1643949097953737 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 26:\n",
      "Batch 5,  loss: 0.16671639382839204\n",
      "Batch 10,  loss: 0.16565713584423064\n",
      "Batch 15,  loss: 0.1475271165370941\n",
      "Batch 20,  loss: 0.15299475193023682\n",
      "Batch 25,  loss: 0.16232129633426667\n",
      "Batch 30,  loss: 0.15619772523641587\n",
      "Batch 35,  loss: 0.20150311589241027\n",
      "Batch 40,  loss: 0.14569028466939926\n",
      "Batch 45,  loss: 0.165679931640625\n",
      "Batch 50,  loss: 0.17103445529937744\n",
      "Batch 55,  loss: 0.17012673169374465\n",
      "Batch 60,  loss: 0.18284704387187958\n",
      "Batch 65,  loss: 0.15000614225864412\n",
      "Batch 70,  loss: 0.16764982640743256\n",
      "Batch 75,  loss: 0.15977407097816468\n",
      "Batch 80,  loss: 0.16530683934688567\n",
      "Batch 85,  loss: 0.1641651064157486\n",
      "Batch 90,  loss: 0.14835565984249116\n",
      "Batch 95,  loss: 0.1836179316043854\n",
      "Batch 100,  loss: 0.14536583423614502\n",
      "Batch 105,  loss: 0.14146729409694672\n",
      "Batch 110,  loss: 0.21425985395908356\n",
      "Batch 115,  loss: 0.16636671125888824\n",
      "Batch 120,  loss: 0.1579735666513443\n",
      "Batch 125,  loss: 0.148028564453125\n",
      "Batch 130,  loss: 0.18213495910167693\n",
      "Batch 135,  loss: 0.20649612247943877\n",
      "Batch 140,  loss: 0.18188607543706894\n",
      "Batch 145,  loss: 0.15325907766819\n",
      "Batch 150,  loss: 0.21071991622447966\n",
      "Batch 155,  loss: 0.16275293231010438\n",
      "Batch 160,  loss: 0.14435093700885773\n",
      "Batch 165,  loss: 0.15225039422512054\n",
      "Batch 170,  loss: 0.20192593932151795\n",
      "Batch 175,  loss: 0.1614854484796524\n",
      "Batch 180,  loss: 0.1547491043806076\n",
      "Batch 185,  loss: 0.19770971238613128\n",
      "Batch 190,  loss: 0.1734231859445572\n",
      "Batch 195,  loss: 0.19947914481163026\n",
      "Batch 200,  loss: 0.15640109181404113\n",
      "Batch 205,  loss: 0.15306587368249894\n",
      "Batch 210,  loss: 0.23069408237934114\n",
      "Batch 215,  loss: 0.13646076023578643\n",
      "Batch 220,  loss: 0.20950038433074952\n",
      "Batch 225,  loss: 0.17756504267454148\n",
      "Batch 230,  loss: 0.1603034794330597\n",
      "Batch 235,  loss: 0.1718145489692688\n",
      "Batch 240,  loss: 0.14347241222858428\n",
      "Batch 245,  loss: 0.159428970515728\n",
      "Batch 250,  loss: 0.15349189788103104\n",
      "Batch 255,  loss: 0.15216320753097534\n",
      "Batch 260,  loss: 0.12880509197711945\n",
      "Batch 265,  loss: 0.16715545505285262\n",
      "Batch 270,  loss: 0.14476220905780793\n",
      "Batch 275,  loss: 0.166852405667305\n",
      "Batch 280,  loss: 0.15993174016475678\n",
      "Batch 285,  loss: 0.1896631807088852\n",
      "Batch 290,  loss: 0.14567862153053285\n",
      "Batch 295,  loss: 0.14507217109203338\n",
      "Batch 300,  loss: 0.15133443474769592\n",
      "Batch 305,  loss: 0.1406915679574013\n",
      "Batch 310,  loss: 0.13563760966062546\n",
      "Batch 315,  loss: 0.17519256770610808\n",
      "Batch 320,  loss: 0.1797743558883667\n",
      "Batch 325,  loss: 0.15414172857999803\n",
      "Batch 330,  loss: 0.19135345816612243\n",
      "Batch 335,  loss: 0.17311708629131317\n",
      "Batch 340,  loss: 0.14041539132595063\n",
      "Batch 345,  loss: 0.14782808870077133\n",
      "Batch 350,  loss: 0.13737427294254304\n",
      "Batch 355,  loss: 0.17436855435371398\n",
      "Batch 360,  loss: 0.1630248546600342\n",
      "Batch 365,  loss: 0.15967569053173064\n",
      "Batch 370,  loss: 0.17428846955299376\n",
      "Batch 375,  loss: 0.1335274949669838\n",
      "Batch 380,  loss: 0.17033058702945708\n",
      "Batch 385,  loss: 0.14983494877815245\n",
      "Batch 390,  loss: 0.15806537568569184\n",
      "Batch 395,  loss: 0.1700364500284195\n",
      "Batch 400,  loss: 0.12067043334245682\n",
      "Batch 405,  loss: 0.1372498854994774\n",
      "Batch 410,  loss: 0.14937951266765595\n",
      "Batch 415,  loss: 0.14887260496616364\n",
      "Batch 420,  loss: 0.1877473071217537\n",
      "Batch 425,  loss: 0.17203656286001207\n",
      "Batch 430,  loss: 0.18446660339832305\n",
      "Batch 435,  loss: 0.17593356370925903\n",
      "Batch 440,  loss: 0.14212699085474015\n",
      "Batch 445,  loss: 0.14066859483718872\n",
      "Batch 450,  loss: 0.1766059696674347\n",
      "Batch 455,  loss: 0.18784943222999573\n",
      "Batch 460,  loss: 0.13795042634010315\n",
      "Batch 465,  loss: 0.12923009395599366\n",
      "Batch 470,  loss: 0.215854611992836\n",
      "Batch 475,  loss: 0.22594693601131438\n",
      "Batch 480,  loss: 0.15273161381483077\n",
      "Batch 485,  loss: 0.2042877584695816\n",
      "Batch 490,  loss: 0.14974737614393235\n",
      "Batch 495,  loss: 0.14536184668540955\n",
      "Batch 500,  loss: 0.199240580201149\n",
      "Batch 505,  loss: 0.1863562673330307\n",
      "Batch 510,  loss: 0.13887018263339995\n",
      "Batch 515,  loss: 0.17411472350358964\n",
      "Batch 520,  loss: 0.1978313833475113\n",
      "Batch 525,  loss: 0.21309130191802977\n",
      "Batch 530,  loss: 0.1816721588373184\n",
      "Batch 535,  loss: 0.14906924664974214\n",
      "Batch 540,  loss: 0.18506015539169313\n",
      "Batch 545,  loss: 0.17122881710529328\n",
      "Batch 550,  loss: 0.15517403930425644\n",
      "Batch 555,  loss: 0.1825639396905899\n",
      "Batch 560,  loss: 0.15962973833084107\n",
      "Batch 565,  loss: 0.2227644294500351\n",
      "Batch 570,  loss: 0.13957403600215912\n",
      "Batch 575,  loss: 0.15253059267997743\n",
      "Batch 580,  loss: 0.16640831232070924\n",
      "Batch 585,  loss: 0.18514791429042815\n",
      "Batch 590,  loss: 0.19153040945529937\n",
      "Batch 595,  loss: 0.17674797922372817\n",
      "Batch 600,  loss: 0.17193815410137175\n",
      "Batch 605,  loss: 0.1748178035020828\n",
      "Batch 610,  loss: 0.15385189801454544\n",
      "Batch 615,  loss: 0.19782850593328477\n",
      "Batch 620,  loss: 0.1761990487575531\n",
      "Batch 625,  loss: 0.1897231310606003\n",
      "Batch 630,  loss: 0.15416060835123063\n",
      "Batch 635,  loss: 0.18525347411632537\n",
      "Batch 640,  loss: 0.12726947367191316\n",
      "Batch 645,  loss: 0.15559039264917374\n",
      "Batch 650,  loss: 0.23166980743408203\n",
      "Batch 655,  loss: 0.19588773101568221\n",
      "Batch 660,  loss: 0.16657037436962127\n",
      "Batch 665,  loss: 0.1710473656654358\n",
      "Batch 670,  loss: 0.14795709699392318\n",
      "Batch 675,  loss: 0.13205511271953582\n",
      "Batch 680,  loss: 0.13477361649274827\n",
      "Batch 685,  loss: 0.15968241095542907\n",
      "Batch 690,  loss: 0.1911432534456253\n",
      "Batch 695,  loss: 0.1494784712791443\n",
      "Batch 700,  loss: 0.1789597138762474\n",
      "Batch 705,  loss: 0.14161175042390822\n",
      "Batch 710,  loss: 0.15209975391626357\n",
      "Batch 715,  loss: 0.16913582980632783\n",
      "Batch 720,  loss: 0.17351940870285035\n",
      "Batch 725,  loss: 0.16983418464660643\n",
      "Batch 730,  loss: 0.14719870388507844\n",
      "Batch 735,  loss: 0.1983702927827835\n",
      "Batch 740,  loss: 0.1656631499528885\n",
      "Batch 745,  loss: 0.1514033630490303\n",
      "Batch 750,  loss: 0.11837012469768524\n",
      "Batch 755,  loss: 0.18266322910785676\n",
      "Batch 760,  loss: 0.15956740081310272\n",
      "Batch 765,  loss: 0.1585739016532898\n",
      "Batch 770,  loss: 0.12648073136806487\n",
      "Batch 775,  loss: 0.15643417835235596\n",
      "Batch 780,  loss: 0.1408662885427475\n",
      "Batch 785,  loss: 0.21144334971904755\n",
      "Batch 790,  loss: 0.1393672361969948\n",
      "Batch 795,  loss: 0.13507770299911498\n",
      "Batch 800,  loss: 0.1622637003660202\n",
      "Batch 805,  loss: 0.16369147300720216\n",
      "Batch 810,  loss: 0.1615035504102707\n",
      "Batch 815,  loss: 0.20184143483638764\n",
      "Batch 820,  loss: 0.18251259326934816\n",
      "Batch 825,  loss: 0.17284526377916337\n",
      "Batch 830,  loss: 0.1571359947323799\n",
      "Batch 835,  loss: 0.16111285835504532\n",
      "Batch 840,  loss: 0.16147626638412477\n",
      "Batch 845,  loss: 0.17050964385271072\n",
      "Batch 850,  loss: 0.16773551404476167\n",
      "Batch 855,  loss: 0.15717985928058625\n",
      "Batch 860,  loss: 0.12287853062152862\n",
      "Batch 865,  loss: 0.14501782953739167\n",
      "Batch 870,  loss: 0.12008367776870728\n",
      "Batch 875,  loss: 0.16296206414699554\n",
      "Batch 880,  loss: 0.16498760282993316\n",
      "Batch 885,  loss: 0.15951105803251267\n",
      "Batch 890,  loss: 0.13686533123254777\n",
      "Batch 895,  loss: 0.14337866604328156\n",
      "Batch 900,  loss: 0.1302897021174431\n",
      "Batch 905,  loss: 0.1272999331355095\n",
      "Batch 910,  loss: 0.1330315962433815\n",
      "Batch 915,  loss: 0.16439614892005922\n",
      "Batch 920,  loss: 0.1553235813975334\n",
      "Batch 925,  loss: 0.19888850897550583\n",
      "Batch 930,  loss: 0.1338009864091873\n",
      "Batch 935,  loss: 0.18795841336250305\n",
      "Batch 940,  loss: 0.17068049013614656\n",
      "Batch 945,  loss: 0.13585424274206162\n",
      "Batch 950,  loss: 0.20475883185863494\n",
      "Batch 955,  loss: 0.12189901322126388\n",
      "Batch 960,  loss: 0.19495119005441666\n",
      "Batch 965,  loss: 0.15619981586933135\n",
      "Batch 970,  loss: 0.13848941177129745\n",
      "Batch 975,  loss: 0.15549698173999787\n",
      "Batch 980,  loss: 0.13480672091245652\n",
      "Batch 985,  loss: 0.22869180738925934\n",
      "Batch 990,  loss: 0.16231483817100525\n",
      "Batch 995,  loss: 0.14941053390502929\n",
      "Batch 1000,  loss: 0.15078558772802353\n",
      "Batch 1005,  loss: 0.1923436254262924\n",
      "Batch 1010,  loss: 0.19589546024799348\n",
      "Batch 1015,  loss: 0.14278112947940827\n",
      "Batch 1020,  loss: 0.14978974163532258\n",
      "Batch 1025,  loss: 0.12085668444633484\n",
      "Batch 1030,  loss: 0.13335174918174744\n",
      "Batch 1035,  loss: 0.14116912186145783\n",
      "Batch 1040,  loss: 0.17461290806531907\n",
      "Batch 1045,  loss: 0.15979088097810745\n",
      "Batch 1050,  loss: 0.1249571606516838\n",
      "Batch 1055,  loss: 0.16017274856567382\n",
      "Batch 1060,  loss: 0.17683980464935303\n",
      "Batch 1065,  loss: 0.15802502930164336\n",
      "Batch 1070,  loss: 0.1640717625617981\n",
      "Batch 1075,  loss: 0.15745644122362137\n",
      "Batch 1080,  loss: 0.18421244323253633\n",
      "Batch 1085,  loss: 0.15965475440025328\n",
      "Batch 1090,  loss: 0.1706734150648117\n",
      "Batch 1095,  loss: 0.14566422253847122\n",
      "Batch 1100,  loss: 0.1779493808746338\n",
      "Batch 1105,  loss: 0.11379924863576889\n",
      "Batch 1110,  loss: 0.18377845585346222\n",
      "Batch 1115,  loss: 0.16057348102331162\n",
      "Batch 1120,  loss: 0.19335511922836304\n",
      "Batch 1125,  loss: 0.17629573941230775\n",
      "Batch 1130,  loss: 0.13326792567968368\n",
      "Batch 1135,  loss: 0.1277299702167511\n",
      "Batch 1140,  loss: 0.1827615514397621\n",
      "Batch 1145,  loss: 0.1834448531270027\n",
      "Batch 1150,  loss: 0.17249736785888672\n",
      "Batch 1155,  loss: 0.162082639336586\n",
      "Batch 1160,  loss: 0.18214288651943206\n",
      "Batch 1165,  loss: 0.15792983025312424\n",
      "Batch 1170,  loss: 0.16940430998802186\n",
      "Batch 1175,  loss: 0.20560572445392608\n",
      "Batch 1180,  loss: 0.1734993949532509\n",
      "Batch 1185,  loss: 0.1491188406944275\n",
      "Batch 1190,  loss: 0.20757742524147033\n",
      "Batch 1195,  loss: 0.19400042295455933\n",
      "Batch 1200,  loss: 0.21113930344581605\n",
      "Batch 1205,  loss: 0.17344371676445008\n",
      "Batch 1210,  loss: 0.1546890065073967\n",
      "Batch 1215,  loss: 0.14483257085084916\n",
      "Batch 1220,  loss: 0.20224300622940064\n",
      "Batch 1225,  loss: 0.20155244171619416\n",
      "Batch 1230,  loss: 0.1425662159919739\n",
      "Batch 1235,  loss: 0.18548507541418074\n",
      "Batch 1240,  loss: 0.15284677743911743\n",
      "Batch 1245,  loss: 0.14593612849712373\n",
      "Batch 1250,  loss: 0.1471791610121727\n",
      "Batch 1255,  loss: 0.18464834690093995\n",
      "Batch 1260,  loss: 0.14441175162792205\n",
      "Batch 1265,  loss: 0.1572565346956253\n",
      "Batch 1270,  loss: 0.18183444291353226\n",
      "Batch 1275,  loss: 0.15446678996086122\n",
      "Batch 1280,  loss: 0.1801323413848877\n",
      "Batch 1285,  loss: 0.15571846663951874\n",
      "Batch 1290,  loss: 0.1549871563911438\n",
      "Batch 1295,  loss: 0.17908446192741395\n",
      "Batch 1300,  loss: 0.1741826444864273\n",
      "Batch 1305,  loss: 0.15170698165893554\n",
      "Batch 1310,  loss: 0.17887310832738876\n",
      "Batch 1315,  loss: 0.15832194685935974\n",
      "Batch 1320,  loss: 0.12222740054130554\n",
      "Batch 1325,  loss: 0.1441813051700592\n",
      "Batch 1330,  loss: 0.1750459522008896\n",
      "Batch 1335,  loss: 0.16928460896015168\n",
      "Batch 1340,  loss: 0.15555872917175292\n",
      "Batch 1345,  loss: 0.19006009101867677\n",
      "Batch 1350,  loss: 0.1369711861014366\n",
      "Batch 1355,  loss: 0.2109713450074196\n",
      "Batch 1360,  loss: 0.14751177728176118\n",
      "Batch 1365,  loss: 0.14364601373672486\n",
      "Batch 1370,  loss: 0.14529166594147683\n",
      "Batch 1375,  loss: 0.17660268545150756\n",
      "Batch 1380,  loss: 0.20169059038162232\n",
      "Batch 1385,  loss: 0.12045368403196335\n",
      "Batch 1390,  loss: 0.15575278997421266\n",
      "Batch 1395,  loss: 0.16037438809871674\n",
      "Batch 1400,  loss: 0.18681169152259827\n",
      "Batch 1405,  loss: 0.168323415517807\n",
      "Batch 1410,  loss: 0.16617707312107086\n",
      "Batch 1415,  loss: 0.16795888990163804\n",
      "Batch 1420,  loss: 0.13192065060138702\n",
      "Batch 1425,  loss: 0.19380497336387634\n",
      "Batch 1430,  loss: 0.1571965217590332\n",
      "Batch 1435,  loss: 0.16388985216617585\n",
      "Batch 1440,  loss: 0.1587913528084755\n",
      "Batch 1445,  loss: 0.1743842989206314\n",
      "Batch 1450,  loss: 0.10451889783143997\n",
      "Batch 1455,  loss: 0.12055451720952988\n",
      "Batch 1460,  loss: 0.14265166819095612\n",
      "Batch 1465,  loss: 0.1544222742319107\n",
      "Batch 1470,  loss: 0.13592107146978377\n",
      "Batch 1475,  loss: 0.1550103709101677\n",
      "Batch 1480,  loss: 0.17320118844509125\n",
      "Batch 1485,  loss: 0.15948792845010756\n",
      "Batch 1490,  loss: 0.15751030445098876\n",
      "Batch 1495,  loss: 0.1891162097454071\n",
      "Batch 1500,  loss: 0.15680466443300248\n",
      "Batch 1505,  loss: 0.13687941879034043\n",
      "Batch 1510,  loss: 0.14332622289657593\n",
      "Batch 1515,  loss: 0.17225786447525024\n",
      "Batch 1520,  loss: 0.17111541777849198\n",
      "Batch 1525,  loss: 0.12307320982217788\n",
      "Batch 1530,  loss: 0.15346235036849976\n",
      "Batch 1535,  loss: 0.1480014592409134\n",
      "Batch 1540,  loss: 0.16868132054805757\n",
      "Batch 1545,  loss: 0.13159817159175874\n",
      "Batch 1550,  loss: 0.17555060386657714\n",
      "Batch 1555,  loss: 0.17020943611860276\n",
      "Batch 1560,  loss: 0.15145639926195145\n",
      "Batch 1565,  loss: 0.16837644577026367\n",
      "Batch 1570,  loss: 0.131057670712471\n",
      "Batch 1575,  loss: 0.19427771270275115\n",
      "Batch 1580,  loss: 0.14667910486459732\n",
      "Batch 1585,  loss: 0.15515960156917571\n",
      "Batch 1590,  loss: 0.173508720099926\n",
      "Batch 1595,  loss: 0.13491300344467164\n",
      "Batch 1600,  loss: 0.21233597993850709\n",
      "Batch 1605,  loss: 0.1292912945151329\n",
      "Batch 1610,  loss: 0.12694419771432877\n",
      "Batch 1615,  loss: 0.16984439194202422\n",
      "Batch 1620,  loss: 0.15691661238670349\n",
      "Batch 1625,  loss: 0.16783410608768462\n",
      "Batch 1630,  loss: 0.14282775223255156\n",
      "Batch 1635,  loss: 0.16055746525526046\n",
      "Batch 1640,  loss: 0.15325081944465638\n",
      "Batch 1645,  loss: 0.16441244184970855\n",
      "Batch 1650,  loss: 0.16478026956319808\n",
      "Batch 1655,  loss: 0.18489806056022645\n",
      "Batch 1660,  loss: 0.13696575313806533\n",
      "Batch 1665,  loss: 0.18700307756662368\n",
      "Batch 1670,  loss: 0.14207397997379304\n",
      "Batch 1675,  loss: 0.19349153935909272\n",
      "Batch 1680,  loss: 0.16756686568260193\n",
      "Batch 1685,  loss: 0.1268285945057869\n",
      "Batch 1690,  loss: 0.19031348824501038\n",
      "Batch 1695,  loss: 0.148979751765728\n",
      "Batch 1700,  loss: 0.195433908700943\n",
      "Batch 1705,  loss: 0.18405610620975493\n",
      "Batch 1710,  loss: 0.1576188787817955\n",
      "Batch 1715,  loss: 0.22670367807149888\n",
      "Batch 1720,  loss: 0.12802281230688095\n",
      "Batch 1725,  loss: 0.16218762695789338\n",
      "Batch 1730,  loss: 0.22699757814407348\n",
      "Batch 1735,  loss: 0.1593530148267746\n",
      "Batch 1740,  loss: 0.17254433035850525\n",
      "Batch 1745,  loss: 0.1417314052581787\n",
      "Batch 1750,  loss: 0.14447384029626847\n",
      "Batch 1755,  loss: 0.1508033186197281\n",
      "Batch 1760,  loss: 0.1664157897233963\n",
      "Batch 1765,  loss: 0.16336266994476317\n",
      "Batch 1770,  loss: 0.1998453140258789\n",
      "Batch 1775,  loss: 0.13470631688833237\n",
      "Batch 1780,  loss: 0.12479474544525146\n",
      "Batch 1785,  loss: 0.20088720321655273\n",
      "Batch 1790,  loss: 0.12555824369192123\n",
      "Batch 1795,  loss: 0.17727945148944854\n",
      "Batch 1800,  loss: 0.13116846680641175\n",
      "Batch 1805,  loss: 0.18200711011886597\n",
      "Batch 1810,  loss: 0.20908384919166564\n",
      "Batch 1815,  loss: 0.12091756463050843\n",
      "Batch 1820,  loss: 0.18637512624263763\n",
      "Batch 1825,  loss: 0.20061232447624205\n",
      "Batch 1830,  loss: 0.15677861869335175\n",
      "Batch 1835,  loss: 0.16840447336435319\n",
      "Batch 1840,  loss: 0.1383867084980011\n",
      "Batch 1845,  loss: 0.19584447890520096\n",
      "Batch 1850,  loss: 0.16283572912216188\n",
      "Batch 1855,  loss: 0.171026411652565\n",
      "Batch 1860,  loss: 0.14866573214530945\n",
      "Batch 1865,  loss: 0.1377563714981079\n",
      "Batch 1870,  loss: 0.14300908744335175\n",
      "Batch 1875,  loss: 0.16771961152553558\n",
      "Batch 1880,  loss: 0.11625738441944122\n",
      "Batch 1885,  loss: 0.11746486574411392\n",
      "Batch 1890,  loss: 0.19260956048965455\n",
      "Batch 1895,  loss: 0.21004339754581453\n",
      "Batch 1900,  loss: 0.130852372944355\n",
      "Batch 1905,  loss: 0.17740244865417482\n",
      "Batch 1910,  loss: 0.17671477943658828\n",
      "Batch 1915,  loss: 0.13798207342624663\n",
      "Batch 1920,  loss: 0.1526890590786934\n",
      "Batch 1925,  loss: 0.21352705359458923\n",
      "Batch 1930,  loss: 0.17706781029701232\n",
      "Batch 1935,  loss: 0.19208312034606934\n",
      "Batch 1940,  loss: 0.2518601566553116\n",
      "Batch 1945,  loss: 0.14514341950416565\n",
      "Batch 1950,  loss: 0.13608317971229553\n",
      "Batch 1955,  loss: 0.15427551418542862\n",
      "Batch 1960,  loss: 0.15073356330394744\n",
      "Batch 1965,  loss: 0.1707339197397232\n",
      "Batch 1970,  loss: 0.16601573526859284\n",
      "Batch 1975,  loss: 0.16301025152206422\n",
      "Batch 1980,  loss: 0.12929675728082657\n",
      "Batch 1985,  loss: 0.16578831076622008\n",
      "Batch 1990,  loss: 0.2127588614821434\n",
      "Batch 1995,  loss: 0.1086876630783081\n",
      "Batch 2000,  loss: 0.16332790106534958\n",
      "Batch 2005,  loss: 0.12782831937074662\n",
      "Batch 2010,  loss: 0.21147685647010803\n",
      "Batch 2015,  loss: 0.17899153828620912\n",
      "Batch 2020,  loss: 0.15034468173980714\n",
      "Batch 2025,  loss: 0.13304681777954103\n",
      "Batch 2030,  loss: 0.1842590481042862\n",
      "Batch 2035,  loss: 0.19010084867477417\n",
      "Batch 2040,  loss: 0.19763631522655487\n",
      "Batch 2045,  loss: 0.22312988638877868\n",
      "Batch 2050,  loss: 0.1466197669506073\n",
      "Batch 2055,  loss: 0.14423038065433502\n",
      "Batch 2060,  loss: 0.21520315557718278\n",
      "Batch 2065,  loss: 0.19184053987264632\n",
      "Batch 2070,  loss: 0.231417116522789\n",
      "Batch 2075,  loss: 0.1969955861568451\n",
      "Batch 2080,  loss: 0.17230716347694397\n",
      "Batch 2085,  loss: 0.19034489691257478\n",
      "Batch 2090,  loss: 0.14438513070344924\n",
      "Batch 2095,  loss: 0.20993736684322356\n",
      "Batch 2100,  loss: 0.17818390130996703\n",
      "Batch 2105,  loss: 0.1619275242090225\n",
      "Batch 2110,  loss: 0.163153937458992\n",
      "Batch 2115,  loss: 0.1511702537536621\n",
      "Batch 2120,  loss: 0.1764728844165802\n",
      "Batch 2125,  loss: 0.13906339555978775\n",
      "Batch 2130,  loss: 0.21355430483818055\n",
      "Batch 2135,  loss: 0.1614577829837799\n",
      "Batch 2140,  loss: 0.13192663788795472\n",
      "Batch 2145,  loss: 0.1352983072400093\n",
      "Batch 2150,  loss: 0.15970107316970825\n",
      "Batch 2155,  loss: 0.15526555329561234\n",
      "Batch 2160,  loss: 0.1435598611831665\n",
      "Batch 2165,  loss: 0.11412387639284134\n",
      "Batch 2170,  loss: 0.17122563421726228\n",
      "Batch 2175,  loss: 0.20404634326696397\n",
      "Batch 2180,  loss: 0.14089474380016326\n",
      "Batch 2185,  loss: 0.1563667595386505\n",
      "Batch 2190,  loss: 0.126635904610157\n",
      "Batch 2195,  loss: 0.20491015613079072\n",
      "Batch 2200,  loss: 0.1555257499217987\n",
      "Batch 2205,  loss: 0.1289273738861084\n",
      "Batch 2210,  loss: 0.14573287069797516\n",
      "Batch 2215,  loss: 0.15802341401576997\n",
      "Batch 2220,  loss: 0.15869929939508437\n",
      "Batch 2225,  loss: 0.15689414739608765\n",
      "Batch 2230,  loss: 0.16162956058979033\n",
      "Batch 2235,  loss: 0.12737470269203185\n",
      "Batch 2240,  loss: 0.11923960596323013\n",
      "Batch 2245,  loss: 0.2061808615922928\n",
      "Batch 2250,  loss: 0.16438719779253005\n",
      "Batch 2255,  loss: 0.14876774847507476\n",
      "Batch 2260,  loss: 0.17316989749670028\n",
      "Batch 2265,  loss: 0.1632257491350174\n",
      "Batch 2270,  loss: 0.17329404056072234\n",
      "Batch 2275,  loss: 0.14077398926019669\n",
      "Batch 2280,  loss: 0.15721817165613175\n",
      "Batch 2285,  loss: 0.16923530995845795\n",
      "Batch 2290,  loss: 0.14374616295099257\n",
      "Batch 2295,  loss: 0.16233160793781282\n",
      "Batch 2300,  loss: 0.1463502511382103\n",
      "Batch 2305,  loss: 0.16070224195718766\n",
      "Batch 2310,  loss: 0.18109725117683412\n",
      "Batch 2315,  loss: 0.13288193941116333\n",
      "Batch 2320,  loss: 0.15200315713882445\n",
      "Batch 2325,  loss: 0.20888231098651885\n",
      "Batch 2330,  loss: 0.1721421957015991\n",
      "Batch 2335,  loss: 0.19562722444534303\n",
      "Batch 2340,  loss: 0.15506494641304017\n",
      "Batch 2345,  loss: 0.18344567120075225\n",
      "Batch 2350,  loss: 0.13046965450048448\n",
      "Batch 2355,  loss: 0.18510106801986695\n",
      "Batch 2360,  loss: 0.1946657657623291\n",
      "Batch 2365,  loss: 0.1781760036945343\n",
      "Batch 2370,  loss: 0.14750648736953736\n",
      "Batch 2375,  loss: 0.16463465988636017\n",
      "Batch 2380,  loss: 0.16679093539714812\n",
      "Batch 2385,  loss: 0.18183261454105376\n",
      "Batch 2390,  loss: 0.13745855689048767\n",
      "Batch 2395,  loss: 0.18497249186038972\n",
      "Batch 2400,  loss: 0.14104526937007905\n",
      "Batch 2405,  loss: 0.1447690486907959\n",
      "Batch 2410,  loss: 0.15669165253639222\n",
      "Batch 2415,  loss: 0.13003156781196595\n",
      "Batch 2420,  loss: 0.15613225996494293\n",
      "Batch 2425,  loss: 0.14661801010370254\n",
      "Batch 2430,  loss: 0.16817800998687743\n",
      "Batch 2435,  loss: 0.1579604595899582\n",
      "Batch 2440,  loss: 0.1792474001646042\n",
      "Batch 2445,  loss: 0.18290848135948182\n",
      "Batch 2450,  loss: 0.18304623365402223\n",
      "Batch 2455,  loss: 0.1694558382034302\n",
      "Batch 2460,  loss: 0.1587991774082184\n",
      "Batch 2465,  loss: 0.16675685048103334\n",
      "Batch 2470,  loss: 0.14419462084770202\n",
      "Batch 2475,  loss: 0.188518987596035\n",
      "Batch 2480,  loss: 0.14457998275756836\n",
      "Batch 2485,  loss: 0.15659331977367402\n",
      "Batch 2490,  loss: 0.13117599338293076\n",
      "Batch 2495,  loss: 0.14805024564266206\n",
      "Batch 2500,  loss: 0.18823122680187226\n",
      "Batch 2505,  loss: 0.14176448583602905\n",
      "Batch 2510,  loss: 0.17881613969802856\n",
      "Batch 2515,  loss: 0.17821424305438996\n",
      "Batch 2520,  loss: 0.1547995090484619\n",
      "Batch 2525,  loss: 0.1557760491967201\n",
      "Batch 2530,  loss: 0.15952885448932647\n",
      "Batch 2535,  loss: 0.14171125143766403\n",
      "Batch 2540,  loss: 0.1576519265770912\n",
      "Batch 2545,  loss: 0.16856124103069306\n",
      "Batch 2550,  loss: 0.13665912598371505\n",
      "Batch 2555,  loss: 0.1705491453409195\n",
      "Batch 2560,  loss: 0.18319627940654754\n",
      "Batch 2565,  loss: 0.162550151348114\n",
      "Batch 2570,  loss: 0.1384582817554474\n",
      "Batch 2575,  loss: 0.18030242919921874\n",
      "Batch 2580,  loss: 0.14288982301950454\n",
      "Batch 2585,  loss: 0.16132486313581468\n",
      "Batch 2590,  loss: 0.15322253108024597\n",
      "Batch 2595,  loss: 0.11731496751308441\n",
      "Batch 2600,  loss: 0.20199861228466034\n",
      "Batch 2605,  loss: 0.17215841114521027\n",
      "Batch 2610,  loss: 0.16524251103401183\n",
      "Batch 2615,  loss: 0.2059949278831482\n",
      "Batch 2620,  loss: 0.12155838757753372\n",
      "Batch 2625,  loss: 0.16889673769474028\n",
      "Batch 2630,  loss: 0.1946748524904251\n",
      "Batch 2635,  loss: 0.16491792798042298\n",
      "Batch 2640,  loss: 0.1524206966161728\n",
      "Batch 2645,  loss: 0.14942438155412674\n",
      "Batch 2650,  loss: 0.14752483665943145\n",
      "Batch 2655,  loss: 0.19300718009471893\n",
      "Batch 2660,  loss: 0.1593892589211464\n",
      "Batch 2665,  loss: 0.17452192306518555\n",
      "Batch 2670,  loss: 0.13957831561565398\n",
      "Batch 2675,  loss: 0.18963219225406647\n",
      "Batch 2680,  loss: 0.12493334412574768\n",
      "Batch 2685,  loss: 0.12311460971832275\n",
      "Batch 2690,  loss: 0.15378406047821044\n",
      "Batch 2695,  loss: 0.14332255572080613\n",
      "Batch 2700,  loss: 0.1411936730146408\n",
      "Batch 2705,  loss: 0.18213373124599458\n",
      "Batch 2710,  loss: 0.1692150801420212\n",
      "Batch 2715,  loss: 0.17348092198371887\n",
      "Batch 2720,  loss: 0.16722692251205445\n",
      "Batch 2725,  loss: 0.20138561725616455\n",
      "Batch 2730,  loss: 0.1547380194067955\n",
      "Batch 2735,  loss: 0.11894220560789108\n",
      "Batch 2740,  loss: 0.13718794137239457\n",
      "Batch 2745,  loss: 0.143770968914032\n",
      "Batch 2750,  loss: 0.17752313017845153\n",
      "Batch 2755,  loss: 0.10831784009933472\n",
      "Batch 2760,  loss: 0.1611873298883438\n",
      "Batch 2765,  loss: 0.17399048805236816\n",
      "Batch 2770,  loss: 0.1976459413766861\n",
      "LOSS train 0.1976459413766861. Validation loss: 0.15963442650433907 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 27:\n",
      "Batch 5,  loss: 0.12142224460840226\n",
      "Batch 10,  loss: 0.13295626342296601\n",
      "Batch 15,  loss: 0.17780228853225707\n",
      "Batch 20,  loss: 0.14266255050897597\n",
      "Batch 25,  loss: 0.1261251151561737\n",
      "Batch 30,  loss: 0.1593780040740967\n",
      "Batch 35,  loss: 0.17386549413204194\n",
      "Batch 40,  loss: 0.12380606830120086\n",
      "Batch 45,  loss: 0.17922767847776414\n",
      "Batch 50,  loss: 0.18162156790494918\n",
      "Batch 55,  loss: 0.15832729041576385\n",
      "Batch 60,  loss: 0.1722871407866478\n",
      "Batch 65,  loss: 0.17967913448810577\n",
      "Batch 70,  loss: 0.19426329433918\n",
      "Batch 75,  loss: 0.11958235055208206\n",
      "Batch 80,  loss: 0.1381105899810791\n",
      "Batch 85,  loss: 0.13274245709180832\n",
      "Batch 90,  loss: 0.1840013712644577\n",
      "Batch 95,  loss: 0.1448239952325821\n",
      "Batch 100,  loss: 0.18791054487228392\n",
      "Batch 105,  loss: 0.1483043372631073\n",
      "Batch 110,  loss: 0.14362930357456208\n",
      "Batch 115,  loss: 0.15248511880636215\n",
      "Batch 120,  loss: 0.17390984892845154\n",
      "Batch 125,  loss: 0.1529353976249695\n",
      "Batch 130,  loss: 0.15393043160438538\n",
      "Batch 135,  loss: 0.13646737039089202\n",
      "Batch 140,  loss: 0.14447588622570037\n",
      "Batch 145,  loss: 0.16303059160709382\n",
      "Batch 150,  loss: 0.158768729865551\n",
      "Batch 155,  loss: 0.15790484100580215\n",
      "Batch 160,  loss: 0.1555200070142746\n",
      "Batch 165,  loss: 0.17960671037435533\n",
      "Batch 170,  loss: 0.1854107290506363\n",
      "Batch 175,  loss: 0.158617103099823\n",
      "Batch 180,  loss: 0.14596756547689438\n",
      "Batch 185,  loss: 0.1254342883825302\n",
      "Batch 190,  loss: 0.13924761414527892\n",
      "Batch 195,  loss: 0.1966216504573822\n",
      "Batch 200,  loss: 0.20307129621505737\n",
      "Batch 205,  loss: 0.15384234189987184\n",
      "Batch 210,  loss: 0.14374788105487823\n",
      "Batch 215,  loss: 0.15739094763994216\n",
      "Batch 220,  loss: 0.15838798135519028\n",
      "Batch 225,  loss: 0.15369890928268432\n",
      "Batch 230,  loss: 0.18521607369184495\n",
      "Batch 235,  loss: 0.18812936544418335\n",
      "Batch 240,  loss: 0.20895405411720275\n",
      "Batch 245,  loss: 0.19449743628501892\n",
      "Batch 250,  loss: 0.1796706110239029\n",
      "Batch 255,  loss: 0.13936326056718826\n",
      "Batch 260,  loss: 0.19269477128982543\n",
      "Batch 265,  loss: 0.17265665382146836\n",
      "Batch 270,  loss: 0.14965431094169618\n",
      "Batch 275,  loss: 0.15208569020032883\n",
      "Batch 280,  loss: 0.1675887182354927\n",
      "Batch 285,  loss: 0.20021504759788514\n",
      "Batch 290,  loss: 0.1532612442970276\n",
      "Batch 295,  loss: 0.14617964774370193\n",
      "Batch 300,  loss: 0.14643556177616118\n",
      "Batch 305,  loss: 0.14778831750154495\n",
      "Batch 310,  loss: 0.15717918872833253\n",
      "Batch 315,  loss: 0.15419600903987885\n",
      "Batch 320,  loss: 0.16000463664531708\n",
      "Batch 325,  loss: 0.17332766056060792\n",
      "Batch 330,  loss: 0.18548376858234406\n",
      "Batch 335,  loss: 0.1310161754488945\n",
      "Batch 340,  loss: 0.15160466134548187\n",
      "Batch 345,  loss: 0.13992590755224227\n",
      "Batch 350,  loss: 0.18918338418006897\n",
      "Batch 355,  loss: 0.134992054104805\n",
      "Batch 360,  loss: 0.15593431293964385\n",
      "Batch 365,  loss: 0.1378646209836006\n",
      "Batch 370,  loss: 0.1862173467874527\n",
      "Batch 375,  loss: 0.1758371114730835\n",
      "Batch 380,  loss: 0.14295744448900222\n",
      "Batch 385,  loss: 0.17589869797229768\n",
      "Batch 390,  loss: 0.18027269691228867\n",
      "Batch 395,  loss: 0.13808598816394807\n",
      "Batch 400,  loss: 0.15034761428833007\n",
      "Batch 405,  loss: 0.17860328853130342\n",
      "Batch 410,  loss: 0.15736361742019653\n",
      "Batch 415,  loss: 0.1620298892259598\n",
      "Batch 420,  loss: 0.18618029952049256\n",
      "Batch 425,  loss: 0.16851864457130433\n",
      "Batch 430,  loss: 0.17169197499752045\n",
      "Batch 435,  loss: 0.14130059629678726\n",
      "Batch 440,  loss: 0.17411654591560363\n",
      "Batch 445,  loss: 0.1574106603860855\n",
      "Batch 450,  loss: 0.17733711153268814\n",
      "Batch 455,  loss: 0.17992892414331435\n",
      "Batch 460,  loss: 0.14997126460075377\n",
      "Batch 465,  loss: 0.20578123033046722\n",
      "Batch 470,  loss: 0.12470059990882873\n",
      "Batch 475,  loss: 0.2026903063058853\n",
      "Batch 480,  loss: 0.16102818250656128\n",
      "Batch 485,  loss: 0.17316439598798752\n",
      "Batch 490,  loss: 0.15626883804798125\n",
      "Batch 495,  loss: 0.20265920609235763\n",
      "Batch 500,  loss: 0.14730020612478256\n",
      "Batch 505,  loss: 0.21519260108470917\n",
      "Batch 510,  loss: 0.19048550724983215\n",
      "Batch 515,  loss: 0.21262692511081696\n",
      "Batch 520,  loss: 0.1696353390812874\n",
      "Batch 525,  loss: 0.1294858068227768\n",
      "Batch 530,  loss: 0.1375615894794464\n",
      "Batch 535,  loss: 0.16184334307909012\n",
      "Batch 540,  loss: 0.18016429245471954\n",
      "Batch 545,  loss: 0.14926571547985076\n",
      "Batch 550,  loss: 0.16607787013053893\n",
      "Batch 555,  loss: 0.17681066393852235\n",
      "Batch 560,  loss: 0.1303391396999359\n",
      "Batch 565,  loss: 0.17003415524959564\n",
      "Batch 570,  loss: 0.18428022861480714\n",
      "Batch 575,  loss: 0.14142851978540422\n",
      "Batch 580,  loss: 0.16274050772190093\n",
      "Batch 585,  loss: 0.1701133966445923\n",
      "Batch 590,  loss: 0.14716399908065797\n",
      "Batch 595,  loss: 0.1613360732793808\n",
      "Batch 600,  loss: 0.20333999693393706\n",
      "Batch 605,  loss: 0.17544825673103331\n",
      "Batch 610,  loss: 0.17013020515441896\n",
      "Batch 615,  loss: 0.2158532977104187\n",
      "Batch 620,  loss: 0.15642310976982116\n",
      "Batch 625,  loss: 0.15727632343769074\n",
      "Batch 630,  loss: 0.16020574569702148\n",
      "Batch 635,  loss: 0.14957009255886078\n",
      "Batch 640,  loss: 0.15280957967042924\n",
      "Batch 645,  loss: 0.15810928642749786\n",
      "Batch 650,  loss: 0.13610268384218216\n",
      "Batch 655,  loss: 0.18076713979244233\n",
      "Batch 660,  loss: 0.1721690610051155\n",
      "Batch 665,  loss: 0.1611858144402504\n",
      "Batch 670,  loss: 0.18493548929691314\n",
      "Batch 675,  loss: 0.14291722029447557\n",
      "Batch 680,  loss: 0.14778976887464523\n",
      "Batch 685,  loss: 0.16948600709438325\n",
      "Batch 690,  loss: 0.12518366426229477\n",
      "Batch 695,  loss: 0.17537391036748887\n",
      "Batch 700,  loss: 0.13605944961309432\n",
      "Batch 705,  loss: 0.1380039021372795\n",
      "Batch 710,  loss: 0.18854362070560454\n",
      "Batch 715,  loss: 0.14623183459043504\n",
      "Batch 720,  loss: 0.1857790917158127\n",
      "Batch 725,  loss: 0.15632806718349457\n",
      "Batch 730,  loss: 0.14966856837272643\n",
      "Batch 735,  loss: 0.1749538540840149\n",
      "Batch 740,  loss: 0.14649292230606079\n",
      "Batch 745,  loss: 0.17591476440429688\n",
      "Batch 750,  loss: 0.16357486546039582\n",
      "Batch 755,  loss: 0.1423086404800415\n",
      "Batch 760,  loss: 0.15575739741325378\n",
      "Batch 765,  loss: 0.12614303976297378\n",
      "Batch 770,  loss: 0.15969223976135255\n",
      "Batch 775,  loss: 0.1739939868450165\n",
      "Batch 780,  loss: 0.11795417219400406\n",
      "Batch 785,  loss: 0.1925154834985733\n",
      "Batch 790,  loss: 0.13725066632032396\n",
      "Batch 795,  loss: 0.12105743438005448\n",
      "Batch 800,  loss: 0.16583745777606965\n",
      "Batch 805,  loss: 0.13809022903442383\n",
      "Batch 810,  loss: 0.1703549087047577\n",
      "Batch 815,  loss: 0.15203269720077514\n",
      "Batch 820,  loss: 0.14715661406517028\n",
      "Batch 825,  loss: 0.18115768134593963\n",
      "Batch 830,  loss: 0.1309751719236374\n",
      "Batch 835,  loss: 0.15644104182720184\n",
      "Batch 840,  loss: 0.1451437622308731\n",
      "Batch 845,  loss: 0.15219622254371643\n",
      "Batch 850,  loss: 0.1732686787843704\n",
      "Batch 855,  loss: 0.14870450496673585\n",
      "Batch 860,  loss: 0.20413619875907899\n",
      "Batch 865,  loss: 0.16152296364307403\n",
      "Batch 870,  loss: 0.14533100426197051\n",
      "Batch 875,  loss: 0.15253160297870635\n",
      "Batch 880,  loss: 0.1954006850719452\n",
      "Batch 885,  loss: 0.1399793431162834\n",
      "Batch 890,  loss: 0.1416885107755661\n",
      "Batch 895,  loss: 0.14386211037635804\n",
      "Batch 900,  loss: 0.2093510866165161\n",
      "Batch 905,  loss: 0.17179071307182311\n",
      "Batch 910,  loss: 0.21268167495727539\n",
      "Batch 915,  loss: 0.13978003859519958\n",
      "Batch 920,  loss: 0.15822588354349137\n",
      "Batch 925,  loss: 0.14341915845870973\n",
      "Batch 930,  loss: 0.17245688438415527\n",
      "Batch 935,  loss: 0.19371431767940522\n",
      "Batch 940,  loss: 0.19657900631427766\n",
      "Batch 945,  loss: 0.12156859934329986\n",
      "Batch 950,  loss: 0.14467417746782302\n",
      "Batch 955,  loss: 0.18590921461582183\n",
      "Batch 960,  loss: 0.2305360198020935\n",
      "Batch 965,  loss: 0.14970967024564744\n",
      "Batch 970,  loss: 0.20110249519348145\n",
      "Batch 975,  loss: 0.16151432543992997\n",
      "Batch 980,  loss: 0.1781310647726059\n",
      "Batch 985,  loss: 0.12571195363998414\n",
      "Batch 990,  loss: 0.1486194312572479\n",
      "Batch 995,  loss: 0.14002465903759004\n",
      "Batch 1000,  loss: 0.18871551156044006\n",
      "Batch 1005,  loss: 0.14731837213039398\n",
      "Batch 1010,  loss: 0.224372062087059\n",
      "Batch 1015,  loss: 0.14076377898454667\n",
      "Batch 1020,  loss: 0.16197816878557206\n",
      "Batch 1025,  loss: 0.21269034147262572\n",
      "Batch 1030,  loss: 0.1439845696091652\n",
      "Batch 1035,  loss: 0.17696347832679749\n",
      "Batch 1040,  loss: 0.18249893188476562\n",
      "Batch 1045,  loss: 0.1583734631538391\n",
      "Batch 1050,  loss: 0.1781747192144394\n",
      "Batch 1055,  loss: 0.12324559688568115\n",
      "Batch 1060,  loss: 0.15272354781627656\n",
      "Batch 1065,  loss: 0.15376178920269012\n",
      "Batch 1070,  loss: 0.1104336529970169\n",
      "Batch 1075,  loss: 0.16046533435583116\n",
      "Batch 1080,  loss: 0.17857745587825774\n",
      "Batch 1085,  loss: 0.18334846049547196\n",
      "Batch 1090,  loss: 0.20978299677371978\n",
      "Batch 1095,  loss: 0.1454566389322281\n",
      "Batch 1100,  loss: 0.14868417382240295\n",
      "Batch 1105,  loss: 0.15397041738033296\n",
      "Batch 1110,  loss: 0.16439543962478637\n",
      "Batch 1115,  loss: 0.1594327509403229\n",
      "Batch 1120,  loss: 0.15605010688304902\n",
      "Batch 1125,  loss: 0.13029513955116273\n",
      "Batch 1130,  loss: 0.14909396916627884\n",
      "Batch 1135,  loss: 0.15172122418880463\n",
      "Batch 1140,  loss: 0.1799922615289688\n",
      "Batch 1145,  loss: 0.13163088411092758\n",
      "Batch 1150,  loss: 0.1519959270954132\n",
      "Batch 1155,  loss: 0.183118137717247\n",
      "Batch 1160,  loss: 0.17459295690059662\n",
      "Batch 1165,  loss: 0.15997530221939088\n",
      "Batch 1170,  loss: 0.1929354786872864\n",
      "Batch 1175,  loss: 0.1696615234017372\n",
      "Batch 1180,  loss: 0.12006928026676178\n",
      "Batch 1185,  loss: 0.15630957186222078\n",
      "Batch 1190,  loss: 0.11291044354438781\n",
      "Batch 1195,  loss: 0.12341042160987854\n",
      "Batch 1200,  loss: 0.17261450588703156\n",
      "Batch 1205,  loss: 0.1994880512356758\n",
      "Batch 1210,  loss: 0.11129606962203979\n",
      "Batch 1215,  loss: 0.16887003779411316\n",
      "Batch 1220,  loss: 0.19032227098941804\n",
      "Batch 1225,  loss: 0.20083545744419098\n",
      "Batch 1230,  loss: 0.13070183396339416\n",
      "Batch 1235,  loss: 0.16858898848295212\n",
      "Batch 1240,  loss: 0.15820976793766023\n",
      "Batch 1245,  loss: 0.16537316441535949\n",
      "Batch 1250,  loss: 0.16768789738416673\n",
      "Batch 1255,  loss: 0.16345727145671846\n",
      "Batch 1260,  loss: 0.17989490330219268\n",
      "Batch 1265,  loss: 0.14184513092041015\n",
      "Batch 1270,  loss: 0.16797203570604324\n",
      "Batch 1275,  loss: 0.1378484398126602\n",
      "Batch 1280,  loss: 0.13667865544557573\n",
      "Batch 1285,  loss: 0.2231975793838501\n",
      "Batch 1290,  loss: 0.16274324357509612\n",
      "Batch 1295,  loss: 0.1437160700559616\n",
      "Batch 1300,  loss: 0.20095935761928557\n",
      "Batch 1305,  loss: 0.16636176705360411\n",
      "Batch 1310,  loss: 0.13144980370998383\n",
      "Batch 1315,  loss: 0.16100760400295258\n",
      "Batch 1320,  loss: 0.17064171731472016\n",
      "Batch 1325,  loss: 0.17341704964637755\n",
      "Batch 1330,  loss: 0.13320280760526657\n",
      "Batch 1335,  loss: 0.15650209784507751\n",
      "Batch 1340,  loss: 0.19968857765197753\n",
      "Batch 1345,  loss: 0.14929611086845399\n",
      "Batch 1350,  loss: 0.13819345384836196\n",
      "Batch 1355,  loss: 0.15188718736171722\n",
      "Batch 1360,  loss: 0.1569216638803482\n",
      "Batch 1365,  loss: 0.12817835062742233\n",
      "Batch 1370,  loss: 0.14947271049022676\n",
      "Batch 1375,  loss: 0.13565475046634673\n",
      "Batch 1380,  loss: 0.16955376863479615\n",
      "Batch 1385,  loss: 0.1754325106739998\n",
      "Batch 1390,  loss: 0.13621512353420256\n",
      "Batch 1395,  loss: 0.13291083425283431\n",
      "Batch 1400,  loss: 0.14891788959503174\n",
      "Batch 1405,  loss: 0.1552783042192459\n",
      "Batch 1410,  loss: 0.1686519980430603\n",
      "Batch 1415,  loss: 0.14108884930610657\n",
      "Batch 1420,  loss: 0.18701709657907487\n",
      "Batch 1425,  loss: 0.17160686552524568\n",
      "Batch 1430,  loss: 0.1411965236067772\n",
      "Batch 1435,  loss: 0.15811680555343627\n",
      "Batch 1440,  loss: 0.14761201441287994\n",
      "Batch 1445,  loss: 0.16766583323478698\n",
      "Batch 1450,  loss: 0.1566342145204544\n",
      "Batch 1455,  loss: 0.14181883335113527\n",
      "Batch 1460,  loss: 0.1465771198272705\n",
      "Batch 1465,  loss: 0.1503770664334297\n",
      "Batch 1470,  loss: 0.19485505372285844\n",
      "Batch 1475,  loss: 0.1905391424894333\n",
      "Batch 1480,  loss: 0.15997768342494964\n",
      "Batch 1485,  loss: 0.15415602922439575\n",
      "Batch 1490,  loss: 0.18123806715011598\n",
      "Batch 1495,  loss: 0.17696020603179932\n",
      "Batch 1500,  loss: 0.2231008380651474\n",
      "Batch 1505,  loss: 0.1556516781449318\n",
      "Batch 1510,  loss: 0.17144253253936767\n",
      "Batch 1515,  loss: 0.20363327562808992\n",
      "Batch 1520,  loss: 0.17476168572902678\n",
      "Batch 1525,  loss: 0.1351047486066818\n",
      "Batch 1530,  loss: 0.1329224556684494\n",
      "Batch 1535,  loss: 0.17998980581760407\n",
      "Batch 1540,  loss: 0.1463143602013588\n",
      "Batch 1545,  loss: 0.1641298145055771\n",
      "Batch 1550,  loss: 0.1814615845680237\n",
      "Batch 1555,  loss: 0.19385819882154465\n",
      "Batch 1560,  loss: 0.14686568677425385\n",
      "Batch 1565,  loss: 0.14874955862760544\n",
      "Batch 1570,  loss: 0.18290679156780243\n",
      "Batch 1575,  loss: 0.14623019993305206\n",
      "Batch 1580,  loss: 0.15708567649126054\n",
      "Batch 1585,  loss: 0.16365422308444977\n",
      "Batch 1590,  loss: 0.17001812160015106\n",
      "Batch 1595,  loss: 0.1337643265724182\n",
      "Batch 1600,  loss: 0.15838665664196014\n",
      "Batch 1605,  loss: 0.19341718554496765\n",
      "Batch 1610,  loss: 0.1853414684534073\n",
      "Batch 1615,  loss: 0.12508057653903962\n",
      "Batch 1620,  loss: 0.2134213328361511\n",
      "Batch 1625,  loss: 0.16040942221879959\n",
      "Batch 1630,  loss: 0.1619361624121666\n",
      "Batch 1635,  loss: 0.13683806657791137\n",
      "Batch 1640,  loss: 0.13528022915124893\n",
      "Batch 1645,  loss: 0.13561763614416122\n",
      "Batch 1650,  loss: 0.18542321622371674\n",
      "Batch 1655,  loss: 0.16395602524280548\n",
      "Batch 1660,  loss: 0.14364780783653258\n",
      "Batch 1665,  loss: 0.1848433256149292\n",
      "Batch 1670,  loss: 0.17808411419391632\n",
      "Batch 1675,  loss: 0.16101817786693573\n",
      "Batch 1680,  loss: 0.1559712618589401\n",
      "Batch 1685,  loss: 0.1349804475903511\n",
      "Batch 1690,  loss: 0.17550800144672393\n",
      "Batch 1695,  loss: 0.16204057335853578\n",
      "Batch 1700,  loss: 0.1516547530889511\n",
      "Batch 1705,  loss: 0.2055557608604431\n",
      "Batch 1710,  loss: 0.14114361703395845\n",
      "Batch 1715,  loss: 0.1751722902059555\n",
      "Batch 1720,  loss: 0.1708161175251007\n",
      "Batch 1725,  loss: 0.14814086854457856\n",
      "Batch 1730,  loss: 0.15967747271060945\n",
      "Batch 1735,  loss: 0.1272052899003029\n",
      "Batch 1740,  loss: 0.16363995373249055\n",
      "Batch 1745,  loss: 0.1996479168534279\n",
      "Batch 1750,  loss: 0.18044569492340087\n",
      "Batch 1755,  loss: 0.12966786175966263\n",
      "Batch 1760,  loss: 0.15270392149686812\n",
      "Batch 1765,  loss: 0.11207624524831772\n",
      "Batch 1770,  loss: 0.15753724575042724\n",
      "Batch 1775,  loss: 0.17057673782110214\n",
      "Batch 1780,  loss: 0.14608816504478456\n",
      "Batch 1785,  loss: 0.1745157614350319\n",
      "Batch 1790,  loss: 0.14707442224025727\n",
      "Batch 1795,  loss: 0.18546944260597228\n",
      "Batch 1800,  loss: 0.1887683540582657\n",
      "Batch 1805,  loss: 0.14865441173315047\n",
      "Batch 1810,  loss: 0.1921052649617195\n",
      "Batch 1815,  loss: 0.17779997885227203\n",
      "Batch 1820,  loss: 0.15507124960422516\n",
      "Batch 1825,  loss: 0.1684524029493332\n",
      "Batch 1830,  loss: 0.16852085888385773\n",
      "Batch 1835,  loss: 0.13185909986495972\n",
      "Batch 1840,  loss: 0.19420165419578553\n",
      "Batch 1845,  loss: 0.15925488024950027\n",
      "Batch 1850,  loss: 0.15362692773342132\n",
      "Batch 1855,  loss: 0.14360041320323944\n",
      "Batch 1860,  loss: 0.13356559425592424\n",
      "Batch 1865,  loss: 0.2248950719833374\n",
      "Batch 1870,  loss: 0.14718708097934724\n",
      "Batch 1875,  loss: 0.15500367283821107\n",
      "Batch 1880,  loss: 0.17079091370105742\n",
      "Batch 1885,  loss: 0.15276860892772676\n",
      "Batch 1890,  loss: 0.17931247651576995\n",
      "Batch 1895,  loss: 0.14720549881458284\n",
      "Batch 1900,  loss: 0.16571942269802092\n",
      "Batch 1905,  loss: 0.17520237863063812\n",
      "Batch 1910,  loss: 0.14970387071371077\n",
      "Batch 1915,  loss: 0.18776982724666597\n",
      "Batch 1920,  loss: 0.15449124574661255\n",
      "Batch 1925,  loss: 0.18525633215904236\n",
      "Batch 1930,  loss: 0.16179300248622894\n",
      "Batch 1935,  loss: 0.17003277093172073\n",
      "Batch 1940,  loss: 0.15717172026634216\n",
      "Batch 1945,  loss: 0.16396645903587342\n",
      "Batch 1950,  loss: 0.2089023247361183\n",
      "Batch 1955,  loss: 0.13902586922049523\n",
      "Batch 1960,  loss: 0.15259700864553452\n",
      "Batch 1965,  loss: 0.11959398984909057\n",
      "Batch 1970,  loss: 0.12603116631507874\n",
      "Batch 1975,  loss: 0.14724314957857132\n",
      "Batch 1980,  loss: 0.160484479367733\n",
      "Batch 1985,  loss: 0.14738512337207793\n",
      "Batch 1990,  loss: 0.1868775486946106\n",
      "Batch 1995,  loss: 0.19134674668312074\n",
      "Batch 2000,  loss: 0.13742813169956208\n",
      "Batch 2005,  loss: 0.14964090883731843\n",
      "Batch 2010,  loss: 0.14866993874311446\n",
      "Batch 2015,  loss: 0.18266611993312837\n",
      "Batch 2020,  loss: 0.17503320425748825\n",
      "Batch 2025,  loss: 0.1667805105447769\n",
      "Batch 2030,  loss: 0.16707929819822312\n",
      "Batch 2035,  loss: 0.19900287985801696\n",
      "Batch 2040,  loss: 0.18989673554897307\n",
      "Batch 2045,  loss: 0.19058347940444947\n",
      "Batch 2050,  loss: 0.2231087267398834\n",
      "Batch 2055,  loss: 0.15455166399478912\n",
      "Batch 2060,  loss: 0.157662233710289\n",
      "Batch 2065,  loss: 0.15553366839885713\n",
      "Batch 2070,  loss: 0.16023662835359573\n",
      "Batch 2075,  loss: 0.15714128017425538\n",
      "Batch 2080,  loss: 0.10942796468734742\n",
      "Batch 2085,  loss: 0.1378207415342331\n",
      "Batch 2090,  loss: 0.1626566916704178\n",
      "Batch 2095,  loss: 0.16741730272769928\n",
      "Batch 2100,  loss: 0.14841994345188142\n",
      "Batch 2105,  loss: 0.15804891735315324\n",
      "Batch 2110,  loss: 0.15090661346912385\n",
      "Batch 2115,  loss: 0.16184940785169602\n",
      "Batch 2120,  loss: 0.18193696737289428\n",
      "Batch 2125,  loss: 0.12758751660585405\n",
      "Batch 2130,  loss: 0.15247540771961213\n",
      "Batch 2135,  loss: 0.1547546148300171\n",
      "Batch 2140,  loss: 0.14100607633590698\n",
      "Batch 2145,  loss: 0.18140318542718886\n",
      "Batch 2150,  loss: 0.15095311105251313\n",
      "Batch 2155,  loss: 0.17079218178987504\n",
      "Batch 2160,  loss: 0.1711639106273651\n",
      "Batch 2165,  loss: 0.15115765929222108\n",
      "Batch 2170,  loss: 0.16748903691768646\n",
      "Batch 2175,  loss: 0.17718664109706878\n",
      "Batch 2180,  loss: 0.14561910182237625\n",
      "Batch 2185,  loss: 0.1387407436966896\n",
      "Batch 2190,  loss: 0.16288332194089888\n",
      "Batch 2195,  loss: 0.16778431832790375\n",
      "Batch 2200,  loss: 0.16836017966270447\n",
      "Batch 2205,  loss: 0.1506151497364044\n",
      "Batch 2210,  loss: 0.21555073261260987\n",
      "Batch 2215,  loss: 0.1855082243680954\n",
      "Batch 2220,  loss: 0.17501163482666016\n",
      "Batch 2225,  loss: 0.15032539367675782\n",
      "Batch 2230,  loss: 0.20747058987617492\n",
      "Batch 2235,  loss: 0.15666547417640686\n",
      "Batch 2240,  loss: 0.1576482117176056\n",
      "Batch 2245,  loss: 0.14886564463377\n",
      "Batch 2250,  loss: 0.1355131596326828\n",
      "Batch 2255,  loss: 0.18417478501796722\n",
      "Batch 2260,  loss: 0.20742118656635283\n",
      "Batch 2265,  loss: 0.13758985698223114\n",
      "Batch 2270,  loss: 0.10694842189550399\n",
      "Batch 2275,  loss: 0.14404827058315278\n",
      "Batch 2280,  loss: 0.14760706275701524\n",
      "Batch 2285,  loss: 0.21000214219093322\n",
      "Batch 2290,  loss: 0.17589573860168456\n",
      "Batch 2295,  loss: 0.1762653112411499\n",
      "Batch 2300,  loss: 0.17654394507408142\n",
      "Batch 2305,  loss: 0.14088096022605895\n",
      "Batch 2310,  loss: 0.17317357063293456\n",
      "Batch 2315,  loss: 0.2283324718475342\n",
      "Batch 2320,  loss: 0.1257878601551056\n",
      "Batch 2325,  loss: 0.16035255789756775\n",
      "Batch 2330,  loss: 0.14221937358379363\n",
      "Batch 2335,  loss: 0.15170198678970337\n",
      "Batch 2340,  loss: 0.18490169048309327\n",
      "Batch 2345,  loss: 0.1658948302268982\n",
      "Batch 2350,  loss: 0.16473116874694824\n",
      "Batch 2355,  loss: 0.14911822974681854\n",
      "Batch 2360,  loss: 0.13693489730358124\n",
      "Batch 2365,  loss: 0.19028360843658448\n",
      "Batch 2370,  loss: 0.1671404629945755\n",
      "Batch 2375,  loss: 0.13792532980442046\n",
      "Batch 2380,  loss: 0.1406477704644203\n",
      "Batch 2385,  loss: 0.17118431031703948\n",
      "Batch 2390,  loss: 0.14876099079847335\n",
      "Batch 2395,  loss: 0.14508162140846254\n",
      "Batch 2400,  loss: 0.12754577547311782\n",
      "Batch 2405,  loss: 0.17198744416236877\n",
      "Batch 2410,  loss: 0.1992690682411194\n",
      "Batch 2415,  loss: 0.1800602912902832\n",
      "Batch 2420,  loss: 0.14930619299411774\n",
      "Batch 2425,  loss: 0.16710050851106645\n",
      "Batch 2430,  loss: 0.1705349177122116\n",
      "Batch 2435,  loss: 0.14541782140731813\n",
      "Batch 2440,  loss: 0.13886574506759644\n",
      "Batch 2445,  loss: 0.12208071500062942\n",
      "Batch 2450,  loss: 0.19143694937229155\n",
      "Batch 2455,  loss: 0.16782474517822266\n",
      "Batch 2460,  loss: 0.12276040315628052\n",
      "Batch 2465,  loss: 0.21942088305950164\n",
      "Batch 2470,  loss: 0.1579396367073059\n",
      "Batch 2475,  loss: 0.18304286599159242\n",
      "Batch 2480,  loss: 0.14906757175922394\n",
      "Batch 2485,  loss: 0.1979313910007477\n",
      "Batch 2490,  loss: 0.15879369378089905\n",
      "Batch 2495,  loss: 0.16007798463106154\n",
      "Batch 2500,  loss: 0.18305573761463165\n",
      "Batch 2505,  loss: 0.1708679974079132\n",
      "Batch 2510,  loss: 0.148949134349823\n",
      "Batch 2515,  loss: 0.16456209421157836\n",
      "Batch 2520,  loss: 0.15755670964717866\n",
      "Batch 2525,  loss: 0.15204511284828187\n",
      "Batch 2530,  loss: 0.15446388423442842\n",
      "Batch 2535,  loss: 0.14430519938468933\n",
      "Batch 2540,  loss: 0.1285053536295891\n",
      "Batch 2545,  loss: 0.1463971272110939\n",
      "Batch 2550,  loss: 0.17194617986679078\n",
      "Batch 2555,  loss: 0.15508174002170563\n",
      "Batch 2560,  loss: 0.12572916299104692\n",
      "Batch 2565,  loss: 0.17312179505825043\n",
      "Batch 2570,  loss: 0.14669231474399566\n",
      "Batch 2575,  loss: 0.14737974405288695\n",
      "Batch 2580,  loss: 0.19430792331695557\n",
      "Batch 2585,  loss: 0.1518680676817894\n",
      "Batch 2590,  loss: 0.14429407715797424\n",
      "Batch 2595,  loss: 0.15687359869480133\n",
      "Batch 2600,  loss: 0.1843338280916214\n",
      "Batch 2605,  loss: 0.15965997576713561\n",
      "Batch 2610,  loss: 0.128634537756443\n",
      "Batch 2615,  loss: 0.19189735651016235\n",
      "Batch 2620,  loss: 0.14088802337646483\n",
      "Batch 2625,  loss: 0.13188473284244537\n",
      "Batch 2630,  loss: 0.1971883535385132\n",
      "Batch 2635,  loss: 0.17496606409549714\n",
      "Batch 2640,  loss: 0.19248872399330139\n",
      "Batch 2645,  loss: 0.20537279695272445\n",
      "Batch 2650,  loss: 0.16286822855472566\n",
      "Batch 2655,  loss: 0.1834890216588974\n",
      "Batch 2660,  loss: 0.14580790996551513\n",
      "Batch 2665,  loss: 0.14142637699842453\n",
      "Batch 2670,  loss: 0.14328509271144868\n",
      "Batch 2675,  loss: 0.13233297765254975\n",
      "Batch 2680,  loss: 0.16742062121629714\n",
      "Batch 2685,  loss: 0.19614078849554062\n",
      "Batch 2690,  loss: 0.1147528886795044\n",
      "Batch 2695,  loss: 0.20013248324394226\n",
      "Batch 2700,  loss: 0.17539111971855165\n",
      "Batch 2705,  loss: 0.16404492557048797\n",
      "Batch 2710,  loss: 0.17479068785905838\n",
      "Batch 2715,  loss: 0.13614410609006883\n",
      "Batch 2720,  loss: 0.12823066264390945\n",
      "Batch 2725,  loss: 0.17444626241922379\n",
      "Batch 2730,  loss: 0.1429124116897583\n",
      "Batch 2735,  loss: 0.2208377957344055\n",
      "Batch 2740,  loss: 0.16272700279951097\n",
      "Batch 2745,  loss: 0.17987531125545503\n",
      "Batch 2750,  loss: 0.13794149607419967\n",
      "Batch 2755,  loss: 0.1411799296736717\n",
      "Batch 2760,  loss: 0.17993416786193847\n",
      "Batch 2765,  loss: 0.11694669574499131\n",
      "Batch 2770,  loss: 0.18715434670448303\n",
      "LOSS train 0.18715434670448303. Validation loss: 0.1645200533384923 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 28:\n",
      "Batch 5,  loss: 0.129184490442276\n",
      "Batch 10,  loss: 0.17076651006937027\n",
      "Batch 15,  loss: 0.15626107901334763\n",
      "Batch 20,  loss: 0.16019618809223174\n",
      "Batch 25,  loss: 0.128204445540905\n",
      "Batch 30,  loss: 0.13249588310718535\n",
      "Batch 35,  loss: 0.16555042564868927\n",
      "Batch 40,  loss: 0.1550224870443344\n",
      "Batch 45,  loss: 0.12457701414823533\n",
      "Batch 50,  loss: 0.12103777080774307\n",
      "Batch 55,  loss: 0.18581790328025818\n",
      "Batch 60,  loss: 0.15571174919605255\n",
      "Batch 65,  loss: 0.1531160980463028\n",
      "Batch 70,  loss: 0.12737168073654176\n",
      "Batch 75,  loss: 0.18410299420356752\n",
      "Batch 80,  loss: 0.14130519479513168\n",
      "Batch 85,  loss: 0.21607044339179993\n",
      "Batch 90,  loss: 0.1535671979188919\n",
      "Batch 95,  loss: 0.17112565338611602\n",
      "Batch 100,  loss: 0.1726393520832062\n",
      "Batch 105,  loss: 0.17027351260185242\n",
      "Batch 110,  loss: 0.21459479928016661\n",
      "Batch 115,  loss: 0.11510803550481796\n",
      "Batch 120,  loss: 0.15201265811920167\n",
      "Batch 125,  loss: 0.1885477051138878\n",
      "Batch 130,  loss: 0.1302917093038559\n",
      "Batch 135,  loss: 0.15485114455223084\n",
      "Batch 140,  loss: 0.16771249920129777\n",
      "Batch 145,  loss: 0.1947239726781845\n",
      "Batch 150,  loss: 0.17107764929533004\n",
      "Batch 155,  loss: 0.18208581805229188\n",
      "Batch 160,  loss: 0.17252128422260285\n",
      "Batch 165,  loss: 0.15205890834331512\n",
      "Batch 170,  loss: 0.12568989396095276\n",
      "Batch 175,  loss: 0.1473490908741951\n",
      "Batch 180,  loss: 0.1636229485273361\n",
      "Batch 185,  loss: 0.20574096143245696\n",
      "Batch 190,  loss: 0.18593509197235109\n",
      "Batch 195,  loss: 0.18555302917957306\n",
      "Batch 200,  loss: 0.145732319355011\n",
      "Batch 205,  loss: 0.1566731035709381\n",
      "Batch 210,  loss: 0.205984628200531\n",
      "Batch 215,  loss: 0.1575116604566574\n",
      "Batch 220,  loss: 0.15045134127140045\n",
      "Batch 225,  loss: 0.21892219483852388\n",
      "Batch 230,  loss: 0.15895645022392274\n",
      "Batch 235,  loss: 0.17336094826459886\n",
      "Batch 240,  loss: 0.18618674278259278\n",
      "Batch 245,  loss: 0.10901746302843093\n",
      "Batch 250,  loss: 0.15030184835195542\n",
      "Batch 255,  loss: 0.17033381760120392\n",
      "Batch 260,  loss: 0.15660444498062134\n",
      "Batch 265,  loss: 0.2102070838212967\n",
      "Batch 270,  loss: 0.2112878143787384\n",
      "Batch 275,  loss: 0.1559624195098877\n",
      "Batch 280,  loss: 0.17080910056829451\n",
      "Batch 285,  loss: 0.12048784494400025\n",
      "Batch 290,  loss: 0.16325862258672713\n",
      "Batch 295,  loss: 0.170858433842659\n",
      "Batch 300,  loss: 0.13351927250623702\n",
      "Batch 305,  loss: 0.13065325915813447\n",
      "Batch 310,  loss: 0.17204986810684203\n",
      "Batch 315,  loss: 0.14098542034626008\n",
      "Batch 320,  loss: 0.1492831975221634\n",
      "Batch 325,  loss: 0.12536082714796065\n",
      "Batch 330,  loss: 0.16369691491127014\n",
      "Batch 335,  loss: 0.1342265248298645\n",
      "Batch 340,  loss: 0.17363605201244353\n",
      "Batch 345,  loss: 0.151667520403862\n",
      "Batch 350,  loss: 0.1841259241104126\n",
      "Batch 355,  loss: 0.12710033506155013\n",
      "Batch 360,  loss: 0.14146750271320344\n",
      "Batch 365,  loss: 0.1632005900144577\n",
      "Batch 370,  loss: 0.18328426778316498\n",
      "Batch 375,  loss: 0.16015762984752654\n",
      "Batch 380,  loss: 0.17060421109199525\n",
      "Batch 385,  loss: 0.19327757358551026\n",
      "Batch 390,  loss: 0.20076235234737397\n",
      "Batch 395,  loss: 0.1439120352268219\n",
      "Batch 400,  loss: 0.1643138587474823\n",
      "Batch 405,  loss: 0.18464455008506775\n",
      "Batch 410,  loss: 0.1745574653148651\n",
      "Batch 415,  loss: 0.15726837813854216\n",
      "Batch 420,  loss: 0.13925880640745164\n",
      "Batch 425,  loss: 0.17521179616451263\n",
      "Batch 430,  loss: 0.17576783895492554\n",
      "Batch 435,  loss: 0.13678890466690063\n",
      "Batch 440,  loss: 0.13939952254295349\n",
      "Batch 445,  loss: 0.1801908791065216\n",
      "Batch 450,  loss: 0.16427861005067826\n",
      "Batch 455,  loss: 0.14963798820972443\n",
      "Batch 460,  loss: 0.14280895590782167\n",
      "Batch 465,  loss: 0.15139571130275725\n",
      "Batch 470,  loss: 0.14321043491363525\n",
      "Batch 475,  loss: 0.17206237316131592\n",
      "Batch 480,  loss: 0.173875093460083\n",
      "Batch 485,  loss: 0.19333743453025817\n",
      "Batch 490,  loss: 0.1471929669380188\n",
      "Batch 495,  loss: 0.11919459402561187\n",
      "Batch 500,  loss: 0.15933281779289246\n",
      "Batch 505,  loss: 0.21317793428897858\n",
      "Batch 510,  loss: 0.15911238938570021\n",
      "Batch 515,  loss: 0.15998562276363373\n",
      "Batch 520,  loss: 0.15125955641269684\n",
      "Batch 525,  loss: 0.11705461144447327\n",
      "Batch 530,  loss: 0.16377755403518676\n",
      "Batch 535,  loss: 0.16577934026718139\n",
      "Batch 540,  loss: 0.1323326274752617\n",
      "Batch 545,  loss: 0.18306436836719514\n",
      "Batch 550,  loss: 0.1458178848028183\n",
      "Batch 555,  loss: 0.14711650013923644\n",
      "Batch 560,  loss: 0.1515872523188591\n",
      "Batch 565,  loss: 0.19293905198574066\n",
      "Batch 570,  loss: 0.1273822531104088\n",
      "Batch 575,  loss: 0.17101228535175322\n",
      "Batch 580,  loss: 0.12654954195022583\n",
      "Batch 585,  loss: 0.14339499473571776\n",
      "Batch 590,  loss: 0.1641858160495758\n",
      "Batch 595,  loss: 0.1754833370447159\n",
      "Batch 600,  loss: 0.1692007526755333\n",
      "Batch 605,  loss: 0.20118597149848938\n",
      "Batch 610,  loss: 0.14682853519916533\n",
      "Batch 615,  loss: 0.19692804664373398\n",
      "Batch 620,  loss: 0.16102792620658873\n",
      "Batch 625,  loss: 0.14333981573581694\n",
      "Batch 630,  loss: 0.21137925386428832\n",
      "Batch 635,  loss: 0.1741113543510437\n",
      "Batch 640,  loss: 0.1683965355157852\n",
      "Batch 645,  loss: 0.15542371869087218\n",
      "Batch 650,  loss: 0.17937975823879243\n",
      "Batch 655,  loss: 0.16524236053228378\n",
      "Batch 660,  loss: 0.1677575886249542\n",
      "Batch 665,  loss: 0.17886601984500886\n",
      "Batch 670,  loss: 0.1692773848772049\n",
      "Batch 675,  loss: 0.14090706408023834\n",
      "Batch 680,  loss: 0.12600426971912385\n",
      "Batch 685,  loss: 0.15456444025039673\n",
      "Batch 690,  loss: 0.1802762731909752\n",
      "Batch 695,  loss: 0.14791288822889329\n",
      "Batch 700,  loss: 0.1288394346833229\n",
      "Batch 705,  loss: 0.15662390291690825\n",
      "Batch 710,  loss: 0.12227363288402557\n",
      "Batch 715,  loss: 0.1405800998210907\n",
      "Batch 720,  loss: 0.18421620428562163\n",
      "Batch 725,  loss: 0.19176755249500274\n",
      "Batch 730,  loss: 0.13163331896066666\n",
      "Batch 735,  loss: 0.18885779678821563\n",
      "Batch 740,  loss: 0.17433149218559266\n",
      "Batch 745,  loss: 0.1393367737531662\n",
      "Batch 750,  loss: 0.15397721529006958\n",
      "Batch 755,  loss: 0.11236646473407745\n",
      "Batch 760,  loss: 0.16801293194293976\n",
      "Batch 765,  loss: 0.16908421963453293\n",
      "Batch 770,  loss: 0.13904971480369568\n",
      "Batch 775,  loss: 0.1406902089715004\n",
      "Batch 780,  loss: 0.15481364876031875\n",
      "Batch 785,  loss: 0.17876067459583284\n",
      "Batch 790,  loss: 0.12897646874189378\n",
      "Batch 795,  loss: 0.15037629902362823\n",
      "Batch 800,  loss: 0.20091866552829743\n",
      "Batch 805,  loss: 0.11843261867761612\n",
      "Batch 810,  loss: 0.13781795799732208\n",
      "Batch 815,  loss: 0.14294725507497788\n",
      "Batch 820,  loss: 0.1579872190952301\n",
      "Batch 825,  loss: 0.18762898445129395\n",
      "Batch 830,  loss: 0.18291075527668\n",
      "Batch 835,  loss: 0.1525001347064972\n",
      "Batch 840,  loss: 0.1445259138941765\n",
      "Batch 845,  loss: 0.1595505252480507\n",
      "Batch 850,  loss: 0.1648097574710846\n",
      "Batch 855,  loss: 0.13884642720222473\n",
      "Batch 860,  loss: 0.15957748889923096\n",
      "Batch 865,  loss: 0.12349380999803543\n",
      "Batch 870,  loss: 0.20553002655506133\n",
      "Batch 875,  loss: 0.13920536786317825\n",
      "Batch 880,  loss: 0.13253853470087051\n",
      "Batch 885,  loss: 0.20436483919620513\n",
      "Batch 890,  loss: 0.1677727445960045\n",
      "Batch 895,  loss: 0.16899246126413345\n",
      "Batch 900,  loss: 0.15745326578617097\n",
      "Batch 905,  loss: 0.11933348625898361\n",
      "Batch 910,  loss: 0.19498778283596038\n",
      "Batch 915,  loss: 0.1495407223701477\n",
      "Batch 920,  loss: 0.1868650883436203\n",
      "Batch 925,  loss: 0.15131985992193223\n",
      "Batch 930,  loss: 0.16871913075447081\n",
      "Batch 935,  loss: 0.13834262490272523\n",
      "Batch 940,  loss: 0.13659995347261428\n",
      "Batch 945,  loss: 0.19784004390239715\n",
      "Batch 950,  loss: 0.18582751005887985\n",
      "Batch 955,  loss: 0.1627422958612442\n",
      "Batch 960,  loss: 0.16495068967342377\n",
      "Batch 965,  loss: 0.15321650505065917\n",
      "Batch 970,  loss: 0.15618773102760314\n",
      "Batch 975,  loss: 0.13136471658945084\n",
      "Batch 980,  loss: 0.15604106783866883\n",
      "Batch 985,  loss: 0.17441947758197784\n",
      "Batch 990,  loss: 0.16593700051307678\n",
      "Batch 995,  loss: 0.15890418887138366\n",
      "Batch 1000,  loss: 0.17375863194465638\n",
      "Batch 1005,  loss: 0.14434204548597335\n",
      "Batch 1010,  loss: 0.18077402412891388\n",
      "Batch 1015,  loss: 0.1876322090625763\n",
      "Batch 1020,  loss: 0.12578006088733673\n",
      "Batch 1025,  loss: 0.16385261416435243\n",
      "Batch 1030,  loss: 0.16871127486228943\n",
      "Batch 1035,  loss: 0.16826553344726564\n",
      "Batch 1040,  loss: 0.13192004710435867\n",
      "Batch 1045,  loss: 0.16953416764736176\n",
      "Batch 1050,  loss: 0.12624664157629012\n",
      "Batch 1055,  loss: 0.20297744870185852\n",
      "Batch 1060,  loss: 0.14534458816051482\n",
      "Batch 1065,  loss: 0.19118449091911316\n",
      "Batch 1070,  loss: 0.1713589534163475\n",
      "Batch 1075,  loss: 0.12264948487281799\n",
      "Batch 1080,  loss: 0.15684387534856797\n",
      "Batch 1085,  loss: 0.18546956777572632\n",
      "Batch 1090,  loss: 0.1423548460006714\n",
      "Batch 1095,  loss: 0.1347600221633911\n",
      "Batch 1100,  loss: 0.13273514807224274\n",
      "Batch 1105,  loss: 0.1664173573255539\n",
      "Batch 1110,  loss: 0.1363613061606884\n",
      "Batch 1115,  loss: 0.13829536288976668\n",
      "Batch 1120,  loss: 0.16497985124588013\n",
      "Batch 1125,  loss: 0.13239217102527617\n",
      "Batch 1130,  loss: 0.15036756098270415\n",
      "Batch 1135,  loss: 0.16700724959373475\n",
      "Batch 1140,  loss: 0.13518651723861694\n",
      "Batch 1145,  loss: 0.15731256902217866\n",
      "Batch 1150,  loss: 0.149407297372818\n",
      "Batch 1155,  loss: 0.17870878875255586\n",
      "Batch 1160,  loss: 0.17231786102056504\n",
      "Batch 1165,  loss: 0.2162763923406601\n",
      "Batch 1170,  loss: 0.17729473114013672\n",
      "Batch 1175,  loss: 0.1519847333431244\n",
      "Batch 1180,  loss: 0.19227079749107362\n",
      "Batch 1185,  loss: 0.22023326456546782\n",
      "Batch 1190,  loss: 0.1331256240606308\n",
      "Batch 1195,  loss: 0.14145951569080353\n",
      "Batch 1200,  loss: 0.16222718060016633\n",
      "Batch 1205,  loss: 0.20050614774227143\n",
      "Batch 1210,  loss: 0.17706666588783265\n",
      "Batch 1215,  loss: 0.17493063509464263\n",
      "Batch 1220,  loss: 0.1598837584257126\n",
      "Batch 1225,  loss: 0.1667428970336914\n",
      "Batch 1230,  loss: 0.21273117065429686\n",
      "Batch 1235,  loss: 0.15877139419317246\n",
      "Batch 1240,  loss: 0.19780926406383514\n",
      "Batch 1245,  loss: 0.13539859056472778\n",
      "Batch 1250,  loss: 0.1553901821374893\n",
      "Batch 1255,  loss: 0.19169497787952422\n",
      "Batch 1260,  loss: 0.13716441094875337\n",
      "Batch 1265,  loss: 0.16316396296024321\n",
      "Batch 1270,  loss: 0.16537049412727356\n",
      "Batch 1275,  loss: 0.16891145706176758\n",
      "Batch 1280,  loss: 0.18437997698783876\n",
      "Batch 1285,  loss: 0.15886487066745758\n",
      "Batch 1290,  loss: 0.16828934848308563\n",
      "Batch 1295,  loss: 0.18193553686141967\n",
      "Batch 1300,  loss: 0.15067674219608307\n",
      "Batch 1305,  loss: 0.1933976113796234\n",
      "Batch 1310,  loss: 0.16742557287216187\n",
      "Batch 1315,  loss: 0.16839761286973953\n",
      "Batch 1320,  loss: 0.15620533376932144\n",
      "Batch 1325,  loss: 0.12675555050373077\n",
      "Batch 1330,  loss: 0.12528012543916703\n",
      "Batch 1335,  loss: 0.1634937822818756\n",
      "Batch 1340,  loss: 0.1533105492591858\n",
      "Batch 1345,  loss: 0.14108349978923798\n",
      "Batch 1350,  loss: 0.12998796105384827\n",
      "Batch 1355,  loss: 0.1770904093980789\n",
      "Batch 1360,  loss: 0.17898026704788209\n",
      "Batch 1365,  loss: 0.11153974831104278\n",
      "Batch 1370,  loss: 0.163343146443367\n",
      "Batch 1375,  loss: 0.14783834367990495\n",
      "Batch 1380,  loss: 0.17733778655529023\n",
      "Batch 1385,  loss: 0.14825119823217392\n",
      "Batch 1390,  loss: 0.1360160604119301\n",
      "Batch 1395,  loss: 0.14255910813808442\n",
      "Batch 1400,  loss: 0.16508744657039642\n",
      "Batch 1405,  loss: 0.12612719982862472\n",
      "Batch 1410,  loss: 0.18664580583572388\n",
      "Batch 1415,  loss: 0.13659365177154542\n",
      "Batch 1420,  loss: 0.1910413146018982\n",
      "Batch 1425,  loss: 0.1915576934814453\n",
      "Batch 1430,  loss: 0.1361943155527115\n",
      "Batch 1435,  loss: 0.18973029553890228\n",
      "Batch 1440,  loss: 0.178324094414711\n",
      "Batch 1445,  loss: 0.19823119044303894\n",
      "Batch 1450,  loss: 0.13652090430259706\n",
      "Batch 1455,  loss: 0.13909346014261245\n",
      "Batch 1460,  loss: 0.14765840172767639\n",
      "Batch 1465,  loss: 0.158440563082695\n",
      "Batch 1470,  loss: 0.1464503675699234\n",
      "Batch 1475,  loss: 0.17404184937477113\n",
      "Batch 1480,  loss: 0.1590094268321991\n",
      "Batch 1485,  loss: 0.16764701306819915\n",
      "Batch 1490,  loss: 0.1154592901468277\n",
      "Batch 1495,  loss: 0.16084054112434387\n",
      "Batch 1500,  loss: 0.14625144600868226\n",
      "Batch 1505,  loss: 0.1415601223707199\n",
      "Batch 1510,  loss: 0.19518505036830902\n",
      "Batch 1515,  loss: 0.13228190392255784\n",
      "Batch 1520,  loss: 0.18648891597986222\n",
      "Batch 1525,  loss: 0.12600469291210176\n",
      "Batch 1530,  loss: 0.14386776089668274\n",
      "Batch 1535,  loss: 0.16179209202528\n",
      "Batch 1540,  loss: 0.14650811553001403\n",
      "Batch 1545,  loss: 0.1994083970785141\n",
      "Batch 1550,  loss: 0.14449552446603775\n",
      "Batch 1555,  loss: 0.14334147274494172\n",
      "Batch 1560,  loss: 0.176048943400383\n",
      "Batch 1565,  loss: 0.1825976103544235\n",
      "Batch 1570,  loss: 0.1488729014992714\n",
      "Batch 1575,  loss: 0.1828896388411522\n",
      "Batch 1580,  loss: 0.156637105345726\n",
      "Batch 1585,  loss: 0.1464235156774521\n",
      "Batch 1590,  loss: 0.1417659193277359\n",
      "Batch 1595,  loss: 0.15026627331972123\n",
      "Batch 1600,  loss: 0.19769969284534455\n",
      "Batch 1605,  loss: 0.17295158803462982\n",
      "Batch 1610,  loss: 0.16021952778100967\n",
      "Batch 1615,  loss: 0.13341018557548523\n",
      "Batch 1620,  loss: 0.17644762098789216\n",
      "Batch 1625,  loss: 0.1596374750137329\n",
      "Batch 1630,  loss: 0.15888651013374328\n",
      "Batch 1635,  loss: 0.17341490983963012\n",
      "Batch 1640,  loss: 0.15391701757907866\n",
      "Batch 1645,  loss: 0.1966851159930229\n",
      "Batch 1650,  loss: 0.15434954911470414\n",
      "Batch 1655,  loss: 0.15401411950588226\n",
      "Batch 1660,  loss: 0.19561601877212526\n",
      "Batch 1665,  loss: 0.13353276997804642\n",
      "Batch 1670,  loss: 0.17607839703559874\n",
      "Batch 1675,  loss: 0.1706739366054535\n",
      "Batch 1680,  loss: 0.16722151041030883\n",
      "Batch 1685,  loss: 0.14913188815116882\n",
      "Batch 1690,  loss: 0.1682642698287964\n",
      "Batch 1695,  loss: 0.20196137130260466\n",
      "Batch 1700,  loss: 0.16690375208854674\n",
      "Batch 1705,  loss: 0.16604073792696\n",
      "Batch 1710,  loss: 0.1521006464958191\n",
      "Batch 1715,  loss: 0.16626842617988585\n",
      "Batch 1720,  loss: 0.15329922884702682\n",
      "Batch 1725,  loss: 0.15328491479158401\n",
      "Batch 1730,  loss: 0.17020319849252702\n",
      "Batch 1735,  loss: 0.19108870923519133\n",
      "Batch 1740,  loss: 0.19246329069137574\n",
      "Batch 1745,  loss: 0.1758030503988266\n",
      "Batch 1750,  loss: 0.15998132526874542\n",
      "Batch 1755,  loss: 0.14185749590396882\n",
      "Batch 1760,  loss: 0.1491251066327095\n",
      "Batch 1765,  loss: 0.15343019962310792\n",
      "Batch 1770,  loss: 0.14382189512252808\n",
      "Batch 1775,  loss: 0.17924183905124663\n",
      "Batch 1780,  loss: 0.1817857801914215\n",
      "Batch 1785,  loss: 0.13567990511655809\n",
      "Batch 1790,  loss: 0.1259723499417305\n",
      "Batch 1795,  loss: 0.17338515520095826\n",
      "Batch 1800,  loss: 0.1797148197889328\n",
      "Batch 1805,  loss: 0.14423311352729798\n",
      "Batch 1810,  loss: 0.2025715231895447\n",
      "Batch 1815,  loss: 0.1822569377720356\n",
      "Batch 1820,  loss: 0.18079599887132644\n",
      "Batch 1825,  loss: 0.17640842944383622\n",
      "Batch 1830,  loss: 0.14357071816921235\n",
      "Batch 1835,  loss: 0.15170101821422577\n",
      "Batch 1840,  loss: 0.12679448276758193\n",
      "Batch 1845,  loss: 0.13789267092943192\n",
      "Batch 1850,  loss: 0.14608109444379808\n",
      "Batch 1855,  loss: 0.16421821415424348\n",
      "Batch 1860,  loss: 0.1777844488620758\n",
      "Batch 1865,  loss: 0.15860000550746917\n",
      "Batch 1870,  loss: 0.15726624727249144\n",
      "Batch 1875,  loss: 0.16905129253864287\n",
      "Batch 1880,  loss: 0.16476755142211913\n",
      "Batch 1885,  loss: 0.16288717091083527\n",
      "Batch 1890,  loss: 0.19770344495773315\n",
      "Batch 1895,  loss: 0.15023691654205323\n",
      "Batch 1900,  loss: 0.14090366959571837\n",
      "Batch 1905,  loss: 0.20256293416023255\n",
      "Batch 1910,  loss: 0.1770138621330261\n",
      "Batch 1915,  loss: 0.1468760997056961\n",
      "Batch 1920,  loss: 0.16774619966745377\n",
      "Batch 1925,  loss: 0.14944142401218413\n",
      "Batch 1930,  loss: 0.18224712759256362\n",
      "Batch 1935,  loss: 0.14004213511943817\n",
      "Batch 1940,  loss: 0.13242519944906234\n",
      "Batch 1945,  loss: 0.14981809854507447\n",
      "Batch 1950,  loss: 0.14237518459558487\n",
      "Batch 1955,  loss: 0.15238609313964843\n",
      "Batch 1960,  loss: 0.1613704264163971\n",
      "Batch 1965,  loss: 0.14792309701442719\n",
      "Batch 1970,  loss: 0.13387887328863143\n",
      "Batch 1975,  loss: 0.18979642987251283\n",
      "Batch 1980,  loss: 0.150721937417984\n",
      "Batch 1985,  loss: 0.17602313905954362\n",
      "Batch 1990,  loss: 0.17898523509502412\n",
      "Batch 1995,  loss: 0.16474437117576599\n",
      "Batch 2000,  loss: 0.15089133381843567\n",
      "Batch 2005,  loss: 0.18418247550725936\n",
      "Batch 2010,  loss: 0.16777862012386321\n",
      "Batch 2015,  loss: 0.19015619158744812\n",
      "Batch 2020,  loss: 0.20780002772808076\n",
      "Batch 2025,  loss: 0.19223950505256654\n",
      "Batch 2030,  loss: 0.15507236868143082\n",
      "Batch 2035,  loss: 0.14009615480899812\n",
      "Batch 2040,  loss: 0.1361450046300888\n",
      "Batch 2045,  loss: 0.1718614548444748\n",
      "Batch 2050,  loss: 0.18392986059188843\n",
      "Batch 2055,  loss: 0.19404147565364838\n",
      "Batch 2060,  loss: 0.17383214682340623\n",
      "Batch 2065,  loss: 0.18997337222099303\n",
      "Batch 2070,  loss: 0.13833872079849244\n",
      "Batch 2075,  loss: 0.20997565388679504\n",
      "Batch 2080,  loss: 0.18108171224594116\n",
      "Batch 2085,  loss: 0.12800804078578948\n",
      "Batch 2090,  loss: 0.13942066580057144\n",
      "Batch 2095,  loss: 0.12177238017320632\n",
      "Batch 2100,  loss: 0.13965982645750047\n",
      "Batch 2105,  loss: 0.16273922622203826\n",
      "Batch 2110,  loss: 0.12905220985412597\n",
      "Batch 2115,  loss: 0.16238200068473815\n",
      "Batch 2120,  loss: 0.12517845034599304\n",
      "Batch 2125,  loss: 0.15217779874801635\n",
      "Batch 2130,  loss: 0.1391112744808197\n",
      "Batch 2135,  loss: 0.17073041200637817\n",
      "Batch 2140,  loss: 0.12882934063673018\n",
      "Batch 2145,  loss: 0.233999764919281\n",
      "Batch 2150,  loss: 0.14600581377744676\n",
      "Batch 2155,  loss: 0.1410827234387398\n",
      "Batch 2160,  loss: 0.18365996479988098\n",
      "Batch 2165,  loss: 0.22288720309734344\n",
      "Batch 2170,  loss: 0.13254640102386475\n",
      "Batch 2175,  loss: 0.21262715458869935\n",
      "Batch 2180,  loss: 0.1900981694459915\n",
      "Batch 2185,  loss: 0.18861729204654692\n",
      "Batch 2190,  loss: 0.19080741405487062\n",
      "Batch 2195,  loss: 0.18294043242931365\n",
      "Batch 2200,  loss: 0.1610005632042885\n",
      "Batch 2205,  loss: 0.1289898306131363\n",
      "Batch 2210,  loss: 0.13560884892940522\n",
      "Batch 2215,  loss: 0.210244819521904\n",
      "Batch 2220,  loss: 0.127767176926136\n",
      "Batch 2225,  loss: 0.15846970677375793\n",
      "Batch 2230,  loss: 0.1603911191225052\n",
      "Batch 2235,  loss: 0.15945173799991608\n",
      "Batch 2240,  loss: 0.1531584531068802\n",
      "Batch 2245,  loss: 0.1556249126791954\n",
      "Batch 2250,  loss: 0.2114671587944031\n",
      "Batch 2255,  loss: 0.17182773351669312\n",
      "Batch 2260,  loss: 0.14793404936790466\n",
      "Batch 2265,  loss: 0.13941551744937897\n",
      "Batch 2270,  loss: 0.14642146974802017\n",
      "Batch 2275,  loss: 0.14942600429058076\n",
      "Batch 2280,  loss: 0.1469649851322174\n",
      "Batch 2285,  loss: 0.15953288674354554\n",
      "Batch 2290,  loss: 0.12914765477180482\n",
      "Batch 2295,  loss: 0.15808529257774354\n",
      "Batch 2300,  loss: 0.15236945152282716\n",
      "Batch 2305,  loss: 0.14826393872499466\n",
      "Batch 2310,  loss: 0.1522423282265663\n",
      "Batch 2315,  loss: 0.20302583575248717\n",
      "Batch 2320,  loss: 0.1444062888622284\n",
      "Batch 2325,  loss: 0.15139964818954468\n",
      "Batch 2330,  loss: 0.13947305381298064\n",
      "Batch 2335,  loss: 0.1491052746772766\n",
      "Batch 2340,  loss: 0.14879528135061265\n",
      "Batch 2345,  loss: 0.16205707043409348\n",
      "Batch 2350,  loss: 0.21136493384838104\n",
      "Batch 2355,  loss: 0.17163456231355667\n",
      "Batch 2360,  loss: 0.16747273355722428\n",
      "Batch 2365,  loss: 0.17579582333564758\n",
      "Batch 2370,  loss: 0.1203417494893074\n",
      "Batch 2375,  loss: 0.14879632294178008\n",
      "Batch 2380,  loss: 0.11787115931510925\n",
      "Batch 2385,  loss: 0.15265665352344512\n",
      "Batch 2390,  loss: 0.13037786930799483\n",
      "Batch 2395,  loss: 0.14677062928676604\n",
      "Batch 2400,  loss: 0.16211300790309907\n",
      "Batch 2405,  loss: 0.13032565712928773\n",
      "Batch 2410,  loss: 0.1351647451519966\n",
      "Batch 2415,  loss: 0.13535995185375213\n",
      "Batch 2420,  loss: 0.18014442622661592\n",
      "Batch 2425,  loss: 0.17965273559093475\n",
      "Batch 2430,  loss: 0.18809401392936706\n",
      "Batch 2435,  loss: 0.19216561317443848\n",
      "Batch 2440,  loss: 0.1447371333837509\n",
      "Batch 2445,  loss: 0.1742052763700485\n",
      "Batch 2450,  loss: 0.19005935788154601\n",
      "Batch 2455,  loss: 0.17126652151346206\n",
      "Batch 2460,  loss: 0.1431821644306183\n",
      "Batch 2465,  loss: 0.17516254782676696\n",
      "Batch 2470,  loss: 0.13378014117479325\n",
      "Batch 2475,  loss: 0.1977461278438568\n",
      "Batch 2480,  loss: 0.14739498347043992\n",
      "Batch 2485,  loss: 0.1673693299293518\n",
      "Batch 2490,  loss: 0.19685152173042297\n",
      "Batch 2495,  loss: 0.12961350232362748\n",
      "Batch 2500,  loss: 0.15878592431545258\n",
      "Batch 2505,  loss: 0.1736190974712372\n",
      "Batch 2510,  loss: 0.19500828683376312\n",
      "Batch 2515,  loss: 0.17460215091705322\n",
      "Batch 2520,  loss: 0.14528562128543854\n",
      "Batch 2525,  loss: 0.20985421240329744\n",
      "Batch 2530,  loss: 0.18653319478034974\n",
      "Batch 2535,  loss: 0.1848738670349121\n",
      "Batch 2540,  loss: 0.20283858776092528\n",
      "Batch 2545,  loss: 0.16410118341445923\n",
      "Batch 2550,  loss: 0.19236781001091002\n",
      "Batch 2555,  loss: 0.16180459707975386\n",
      "Batch 2560,  loss: 0.19547211229801179\n",
      "Batch 2565,  loss: 0.17474796772003173\n",
      "Batch 2570,  loss: 0.15373984724283218\n",
      "Batch 2575,  loss: 0.13929673731327058\n",
      "Batch 2580,  loss: 0.17289929389953612\n",
      "Batch 2585,  loss: 0.15208733975887298\n",
      "Batch 2590,  loss: 0.1349332720041275\n",
      "Batch 2595,  loss: 0.1289512485265732\n",
      "Batch 2600,  loss: 0.17193267345428467\n",
      "Batch 2605,  loss: 0.14368805885314942\n",
      "Batch 2610,  loss: 0.17327743172645568\n",
      "Batch 2615,  loss: 0.17021831274032592\n",
      "Batch 2620,  loss: 0.1642451226711273\n",
      "Batch 2625,  loss: 0.16288163959980012\n",
      "Batch 2630,  loss: 0.18728503882884978\n",
      "Batch 2635,  loss: 0.18605400621891022\n",
      "Batch 2640,  loss: 0.1768524557352066\n",
      "Batch 2645,  loss: 0.1697641894221306\n",
      "Batch 2650,  loss: 0.13853963166475297\n",
      "Batch 2655,  loss: 0.11038742512464524\n",
      "Batch 2660,  loss: 0.12068717479705811\n",
      "Batch 2665,  loss: 0.18879093527793883\n",
      "Batch 2670,  loss: 0.13902958929538728\n",
      "Batch 2675,  loss: 0.16202536523342131\n",
      "Batch 2680,  loss: 0.14300274848937988\n",
      "Batch 2685,  loss: 0.11974585205316543\n",
      "Batch 2690,  loss: 0.14866055995225907\n",
      "Batch 2695,  loss: 0.17227132320404054\n",
      "Batch 2700,  loss: 0.20331428349018096\n",
      "Batch 2705,  loss: 0.1763679176568985\n",
      "Batch 2710,  loss: 0.1610269844532013\n",
      "Batch 2715,  loss: 0.10913930237293243\n",
      "Batch 2720,  loss: 0.1819100260734558\n",
      "Batch 2725,  loss: 0.22192560732364655\n",
      "Batch 2730,  loss: 0.21296720802783967\n",
      "Batch 2735,  loss: 0.16121080815792083\n",
      "Batch 2740,  loss: 0.13121502697467805\n",
      "Batch 2745,  loss: 0.17439966797828674\n",
      "Batch 2750,  loss: 0.1355456978082657\n",
      "Batch 2755,  loss: 0.13095751851797105\n",
      "Batch 2760,  loss: 0.20569142699241638\n",
      "Batch 2765,  loss: 0.1731118768453598\n",
      "Batch 2770,  loss: 0.1624339699745178\n",
      "LOSS train 0.1624339699745178. Validation loss: 0.15692350969270424 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 29:\n",
      "Batch 5,  loss: 0.136116062104702\n",
      "Batch 10,  loss: 0.18552595376968384\n",
      "Batch 15,  loss: 0.16466287523508072\n",
      "Batch 20,  loss: 0.13961558938026428\n",
      "Batch 25,  loss: 0.16382937282323837\n",
      "Batch 30,  loss: 0.134983628988266\n",
      "Batch 35,  loss: 0.17211222350597383\n",
      "Batch 40,  loss: 0.16464739739894868\n",
      "Batch 45,  loss: 0.21368471086025237\n",
      "Batch 50,  loss: 0.1849367082118988\n",
      "Batch 55,  loss: 0.140551920235157\n",
      "Batch 60,  loss: 0.1717414453625679\n",
      "Batch 65,  loss: 0.1850332200527191\n",
      "Batch 70,  loss: 0.1587117552757263\n",
      "Batch 75,  loss: 0.17153920829296113\n",
      "Batch 80,  loss: 0.19877314269542695\n",
      "Batch 85,  loss: 0.1688675418496132\n",
      "Batch 90,  loss: 0.1591006860136986\n",
      "Batch 95,  loss: 0.1692112937569618\n",
      "Batch 100,  loss: 0.17559459060430527\n",
      "Batch 105,  loss: 0.15703664422035218\n",
      "Batch 110,  loss: 0.15533982515335082\n",
      "Batch 115,  loss: 0.18677484691143037\n",
      "Batch 120,  loss: 0.15253390818834306\n",
      "Batch 125,  loss: 0.15904537141323088\n",
      "Batch 130,  loss: 0.14041800051927567\n",
      "Batch 135,  loss: 0.1726972222328186\n",
      "Batch 140,  loss: 0.13944086730480193\n",
      "Batch 145,  loss: 0.14399652928113937\n",
      "Batch 150,  loss: 0.13075172752141953\n",
      "Batch 155,  loss: 0.15387134850025178\n",
      "Batch 160,  loss: 0.1434628278017044\n",
      "Batch 165,  loss: 0.17570780217647552\n",
      "Batch 170,  loss: 0.1415517345070839\n",
      "Batch 175,  loss: 0.13569201976060868\n",
      "Batch 180,  loss: 0.1666047066450119\n",
      "Batch 185,  loss: 0.14191671907901765\n",
      "Batch 190,  loss: 0.17727947235107422\n",
      "Batch 195,  loss: 0.1546828493475914\n",
      "Batch 200,  loss: 0.13928697854280472\n",
      "Batch 205,  loss: 0.12618534117937089\n",
      "Batch 210,  loss: 0.14453572332859038\n",
      "Batch 215,  loss: 0.1223070964217186\n",
      "Batch 220,  loss: 0.15999749153852463\n",
      "Batch 225,  loss: 0.17485010325908662\n",
      "Batch 230,  loss: 0.1698704719543457\n",
      "Batch 235,  loss: 0.1572056919336319\n",
      "Batch 240,  loss: 0.16513656675815583\n",
      "Batch 245,  loss: 0.15099945217370986\n",
      "Batch 250,  loss: 0.15579946637153624\n",
      "Batch 255,  loss: 0.16097029745578767\n",
      "Batch 260,  loss: 0.13435293436050416\n",
      "Batch 265,  loss: 0.14558149874210358\n",
      "Batch 270,  loss: 0.11033357381820678\n",
      "Batch 275,  loss: 0.1932094305753708\n",
      "Batch 280,  loss: 0.15073841214179992\n",
      "Batch 285,  loss: 0.1888277918100357\n",
      "Batch 290,  loss: 0.1950765907764435\n",
      "Batch 295,  loss: 0.16394141614437102\n",
      "Batch 300,  loss: 0.17088534384965898\n",
      "Batch 305,  loss: 0.15984958708286284\n",
      "Batch 310,  loss: 0.12596550285816194\n",
      "Batch 315,  loss: 0.22962912023067475\n",
      "Batch 320,  loss: 0.12697595953941346\n",
      "Batch 325,  loss: 0.1448614001274109\n",
      "Batch 330,  loss: 0.21725887656211854\n",
      "Batch 335,  loss: 0.14375903755426406\n",
      "Batch 340,  loss: 0.17568832039833068\n",
      "Batch 345,  loss: 0.13124290257692336\n",
      "Batch 350,  loss: 0.19370621740818023\n",
      "Batch 355,  loss: 0.14828510135412215\n",
      "Batch 360,  loss: 0.16146707236766816\n",
      "Batch 365,  loss: 0.16399700045585633\n",
      "Batch 370,  loss: 0.1837385207414627\n",
      "Batch 375,  loss: 0.15829411894083023\n",
      "Batch 380,  loss: 0.160511314868927\n",
      "Batch 385,  loss: 0.12418485581874847\n",
      "Batch 390,  loss: 0.13070665597915648\n",
      "Batch 395,  loss: 0.13923588395118713\n",
      "Batch 400,  loss: 0.14294856190681457\n",
      "Batch 405,  loss: 0.14840482026338578\n",
      "Batch 410,  loss: 0.17289476990699768\n",
      "Batch 415,  loss: 0.14576307833194732\n",
      "Batch 420,  loss: 0.19289277791976928\n",
      "Batch 425,  loss: 0.1614248976111412\n",
      "Batch 430,  loss: 0.22189490795135497\n",
      "Batch 435,  loss: 0.20073408484458924\n",
      "Batch 440,  loss: 0.1521687775850296\n",
      "Batch 445,  loss: 0.1742616981267929\n",
      "Batch 450,  loss: 0.1788610816001892\n",
      "Batch 455,  loss: 0.1610723003745079\n",
      "Batch 460,  loss: 0.1447756975889206\n",
      "Batch 465,  loss: 0.13345132172107696\n",
      "Batch 470,  loss: 0.15784540474414827\n",
      "Batch 475,  loss: 0.168085777759552\n",
      "Batch 480,  loss: 0.16416624933481216\n",
      "Batch 485,  loss: 0.16427325159311296\n",
      "Batch 490,  loss: 0.12745343148708344\n",
      "Batch 495,  loss: 0.12380251437425613\n",
      "Batch 500,  loss: 0.11942449659109115\n",
      "Batch 505,  loss: 0.1821366012096405\n",
      "Batch 510,  loss: 0.1651310980319977\n",
      "Batch 515,  loss: 0.17670034170150756\n",
      "Batch 520,  loss: 0.17103223204612733\n",
      "Batch 525,  loss: 0.1425194889307022\n",
      "Batch 530,  loss: 0.17756112068891525\n",
      "Batch 535,  loss: 0.23383931517601014\n",
      "Batch 540,  loss: 0.1625167742371559\n",
      "Batch 545,  loss: 0.11793671250343322\n",
      "Batch 550,  loss: 0.1431021809577942\n",
      "Batch 555,  loss: 0.16478187143802642\n",
      "Batch 560,  loss: 0.17301860004663466\n",
      "Batch 565,  loss: 0.15487080365419387\n",
      "Batch 570,  loss: 0.16646806001663209\n",
      "Batch 575,  loss: 0.16795101761817932\n",
      "Batch 580,  loss: 0.16901964843273162\n",
      "Batch 585,  loss: 0.13836016952991487\n",
      "Batch 590,  loss: 0.12190949767827988\n",
      "Batch 595,  loss: 0.1571335107088089\n",
      "Batch 600,  loss: 0.1617807924747467\n",
      "Batch 605,  loss: 0.12065693736076355\n",
      "Batch 610,  loss: 0.16094460487365722\n",
      "Batch 615,  loss: 0.16242413818836213\n",
      "Batch 620,  loss: 0.15632096230983733\n",
      "Batch 625,  loss: 0.1349179431796074\n",
      "Batch 630,  loss: 0.16373079866170884\n",
      "Batch 635,  loss: 0.1659970074892044\n",
      "Batch 640,  loss: 0.1843131512403488\n",
      "Batch 645,  loss: 0.14875464886426926\n",
      "Batch 650,  loss: 0.15600394904613496\n",
      "Batch 655,  loss: 0.1224137857556343\n",
      "Batch 660,  loss: 0.15158093869686126\n",
      "Batch 665,  loss: 0.15958508849143982\n",
      "Batch 670,  loss: 0.1281366914510727\n",
      "Batch 675,  loss: 0.16056570261716843\n",
      "Batch 680,  loss: 0.17791554629802703\n",
      "Batch 685,  loss: 0.15395376086235046\n",
      "Batch 690,  loss: 0.15453035980463029\n",
      "Batch 695,  loss: 0.209163835644722\n",
      "Batch 700,  loss: 0.14459504783153534\n",
      "Batch 705,  loss: 0.19139280319213867\n",
      "Batch 710,  loss: 0.1310769110918045\n",
      "Batch 715,  loss: 0.17182834446430206\n",
      "Batch 720,  loss: 0.16050828397274017\n",
      "Batch 725,  loss: 0.14517271220684053\n",
      "Batch 730,  loss: 0.12684573233127594\n",
      "Batch 735,  loss: 0.22711805403232574\n",
      "Batch 740,  loss: 0.21342939734458924\n",
      "Batch 745,  loss: 0.14737026691436766\n",
      "Batch 750,  loss: 0.1427242413163185\n",
      "Batch 755,  loss: 0.1961172729730606\n",
      "Batch 760,  loss: 0.17261793911457063\n",
      "Batch 765,  loss: 0.17997840344905852\n",
      "Batch 770,  loss: 0.16841422766447067\n",
      "Batch 775,  loss: 0.1238841325044632\n",
      "Batch 780,  loss: 0.14959767162799836\n",
      "Batch 785,  loss: 0.17445700764656066\n",
      "Batch 790,  loss: 0.1711219221353531\n",
      "Batch 795,  loss: 0.14261367917060852\n",
      "Batch 800,  loss: 0.1894403040409088\n",
      "Batch 805,  loss: 0.14335324615240097\n",
      "Batch 810,  loss: 0.16313580870628358\n",
      "Batch 815,  loss: 0.12660665363073348\n",
      "Batch 820,  loss: 0.1487180158495903\n",
      "Batch 825,  loss: 0.17604506611824036\n",
      "Batch 830,  loss: 0.16874343454837798\n",
      "Batch 835,  loss: 0.18710092604160308\n",
      "Batch 840,  loss: 0.15202618390321732\n",
      "Batch 845,  loss: 0.15558462142944335\n",
      "Batch 850,  loss: 0.1642405331134796\n",
      "Batch 855,  loss: 0.17253919839859008\n",
      "Batch 860,  loss: 0.1627943128347397\n",
      "Batch 865,  loss: 0.15450531840324402\n",
      "Batch 870,  loss: 0.1616861879825592\n",
      "Batch 875,  loss: 0.11074326932430267\n",
      "Batch 880,  loss: 0.17081510424613952\n",
      "Batch 885,  loss: 0.18901426792144777\n",
      "Batch 890,  loss: 0.14368156641721724\n",
      "Batch 895,  loss: 0.18052354454994202\n",
      "Batch 900,  loss: 0.13832427710294723\n",
      "Batch 905,  loss: 0.18557525873184205\n",
      "Batch 910,  loss: 0.13606372475624084\n",
      "Batch 915,  loss: 0.14341164082288743\n",
      "Batch 920,  loss: 0.16950689554214476\n",
      "Batch 925,  loss: 0.1654732882976532\n",
      "Batch 930,  loss: 0.17642883062362671\n",
      "Batch 935,  loss: 0.13761739134788514\n",
      "Batch 940,  loss: 0.17406902015209197\n",
      "Batch 945,  loss: 0.13159082680940629\n",
      "Batch 950,  loss: 0.12976589500904084\n",
      "Batch 955,  loss: 0.14820175170898436\n",
      "Batch 960,  loss: 0.14106040596961975\n",
      "Batch 965,  loss: 0.1337764397263527\n",
      "Batch 970,  loss: 0.13294088542461396\n",
      "Batch 975,  loss: 0.14770610630512238\n",
      "Batch 980,  loss: 0.14432364851236343\n",
      "Batch 985,  loss: 0.1596779316663742\n",
      "Batch 990,  loss: 0.1621220514178276\n",
      "Batch 995,  loss: 0.18301016986370086\n",
      "Batch 1000,  loss: 0.19489870667457582\n",
      "Batch 1005,  loss: 0.16113190054893495\n",
      "Batch 1010,  loss: 0.207207091152668\n",
      "Batch 1015,  loss: 0.15751074254512787\n",
      "Batch 1020,  loss: 0.1436823457479477\n",
      "Batch 1025,  loss: 0.1742279052734375\n",
      "Batch 1030,  loss: 0.17483986914157867\n",
      "Batch 1035,  loss: 0.14774870872497559\n",
      "Batch 1040,  loss: 0.1475173592567444\n",
      "Batch 1045,  loss: 0.13836573511362077\n",
      "Batch 1050,  loss: 0.16927325427532197\n",
      "Batch 1055,  loss: 0.10177724212408065\n",
      "Batch 1060,  loss: 0.1723565638065338\n",
      "Batch 1065,  loss: 0.14646148979663848\n",
      "Batch 1070,  loss: 0.13264919817447662\n",
      "Batch 1075,  loss: 0.15880680382251738\n",
      "Batch 1080,  loss: 0.15759209990501405\n",
      "Batch 1085,  loss: 0.19719310700893403\n",
      "Batch 1090,  loss: 0.1465306520462036\n",
      "Batch 1095,  loss: 0.12351709455251694\n",
      "Batch 1100,  loss: 0.14546156525611878\n",
      "Batch 1105,  loss: 0.19904134273529053\n",
      "Batch 1110,  loss: 0.15074179023504258\n",
      "Batch 1115,  loss: 0.13656747490167617\n",
      "Batch 1120,  loss: 0.1421867236495018\n",
      "Batch 1125,  loss: 0.159298437833786\n",
      "Batch 1130,  loss: 0.17406813204288482\n",
      "Batch 1135,  loss: 0.14259136319160462\n",
      "Batch 1140,  loss: 0.14846885725855827\n",
      "Batch 1145,  loss: 0.17000559568405152\n",
      "Batch 1150,  loss: 0.14466105699539183\n",
      "Batch 1155,  loss: 0.1574075549840927\n",
      "Batch 1160,  loss: 0.1509483724832535\n",
      "Batch 1165,  loss: 0.13083894848823546\n",
      "Batch 1170,  loss: 0.14325438141822816\n",
      "Batch 1175,  loss: 0.13088697493076323\n",
      "Batch 1180,  loss: 0.1884157031774521\n",
      "Batch 1185,  loss: 0.13141992092132568\n",
      "Batch 1190,  loss: 0.21039892137050628\n",
      "Batch 1195,  loss: 0.18214624971151352\n",
      "Batch 1200,  loss: 0.14563195258378983\n",
      "Batch 1205,  loss: 0.15574502050876618\n",
      "Batch 1210,  loss: 0.15333203077316285\n",
      "Batch 1215,  loss: 0.14959942996501924\n",
      "Batch 1220,  loss: 0.1883406639099121\n",
      "Batch 1225,  loss: 0.19006873816251754\n",
      "Batch 1230,  loss: 0.15181422233581543\n",
      "Batch 1235,  loss: 0.13791207671165467\n",
      "Batch 1240,  loss: 0.18352992236614227\n",
      "Batch 1245,  loss: 0.17432489544153212\n",
      "Batch 1250,  loss: 0.15187438130378722\n",
      "Batch 1255,  loss: 0.14225184172391891\n",
      "Batch 1260,  loss: 0.1801356077194214\n",
      "Batch 1265,  loss: 0.16696852445602417\n",
      "Batch 1270,  loss: 0.1565818101167679\n",
      "Batch 1275,  loss: 0.1584590643644333\n",
      "Batch 1280,  loss: 0.1505598321557045\n",
      "Batch 1285,  loss: 0.16279884725809096\n",
      "Batch 1290,  loss: 0.15042218565940857\n",
      "Batch 1295,  loss: 0.16443075686693193\n",
      "Batch 1300,  loss: 0.1682590901851654\n",
      "Batch 1305,  loss: 0.21122089326381682\n",
      "Batch 1310,  loss: 0.16322283446788788\n",
      "Batch 1315,  loss: 0.15810737013816833\n",
      "Batch 1320,  loss: 0.14626360237598418\n",
      "Batch 1325,  loss: 0.16152032762765883\n",
      "Batch 1330,  loss: 0.13433777242898942\n",
      "Batch 1335,  loss: 0.16682488322257996\n",
      "Batch 1340,  loss: 0.20044344961643218\n",
      "Batch 1345,  loss: 0.12791274189949037\n",
      "Batch 1350,  loss: 0.1715533196926117\n",
      "Batch 1355,  loss: 0.1535451740026474\n",
      "Batch 1360,  loss: 0.126773464679718\n",
      "Batch 1365,  loss: 0.13636584281921388\n",
      "Batch 1370,  loss: 0.17266000509262086\n",
      "Batch 1375,  loss: 0.15273261666297913\n",
      "Batch 1380,  loss: 0.14084113389253616\n",
      "Batch 1385,  loss: 0.1305844008922577\n",
      "Batch 1390,  loss: 0.15530889630317687\n",
      "Batch 1395,  loss: 0.15602854639291763\n",
      "Batch 1400,  loss: 0.1257459118962288\n",
      "Batch 1405,  loss: 0.1869574084877968\n",
      "Batch 1410,  loss: 0.20343296527862548\n",
      "Batch 1415,  loss: 0.16340393871068953\n",
      "Batch 1420,  loss: 0.15983856320381165\n",
      "Batch 1425,  loss: 0.1668413072824478\n",
      "Batch 1430,  loss: 0.17153429090976716\n",
      "Batch 1435,  loss: 0.14556139707565308\n",
      "Batch 1440,  loss: 0.1537247896194458\n",
      "Batch 1445,  loss: 0.21068682968616487\n",
      "Batch 1450,  loss: 0.15300631374120713\n",
      "Batch 1455,  loss: 0.17224632501602172\n",
      "Batch 1460,  loss: 0.14224762916564943\n",
      "Batch 1465,  loss: 0.15365135967731475\n",
      "Batch 1470,  loss: 0.14100519865751265\n",
      "Batch 1475,  loss: 0.15383442789316176\n",
      "Batch 1480,  loss: 0.16109454035758972\n",
      "Batch 1485,  loss: 0.1672768771648407\n",
      "Batch 1490,  loss: 0.18834057748317717\n",
      "Batch 1495,  loss: 0.14629760086536409\n",
      "Batch 1500,  loss: 0.15524189919233322\n",
      "Batch 1505,  loss: 0.2125435322523117\n",
      "Batch 1510,  loss: 0.1970336690545082\n",
      "Batch 1515,  loss: 0.14093695282936097\n",
      "Batch 1520,  loss: 0.15216513872146606\n",
      "Batch 1525,  loss: 0.13749395608901976\n",
      "Batch 1530,  loss: 0.1737835168838501\n",
      "Batch 1535,  loss: 0.1580556958913803\n",
      "Batch 1540,  loss: 0.15846655741333962\n",
      "Batch 1545,  loss: 0.1400843784213066\n",
      "Batch 1550,  loss: 0.14033822417259217\n",
      "Batch 1555,  loss: 0.1538683921098709\n",
      "Batch 1560,  loss: 0.12981207966804503\n",
      "Batch 1565,  loss: 0.16535834223031998\n",
      "Batch 1570,  loss: 0.1893417328596115\n",
      "Batch 1575,  loss: 0.1592016786336899\n",
      "Batch 1580,  loss: 0.14743274748325347\n",
      "Batch 1585,  loss: 0.17342155873775483\n",
      "Batch 1590,  loss: 0.18863757252693175\n",
      "Batch 1595,  loss: 0.1405942976474762\n",
      "Batch 1600,  loss: 0.1614368289709091\n",
      "Batch 1605,  loss: 0.18795223534107208\n",
      "Batch 1610,  loss: 0.13582051992416383\n",
      "Batch 1615,  loss: 0.12325776219367982\n",
      "Batch 1620,  loss: 0.1504931703209877\n",
      "Batch 1625,  loss: 0.12995075583457946\n",
      "Batch 1630,  loss: 0.18148162066936493\n",
      "Batch 1635,  loss: 0.17010405361652375\n",
      "Batch 1640,  loss: 0.13594392985105513\n",
      "Batch 1645,  loss: 0.15334284752607347\n",
      "Batch 1650,  loss: 0.15899548381567002\n",
      "Batch 1655,  loss: 0.2015508830547333\n",
      "Batch 1660,  loss: 0.17752932608127595\n",
      "Batch 1665,  loss: 0.17199637591838837\n",
      "Batch 1670,  loss: 0.14085593074560165\n",
      "Batch 1675,  loss: 0.12808660566806793\n",
      "Batch 1680,  loss: 0.13811127245426177\n",
      "Batch 1685,  loss: 0.12822121381759644\n",
      "Batch 1690,  loss: 0.18309994488954545\n",
      "Batch 1695,  loss: 0.16553691923618316\n",
      "Batch 1700,  loss: 0.18731048107147216\n",
      "Batch 1705,  loss: 0.1802467554807663\n",
      "Batch 1710,  loss: 0.16679712533950805\n",
      "Batch 1715,  loss: 0.14469880163669585\n",
      "Batch 1720,  loss: 0.16427593380212785\n",
      "Batch 1725,  loss: 0.15648378431797028\n",
      "Batch 1730,  loss: 0.15278870463371277\n",
      "Batch 1735,  loss: 0.1591457337141037\n",
      "Batch 1740,  loss: 0.1551029935479164\n",
      "Batch 1745,  loss: 0.14103468507528305\n",
      "Batch 1750,  loss: 0.17250893115997315\n",
      "Batch 1755,  loss: 0.181178417801857\n",
      "Batch 1760,  loss: 0.14234041124582292\n",
      "Batch 1765,  loss: 0.1562102511525154\n",
      "Batch 1770,  loss: 0.196884486079216\n",
      "Batch 1775,  loss: 0.19326259791851044\n",
      "Batch 1780,  loss: 0.18092020750045776\n",
      "Batch 1785,  loss: 0.14674999415874482\n",
      "Batch 1790,  loss: 0.11932757943868637\n",
      "Batch 1795,  loss: 0.12993899881839752\n",
      "Batch 1800,  loss: 0.15504781454801558\n",
      "Batch 1805,  loss: 0.13883200734853746\n",
      "Batch 1810,  loss: 0.14372289031744004\n",
      "Batch 1815,  loss: 0.15039822608232498\n",
      "Batch 1820,  loss: 0.1602690950036049\n",
      "Batch 1825,  loss: 0.1410682663321495\n",
      "Batch 1830,  loss: 0.17220028340816498\n",
      "Batch 1835,  loss: 0.18625318706035615\n",
      "Batch 1840,  loss: 0.23174833059310912\n",
      "Batch 1845,  loss: 0.17070049941539764\n",
      "Batch 1850,  loss: 0.22821824252605438\n",
      "Batch 1855,  loss: 0.17707769572734833\n",
      "Batch 1860,  loss: 0.17019072771072388\n",
      "Batch 1865,  loss: 0.12952630519866942\n",
      "Batch 1870,  loss: 0.15394299775362014\n",
      "Batch 1875,  loss: 0.20205391198396683\n",
      "Batch 1880,  loss: 0.170336252450943\n",
      "Batch 1885,  loss: 0.20981973111629487\n",
      "Batch 1890,  loss: 0.1396359920501709\n",
      "Batch 1895,  loss: 0.19150743186473845\n",
      "Batch 1900,  loss: 0.14333586096763612\n",
      "Batch 1905,  loss: 0.17838826775550842\n",
      "Batch 1910,  loss: 0.15206941738724708\n",
      "Batch 1915,  loss: 0.17797802090644838\n",
      "Batch 1920,  loss: 0.13214239180088044\n",
      "Batch 1925,  loss: 0.1659129351377487\n",
      "Batch 1930,  loss: 0.1555587410926819\n",
      "Batch 1935,  loss: 0.17185594737529755\n",
      "Batch 1940,  loss: 0.15488959848880768\n",
      "Batch 1945,  loss: 0.18370887339115144\n",
      "Batch 1950,  loss: 0.15412447601556778\n",
      "Batch 1955,  loss: 0.129719477891922\n",
      "Batch 1960,  loss: 0.1388932555913925\n",
      "Batch 1965,  loss: 0.10376481264829636\n",
      "Batch 1970,  loss: 0.2135854870080948\n",
      "Batch 1975,  loss: 0.16952120661735534\n",
      "Batch 1980,  loss: 0.15544151961803437\n",
      "Batch 1985,  loss: 0.17200949937105178\n",
      "Batch 1990,  loss: 0.1677586942911148\n",
      "Batch 1995,  loss: 0.1601135402917862\n",
      "Batch 2000,  loss: 0.15502992570400237\n",
      "Batch 2005,  loss: 0.1480223923921585\n",
      "Batch 2010,  loss: 0.16887223422527314\n",
      "Batch 2015,  loss: 0.18499885499477386\n",
      "Batch 2020,  loss: 0.12596853226423263\n",
      "Batch 2025,  loss: 0.17270777821540834\n",
      "Batch 2030,  loss: 0.12833262979984283\n",
      "Batch 2035,  loss: 0.10511288791894913\n",
      "Batch 2040,  loss: 0.16116981208324432\n",
      "Batch 2045,  loss: 0.1549843966960907\n",
      "Batch 2050,  loss: 0.15801507830619813\n",
      "Batch 2055,  loss: 0.17763015925884246\n",
      "Batch 2060,  loss: 0.14924750626087188\n",
      "Batch 2065,  loss: 0.22586551308631897\n",
      "Batch 2070,  loss: 0.16965543925762178\n",
      "Batch 2075,  loss: 0.17084964364767075\n",
      "Batch 2080,  loss: 0.14912994503974913\n",
      "Batch 2085,  loss: 0.16167044043540954\n",
      "Batch 2090,  loss: 0.19966139197349547\n",
      "Batch 2095,  loss: 0.15687687397003175\n",
      "Batch 2100,  loss: 0.1813717871904373\n",
      "Batch 2105,  loss: 0.19024911075830458\n",
      "Batch 2110,  loss: 0.16520242989063263\n",
      "Batch 2115,  loss: 0.19442808926105498\n",
      "Batch 2120,  loss: 0.13017525821924208\n",
      "Batch 2125,  loss: 0.14911115318536758\n",
      "Batch 2130,  loss: 0.10925557613372802\n",
      "Batch 2135,  loss: 0.1672373205423355\n",
      "Batch 2140,  loss: 0.13069677352905273\n",
      "Batch 2145,  loss: 0.125780588388443\n",
      "Batch 2150,  loss: 0.17837943732738495\n",
      "Batch 2155,  loss: 0.18899547308683395\n",
      "Batch 2160,  loss: 0.17894343435764312\n",
      "Batch 2165,  loss: 0.16440028846263885\n",
      "Batch 2170,  loss: 0.2380894422531128\n",
      "Batch 2175,  loss: 0.15092717111110687\n",
      "Batch 2180,  loss: 0.16644375920295715\n",
      "Batch 2185,  loss: 0.16544221639633178\n",
      "Batch 2190,  loss: 0.14129026979207993\n",
      "Batch 2195,  loss: 0.15064021944999695\n",
      "Batch 2200,  loss: 0.1268716424703598\n",
      "Batch 2205,  loss: 0.1588907390832901\n",
      "Batch 2210,  loss: 0.18004174530506134\n",
      "Batch 2215,  loss: 0.15564749091863633\n",
      "Batch 2220,  loss: 0.17036136984825134\n",
      "Batch 2225,  loss: 0.1670941174030304\n",
      "Batch 2230,  loss: 0.15001740604639052\n",
      "Batch 2235,  loss: 0.2034722536802292\n",
      "Batch 2240,  loss: 0.14937977194786073\n",
      "Batch 2245,  loss: 0.1193555474281311\n",
      "Batch 2250,  loss: 0.1715198665857315\n",
      "Batch 2255,  loss: 0.15719212591648102\n",
      "Batch 2260,  loss: 0.1419718712568283\n",
      "Batch 2265,  loss: 0.1596795439720154\n",
      "Batch 2270,  loss: 0.15345476269721986\n",
      "Batch 2275,  loss: 0.180931693315506\n",
      "Batch 2280,  loss: 0.18006671071052552\n",
      "Batch 2285,  loss: 0.20212750732898713\n",
      "Batch 2290,  loss: 0.14935772120952606\n",
      "Batch 2295,  loss: 0.21331990361213685\n",
      "Batch 2300,  loss: 0.15273496210575105\n",
      "Batch 2305,  loss: 0.20508669316768646\n",
      "Batch 2310,  loss: 0.14852280914783478\n",
      "Batch 2315,  loss: 0.13864686191082\n",
      "Batch 2320,  loss: 0.16697828769683837\n",
      "Batch 2325,  loss: 0.1826522797346115\n",
      "Batch 2330,  loss: 0.20073334276676177\n",
      "Batch 2335,  loss: 0.14398733228445054\n",
      "Batch 2340,  loss: 0.1641123563051224\n",
      "Batch 2345,  loss: 0.18385225534439087\n",
      "Batch 2350,  loss: 0.21306219100952148\n",
      "Batch 2355,  loss: 0.16607743203639985\n",
      "Batch 2360,  loss: 0.1892901450395584\n",
      "Batch 2365,  loss: 0.15345695316791536\n",
      "Batch 2370,  loss: 0.1696900263428688\n",
      "Batch 2375,  loss: 0.2232615277171135\n",
      "Batch 2380,  loss: 0.1408955305814743\n",
      "Batch 2385,  loss: 0.16938329935073854\n",
      "Batch 2390,  loss: 0.12917081266641617\n",
      "Batch 2395,  loss: 0.15952311605215072\n",
      "Batch 2400,  loss: 0.1489635944366455\n",
      "Batch 2405,  loss: 0.16370732188224793\n",
      "Batch 2410,  loss: 0.18559202849864959\n",
      "Batch 2415,  loss: 0.1769149661064148\n",
      "Batch 2420,  loss: 0.166046205163002\n",
      "Batch 2425,  loss: 0.14426851719617845\n",
      "Batch 2430,  loss: 0.1668928399682045\n",
      "Batch 2435,  loss: 0.15843534767627715\n",
      "Batch 2440,  loss: 0.16791369318962096\n",
      "Batch 2445,  loss: 0.16737660765647888\n",
      "Batch 2450,  loss: 0.14499093145132064\n",
      "Batch 2455,  loss: 0.15070306956768037\n",
      "Batch 2460,  loss: 0.17095586359500886\n",
      "Batch 2465,  loss: 0.15988339185714723\n",
      "Batch 2470,  loss: 0.16345446556806564\n",
      "Batch 2475,  loss: 0.15922823548316956\n",
      "Batch 2480,  loss: 0.19756539165973663\n",
      "Batch 2485,  loss: 0.16441846787929534\n",
      "Batch 2490,  loss: 0.1660851627588272\n",
      "Batch 2495,  loss: 0.1530782625079155\n",
      "Batch 2500,  loss: 0.1402747303247452\n",
      "Batch 2505,  loss: 0.16126674115657808\n",
      "Batch 2510,  loss: 0.13118888139724733\n",
      "Batch 2515,  loss: 0.1524534210562706\n",
      "Batch 2520,  loss: 0.16466700732707978\n",
      "Batch 2525,  loss: 0.1931856691837311\n",
      "Batch 2530,  loss: 0.1819952219724655\n",
      "Batch 2535,  loss: 0.14889143407344818\n",
      "Batch 2540,  loss: 0.18366585671901703\n",
      "Batch 2545,  loss: 0.14695709496736525\n",
      "Batch 2550,  loss: 0.1466231480240822\n",
      "Batch 2555,  loss: 0.1430472806096077\n",
      "Batch 2560,  loss: 0.1416599780321121\n",
      "Batch 2565,  loss: 0.15358264446258546\n",
      "Batch 2570,  loss: 0.12214360684156418\n",
      "Batch 2575,  loss: 0.16415271759033204\n",
      "Batch 2580,  loss: 0.14811509996652603\n",
      "Batch 2585,  loss: 0.17698589563369752\n",
      "Batch 2590,  loss: 0.16675965487957\n",
      "Batch 2595,  loss: 0.14557621479034424\n",
      "Batch 2600,  loss: 0.19430729895830154\n",
      "Batch 2605,  loss: 0.187996244430542\n",
      "Batch 2610,  loss: 0.12785849571228028\n",
      "Batch 2615,  loss: 0.151052887737751\n",
      "Batch 2620,  loss: 0.1676054432988167\n",
      "Batch 2625,  loss: 0.13257275521755219\n",
      "Batch 2630,  loss: 0.15150238424539567\n",
      "Batch 2635,  loss: 0.18541940152645112\n",
      "Batch 2640,  loss: 0.15666240751743316\n",
      "Batch 2645,  loss: 0.14893320798873902\n",
      "Batch 2650,  loss: 0.1677653431892395\n",
      "Batch 2655,  loss: 0.1549367293715477\n",
      "Batch 2660,  loss: 0.1440801277756691\n",
      "Batch 2665,  loss: 0.1455448254942894\n",
      "Batch 2670,  loss: 0.15095744878053666\n",
      "Batch 2675,  loss: 0.16117435842752456\n",
      "Batch 2680,  loss: 0.2138752520084381\n",
      "Batch 2685,  loss: 0.16756385564804077\n",
      "Batch 2690,  loss: 0.14694257378578185\n",
      "Batch 2695,  loss: 0.1294004052877426\n",
      "Batch 2700,  loss: 0.13166192919015884\n",
      "Batch 2705,  loss: 0.15781903266906738\n",
      "Batch 2710,  loss: 0.1764368772506714\n",
      "Batch 2715,  loss: 0.18386192321777345\n",
      "Batch 2720,  loss: 0.1235304594039917\n",
      "Batch 2725,  loss: 0.20440018475055693\n",
      "Batch 2730,  loss: 0.20097458958625794\n",
      "Batch 2735,  loss: 0.1253386467695236\n",
      "Batch 2740,  loss: 0.14218418002128602\n",
      "Batch 2745,  loss: 0.1689792364835739\n",
      "Batch 2750,  loss: 0.1377370223402977\n",
      "Batch 2755,  loss: 0.13905863016843795\n",
      "Batch 2760,  loss: 0.1341774895787239\n",
      "Batch 2765,  loss: 0.16109599769115449\n",
      "Batch 2770,  loss: 0.187701578438282\n",
      "LOSS train 0.187701578438282. Validation loss: 0.16004136571212224 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 30:\n",
      "Batch 5,  loss: 0.17979909479618073\n",
      "Batch 10,  loss: 0.16628413796424865\n",
      "Batch 15,  loss: 0.1449173331260681\n",
      "Batch 20,  loss: 0.1310091957449913\n",
      "Batch 25,  loss: 0.19083382189273834\n",
      "Batch 30,  loss: 0.1278616949915886\n",
      "Batch 35,  loss: 0.18280340731143951\n",
      "Batch 40,  loss: 0.23823102414608002\n",
      "Batch 45,  loss: 0.18389341086149216\n",
      "Batch 50,  loss: 0.12917787432670594\n",
      "Batch 55,  loss: 0.17383822798728943\n",
      "Batch 60,  loss: 0.19692061245441436\n",
      "Batch 65,  loss: 0.18152633011341096\n",
      "Batch 70,  loss: 0.16441023200750352\n",
      "Batch 75,  loss: 0.1368242770433426\n",
      "Batch 80,  loss: 0.14678931683301927\n",
      "Batch 85,  loss: 0.14711239337921142\n",
      "Batch 90,  loss: 0.13406644612550736\n",
      "Batch 95,  loss: 0.1997788891196251\n",
      "Batch 100,  loss: 0.20212276875972748\n",
      "Batch 105,  loss: 0.1668223887681961\n",
      "Batch 110,  loss: 0.16506099998950957\n",
      "Batch 115,  loss: 0.14581921100616455\n",
      "Batch 120,  loss: 0.13351222425699233\n",
      "Batch 125,  loss: 0.14119988083839416\n",
      "Batch 130,  loss: 0.15230946242809296\n",
      "Batch 135,  loss: 0.15350461453199388\n",
      "Batch 140,  loss: 0.16291139870882035\n",
      "Batch 145,  loss: 0.1557142525911331\n",
      "Batch 150,  loss: 0.14421456456184387\n",
      "Batch 155,  loss: 0.21600539982318878\n",
      "Batch 160,  loss: 0.18421571999788283\n",
      "Batch 165,  loss: 0.15415103137493133\n",
      "Batch 170,  loss: 0.15134420692920686\n",
      "Batch 175,  loss: 0.15742334425449372\n",
      "Batch 180,  loss: 0.1413235619664192\n",
      "Batch 185,  loss: 0.1771800011396408\n",
      "Batch 190,  loss: 0.14490935802459717\n",
      "Batch 195,  loss: 0.17279398143291474\n",
      "Batch 200,  loss: 0.19265308678150178\n",
      "Batch 205,  loss: 0.13322645723819732\n",
      "Batch 210,  loss: 0.184845370054245\n",
      "Batch 215,  loss: 0.16818621456623079\n",
      "Batch 220,  loss: 0.1423804521560669\n",
      "Batch 225,  loss: 0.18642290830612182\n",
      "Batch 230,  loss: 0.18897147476673126\n",
      "Batch 235,  loss: 0.15581293851137162\n",
      "Batch 240,  loss: 0.1985674560070038\n",
      "Batch 245,  loss: 0.1347049742937088\n",
      "Batch 250,  loss: 0.19140268564224244\n",
      "Batch 255,  loss: 0.17873189449310303\n",
      "Batch 260,  loss: 0.16615932434797287\n",
      "Batch 265,  loss: 0.1581789016723633\n",
      "Batch 270,  loss: 0.17898812890052795\n",
      "Batch 275,  loss: 0.19305124878883362\n",
      "Batch 280,  loss: 0.16187264174222946\n",
      "Batch 285,  loss: 0.1555396169424057\n",
      "Batch 290,  loss: 0.1758375883102417\n",
      "Batch 295,  loss: 0.14057888388633727\n",
      "Batch 300,  loss: 0.17305979132652283\n",
      "Batch 305,  loss: 0.12674426287412643\n",
      "Batch 310,  loss: 0.17249689102172852\n",
      "Batch 315,  loss: 0.14401300996541977\n",
      "Batch 320,  loss: 0.15250955820083617\n",
      "Batch 325,  loss: 0.14530383944511413\n",
      "Batch 330,  loss: 0.15003369599580765\n",
      "Batch 335,  loss: 0.15062054097652436\n",
      "Batch 340,  loss: 0.1604864239692688\n",
      "Batch 345,  loss: 0.1980326294898987\n",
      "Batch 350,  loss: 0.17450879216194154\n",
      "Batch 355,  loss: 0.15909917056560516\n",
      "Batch 360,  loss: 0.16037220805883406\n",
      "Batch 365,  loss: 0.1455896645784378\n",
      "Batch 370,  loss: 0.17910133302211761\n",
      "Batch 375,  loss: 0.1651068538427353\n",
      "Batch 380,  loss: 0.15198584347963334\n",
      "Batch 385,  loss: 0.1387793242931366\n",
      "Batch 390,  loss: 0.1473893329501152\n",
      "Batch 395,  loss: 0.14939279854297638\n",
      "Batch 400,  loss: 0.1444198191165924\n",
      "Batch 405,  loss: 0.14116663485765457\n",
      "Batch 410,  loss: 0.17388847172260286\n",
      "Batch 415,  loss: 0.21924883127212524\n",
      "Batch 420,  loss: 0.16064063012599944\n",
      "Batch 425,  loss: 0.1727381318807602\n",
      "Batch 430,  loss: 0.14797260612249374\n",
      "Batch 435,  loss: 0.13801950514316558\n",
      "Batch 440,  loss: 0.1649526387453079\n",
      "Batch 445,  loss: 0.1126198187470436\n",
      "Batch 450,  loss: 0.138499017059803\n",
      "Batch 455,  loss: 0.1470351606607437\n",
      "Batch 460,  loss: 0.1418822318315506\n",
      "Batch 465,  loss: 0.1715235561132431\n",
      "Batch 470,  loss: 0.1680813640356064\n",
      "Batch 475,  loss: 0.14729438871145248\n",
      "Batch 480,  loss: 0.1498150959610939\n",
      "Batch 485,  loss: 0.11784078925848007\n",
      "Batch 490,  loss: 0.162562558054924\n",
      "Batch 495,  loss: 0.16547527015209199\n",
      "Batch 500,  loss: 0.15740467458963395\n",
      "Batch 505,  loss: 0.14697861671447754\n",
      "Batch 510,  loss: 0.15557780265808105\n",
      "Batch 515,  loss: 0.1812127262353897\n",
      "Batch 520,  loss: 0.18495630472898483\n",
      "Batch 525,  loss: 0.15877008736133574\n",
      "Batch 530,  loss: 0.169948011636734\n",
      "Batch 535,  loss: 0.14981264173984526\n",
      "Batch 540,  loss: 0.16851992160081863\n",
      "Batch 545,  loss: 0.13432049751281738\n",
      "Batch 550,  loss: 0.13397239595651628\n",
      "Batch 555,  loss: 0.1434556245803833\n",
      "Batch 560,  loss: 0.18839291036128997\n",
      "Batch 565,  loss: 0.12635338604450225\n",
      "Batch 570,  loss: 0.16263051629066466\n",
      "Batch 575,  loss: 0.13866523951292037\n",
      "Batch 580,  loss: 0.19592562019824983\n",
      "Batch 585,  loss: 0.17913047671318055\n",
      "Batch 590,  loss: 0.21080001294612885\n",
      "Batch 595,  loss: 0.1497699499130249\n",
      "Batch 600,  loss: 0.1552463710308075\n",
      "Batch 605,  loss: 0.15686360001564026\n",
      "Batch 610,  loss: 0.13172427862882613\n",
      "Batch 615,  loss: 0.12509903013706208\n",
      "Batch 620,  loss: 0.16010122895240783\n",
      "Batch 625,  loss: 0.1640774130821228\n",
      "Batch 630,  loss: 0.14148395657539367\n",
      "Batch 635,  loss: 0.1673561602830887\n",
      "Batch 640,  loss: 0.13814376294612885\n",
      "Batch 645,  loss: 0.12634795904159546\n",
      "Batch 650,  loss: 0.15004221796989442\n",
      "Batch 655,  loss: 0.10668385028839111\n",
      "Batch 660,  loss: 0.1568290799856186\n",
      "Batch 665,  loss: 0.1685606211423874\n",
      "Batch 670,  loss: 0.13518478572368622\n",
      "Batch 675,  loss: 0.15679415166378022\n",
      "Batch 680,  loss: 0.12543175518512725\n",
      "Batch 685,  loss: 0.19433433711528778\n",
      "Batch 690,  loss: 0.13534830808639525\n",
      "Batch 695,  loss: 0.11645595878362655\n",
      "Batch 700,  loss: 0.18744286000728608\n",
      "Batch 705,  loss: 0.1292475774884224\n",
      "Batch 710,  loss: 0.1406326562166214\n",
      "Batch 715,  loss: 0.18556649684906007\n",
      "Batch 720,  loss: 0.13273324966430664\n",
      "Batch 725,  loss: 0.1268948346376419\n",
      "Batch 730,  loss: 0.13996609151363373\n",
      "Batch 735,  loss: 0.17349754571914672\n",
      "Batch 740,  loss: 0.17062199115753174\n",
      "Batch 745,  loss: 0.12258412390947342\n",
      "Batch 750,  loss: 0.15145631283521652\n",
      "Batch 755,  loss: 0.17819821536540986\n",
      "Batch 760,  loss: 0.2036126434803009\n",
      "Batch 765,  loss: 0.14689001739025115\n",
      "Batch 770,  loss: 0.15329896956682204\n",
      "Batch 775,  loss: 0.17411141991615295\n",
      "Batch 780,  loss: 0.13739061653614043\n",
      "Batch 785,  loss: 0.1534635305404663\n",
      "Batch 790,  loss: 0.15298729091882707\n",
      "Batch 795,  loss: 0.15828730612993241\n",
      "Batch 800,  loss: 0.16478711366653442\n",
      "Batch 805,  loss: 0.1437276929616928\n",
      "Batch 810,  loss: 0.11536740809679032\n",
      "Batch 815,  loss: 0.13059268444776534\n",
      "Batch 820,  loss: 0.12840803861618041\n",
      "Batch 825,  loss: 0.14581881165504457\n",
      "Batch 830,  loss: 0.1918592244386673\n",
      "Batch 835,  loss: 0.12718658447265624\n",
      "Batch 840,  loss: 0.15867561399936675\n",
      "Batch 845,  loss: 0.1559283286333084\n",
      "Batch 850,  loss: 0.19162107706069947\n",
      "Batch 855,  loss: 0.17824985831975937\n",
      "Batch 860,  loss: 0.15996096432209014\n",
      "Batch 865,  loss: 0.18199135959148408\n",
      "Batch 870,  loss: 0.1240537166595459\n",
      "Batch 875,  loss: 0.17528265118598937\n",
      "Batch 880,  loss: 0.1477183073759079\n",
      "Batch 885,  loss: 0.13555189371109008\n",
      "Batch 890,  loss: 0.16981559097766877\n",
      "Batch 895,  loss: 0.16395360976457596\n",
      "Batch 900,  loss: 0.1814548432826996\n",
      "Batch 905,  loss: 0.15325723290443422\n",
      "Batch 910,  loss: 0.16900610625743867\n",
      "Batch 915,  loss: 0.16483066380023956\n",
      "Batch 920,  loss: 0.1803407698869705\n",
      "Batch 925,  loss: 0.1982216566801071\n",
      "Batch 930,  loss: 0.1586577355861664\n",
      "Batch 935,  loss: 0.147423055768013\n",
      "Batch 940,  loss: 0.13465916663408278\n",
      "Batch 945,  loss: 0.17436705380678177\n",
      "Batch 950,  loss: 0.12925853133201598\n",
      "Batch 955,  loss: 0.17779194116592406\n",
      "Batch 960,  loss: 0.14368760138750075\n",
      "Batch 965,  loss: 0.14339018613100052\n",
      "Batch 970,  loss: 0.16662491261959075\n",
      "Batch 975,  loss: 0.19765031933784485\n",
      "Batch 980,  loss: 0.16321482360363007\n",
      "Batch 985,  loss: 0.19194760620594026\n",
      "Batch 990,  loss: 0.15830083787441254\n",
      "Batch 995,  loss: 0.1906419038772583\n",
      "Batch 1000,  loss: 0.137653748691082\n",
      "Batch 1005,  loss: 0.16264183521270753\n",
      "Batch 1010,  loss: 0.14917546212673188\n",
      "Batch 1015,  loss: 0.16762068569660188\n",
      "Batch 1020,  loss: 0.17429982274770736\n",
      "Batch 1025,  loss: 0.135577492415905\n",
      "Batch 1030,  loss: 0.1509450227022171\n",
      "Batch 1035,  loss: 0.17712138891220092\n",
      "Batch 1040,  loss: 0.14852070808410645\n",
      "Batch 1045,  loss: 0.12687589675188066\n",
      "Batch 1050,  loss: 0.1686024397611618\n",
      "Batch 1055,  loss: 0.11853949278593064\n",
      "Batch 1060,  loss: 0.1964036703109741\n",
      "Batch 1065,  loss: 0.1895355761051178\n",
      "Batch 1070,  loss: 0.12526197582483292\n",
      "Batch 1075,  loss: 0.1370706230401993\n",
      "Batch 1080,  loss: 0.13731787502765655\n",
      "Batch 1085,  loss: 0.1584795445203781\n",
      "Batch 1090,  loss: 0.16571175456047058\n",
      "Batch 1095,  loss: 0.1754906430840492\n",
      "Batch 1100,  loss: 0.1493233859539032\n",
      "Batch 1105,  loss: 0.17445297092199324\n",
      "Batch 1110,  loss: 0.1701190859079361\n",
      "Batch 1115,  loss: 0.15571000427007675\n",
      "Batch 1120,  loss: 0.15397657454013824\n",
      "Batch 1125,  loss: 0.14846178591251374\n",
      "Batch 1130,  loss: 0.17920584231615067\n",
      "Batch 1135,  loss: 0.16563192009925842\n",
      "Batch 1140,  loss: 0.1702723830938339\n",
      "Batch 1145,  loss: 0.20962143838405609\n",
      "Batch 1150,  loss: 0.24048397541046143\n",
      "Batch 1155,  loss: 0.15036470592021942\n",
      "Batch 1160,  loss: 0.13208980858325958\n",
      "Batch 1165,  loss: 0.14982914924621582\n",
      "Batch 1170,  loss: 0.1351453348994255\n",
      "Batch 1175,  loss: 0.16973596513271333\n",
      "Batch 1180,  loss: 0.14849490970373153\n",
      "Batch 1185,  loss: 0.15051499605178834\n",
      "Batch 1190,  loss: 0.1661648392677307\n",
      "Batch 1195,  loss: 0.15939741283655168\n",
      "Batch 1200,  loss: 0.16084737479686737\n",
      "Batch 1205,  loss: 0.16543323397636414\n",
      "Batch 1210,  loss: 0.15119843631982804\n",
      "Batch 1215,  loss: 0.14757500141859053\n",
      "Batch 1220,  loss: 0.18520928770303727\n",
      "Batch 1225,  loss: 0.14819377958774566\n",
      "Batch 1230,  loss: 0.18550100326538085\n",
      "Batch 1235,  loss: 0.16110361218452454\n",
      "Batch 1240,  loss: 0.14670591652393342\n",
      "Batch 1245,  loss: 0.15892456769943236\n",
      "Batch 1250,  loss: 0.21026446521282197\n",
      "Batch 1255,  loss: 0.16533138155937194\n",
      "Batch 1260,  loss: 0.18820785284042357\n",
      "Batch 1265,  loss: 0.1577790006995201\n",
      "Batch 1270,  loss: 0.1324795588850975\n",
      "Batch 1275,  loss: 0.14027427285909652\n",
      "Batch 1280,  loss: 0.191413214802742\n",
      "Batch 1285,  loss: 0.16272563636302947\n",
      "Batch 1290,  loss: 0.1301986739039421\n",
      "Batch 1295,  loss: 0.13222576677799225\n",
      "Batch 1300,  loss: 0.17659451067447662\n",
      "Batch 1305,  loss: 0.1450446605682373\n",
      "Batch 1310,  loss: 0.1496163174510002\n",
      "Batch 1315,  loss: 0.1704167291522026\n",
      "Batch 1320,  loss: 0.1742963194847107\n",
      "Batch 1325,  loss: 0.16069320142269133\n",
      "Batch 1330,  loss: 0.16155242621898652\n",
      "Batch 1335,  loss: 0.159620763361454\n",
      "Batch 1340,  loss: 0.11793757975101471\n",
      "Batch 1345,  loss: 0.14959697127342225\n",
      "Batch 1350,  loss: 0.1397470936179161\n",
      "Batch 1355,  loss: 0.19776375591754913\n",
      "Batch 1360,  loss: 0.18740814179182053\n",
      "Batch 1365,  loss: 0.16777351200580598\n",
      "Batch 1370,  loss: 0.20035801827907562\n",
      "Batch 1375,  loss: 0.12218906283378601\n",
      "Batch 1380,  loss: 0.14711783528327943\n",
      "Batch 1385,  loss: 0.19841906875371934\n",
      "Batch 1390,  loss: 0.1588735595345497\n",
      "Batch 1395,  loss: 0.18618881106376647\n",
      "Batch 1400,  loss: 0.16557870507240297\n",
      "Batch 1405,  loss: 0.13480162918567656\n",
      "Batch 1410,  loss: 0.16597707867622374\n",
      "Batch 1415,  loss: 0.14283066242933273\n",
      "Batch 1420,  loss: 0.18914799988269806\n",
      "Batch 1425,  loss: 0.12290721237659455\n",
      "Batch 1430,  loss: 0.16095393896102905\n",
      "Batch 1435,  loss: 0.1684173345565796\n",
      "Batch 1440,  loss: 0.1503741130232811\n",
      "Batch 1445,  loss: 0.1406413048505783\n",
      "Batch 1450,  loss: 0.15906157195568085\n",
      "Batch 1455,  loss: 0.15298623740673065\n",
      "Batch 1460,  loss: 0.19847686290740968\n",
      "Batch 1465,  loss: 0.1378713145852089\n",
      "Batch 1470,  loss: 0.1276157781481743\n",
      "Batch 1475,  loss: 0.17196642756462097\n",
      "Batch 1480,  loss: 0.18665119707584382\n",
      "Batch 1485,  loss: 0.16703007817268373\n",
      "Batch 1490,  loss: 0.1644303485751152\n",
      "Batch 1495,  loss: 0.14610301256179808\n",
      "Batch 1500,  loss: 0.20016186237335204\n",
      "Batch 1505,  loss: 0.15907857269048692\n",
      "Batch 1510,  loss: 0.14856238663196564\n",
      "Batch 1515,  loss: 0.16133402585983275\n",
      "Batch 1520,  loss: 0.13384118676185608\n",
      "Batch 1525,  loss: 0.12310535311698914\n",
      "Batch 1530,  loss: 0.16008606553077698\n",
      "Batch 1535,  loss: 0.15893240571022033\n",
      "Batch 1540,  loss: 0.17685974836349488\n",
      "Batch 1545,  loss: 0.1384692221879959\n",
      "Batch 1550,  loss: 0.1461066409945488\n",
      "Batch 1555,  loss: 0.20731465220451356\n",
      "Batch 1560,  loss: 0.2048799693584442\n",
      "Batch 1565,  loss: 0.1567301869392395\n",
      "Batch 1570,  loss: 0.16210912466049193\n",
      "Batch 1575,  loss: 0.15406627506017684\n",
      "Batch 1580,  loss: 0.1379940152168274\n",
      "Batch 1585,  loss: 0.17912876904010772\n",
      "Batch 1590,  loss: 0.16947667598724364\n",
      "Batch 1595,  loss: 0.14910470247268676\n",
      "Batch 1600,  loss: 0.15095779299736023\n",
      "Batch 1605,  loss: 0.16715890765190125\n",
      "Batch 1610,  loss: 0.16022264659404756\n",
      "Batch 1615,  loss: 0.15435842871665956\n",
      "Batch 1620,  loss: 0.14115309417247773\n",
      "Batch 1625,  loss: 0.16280486285686493\n",
      "Batch 1630,  loss: 0.10861043184995652\n",
      "Batch 1635,  loss: 0.1561496764421463\n",
      "Batch 1640,  loss: 0.19739970564842224\n",
      "Batch 1645,  loss: 0.1411528021097183\n",
      "Batch 1650,  loss: 0.16590831577777862\n",
      "Batch 1655,  loss: 0.17363945841789247\n",
      "Batch 1660,  loss: 0.19023636132478713\n",
      "Batch 1665,  loss: 0.15753254294395447\n",
      "Batch 1670,  loss: 0.16281247437000274\n",
      "Batch 1675,  loss: 0.14910784363746643\n",
      "Batch 1680,  loss: 0.14536439180374144\n",
      "Batch 1685,  loss: 0.14170129001140594\n",
      "Batch 1690,  loss: 0.18102822303771973\n",
      "Batch 1695,  loss: 0.16808075904846193\n",
      "Batch 1700,  loss: 0.18802421689033508\n",
      "Batch 1705,  loss: 0.16570398658514024\n",
      "Batch 1710,  loss: 0.18482618331909179\n",
      "Batch 1715,  loss: 0.18893132656812667\n",
      "Batch 1720,  loss: 0.18402206599712373\n",
      "Batch 1725,  loss: 0.17495308816432953\n",
      "Batch 1730,  loss: 0.12593032270669938\n",
      "Batch 1735,  loss: 0.15426640808582306\n",
      "Batch 1740,  loss: 0.12261422276496887\n",
      "Batch 1745,  loss: 0.15184510350227357\n",
      "Batch 1750,  loss: 0.167556968331337\n",
      "Batch 1755,  loss: 0.12901722341775895\n",
      "Batch 1760,  loss: 0.13530531972646714\n",
      "Batch 1765,  loss: 0.1624177426099777\n",
      "Batch 1770,  loss: 0.1790090873837471\n",
      "Batch 1775,  loss: 0.16475326418876649\n",
      "Batch 1780,  loss: 0.17202809154987336\n",
      "Batch 1785,  loss: 0.1514967605471611\n",
      "Batch 1790,  loss: 0.1342902049422264\n",
      "Batch 1795,  loss: 0.19758869111537933\n",
      "Batch 1800,  loss: 0.14114439189434053\n",
      "Batch 1805,  loss: 0.1334880143404007\n",
      "Batch 1810,  loss: 0.12896746397018433\n",
      "Batch 1815,  loss: 0.16117359697818756\n",
      "Batch 1820,  loss: 0.18229962587356568\n",
      "Batch 1825,  loss: 0.14245666414499283\n",
      "Batch 1830,  loss: 0.19721922874450684\n",
      "Batch 1835,  loss: 0.16541221290826796\n",
      "Batch 1840,  loss: 0.1605888545513153\n",
      "Batch 1845,  loss: 0.15451705008745192\n",
      "Batch 1850,  loss: 0.19847017526626587\n",
      "Batch 1855,  loss: 0.12609681040048598\n",
      "Batch 1860,  loss: 0.13879922926425933\n",
      "Batch 1865,  loss: 0.1513060674071312\n",
      "Batch 1870,  loss: 0.19284006655216218\n",
      "Batch 1875,  loss: 0.13213074803352357\n",
      "Batch 1880,  loss: 0.1367654711008072\n",
      "Batch 1885,  loss: 0.16340942978858947\n",
      "Batch 1890,  loss: 0.16878259629011155\n",
      "Batch 1895,  loss: 0.18977461755275726\n",
      "Batch 1900,  loss: 0.12607858180999756\n",
      "Batch 1905,  loss: 0.16295602321624755\n",
      "Batch 1910,  loss: 0.13269229829311371\n",
      "Batch 1915,  loss: 0.15051045268774033\n",
      "Batch 1920,  loss: 0.14640261232852936\n",
      "Batch 1925,  loss: 0.1576809674501419\n",
      "Batch 1930,  loss: 0.13792543560266496\n",
      "Batch 1935,  loss: 0.14788694083690643\n",
      "Batch 1940,  loss: 0.21288052797317505\n",
      "Batch 1945,  loss: 0.12447115182876586\n",
      "Batch 1950,  loss: 0.1493629425764084\n",
      "Batch 1955,  loss: 0.21293820142745973\n",
      "Batch 1960,  loss: 0.1705043539404869\n",
      "Batch 1965,  loss: 0.16971601843833922\n",
      "Batch 1970,  loss: 0.17500918507575988\n",
      "Batch 1975,  loss: 0.14701697826385499\n",
      "Batch 1980,  loss: 0.17762032449245452\n",
      "Batch 1985,  loss: 0.16171872913837432\n",
      "Batch 1990,  loss: 0.13857388794422149\n",
      "Batch 1995,  loss: 0.15470609962940216\n",
      "Batch 2000,  loss: 0.16423118859529495\n",
      "Batch 2005,  loss: 0.1809680014848709\n",
      "Batch 2010,  loss: 0.17240991592407226\n",
      "Batch 2015,  loss: 0.15210185199975967\n",
      "Batch 2020,  loss: 0.16916641891002654\n",
      "Batch 2025,  loss: 0.18302612006664276\n",
      "Batch 2030,  loss: 0.152457095682621\n",
      "Batch 2035,  loss: 0.16094602644443512\n",
      "Batch 2040,  loss: 0.1324138432741165\n",
      "Batch 2045,  loss: 0.13033229112625122\n",
      "Batch 2050,  loss: 0.14217946529388428\n",
      "Batch 2055,  loss: 0.11671903282403946\n",
      "Batch 2060,  loss: 0.17665276527404786\n",
      "Batch 2065,  loss: 0.16439988017082213\n",
      "Batch 2070,  loss: 0.09278168678283691\n",
      "Batch 2075,  loss: 0.18921123296022416\n",
      "Batch 2080,  loss: 0.1330205351114273\n",
      "Batch 2085,  loss: 0.1411723330616951\n",
      "Batch 2090,  loss: 0.15067620277404786\n",
      "Batch 2095,  loss: 0.13075094521045685\n",
      "Batch 2100,  loss: 0.14806529134511948\n",
      "Batch 2105,  loss: 0.18947684466838838\n",
      "Batch 2110,  loss: 0.13919907063245773\n",
      "Batch 2115,  loss: 0.14525183737277986\n",
      "Batch 2120,  loss: 0.18346319794654847\n",
      "Batch 2125,  loss: 0.1875899463891983\n",
      "Batch 2130,  loss: 0.16025842875242233\n",
      "Batch 2135,  loss: 0.14385911226272582\n",
      "Batch 2140,  loss: 0.1827034056186676\n",
      "Batch 2145,  loss: 0.15389850437641145\n",
      "Batch 2150,  loss: 0.14913755506277085\n",
      "Batch 2155,  loss: 0.18542611598968506\n",
      "Batch 2160,  loss: 0.17952364087104797\n",
      "Batch 2165,  loss: 0.1398106560111046\n",
      "Batch 2170,  loss: 0.16147949397563935\n",
      "Batch 2175,  loss: 0.1301790252327919\n",
      "Batch 2180,  loss: 0.1669379562139511\n",
      "Batch 2185,  loss: 0.1740262985229492\n",
      "Batch 2190,  loss: 0.1960378557443619\n",
      "Batch 2195,  loss: 0.13471795320510865\n",
      "Batch 2200,  loss: 0.20419521480798722\n",
      "Batch 2205,  loss: 0.16355990171432494\n",
      "Batch 2210,  loss: 0.1505239263176918\n",
      "Batch 2215,  loss: 0.15241386890411376\n",
      "Batch 2220,  loss: 0.12778627276420593\n",
      "Batch 2225,  loss: 0.1370511993765831\n",
      "Batch 2230,  loss: 0.1672338217496872\n",
      "Batch 2235,  loss: 0.2046816498041153\n",
      "Batch 2240,  loss: 0.14645655155181886\n",
      "Batch 2245,  loss: 0.14514911025762559\n",
      "Batch 2250,  loss: 0.1349114239215851\n",
      "Batch 2255,  loss: 0.16406897753477095\n",
      "Batch 2260,  loss: 0.17082629799842836\n",
      "Batch 2265,  loss: 0.14623485654592513\n",
      "Batch 2270,  loss: 0.21117461919784547\n",
      "Batch 2275,  loss: 0.17211434245109558\n",
      "Batch 2280,  loss: 0.1372722268104553\n",
      "Batch 2285,  loss: 0.13382110446691514\n",
      "Batch 2290,  loss: 0.16266614198684692\n",
      "Batch 2295,  loss: 0.17513033747673035\n",
      "Batch 2300,  loss: 0.17146207094192506\n",
      "Batch 2305,  loss: 0.1109180361032486\n",
      "Batch 2310,  loss: 0.1536395490169525\n",
      "Batch 2315,  loss: 0.14729048162698746\n",
      "Batch 2320,  loss: 0.14074278026819229\n",
      "Batch 2325,  loss: 0.1921222060918808\n",
      "Batch 2330,  loss: 0.15702717006206512\n",
      "Batch 2335,  loss: 0.1754453659057617\n",
      "Batch 2340,  loss: 0.17049106061458588\n",
      "Batch 2345,  loss: 0.14527826011180878\n",
      "Batch 2350,  loss: 0.15611065924167633\n",
      "Batch 2355,  loss: 0.1196246400475502\n",
      "Batch 2360,  loss: 0.14533942192792892\n",
      "Batch 2365,  loss: 0.18968429863452912\n",
      "Batch 2370,  loss: 0.16722395569086074\n",
      "Batch 2375,  loss: 0.1508062869310379\n",
      "Batch 2380,  loss: 0.10248698741197586\n",
      "Batch 2385,  loss: 0.1704280585050583\n",
      "Batch 2390,  loss: 0.17314480543136596\n",
      "Batch 2395,  loss: 0.18223946094512938\n",
      "Batch 2400,  loss: 0.1749120831489563\n",
      "Batch 2405,  loss: 0.1684492215514183\n",
      "Batch 2410,  loss: 0.17694087252020835\n",
      "Batch 2415,  loss: 0.13621865063905716\n",
      "Batch 2420,  loss: 0.13412321209907532\n",
      "Batch 2425,  loss: 0.14714794754981994\n",
      "Batch 2430,  loss: 0.20208605825901033\n",
      "Batch 2435,  loss: 0.18033721745014192\n",
      "Batch 2440,  loss: 0.1467481881380081\n",
      "Batch 2445,  loss: 0.13534369319677353\n",
      "Batch 2450,  loss: 0.1400939404964447\n",
      "Batch 2455,  loss: 0.17999870032072068\n",
      "Batch 2460,  loss: 0.16891450583934783\n",
      "Batch 2465,  loss: 0.163486947119236\n",
      "Batch 2470,  loss: 0.16664408147335052\n",
      "Batch 2475,  loss: 0.1501176357269287\n",
      "Batch 2480,  loss: 0.1213428720831871\n",
      "Batch 2485,  loss: 0.1924183577299118\n",
      "Batch 2490,  loss: 0.1261323645710945\n",
      "Batch 2495,  loss: 0.19928059875965118\n",
      "Batch 2500,  loss: 0.14377849847078322\n",
      "Batch 2505,  loss: 0.14692297130823134\n",
      "Batch 2510,  loss: 0.12276896685361863\n",
      "Batch 2515,  loss: 0.16556052714586258\n",
      "Batch 2520,  loss: 0.21907054185867308\n",
      "Batch 2525,  loss: 0.20206813961267472\n",
      "Batch 2530,  loss: 0.22667333483695984\n",
      "Batch 2535,  loss: 0.19630667567253113\n",
      "Batch 2540,  loss: 0.1466209262609482\n",
      "Batch 2545,  loss: 0.13925955891609193\n",
      "Batch 2550,  loss: 0.14339260160923004\n",
      "Batch 2555,  loss: 0.20948535799980164\n",
      "Batch 2560,  loss: 0.15972992777824402\n",
      "Batch 2565,  loss: 0.15230079889297485\n",
      "Batch 2570,  loss: 0.14040470719337464\n",
      "Batch 2575,  loss: 0.19935648739337922\n",
      "Batch 2580,  loss: 0.15583351403474807\n",
      "Batch 2585,  loss: 0.1925811856985092\n",
      "Batch 2590,  loss: 0.1377192258834839\n",
      "Batch 2595,  loss: 0.16457440108060836\n",
      "Batch 2600,  loss: 0.1616562008857727\n",
      "Batch 2605,  loss: 0.12716629952192307\n",
      "Batch 2610,  loss: 0.14651323705911637\n",
      "Batch 2615,  loss: 0.1325178861618042\n",
      "Batch 2620,  loss: 0.17059958279132842\n",
      "Batch 2625,  loss: 0.1643179625272751\n",
      "Batch 2630,  loss: 0.12598440647125245\n",
      "Batch 2635,  loss: 0.12390350252389908\n",
      "Batch 2640,  loss: 0.1787493646144867\n",
      "Batch 2645,  loss: 0.1315715953707695\n",
      "Batch 2650,  loss: 0.1243227556347847\n",
      "Batch 2655,  loss: 0.14405031353235245\n",
      "Batch 2660,  loss: 0.16340642273426056\n",
      "Batch 2665,  loss: 0.14287301301956176\n",
      "Batch 2670,  loss: 0.14743662774562835\n",
      "Batch 2675,  loss: 0.17035144865512847\n",
      "Batch 2680,  loss: 0.18560796082019806\n",
      "Batch 2685,  loss: 0.1335037812590599\n",
      "Batch 2690,  loss: 0.16014640033245087\n",
      "Batch 2695,  loss: 0.17950973212718963\n",
      "Batch 2700,  loss: 0.11426924914121628\n",
      "Batch 2705,  loss: 0.17409704029560089\n",
      "Batch 2710,  loss: 0.13898348808288574\n",
      "Batch 2715,  loss: 0.1842359870672226\n",
      "Batch 2720,  loss: 0.1546215295791626\n",
      "Batch 2725,  loss: 0.14836121648550032\n",
      "Batch 2730,  loss: 0.12733902633190156\n",
      "Batch 2735,  loss: 0.1777347594499588\n",
      "Batch 2740,  loss: 0.1723383069038391\n",
      "Batch 2745,  loss: 0.1901114046573639\n",
      "Batch 2750,  loss: 0.18783056139945983\n",
      "Batch 2755,  loss: 0.14125037789344788\n",
      "Batch 2760,  loss: 0.2203987255692482\n",
      "Batch 2765,  loss: 0.16792830228805541\n",
      "Batch 2770,  loss: 0.17793608605861663\n",
      "LOSS train 0.17793608605861663. Validation loss: 0.16425558336432677 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 31:\n",
      "Batch 5,  loss: 0.15217136442661286\n",
      "Batch 10,  loss: 0.13549615442752838\n",
      "Batch 15,  loss: 0.17133352756500245\n",
      "Batch 20,  loss: 0.1265009045600891\n",
      "Batch 25,  loss: 0.13431835174560547\n",
      "Batch 30,  loss: 0.15445480793714522\n",
      "Batch 35,  loss: 0.17095531523227692\n",
      "Batch 40,  loss: 0.16648143231868745\n",
      "Batch 45,  loss: 0.1237632915377617\n",
      "Batch 50,  loss: 0.14890076816082\n",
      "Batch 55,  loss: 0.15679991394281387\n",
      "Batch 60,  loss: 0.17145774215459825\n",
      "Batch 65,  loss: 0.15449831634759903\n",
      "Batch 70,  loss: 0.15724482834339143\n",
      "Batch 75,  loss: 0.1389912948012352\n",
      "Batch 80,  loss: 0.1532178908586502\n",
      "Batch 85,  loss: 0.12926466017961502\n",
      "Batch 90,  loss: 0.16531299650669098\n",
      "Batch 95,  loss: 0.1372040867805481\n",
      "Batch 100,  loss: 0.18784499168395996\n",
      "Batch 105,  loss: 0.14183643460273743\n",
      "Batch 110,  loss: 0.17939167022705077\n",
      "Batch 115,  loss: 0.221245414018631\n",
      "Batch 120,  loss: 0.15559206455945968\n",
      "Batch 125,  loss: 0.17823230028152465\n",
      "Batch 130,  loss: 0.1624341905117035\n",
      "Batch 135,  loss: 0.1713858351111412\n",
      "Batch 140,  loss: 0.17643277049064637\n",
      "Batch 145,  loss: 0.14372735917568208\n",
      "Batch 150,  loss: 0.1347946345806122\n",
      "Batch 155,  loss: 0.16840893924236297\n",
      "Batch 160,  loss: 0.13475918769836426\n",
      "Batch 165,  loss: 0.11639514565467834\n",
      "Batch 170,  loss: 0.15286386907100677\n",
      "Batch 175,  loss: 0.1393713176250458\n",
      "Batch 180,  loss: 0.1940930515527725\n",
      "Batch 185,  loss: 0.13282333314418793\n",
      "Batch 190,  loss: 0.15317260026931762\n",
      "Batch 195,  loss: 0.17051466256380082\n",
      "Batch 200,  loss: 0.1807528853416443\n",
      "Batch 205,  loss: 0.1701263889670372\n",
      "Batch 210,  loss: 0.1838340863585472\n",
      "Batch 215,  loss: 0.1423515796661377\n",
      "Batch 220,  loss: 0.1671547159552574\n",
      "Batch 225,  loss: 0.17558395862579346\n",
      "Batch 230,  loss: 0.14017497450113298\n",
      "Batch 235,  loss: 0.13165607899427414\n",
      "Batch 240,  loss: 0.1600896954536438\n",
      "Batch 245,  loss: 0.13589797019958497\n",
      "Batch 250,  loss: 0.16378365457057953\n",
      "Batch 255,  loss: 0.17839838862419127\n",
      "Batch 260,  loss: 0.1465981975197792\n",
      "Batch 265,  loss: 0.13680134415626527\n",
      "Batch 270,  loss: 0.14912019968032836\n",
      "Batch 275,  loss: 0.16419199705123902\n",
      "Batch 280,  loss: 0.16897471845149994\n",
      "Batch 285,  loss: 0.1490173175930977\n",
      "Batch 290,  loss: 0.15754664391279222\n",
      "Batch 295,  loss: 0.15552107840776444\n",
      "Batch 300,  loss: 0.14757209420204162\n",
      "Batch 305,  loss: 0.15201057195663453\n",
      "Batch 310,  loss: 0.14468268305063248\n",
      "Batch 315,  loss: 0.1462111458182335\n",
      "Batch 320,  loss: 0.14773952811956406\n",
      "Batch 325,  loss: 0.1486852079629898\n",
      "Batch 330,  loss: 0.21379607617855073\n",
      "Batch 335,  loss: 0.17822551727294922\n",
      "Batch 340,  loss: 0.2103353977203369\n",
      "Batch 345,  loss: 0.19630365073680878\n",
      "Batch 350,  loss: 0.17833439409732818\n",
      "Batch 355,  loss: 0.13613245636224747\n",
      "Batch 360,  loss: 0.170671284198761\n",
      "Batch 365,  loss: 0.15989892780780793\n",
      "Batch 370,  loss: 0.1816866874694824\n",
      "Batch 375,  loss: 0.1659199208021164\n",
      "Batch 380,  loss: 0.14680755138397217\n",
      "Batch 385,  loss: 0.1448123872280121\n",
      "Batch 390,  loss: 0.14067782759666442\n",
      "Batch 395,  loss: 0.14194379150867462\n",
      "Batch 400,  loss: 0.20529358386993407\n",
      "Batch 405,  loss: 0.16114760041236878\n",
      "Batch 410,  loss: 0.1486310362815857\n",
      "Batch 415,  loss: 0.14612644761800767\n",
      "Batch 420,  loss: 0.16270231008529662\n",
      "Batch 425,  loss: 0.1550826258957386\n",
      "Batch 430,  loss: 0.14960230886936188\n",
      "Batch 435,  loss: 0.11177971363067626\n",
      "Batch 440,  loss: 0.16331429779529572\n",
      "Batch 445,  loss: 0.18540298640727998\n",
      "Batch 450,  loss: 0.15096698701381683\n",
      "Batch 455,  loss: 0.2118232160806656\n",
      "Batch 460,  loss: 0.15196133255958558\n",
      "Batch 465,  loss: 0.12292930781841278\n",
      "Batch 470,  loss: 0.1438444286584854\n",
      "Batch 475,  loss: 0.13216121792793273\n",
      "Batch 480,  loss: 0.2017287939786911\n",
      "Batch 485,  loss: 0.16838861703872682\n",
      "Batch 490,  loss: 0.17345492392778397\n",
      "Batch 495,  loss: 0.1374115064740181\n",
      "Batch 500,  loss: 0.16278799325227739\n",
      "Batch 505,  loss: 0.14361334443092347\n",
      "Batch 510,  loss: 0.14243759512901305\n",
      "Batch 515,  loss: 0.15601454973220824\n",
      "Batch 520,  loss: 0.15352586507797242\n",
      "Batch 525,  loss: 0.1134605273604393\n",
      "Batch 530,  loss: 0.1645943522453308\n",
      "Batch 535,  loss: 0.13704562187194824\n",
      "Batch 540,  loss: 0.12454864084720611\n",
      "Batch 545,  loss: 0.14935945570468903\n",
      "Batch 550,  loss: 0.16378979831933976\n",
      "Batch 555,  loss: 0.1586263060569763\n",
      "Batch 560,  loss: 0.1411491736769676\n",
      "Batch 565,  loss: 0.19054513275623322\n",
      "Batch 570,  loss: 0.17977529615163804\n",
      "Batch 575,  loss: 0.13038162887096405\n",
      "Batch 580,  loss: 0.15070197880268096\n",
      "Batch 585,  loss: 0.1362785965204239\n",
      "Batch 590,  loss: 0.1458032876253128\n",
      "Batch 595,  loss: 0.13702605962753295\n",
      "Batch 600,  loss: 0.13945680260658264\n",
      "Batch 605,  loss: 0.2003018379211426\n",
      "Batch 610,  loss: 0.13984068483114243\n",
      "Batch 615,  loss: 0.16293781399726867\n",
      "Batch 620,  loss: 0.16019999086856843\n",
      "Batch 625,  loss: 0.11965885609388352\n",
      "Batch 630,  loss: 0.17732527256011962\n",
      "Batch 635,  loss: 0.18056579828262329\n",
      "Batch 640,  loss: 0.17486535310745238\n",
      "Batch 645,  loss: 0.13531342297792434\n",
      "Batch 650,  loss: 0.18198092728853227\n",
      "Batch 655,  loss: 0.1388562425971031\n",
      "Batch 660,  loss: 0.170546954870224\n",
      "Batch 665,  loss: 0.15510796308517455\n",
      "Batch 670,  loss: 0.13182344138622284\n",
      "Batch 675,  loss: 0.17559508681297303\n",
      "Batch 680,  loss: 0.13491034209728242\n",
      "Batch 685,  loss: 0.16267695128917695\n",
      "Batch 690,  loss: 0.16359474062919616\n",
      "Batch 695,  loss: 0.14726395905017853\n",
      "Batch 700,  loss: 0.17009952962398528\n",
      "Batch 705,  loss: 0.1491573601961136\n",
      "Batch 710,  loss: 0.1536245286464691\n",
      "Batch 715,  loss: 0.1705200642347336\n",
      "Batch 720,  loss: 0.16890953481197357\n",
      "Batch 725,  loss: 0.17262579649686813\n",
      "Batch 730,  loss: 0.16509494185447693\n",
      "Batch 735,  loss: 0.1517190933227539\n",
      "Batch 740,  loss: 0.15597665756940843\n",
      "Batch 745,  loss: 0.17800825387239455\n",
      "Batch 750,  loss: 0.12974481880664826\n",
      "Batch 755,  loss: 0.17166662216186523\n",
      "Batch 760,  loss: 0.200228750705719\n",
      "Batch 765,  loss: 0.16073341965675353\n",
      "Batch 770,  loss: 0.15310992151498795\n",
      "Batch 775,  loss: 0.1622881680727005\n",
      "Batch 780,  loss: 0.14497726857662202\n",
      "Batch 785,  loss: 0.18277935385704042\n",
      "Batch 790,  loss: 0.1494917869567871\n",
      "Batch 795,  loss: 0.12795665562152864\n",
      "Batch 800,  loss: 0.17105942368507385\n",
      "Batch 805,  loss: 0.1456079065799713\n",
      "Batch 810,  loss: 0.17550439536571502\n",
      "Batch 815,  loss: 0.14989151805639267\n",
      "Batch 820,  loss: 0.16034068763256074\n",
      "Batch 825,  loss: 0.17139825820922852\n",
      "Batch 830,  loss: 0.19576969742774963\n",
      "Batch 835,  loss: 0.13924609124660492\n",
      "Batch 840,  loss: 0.17257020175457\n",
      "Batch 845,  loss: 0.12831512540578843\n",
      "Batch 850,  loss: 0.18671540915966034\n",
      "Batch 855,  loss: 0.13256202191114425\n",
      "Batch 860,  loss: 0.13480335623025894\n",
      "Batch 865,  loss: 0.16998881697654725\n",
      "Batch 870,  loss: 0.15762499570846558\n",
      "Batch 875,  loss: 0.17243084013462068\n",
      "Batch 880,  loss: 0.186296546459198\n",
      "Batch 885,  loss: 0.1261650502681732\n",
      "Batch 890,  loss: 0.1733245611190796\n",
      "Batch 895,  loss: 0.15219420194625854\n",
      "Batch 900,  loss: 0.15982916355133056\n",
      "Batch 905,  loss: 0.1746559038758278\n",
      "Batch 910,  loss: 0.14914360642433167\n",
      "Batch 915,  loss: 0.21357323229312897\n",
      "Batch 920,  loss: 0.1231076881289482\n",
      "Batch 925,  loss: 0.1561133846640587\n",
      "Batch 930,  loss: 0.19272913336753844\n",
      "Batch 935,  loss: 0.14159399271011353\n",
      "Batch 940,  loss: 0.1414073258638382\n",
      "Batch 945,  loss: 0.17013502418994902\n",
      "Batch 950,  loss: 0.2035128206014633\n",
      "Batch 955,  loss: 0.15662393271923064\n",
      "Batch 960,  loss: 0.21205472201108932\n",
      "Batch 965,  loss: 0.18560535907745362\n",
      "Batch 970,  loss: 0.15544527918100357\n",
      "Batch 975,  loss: 0.1277587041258812\n",
      "Batch 980,  loss: 0.16586675941944123\n",
      "Batch 985,  loss: 0.16221096217632294\n",
      "Batch 990,  loss: 0.1296376883983612\n",
      "Batch 995,  loss: 0.15380984246730806\n",
      "Batch 1000,  loss: 0.19900785833597184\n",
      "Batch 1005,  loss: 0.16108160167932511\n",
      "Batch 1010,  loss: 0.21803568601608275\n",
      "Batch 1015,  loss: 0.12691758275032045\n",
      "Batch 1020,  loss: 0.16058315485715866\n",
      "Batch 1025,  loss: 0.19248588085174562\n",
      "Batch 1030,  loss: 0.1425266295671463\n",
      "Batch 1035,  loss: 0.18183307349681854\n",
      "Batch 1040,  loss: 0.17103440761566163\n",
      "Batch 1045,  loss: 0.12825565040111542\n",
      "Batch 1050,  loss: 0.16853511929512024\n",
      "Batch 1055,  loss: 0.15660125613212586\n",
      "Batch 1060,  loss: 0.16694921255111694\n",
      "Batch 1065,  loss: 0.19282338619232178\n",
      "Batch 1070,  loss: 0.1645350784063339\n",
      "Batch 1075,  loss: 0.15665338188409805\n",
      "Batch 1080,  loss: 0.13687265813350677\n",
      "Batch 1085,  loss: 0.14967701137065886\n",
      "Batch 1090,  loss: 0.1454378306865692\n",
      "Batch 1095,  loss: 0.12787668108940126\n",
      "Batch 1100,  loss: 0.17605780065059662\n",
      "Batch 1105,  loss: 0.16069200932979583\n",
      "Batch 1110,  loss: 0.15397521257400512\n",
      "Batch 1115,  loss: 0.14864977300167084\n",
      "Batch 1120,  loss: 0.163296240568161\n",
      "Batch 1125,  loss: 0.1749290943145752\n",
      "Batch 1130,  loss: 0.1483871817588806\n",
      "Batch 1135,  loss: 0.158935546875\n",
      "Batch 1140,  loss: 0.12108717858791351\n",
      "Batch 1145,  loss: 0.15470030903816223\n",
      "Batch 1150,  loss: 0.16116389334201814\n",
      "Batch 1155,  loss: 0.17257716357707978\n",
      "Batch 1160,  loss: 0.15889507830142974\n",
      "Batch 1165,  loss: 0.13827140331268312\n",
      "Batch 1170,  loss: 0.1445039540529251\n",
      "Batch 1175,  loss: 0.1876114785671234\n",
      "Batch 1180,  loss: 0.18773765861988068\n",
      "Batch 1185,  loss: 0.17942878603935242\n",
      "Batch 1190,  loss: 0.15646731853485107\n",
      "Batch 1195,  loss: 0.17581979930400848\n",
      "Batch 1200,  loss: 0.12668645530939102\n",
      "Batch 1205,  loss: 0.15939068049192429\n",
      "Batch 1210,  loss: 0.16543545573949814\n",
      "Batch 1215,  loss: 0.14230065941810607\n",
      "Batch 1220,  loss: 0.19108811020851135\n",
      "Batch 1225,  loss: 0.1500651180744171\n",
      "Batch 1230,  loss: 0.14634762853384017\n",
      "Batch 1235,  loss: 0.1637245938181877\n",
      "Batch 1240,  loss: 0.20325293838977815\n",
      "Batch 1245,  loss: 0.1615525245666504\n",
      "Batch 1250,  loss: 0.1634770452976227\n",
      "Batch 1255,  loss: 0.1412731572985649\n",
      "Batch 1260,  loss: 0.15021408796310426\n",
      "Batch 1265,  loss: 0.1626162588596344\n",
      "Batch 1270,  loss: 0.1819740742444992\n",
      "Batch 1275,  loss: 0.16103317737579345\n",
      "Batch 1280,  loss: 0.15323572605848312\n",
      "Batch 1285,  loss: 0.18470973819494246\n",
      "Batch 1290,  loss: 0.1409137487411499\n",
      "Batch 1295,  loss: 0.14201165735721588\n",
      "Batch 1300,  loss: 0.17815155833959578\n",
      "Batch 1305,  loss: 0.12366764098405839\n",
      "Batch 1310,  loss: 0.1849222421646118\n",
      "Batch 1315,  loss: 0.17645082771778106\n",
      "Batch 1320,  loss: 0.1498152270913124\n",
      "Batch 1325,  loss: 0.12534137368202208\n",
      "Batch 1330,  loss: 0.1399604335427284\n",
      "Batch 1335,  loss: 0.15951079428195952\n",
      "Batch 1340,  loss: 0.16328159272670745\n",
      "Batch 1345,  loss: 0.13771275132894517\n",
      "Batch 1350,  loss: 0.18373315334320067\n",
      "Batch 1355,  loss: 0.14494423866271972\n",
      "Batch 1360,  loss: 0.1187944084405899\n",
      "Batch 1365,  loss: 0.19286311864852906\n",
      "Batch 1370,  loss: 0.13891557455062867\n",
      "Batch 1375,  loss: 0.1615867108106613\n",
      "Batch 1380,  loss: 0.24367452263832093\n",
      "Batch 1385,  loss: 0.16934907734394072\n",
      "Batch 1390,  loss: 0.21616885662078858\n",
      "Batch 1395,  loss: 0.156169593334198\n",
      "Batch 1400,  loss: 0.17843809425830842\n",
      "Batch 1405,  loss: 0.15271935164928435\n",
      "Batch 1410,  loss: 0.13578791916370392\n",
      "Batch 1415,  loss: 0.15441774129867553\n",
      "Batch 1420,  loss: 0.1573783576488495\n",
      "Batch 1425,  loss: 0.18564721941947937\n",
      "Batch 1430,  loss: 0.13375783264636992\n",
      "Batch 1435,  loss: 0.16620551347732543\n",
      "Batch 1440,  loss: 0.20267821550369264\n",
      "Batch 1445,  loss: 0.1683247521519661\n",
      "Batch 1450,  loss: 0.15944713950157166\n",
      "Batch 1455,  loss: 0.15668385177850724\n",
      "Batch 1460,  loss: 0.1305585488677025\n",
      "Batch 1465,  loss: 0.1943886995315552\n",
      "Batch 1470,  loss: 0.14593913555145263\n",
      "Batch 1475,  loss: 0.1520555719733238\n",
      "Batch 1480,  loss: 0.20973504781723024\n",
      "Batch 1485,  loss: 0.1582830935716629\n",
      "Batch 1490,  loss: 0.1737167775630951\n",
      "Batch 1495,  loss: 0.1278446838259697\n",
      "Batch 1500,  loss: 0.14084914624691008\n",
      "Batch 1505,  loss: 0.16732577085494996\n",
      "Batch 1510,  loss: 0.1600210726261139\n",
      "Batch 1515,  loss: 0.16627358943223952\n",
      "Batch 1520,  loss: 0.18440339118242263\n",
      "Batch 1525,  loss: 0.1888058990240097\n",
      "Batch 1530,  loss: 0.11210260093212128\n",
      "Batch 1535,  loss: 0.16298179924488068\n",
      "Batch 1540,  loss: 0.16475145518779755\n",
      "Batch 1545,  loss: 0.1503347396850586\n",
      "Batch 1550,  loss: 0.14582540988922119\n",
      "Batch 1555,  loss: 0.14736328423023223\n",
      "Batch 1560,  loss: 0.23725931644439696\n",
      "Batch 1565,  loss: 0.12135531902313232\n",
      "Batch 1570,  loss: 0.15378066897392273\n",
      "Batch 1575,  loss: 0.1552118867635727\n",
      "Batch 1580,  loss: 0.14125095307826996\n",
      "Batch 1585,  loss: 0.15159550309181213\n",
      "Batch 1590,  loss: 0.1255418464541435\n",
      "Batch 1595,  loss: 0.129233019053936\n",
      "Batch 1600,  loss: 0.16116016656160354\n",
      "Batch 1605,  loss: 0.1366569846868515\n",
      "Batch 1610,  loss: 0.16648386120796205\n",
      "Batch 1615,  loss: 0.14365298748016359\n",
      "Batch 1620,  loss: 0.15181494653224945\n",
      "Batch 1625,  loss: 0.1613635689020157\n",
      "Batch 1630,  loss: 0.15991163849830628\n",
      "Batch 1635,  loss: 0.1787608116865158\n",
      "Batch 1640,  loss: 0.14386229813098908\n",
      "Batch 1645,  loss: 0.14414332807064056\n",
      "Batch 1650,  loss: 0.21230317056179046\n",
      "Batch 1655,  loss: 0.17071697413921355\n",
      "Batch 1660,  loss: 0.13262514919042587\n",
      "Batch 1665,  loss: 0.15964121520519256\n",
      "Batch 1670,  loss: 0.15091811567544938\n",
      "Batch 1675,  loss: 0.16131094247102737\n",
      "Batch 1680,  loss: 0.1272544488310814\n",
      "Batch 1685,  loss: 0.1645475834608078\n",
      "Batch 1690,  loss: 0.13188940435647964\n",
      "Batch 1695,  loss: 0.18002835512161255\n",
      "Batch 1700,  loss: 0.207953941822052\n",
      "Batch 1705,  loss: 0.18154906779527663\n",
      "Batch 1710,  loss: 0.1666414976119995\n",
      "Batch 1715,  loss: 0.16463117748498918\n",
      "Batch 1720,  loss: 0.14085253328084946\n",
      "Batch 1725,  loss: 0.1503949224948883\n",
      "Batch 1730,  loss: 0.1519961968064308\n",
      "Batch 1735,  loss: 0.18077837973833083\n",
      "Batch 1740,  loss: 0.12956908345222473\n",
      "Batch 1745,  loss: 0.1544537976384163\n",
      "Batch 1750,  loss: 0.13432311415672302\n",
      "Batch 1755,  loss: 0.14086111187934874\n",
      "Batch 1760,  loss: 0.13688241094350814\n",
      "Batch 1765,  loss: 0.16835289895534516\n",
      "Batch 1770,  loss: 0.17091505527496337\n",
      "Batch 1775,  loss: 0.15640821903944016\n",
      "Batch 1780,  loss: 0.18200357258319855\n",
      "Batch 1785,  loss: 0.17207533717155457\n",
      "Batch 1790,  loss: 0.1427765056490898\n",
      "Batch 1795,  loss: 0.14261992871761323\n",
      "Batch 1800,  loss: 0.14730473905801772\n",
      "Batch 1805,  loss: 0.15047478973865508\n",
      "Batch 1810,  loss: 0.17491360604763032\n",
      "Batch 1815,  loss: 0.16590115427970886\n",
      "Batch 1820,  loss: 0.20643761157989501\n",
      "Batch 1825,  loss: 0.1995759129524231\n",
      "Batch 1830,  loss: 0.11945693045854569\n",
      "Batch 1835,  loss: 0.1495182052254677\n",
      "Batch 1840,  loss: 0.16876950860023499\n",
      "Batch 1845,  loss: 0.1481802687048912\n",
      "Batch 1850,  loss: 0.1287144511938095\n",
      "Batch 1855,  loss: 0.15269033759832382\n",
      "Batch 1860,  loss: 0.1639591336250305\n",
      "Batch 1865,  loss: 0.14854701161384581\n",
      "Batch 1870,  loss: 0.14765794724225997\n",
      "Batch 1875,  loss: 0.12930188924074174\n",
      "Batch 1880,  loss: 0.13679347932338715\n",
      "Batch 1885,  loss: 0.16239978671073912\n",
      "Batch 1890,  loss: 0.15718734562397002\n",
      "Batch 1895,  loss: 0.1540179282426834\n",
      "Batch 1900,  loss: 0.20291308760643006\n",
      "Batch 1905,  loss: 0.15293774306774138\n",
      "Batch 1910,  loss: 0.14839497208595276\n",
      "Batch 1915,  loss: 0.144008669257164\n",
      "Batch 1920,  loss: 0.17196457982063293\n",
      "Batch 1925,  loss: 0.11816743463277816\n",
      "Batch 1930,  loss: 0.16282414197921752\n",
      "Batch 1935,  loss: 0.14474692940711975\n",
      "Batch 1940,  loss: 0.16918023228645324\n",
      "Batch 1945,  loss: 0.20869373083114623\n",
      "Batch 1950,  loss: 0.16966267824172973\n",
      "Batch 1955,  loss: 0.1242165669798851\n",
      "Batch 1960,  loss: 0.1371513620018959\n",
      "Batch 1965,  loss: 0.13398404121398927\n",
      "Batch 1970,  loss: 0.1469881296157837\n",
      "Batch 1975,  loss: 0.16904891431331634\n",
      "Batch 1980,  loss: 0.20213665068149567\n",
      "Batch 1985,  loss: 0.13766733855009078\n",
      "Batch 1990,  loss: 0.14052590876817703\n",
      "Batch 1995,  loss: 0.17249175906181335\n",
      "Batch 2000,  loss: 0.16623335778713227\n",
      "Batch 2005,  loss: 0.15863197892904282\n",
      "Batch 2010,  loss: 0.16724832653999328\n",
      "Batch 2015,  loss: 0.16345013678073883\n",
      "Batch 2020,  loss: 0.17055319249629974\n",
      "Batch 2025,  loss: 0.13224166184663771\n",
      "Batch 2030,  loss: 0.15590218007564544\n",
      "Batch 2035,  loss: 0.17418400645256044\n",
      "Batch 2040,  loss: 0.14083444625139235\n",
      "Batch 2045,  loss: 0.15745246410369873\n",
      "Batch 2050,  loss: 0.1273783713579178\n",
      "Batch 2055,  loss: 0.14450489580631257\n",
      "Batch 2060,  loss: 0.13197087049484252\n",
      "Batch 2065,  loss: 0.16366076171398164\n",
      "Batch 2070,  loss: 0.1476732462644577\n",
      "Batch 2075,  loss: 0.1544487416744232\n",
      "Batch 2080,  loss: 0.15281789600849152\n",
      "Batch 2085,  loss: 0.1938108518719673\n",
      "Batch 2090,  loss: 0.17552037239074708\n",
      "Batch 2095,  loss: 0.13260192126035691\n",
      "Batch 2100,  loss: 0.1946007341146469\n",
      "Batch 2105,  loss: 0.17637188583612443\n",
      "Batch 2110,  loss: 0.1331270545721054\n",
      "Batch 2115,  loss: 0.1637108713388443\n",
      "Batch 2120,  loss: 0.15287259519100188\n",
      "Batch 2125,  loss: 0.134850150346756\n",
      "Batch 2130,  loss: 0.16026025861501694\n",
      "Batch 2135,  loss: 0.14250111877918242\n",
      "Batch 2140,  loss: 0.14192246794700622\n",
      "Batch 2145,  loss: 0.15794009268283843\n",
      "Batch 2150,  loss: 0.16184853464365007\n",
      "Batch 2155,  loss: 0.14136100709438323\n",
      "Batch 2160,  loss: 0.21886146068572998\n",
      "Batch 2165,  loss: 0.15995421707630159\n",
      "Batch 2170,  loss: 0.13752749115228652\n",
      "Batch 2175,  loss: 0.18097205460071564\n",
      "Batch 2180,  loss: 0.16401047110557557\n",
      "Batch 2185,  loss: 0.12740080505609513\n",
      "Batch 2190,  loss: 0.1672670215368271\n",
      "Batch 2195,  loss: 0.17019364535808562\n",
      "Batch 2200,  loss: 0.1693628251552582\n",
      "Batch 2205,  loss: 0.12663644254207612\n",
      "Batch 2210,  loss: 0.167299222946167\n",
      "Batch 2215,  loss: 0.1488172620534897\n",
      "Batch 2220,  loss: 0.17442167848348616\n",
      "Batch 2225,  loss: 0.2006056547164917\n",
      "Batch 2230,  loss: 0.15630462169647216\n",
      "Batch 2235,  loss: 0.16982802748680115\n",
      "Batch 2240,  loss: 0.1647528037428856\n",
      "Batch 2245,  loss: 0.1525432735681534\n",
      "Batch 2250,  loss: 0.16503283828496934\n",
      "Batch 2255,  loss: 0.1238016277551651\n",
      "Batch 2260,  loss: 0.14755161553621293\n",
      "Batch 2265,  loss: 0.17184026837348937\n",
      "Batch 2270,  loss: 0.1332642987370491\n",
      "Batch 2275,  loss: 0.13441754281520843\n",
      "Batch 2280,  loss: 0.11934310048818589\n",
      "Batch 2285,  loss: 0.1428522765636444\n",
      "Batch 2290,  loss: 0.13909863084554672\n",
      "Batch 2295,  loss: 0.150925412774086\n",
      "Batch 2300,  loss: 0.15885339975357055\n",
      "Batch 2305,  loss: 0.15163513422012329\n",
      "Batch 2310,  loss: 0.1510170042514801\n",
      "Batch 2315,  loss: 0.15568189173936844\n",
      "Batch 2320,  loss: 0.16204792410135269\n",
      "Batch 2325,  loss: 0.16184547245502473\n",
      "Batch 2330,  loss: 0.18377414494752883\n",
      "Batch 2335,  loss: 0.15008807480335234\n",
      "Batch 2340,  loss: 0.17144223153591157\n",
      "Batch 2345,  loss: 0.16344866901636124\n",
      "Batch 2350,  loss: 0.16310898959636688\n",
      "Batch 2355,  loss: 0.1900110974907875\n",
      "Batch 2360,  loss: 0.16633021533489228\n",
      "Batch 2365,  loss: 0.1669619709253311\n",
      "Batch 2370,  loss: 0.13524869382381438\n",
      "Batch 2375,  loss: 0.1763297736644745\n",
      "Batch 2380,  loss: 0.1713322341442108\n",
      "Batch 2385,  loss: 0.12367503494024276\n",
      "Batch 2390,  loss: 0.14402257204055785\n",
      "Batch 2395,  loss: 0.14107316136360168\n",
      "Batch 2400,  loss: 0.1399375766515732\n",
      "Batch 2405,  loss: 0.2040384143590927\n",
      "Batch 2410,  loss: 0.1769708901643753\n",
      "Batch 2415,  loss: 0.16535696387290955\n",
      "Batch 2420,  loss: 0.16557885110378265\n",
      "Batch 2425,  loss: 0.1744075745344162\n",
      "Batch 2430,  loss: 0.16060027927160264\n",
      "Batch 2435,  loss: 0.1256921961903572\n",
      "Batch 2440,  loss: 0.1677237033843994\n",
      "Batch 2445,  loss: 0.13569240868091584\n",
      "Batch 2450,  loss: 0.14415949136018752\n",
      "Batch 2455,  loss: 0.14347268939018248\n",
      "Batch 2460,  loss: 0.19475535154342652\n",
      "Batch 2465,  loss: 0.16162143349647523\n",
      "Batch 2470,  loss: 0.1473125085234642\n",
      "Batch 2475,  loss: 0.1377154618501663\n",
      "Batch 2480,  loss: 0.15825575292110444\n",
      "Batch 2485,  loss: 0.144397833943367\n",
      "Batch 2490,  loss: 0.14344082176685333\n",
      "Batch 2495,  loss: 0.16860583275556565\n",
      "Batch 2500,  loss: 0.14973740875720978\n",
      "Batch 2505,  loss: 0.17846247404813767\n",
      "Batch 2510,  loss: 0.12394307553768158\n",
      "Batch 2515,  loss: 0.16275232434272766\n",
      "Batch 2520,  loss: 0.13352107405662536\n",
      "Batch 2525,  loss: 0.17890757024288179\n",
      "Batch 2530,  loss: 0.16461913883686066\n",
      "Batch 2535,  loss: 0.15525977313518524\n",
      "Batch 2540,  loss: 0.14842594116926194\n",
      "Batch 2545,  loss: 0.15729233026504516\n",
      "Batch 2550,  loss: 0.14843655228614808\n",
      "Batch 2555,  loss: 0.18740736544132233\n",
      "Batch 2560,  loss: 0.1997707337141037\n",
      "Batch 2565,  loss: 0.1462807059288025\n",
      "Batch 2570,  loss: 0.1395783618092537\n",
      "Batch 2575,  loss: 0.1387186512351036\n",
      "Batch 2580,  loss: 0.20534100532531738\n",
      "Batch 2585,  loss: 0.1317516714334488\n",
      "Batch 2590,  loss: 0.1400562822818756\n",
      "Batch 2595,  loss: 0.16276213824748992\n",
      "Batch 2600,  loss: 0.19458643198013306\n",
      "Batch 2605,  loss: 0.14457056820392608\n",
      "Batch 2610,  loss: 0.15565525740385056\n",
      "Batch 2615,  loss: 0.18785768151283264\n",
      "Batch 2620,  loss: 0.17253853380680084\n",
      "Batch 2625,  loss: 0.19645390510559083\n",
      "Batch 2630,  loss: 0.1337010830640793\n",
      "Batch 2635,  loss: 0.13278088122606277\n",
      "Batch 2640,  loss: 0.19171479046344758\n",
      "Batch 2645,  loss: 0.14190253615379333\n",
      "Batch 2650,  loss: 0.11723219752311706\n",
      "Batch 2655,  loss: 0.16011750996112822\n",
      "Batch 2660,  loss: 0.16422169506549836\n",
      "Batch 2665,  loss: 0.15845052599906922\n",
      "Batch 2670,  loss: 0.14407847970724105\n",
      "Batch 2675,  loss: 0.13460015654563903\n",
      "Batch 2680,  loss: 0.16611975133419038\n",
      "Batch 2685,  loss: 0.1618558645248413\n",
      "Batch 2690,  loss: 0.12404368817806244\n",
      "Batch 2695,  loss: 0.12404261827468872\n",
      "Batch 2700,  loss: 0.14832737445831298\n",
      "Batch 2705,  loss: 0.14935327172279358\n",
      "Batch 2710,  loss: 0.13476716727018356\n",
      "Batch 2715,  loss: 0.15109084993600846\n",
      "Batch 2720,  loss: 0.14510286450386048\n",
      "Batch 2725,  loss: 0.16005709767341614\n",
      "Batch 2730,  loss: 0.20531193017959595\n",
      "Batch 2735,  loss: 0.13137828409671784\n",
      "Batch 2740,  loss: 0.15238780677318572\n",
      "Batch 2745,  loss: 0.15368342995643616\n",
      "Batch 2750,  loss: 0.16335339397192\n",
      "Batch 2755,  loss: 0.15520298033952712\n",
      "Batch 2760,  loss: 0.16164783090353013\n",
      "Batch 2765,  loss: 0.16010941863059996\n",
      "Batch 2770,  loss: 0.1524506017565727\n",
      "LOSS train 0.1524506017565727. Validation loss: 0.15732358726845294 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 32:\n",
      "Batch 5,  loss: 0.13671343326568602\n",
      "Batch 10,  loss: 0.17211800962686538\n",
      "Batch 15,  loss: 0.16401324719190596\n",
      "Batch 20,  loss: 0.14045598804950715\n",
      "Batch 25,  loss: 0.16911452114582062\n",
      "Batch 30,  loss: 0.15323655307292938\n",
      "Batch 35,  loss: 0.15863949060440063\n",
      "Batch 40,  loss: 0.11429512724280358\n",
      "Batch 45,  loss: 0.15198957920074463\n",
      "Batch 50,  loss: 0.17972221970558167\n",
      "Batch 55,  loss: 0.16143718212842942\n",
      "Batch 60,  loss: 0.15086683332920076\n",
      "Batch 65,  loss: 0.1427184224128723\n",
      "Batch 70,  loss: 0.14105622470378876\n",
      "Batch 75,  loss: 0.1777801275253296\n",
      "Batch 80,  loss: 0.16950115263462068\n",
      "Batch 85,  loss: 0.15807596147060393\n",
      "Batch 90,  loss: 0.18063195049762726\n",
      "Batch 95,  loss: 0.20489182323217392\n",
      "Batch 100,  loss: 0.16061262041330338\n",
      "Batch 105,  loss: 0.13085073083639145\n",
      "Batch 110,  loss: 0.14860134869813918\n",
      "Batch 115,  loss: 0.16554442197084426\n",
      "Batch 120,  loss: 0.13753962218761445\n",
      "Batch 125,  loss: 0.2001994252204895\n",
      "Batch 130,  loss: 0.14691390097141266\n",
      "Batch 135,  loss: 0.13499063700437547\n",
      "Batch 140,  loss: 0.13622925654053689\n",
      "Batch 145,  loss: 0.16466308236122132\n",
      "Batch 150,  loss: 0.18786782622337342\n",
      "Batch 155,  loss: 0.17346178293228148\n",
      "Batch 160,  loss: 0.16104828268289567\n",
      "Batch 165,  loss: 0.15099718421697617\n",
      "Batch 170,  loss: 0.22039511948823928\n",
      "Batch 175,  loss: 0.16262370645999907\n",
      "Batch 180,  loss: 0.14792520552873611\n",
      "Batch 185,  loss: 0.16883352696895598\n",
      "Batch 190,  loss: 0.1744581714272499\n",
      "Batch 195,  loss: 0.18439240753650665\n",
      "Batch 200,  loss: 0.19166778773069382\n",
      "Batch 205,  loss: 0.1310025930404663\n",
      "Batch 210,  loss: 0.1596039891242981\n",
      "Batch 215,  loss: 0.16668291687965392\n",
      "Batch 220,  loss: 0.13148538917303085\n",
      "Batch 225,  loss: 0.17520523369312285\n",
      "Batch 230,  loss: 0.16176681220531464\n",
      "Batch 235,  loss: 0.15887180715799332\n",
      "Batch 240,  loss: 0.144807893037796\n",
      "Batch 245,  loss: 0.24183000028133392\n",
      "Batch 250,  loss: 0.150381039083004\n",
      "Batch 255,  loss: 0.1655344009399414\n",
      "Batch 260,  loss: 0.13122286647558212\n",
      "Batch 265,  loss: 0.1780473217368126\n",
      "Batch 270,  loss: 0.15684028714895248\n",
      "Batch 275,  loss: 0.1616432249546051\n",
      "Batch 280,  loss: 0.15281932950019836\n",
      "Batch 285,  loss: 0.15655021220445633\n",
      "Batch 290,  loss: 0.2339484542608261\n",
      "Batch 295,  loss: 0.15864317715168\n",
      "Batch 300,  loss: 0.15362241864204407\n",
      "Batch 305,  loss: 0.16336701512336732\n",
      "Batch 310,  loss: 0.15228240936994553\n",
      "Batch 315,  loss: 0.1621099144220352\n",
      "Batch 320,  loss: 0.2176563024520874\n",
      "Batch 325,  loss: 0.15382918417453767\n",
      "Batch 330,  loss: 0.18844059407711028\n",
      "Batch 335,  loss: 0.13017305582761765\n",
      "Batch 340,  loss: 0.18710907995700837\n",
      "Batch 345,  loss: 0.17946899235248565\n",
      "Batch 350,  loss: 0.14471566677093506\n",
      "Batch 355,  loss: 0.1382024794816971\n",
      "Batch 360,  loss: 0.14103370159864426\n",
      "Batch 365,  loss: 0.20430927872657775\n",
      "Batch 370,  loss: 0.17421573400497437\n",
      "Batch 375,  loss: 0.1327112451195717\n",
      "Batch 380,  loss: 0.1698659300804138\n",
      "Batch 385,  loss: 0.17691029608249664\n",
      "Batch 390,  loss: 0.17719578444957734\n",
      "Batch 395,  loss: 0.20239574909210206\n",
      "Batch 400,  loss: 0.1510026216506958\n",
      "Batch 405,  loss: 0.12490206211805344\n",
      "Batch 410,  loss: 0.12724031060934066\n",
      "Batch 415,  loss: 0.15972538143396378\n",
      "Batch 420,  loss: 0.14054058492183685\n",
      "Batch 425,  loss: 0.16335289180278778\n",
      "Batch 430,  loss: 0.21832121312618255\n",
      "Batch 435,  loss: 0.1328066498041153\n",
      "Batch 440,  loss: 0.1571432262659073\n",
      "Batch 445,  loss: 0.14812738597393035\n",
      "Batch 450,  loss: 0.16768351793289185\n",
      "Batch 455,  loss: 0.1774035483598709\n",
      "Batch 460,  loss: 0.1458624392747879\n",
      "Batch 465,  loss: 0.15351657569408417\n",
      "Batch 470,  loss: 0.16209931522607804\n",
      "Batch 475,  loss: 0.12209041565656661\n",
      "Batch 480,  loss: 0.13014987707138062\n",
      "Batch 485,  loss: 0.14756967425346373\n",
      "Batch 490,  loss: 0.15989844501018524\n",
      "Batch 495,  loss: 0.14564311504364014\n",
      "Batch 500,  loss: 0.15921831130981445\n",
      "Batch 505,  loss: 0.17351358532905578\n",
      "Batch 510,  loss: 0.1465463638305664\n",
      "Batch 515,  loss: 0.15731795728206635\n",
      "Batch 520,  loss: 0.17430658936500548\n",
      "Batch 525,  loss: 0.13840328454971312\n",
      "Batch 530,  loss: 0.16092184484004973\n",
      "Batch 535,  loss: 0.15035119354724885\n",
      "Batch 540,  loss: 0.20063626766204834\n",
      "Batch 545,  loss: 0.1390121430158615\n",
      "Batch 550,  loss: 0.1632750928401947\n",
      "Batch 555,  loss: 0.1246057003736496\n",
      "Batch 560,  loss: 0.16592682301998138\n",
      "Batch 565,  loss: 0.13468196392059326\n",
      "Batch 570,  loss: 0.1627133622765541\n",
      "Batch 575,  loss: 0.14203065931797026\n",
      "Batch 580,  loss: 0.11752960830926895\n",
      "Batch 585,  loss: 0.12784941792488097\n",
      "Batch 590,  loss: 0.17906377613544464\n",
      "Batch 595,  loss: 0.12865975350141526\n",
      "Batch 600,  loss: 0.17521532773971557\n",
      "Batch 605,  loss: 0.13681446611881257\n",
      "Batch 610,  loss: 0.1813472956418991\n",
      "Batch 615,  loss: 0.12421261519193649\n",
      "Batch 620,  loss: 0.1830216094851494\n",
      "Batch 625,  loss: 0.1260984256863594\n",
      "Batch 630,  loss: 0.1440925896167755\n",
      "Batch 635,  loss: 0.18298751413822173\n",
      "Batch 640,  loss: 0.16481806039810182\n",
      "Batch 645,  loss: 0.18922251164913179\n",
      "Batch 650,  loss: 0.12700364738702774\n",
      "Batch 655,  loss: 0.129710353910923\n",
      "Batch 660,  loss: 0.15313746631145478\n",
      "Batch 665,  loss: 0.11185707300901412\n",
      "Batch 670,  loss: 0.16544604003429414\n",
      "Batch 675,  loss: 0.15609628856182098\n",
      "Batch 680,  loss: 0.15023381412029266\n",
      "Batch 685,  loss: 0.13769232332706452\n",
      "Batch 690,  loss: 0.15355896055698395\n",
      "Batch 695,  loss: 0.13455277383327485\n",
      "Batch 700,  loss: 0.18545109629631043\n",
      "Batch 705,  loss: 0.12474680095911025\n",
      "Batch 710,  loss: 0.17225426733493804\n",
      "Batch 715,  loss: 0.20596507340669631\n",
      "Batch 720,  loss: 0.1765327572822571\n",
      "Batch 725,  loss: 0.12853512912988663\n",
      "Batch 730,  loss: 0.13023699671030045\n",
      "Batch 735,  loss: 0.1761606067419052\n",
      "Batch 740,  loss: 0.1374674081802368\n",
      "Batch 745,  loss: 0.15950572341680527\n",
      "Batch 750,  loss: 0.17816118597984315\n",
      "Batch 755,  loss: 0.19705920815467834\n",
      "Batch 760,  loss: 0.14413624107837678\n",
      "Batch 765,  loss: 0.1797154277563095\n",
      "Batch 770,  loss: 0.12918042242527009\n",
      "Batch 775,  loss: 0.1661958158016205\n",
      "Batch 780,  loss: 0.11086778044700622\n",
      "Batch 785,  loss: 0.1654118448495865\n",
      "Batch 790,  loss: 0.13003480434417725\n",
      "Batch 795,  loss: 0.13985838145017623\n",
      "Batch 800,  loss: 0.15522341132164003\n",
      "Batch 805,  loss: 0.1460162878036499\n",
      "Batch 810,  loss: 0.16467559784650804\n",
      "Batch 815,  loss: 0.1659139722585678\n",
      "Batch 820,  loss: 0.14036680459976197\n",
      "Batch 825,  loss: 0.1934840440750122\n",
      "Batch 830,  loss: 0.15449433773756027\n",
      "Batch 835,  loss: 0.14183259308338164\n",
      "Batch 840,  loss: 0.18354911506175994\n",
      "Batch 845,  loss: 0.14370969384908677\n",
      "Batch 850,  loss: 0.1526249200105667\n",
      "Batch 855,  loss: 0.15050988793373107\n",
      "Batch 860,  loss: 0.14907034784555434\n",
      "Batch 865,  loss: 0.1049224317073822\n",
      "Batch 870,  loss: 0.12420182526111603\n",
      "Batch 875,  loss: 0.18423994183540343\n",
      "Batch 880,  loss: 0.17157211601734162\n",
      "Batch 885,  loss: 0.21883344650268555\n",
      "Batch 890,  loss: 0.1364281803369522\n",
      "Batch 895,  loss: 0.16820549368858337\n",
      "Batch 900,  loss: 0.14627398252487184\n",
      "Batch 905,  loss: 0.12200798690319062\n",
      "Batch 910,  loss: 0.19374622851610185\n",
      "Batch 915,  loss: 0.1461332082748413\n",
      "Batch 920,  loss: 0.16576798707246782\n",
      "Batch 925,  loss: 0.14031115621328355\n",
      "Batch 930,  loss: 0.18007861375808715\n",
      "Batch 935,  loss: 0.13938994705677032\n",
      "Batch 940,  loss: 0.14217704087495803\n",
      "Batch 945,  loss: 0.1581781715154648\n",
      "Batch 950,  loss: 0.13277984261512757\n",
      "Batch 955,  loss: 0.15613569021224977\n",
      "Batch 960,  loss: 0.13017515391111373\n",
      "Batch 965,  loss: 0.15177308917045593\n",
      "Batch 970,  loss: 0.17223090529441834\n",
      "Batch 975,  loss: 0.1498984068632126\n",
      "Batch 980,  loss: 0.19340899139642714\n",
      "Batch 985,  loss: 0.11898159831762314\n",
      "Batch 990,  loss: 0.21376618146896362\n",
      "Batch 995,  loss: 0.1547534942626953\n",
      "Batch 1000,  loss: 0.15243032574653625\n",
      "Batch 1005,  loss: 0.15856808871030809\n",
      "Batch 1010,  loss: 0.1864658609032631\n",
      "Batch 1015,  loss: 0.10927434265613556\n",
      "Batch 1020,  loss: 0.13715374618768691\n",
      "Batch 1025,  loss: 0.14608343541622162\n",
      "Batch 1030,  loss: 0.21372622549533843\n",
      "Batch 1035,  loss: 0.16305842399597167\n",
      "Batch 1040,  loss: 0.14332758784294128\n",
      "Batch 1045,  loss: 0.15110864937305452\n",
      "Batch 1050,  loss: 0.13526442348957063\n",
      "Batch 1055,  loss: 0.171253564953804\n",
      "Batch 1060,  loss: 0.16697454154491426\n",
      "Batch 1065,  loss: 0.2425435721874237\n",
      "Batch 1070,  loss: 0.1455512285232544\n",
      "Batch 1075,  loss: 0.15899122655391693\n",
      "Batch 1080,  loss: 0.12852623909711838\n",
      "Batch 1085,  loss: 0.15997641831636428\n",
      "Batch 1090,  loss: 0.15823695659637452\n",
      "Batch 1095,  loss: 0.11945090144872665\n",
      "Batch 1100,  loss: 0.1572896957397461\n",
      "Batch 1105,  loss: 0.1599988892674446\n",
      "Batch 1110,  loss: 0.139994053542614\n",
      "Batch 1115,  loss: 0.16897741109132766\n",
      "Batch 1120,  loss: 0.19444330632686616\n",
      "Batch 1125,  loss: 0.19035440385341645\n",
      "Batch 1130,  loss: 0.13947242200374604\n",
      "Batch 1135,  loss: 0.13252581506967545\n",
      "Batch 1140,  loss: 0.16675677001476288\n",
      "Batch 1145,  loss: 0.1695024311542511\n",
      "Batch 1150,  loss: 0.18969295620918275\n",
      "Batch 1155,  loss: 0.183396378159523\n",
      "Batch 1160,  loss: 0.17591652274131775\n",
      "Batch 1165,  loss: 0.11814745962619781\n",
      "Batch 1170,  loss: 0.17465212047100068\n",
      "Batch 1175,  loss: 0.16291991323232652\n",
      "Batch 1180,  loss: 0.18083378225564956\n",
      "Batch 1185,  loss: 0.2003691762685776\n",
      "Batch 1190,  loss: 0.14938789308071138\n",
      "Batch 1195,  loss: 0.14610321968793868\n",
      "Batch 1200,  loss: 0.13483903408050538\n",
      "Batch 1205,  loss: 0.1436721920967102\n",
      "Batch 1210,  loss: 0.17298586666584015\n",
      "Batch 1215,  loss: 0.13472154438495637\n",
      "Batch 1220,  loss: 0.13922280967235565\n",
      "Batch 1225,  loss: 0.15531598627567292\n",
      "Batch 1230,  loss: 0.17859427332878114\n",
      "Batch 1235,  loss: 0.14640220999717712\n",
      "Batch 1240,  loss: 0.16002464294433594\n",
      "Batch 1245,  loss: 0.1479368045926094\n",
      "Batch 1250,  loss: 0.17817474603652955\n",
      "Batch 1255,  loss: 0.16861501932144166\n",
      "Batch 1260,  loss: 0.16298187971115113\n",
      "Batch 1265,  loss: 0.15806877315044404\n",
      "Batch 1270,  loss: 0.21641849279403685\n",
      "Batch 1275,  loss: 0.1615049123764038\n",
      "Batch 1280,  loss: 0.18231761753559111\n",
      "Batch 1285,  loss: 0.14759711027145386\n",
      "Batch 1290,  loss: 0.15604582279920579\n",
      "Batch 1295,  loss: 0.15518521666526794\n",
      "Batch 1300,  loss: 0.13940804153680803\n",
      "Batch 1305,  loss: 0.17170166075229645\n",
      "Batch 1310,  loss: 0.1830979973077774\n",
      "Batch 1315,  loss: 0.14763144850730897\n",
      "Batch 1320,  loss: 0.1246479719877243\n",
      "Batch 1325,  loss: 0.1341873973608017\n",
      "Batch 1330,  loss: 0.1497405230998993\n",
      "Batch 1335,  loss: 0.1402300000190735\n",
      "Batch 1340,  loss: 0.14028916209936143\n",
      "Batch 1345,  loss: 0.17529114782810212\n",
      "Batch 1350,  loss: 0.13395352363586427\n",
      "Batch 1355,  loss: 0.15984672904014588\n",
      "Batch 1360,  loss: 0.12560090869665147\n",
      "Batch 1365,  loss: 0.16522126495838166\n",
      "Batch 1370,  loss: 0.15843891948461533\n",
      "Batch 1375,  loss: 0.2069493532180786\n",
      "Batch 1380,  loss: 0.1921907439827919\n",
      "Batch 1385,  loss: 0.16899524629116058\n",
      "Batch 1390,  loss: 0.19591535925865172\n",
      "Batch 1395,  loss: 0.2030241906642914\n",
      "Batch 1400,  loss: 0.19074853062629699\n",
      "Batch 1405,  loss: 0.19400656819343567\n",
      "Batch 1410,  loss: 0.1723594069480896\n",
      "Batch 1415,  loss: 0.18523130863904952\n",
      "Batch 1420,  loss: 0.13911942690610885\n",
      "Batch 1425,  loss: 0.15573596060276032\n",
      "Batch 1430,  loss: 0.1373793140053749\n",
      "Batch 1435,  loss: 0.11859959810972213\n",
      "Batch 1440,  loss: 0.16191699504852294\n",
      "Batch 1445,  loss: 0.17016155123710633\n",
      "Batch 1450,  loss: 0.15447987020015716\n",
      "Batch 1455,  loss: 0.14143316745758056\n",
      "Batch 1460,  loss: 0.1722290635108948\n",
      "Batch 1465,  loss: 0.2133910536766052\n",
      "Batch 1470,  loss: 0.12638017237186433\n",
      "Batch 1475,  loss: 0.14019189178943633\n",
      "Batch 1480,  loss: 0.15951912701129914\n",
      "Batch 1485,  loss: 0.13313878774642945\n",
      "Batch 1490,  loss: 0.17212955951690673\n",
      "Batch 1495,  loss: 0.18119507580995559\n",
      "Batch 1500,  loss: 0.21430006623268127\n",
      "Batch 1505,  loss: 0.13474035263061523\n",
      "Batch 1510,  loss: 0.1659136265516281\n",
      "Batch 1515,  loss: 0.1874394029378891\n",
      "Batch 1520,  loss: 0.18648760318756102\n",
      "Batch 1525,  loss: 0.16918963491916655\n",
      "Batch 1530,  loss: 0.17888323366641998\n",
      "Batch 1535,  loss: 0.15895097851753234\n",
      "Batch 1540,  loss: 0.1603915959596634\n",
      "Batch 1545,  loss: 0.13483676314353943\n",
      "Batch 1550,  loss: 0.15371378213167192\n",
      "Batch 1555,  loss: 0.21453822553157806\n",
      "Batch 1560,  loss: 0.14297946393489838\n",
      "Batch 1565,  loss: 0.14877000451087952\n",
      "Batch 1570,  loss: 0.0974249079823494\n",
      "Batch 1575,  loss: 0.12405393868684769\n",
      "Batch 1580,  loss: 0.156642410159111\n",
      "Batch 1585,  loss: 0.16572403013706208\n",
      "Batch 1590,  loss: 0.2090670272707939\n",
      "Batch 1595,  loss: 0.15359622836112977\n",
      "Batch 1600,  loss: 0.19649904668331147\n",
      "Batch 1605,  loss: 0.16024860888719558\n",
      "Batch 1610,  loss: 0.14359544962644577\n",
      "Batch 1615,  loss: 0.13879936933517456\n",
      "Batch 1620,  loss: 0.1253875732421875\n",
      "Batch 1625,  loss: 0.1565687596797943\n",
      "Batch 1630,  loss: 0.1610792398452759\n",
      "Batch 1635,  loss: 0.13864534199237824\n",
      "Batch 1640,  loss: 0.15808066427707673\n",
      "Batch 1645,  loss: 0.2212984412908554\n",
      "Batch 1650,  loss: 0.15377408564090728\n",
      "Batch 1655,  loss: 0.15156351923942565\n",
      "Batch 1660,  loss: 0.18101108819246292\n",
      "Batch 1665,  loss: 0.10368951559066772\n",
      "Batch 1670,  loss: 0.1963910162448883\n",
      "Batch 1675,  loss: 0.14012276530265808\n",
      "Batch 1680,  loss: 0.14443527460098265\n",
      "Batch 1685,  loss: 0.1722427561879158\n",
      "Batch 1690,  loss: 0.1504148617386818\n",
      "Batch 1695,  loss: 0.15716227144002914\n",
      "Batch 1700,  loss: 0.17177054136991501\n",
      "Batch 1705,  loss: 0.189870947599411\n",
      "Batch 1710,  loss: 0.16169886142015458\n",
      "Batch 1715,  loss: 0.18314128518104553\n",
      "Batch 1720,  loss: 0.13454827219247817\n",
      "Batch 1725,  loss: 0.14170042872428895\n",
      "Batch 1730,  loss: 0.16172852814197541\n",
      "Batch 1735,  loss: 0.17956655025482177\n",
      "Batch 1740,  loss: 0.15796835124492645\n",
      "Batch 1745,  loss: 0.15212092995643617\n",
      "Batch 1750,  loss: 0.16100950837135314\n",
      "Batch 1755,  loss: 0.19070894718170167\n",
      "Batch 1760,  loss: 0.14463407248258592\n",
      "Batch 1765,  loss: 0.1691093325614929\n",
      "Batch 1770,  loss: 0.15469760000705718\n",
      "Batch 1775,  loss: 0.1938283324241638\n",
      "Batch 1780,  loss: 0.22003054320812226\n",
      "Batch 1785,  loss: 0.1248930737376213\n",
      "Batch 1790,  loss: 0.16707185804843902\n",
      "Batch 1795,  loss: 0.18489503264427185\n",
      "Batch 1800,  loss: 0.13495396971702575\n",
      "Batch 1805,  loss: 0.12748672366142272\n",
      "Batch 1810,  loss: 0.12724958658218383\n",
      "Batch 1815,  loss: 0.11399065405130386\n",
      "Batch 1820,  loss: 0.14758214354515076\n",
      "Batch 1825,  loss: 0.14543190896511077\n",
      "Batch 1830,  loss: 0.12921628654003142\n",
      "Batch 1835,  loss: 0.1392078682780266\n",
      "Batch 1840,  loss: 0.13978265225887299\n",
      "Batch 1845,  loss: 0.16754326224327087\n",
      "Batch 1850,  loss: 0.15484744310379028\n",
      "Batch 1855,  loss: 0.12596689611673356\n",
      "Batch 1860,  loss: 0.13653462380170822\n",
      "Batch 1865,  loss: 0.1577882081270218\n",
      "Batch 1870,  loss: 0.14273596107959746\n",
      "Batch 1875,  loss: 0.12230017632246018\n",
      "Batch 1880,  loss: 0.1738201230764389\n",
      "Batch 1885,  loss: 0.1489049807190895\n",
      "Batch 1890,  loss: 0.13498036414384842\n",
      "Batch 1895,  loss: 0.13713951408863068\n",
      "Batch 1900,  loss: 0.15124346166849137\n",
      "Batch 1905,  loss: 0.16834745705127716\n",
      "Batch 1910,  loss: 0.17646073400974274\n",
      "Batch 1915,  loss: 0.23474668860435485\n",
      "Batch 1920,  loss: 0.12214242070913314\n",
      "Batch 1925,  loss: 0.14521538615226745\n",
      "Batch 1930,  loss: 0.1614202529191971\n",
      "Batch 1935,  loss: 0.1568798154592514\n",
      "Batch 1940,  loss: 0.16155121773481368\n",
      "Batch 1945,  loss: 0.1308120995759964\n",
      "Batch 1950,  loss: 0.1554396778345108\n",
      "Batch 1955,  loss: 0.16831824481487273\n",
      "Batch 1960,  loss: 0.20375381857156755\n",
      "Batch 1965,  loss: 0.19989017248153687\n",
      "Batch 1970,  loss: 0.1507876917719841\n",
      "Batch 1975,  loss: 0.13893300890922547\n",
      "Batch 1980,  loss: 0.21631171107292174\n",
      "Batch 1985,  loss: 0.19318512678146363\n",
      "Batch 1990,  loss: 0.17260405123233796\n",
      "Batch 1995,  loss: 0.13643417954444886\n",
      "Batch 2000,  loss: 0.17733935117721558\n",
      "Batch 2005,  loss: 0.15509792864322663\n",
      "Batch 2010,  loss: 0.1693771854043007\n",
      "Batch 2015,  loss: 0.17489008605480194\n",
      "Batch 2020,  loss: 0.18351706862449646\n",
      "Batch 2025,  loss: 0.17598165571689606\n",
      "Batch 2030,  loss: 0.1660647690296173\n",
      "Batch 2035,  loss: 0.1758953243494034\n",
      "Batch 2040,  loss: 0.16861719489097596\n",
      "Batch 2045,  loss: 0.1562629982829094\n",
      "Batch 2050,  loss: 0.15160441994667054\n",
      "Batch 2055,  loss: 0.11532109379768371\n",
      "Batch 2060,  loss: 0.19370250403881073\n",
      "Batch 2065,  loss: 0.15225509256124498\n",
      "Batch 2070,  loss: 0.1817099779844284\n",
      "Batch 2075,  loss: 0.1250050202012062\n",
      "Batch 2080,  loss: 0.17209087908267975\n",
      "Batch 2085,  loss: 0.18464267551898955\n",
      "Batch 2090,  loss: 0.11971457451581954\n",
      "Batch 2095,  loss: 0.16923129558563232\n",
      "Batch 2100,  loss: 0.18833414018154143\n",
      "Batch 2105,  loss: 0.1509201556444168\n",
      "Batch 2110,  loss: 0.12913255989551545\n",
      "Batch 2115,  loss: 0.1706037253141403\n",
      "Batch 2120,  loss: 0.17270318567752838\n",
      "Batch 2125,  loss: 0.1612243413925171\n",
      "Batch 2130,  loss: 0.20758585631847382\n",
      "Batch 2135,  loss: 0.12798506021499634\n",
      "Batch 2140,  loss: 0.11237571537494659\n",
      "Batch 2145,  loss: 0.13810689747333527\n",
      "Batch 2150,  loss: 0.1406959056854248\n",
      "Batch 2155,  loss: 0.1740841507911682\n",
      "Batch 2160,  loss: 0.1473310187458992\n",
      "Batch 2165,  loss: 0.1326796755194664\n",
      "Batch 2170,  loss: 0.16229094564914703\n",
      "Batch 2175,  loss: 0.1542452394962311\n",
      "Batch 2180,  loss: 0.12353991270065308\n",
      "Batch 2185,  loss: 0.24498986601829528\n",
      "Batch 2190,  loss: 0.14701772034168242\n",
      "Batch 2195,  loss: 0.1410433515906334\n",
      "Batch 2200,  loss: 0.18953873515129088\n",
      "Batch 2205,  loss: 0.1496427834033966\n",
      "Batch 2210,  loss: 0.15319609642028809\n",
      "Batch 2215,  loss: 0.15375901460647584\n",
      "Batch 2220,  loss: 0.15088505148887635\n",
      "Batch 2225,  loss: 0.19214956760406493\n",
      "Batch 2230,  loss: 0.12130469083786011\n",
      "Batch 2235,  loss: 0.16854856312274932\n",
      "Batch 2240,  loss: 0.13960156291723252\n",
      "Batch 2245,  loss: 0.14269587397575378\n",
      "Batch 2250,  loss: 0.20801590979099274\n",
      "Batch 2255,  loss: 0.16021979302167894\n",
      "Batch 2260,  loss: 0.11743915528059005\n",
      "Batch 2265,  loss: 0.14201585948467255\n",
      "Batch 2270,  loss: 0.16077296882867814\n",
      "Batch 2275,  loss: 0.19393056333065034\n",
      "Batch 2280,  loss: 0.14012177884578705\n",
      "Batch 2285,  loss: 0.14226946234703064\n",
      "Batch 2290,  loss: 0.15780181884765626\n",
      "Batch 2295,  loss: 0.19188860356807708\n",
      "Batch 2300,  loss: 0.13133233338594436\n",
      "Batch 2305,  loss: 0.1329135775566101\n",
      "Batch 2310,  loss: 0.18238188326358795\n",
      "Batch 2315,  loss: 0.1590205281972885\n",
      "Batch 2320,  loss: 0.17844147533178328\n",
      "Batch 2325,  loss: 0.15708621442317963\n",
      "Batch 2330,  loss: 0.19253983199596406\n",
      "Batch 2335,  loss: 0.12296509593725205\n",
      "Batch 2340,  loss: 0.1413033127784729\n",
      "Batch 2345,  loss: 0.15871289521455764\n",
      "Batch 2350,  loss: 0.18154193758964537\n",
      "Batch 2355,  loss: 0.1687351107597351\n",
      "Batch 2360,  loss: 0.1598725736141205\n",
      "Batch 2365,  loss: 0.13659384250640869\n",
      "Batch 2370,  loss: 0.17071819603443145\n",
      "Batch 2375,  loss: 0.15983401536941527\n",
      "Batch 2380,  loss: 0.17860881686210633\n",
      "Batch 2385,  loss: 0.17078415751457215\n",
      "Batch 2390,  loss: 0.13516657948493957\n",
      "Batch 2395,  loss: 0.16183483898639678\n",
      "Batch 2400,  loss: 0.17089448869228363\n",
      "Batch 2405,  loss: 0.14428406059741974\n",
      "Batch 2410,  loss: 0.1362804055213928\n",
      "Batch 2415,  loss: 0.11794759035110473\n",
      "Batch 2420,  loss: 0.1329634189605713\n",
      "Batch 2425,  loss: 0.17839273810386658\n",
      "Batch 2430,  loss: 0.13112152218818665\n",
      "Batch 2435,  loss: 0.1361875742673874\n",
      "Batch 2440,  loss: 0.138005068898201\n",
      "Batch 2445,  loss: 0.1442155197262764\n",
      "Batch 2450,  loss: 0.17458269894123077\n",
      "Batch 2455,  loss: 0.13646343648433684\n",
      "Batch 2460,  loss: 0.1276253193616867\n",
      "Batch 2465,  loss: 0.1711304321885109\n",
      "Batch 2470,  loss: 0.12957133054733277\n",
      "Batch 2475,  loss: 0.16093632727861404\n",
      "Batch 2480,  loss: 0.17139841318130494\n",
      "Batch 2485,  loss: 0.1528303489089012\n",
      "Batch 2490,  loss: 0.2079579144716263\n",
      "Batch 2495,  loss: 0.14287470430135726\n",
      "Batch 2500,  loss: 0.14505670368671417\n",
      "Batch 2505,  loss: 0.19657341837882997\n",
      "Batch 2510,  loss: 0.13532097786664962\n",
      "Batch 2515,  loss: 0.144745072722435\n",
      "Batch 2520,  loss: 0.13084565699100495\n",
      "Batch 2525,  loss: 0.18978295028209685\n",
      "Batch 2530,  loss: 0.1668776512145996\n",
      "Batch 2535,  loss: 0.16494624316692352\n",
      "Batch 2540,  loss: 0.14006558507680894\n",
      "Batch 2545,  loss: 0.18757902085781097\n",
      "Batch 2550,  loss: 0.15248213410377504\n",
      "Batch 2555,  loss: 0.15449129939079284\n",
      "Batch 2560,  loss: 0.1452266529202461\n",
      "Batch 2565,  loss: 0.15829152762889862\n",
      "Batch 2570,  loss: 0.125335992872715\n",
      "Batch 2575,  loss: 0.12433800697326661\n",
      "Batch 2580,  loss: 0.12456841170787811\n",
      "Batch 2585,  loss: 0.16355707347393036\n",
      "Batch 2590,  loss: 0.13898328244686126\n",
      "Batch 2595,  loss: 0.1552547037601471\n",
      "Batch 2600,  loss: 0.1615643709897995\n",
      "Batch 2605,  loss: 0.16449421346187593\n",
      "Batch 2610,  loss: 0.14824774414300917\n",
      "Batch 2615,  loss: 0.17016905844211577\n",
      "Batch 2620,  loss: 0.1788826197385788\n",
      "Batch 2625,  loss: 0.19792493283748627\n",
      "Batch 2630,  loss: 0.1712449699640274\n",
      "Batch 2635,  loss: 0.15550448447465898\n",
      "Batch 2640,  loss: 0.13979585617780685\n",
      "Batch 2645,  loss: 0.14407687038183212\n",
      "Batch 2650,  loss: 0.23158470392227173\n",
      "Batch 2655,  loss: 0.11021080762147903\n",
      "Batch 2660,  loss: 0.12121609151363373\n",
      "Batch 2665,  loss: 0.1332501068711281\n",
      "Batch 2670,  loss: 0.1821589633822441\n",
      "Batch 2675,  loss: 0.1711938589811325\n",
      "Batch 2680,  loss: 0.17254841029644014\n",
      "Batch 2685,  loss: 0.17457444369792938\n",
      "Batch 2690,  loss: 0.12105177640914917\n",
      "Batch 2695,  loss: 0.17148454189300538\n",
      "Batch 2700,  loss: 0.15411217808723449\n",
      "Batch 2705,  loss: 0.1623927116394043\n",
      "Batch 2710,  loss: 0.13545359522104264\n",
      "Batch 2715,  loss: 0.16152956783771516\n",
      "Batch 2720,  loss: 0.14626439064741134\n",
      "Batch 2725,  loss: 0.1526463210582733\n",
      "Batch 2730,  loss: 0.17049914002418518\n",
      "Batch 2735,  loss: 0.1509988322854042\n",
      "Batch 2740,  loss: 0.1636430263519287\n",
      "Batch 2745,  loss: 0.11819937378168106\n",
      "Batch 2750,  loss: 0.13996486365795135\n",
      "Batch 2755,  loss: 0.1095261350274086\n",
      "Batch 2760,  loss: 0.1439182072877884\n",
      "Batch 2765,  loss: 0.13355136066675186\n",
      "Batch 2770,  loss: 0.158659827709198\n",
      "LOSS train 0.158659827709198. Validation loss: 0.16097123770332136 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 33:\n",
      "Batch 5,  loss: 0.13161619156599044\n",
      "Batch 10,  loss: 0.15824172347784043\n",
      "Batch 15,  loss: 0.1479245215654373\n",
      "Batch 20,  loss: 0.13971601873636247\n",
      "Batch 25,  loss: 0.12239009439945221\n",
      "Batch 30,  loss: 0.1491676986217499\n",
      "Batch 35,  loss: 0.2132638782262802\n",
      "Batch 40,  loss: 0.17014253437519072\n",
      "Batch 45,  loss: 0.13609323054552078\n",
      "Batch 50,  loss: 0.1585559755563736\n",
      "Batch 55,  loss: 0.17433471083641053\n",
      "Batch 60,  loss: 0.17922562062740327\n",
      "Batch 65,  loss: 0.12553199231624604\n",
      "Batch 70,  loss: 0.15704387724399566\n",
      "Batch 75,  loss: 0.20456721186637877\n",
      "Batch 80,  loss: 0.1604996681213379\n",
      "Batch 85,  loss: 0.13569412529468536\n",
      "Batch 90,  loss: 0.2012184590101242\n",
      "Batch 95,  loss: 0.1445862427353859\n",
      "Batch 100,  loss: 0.13282932341098785\n",
      "Batch 105,  loss: 0.19062487483024598\n",
      "Batch 110,  loss: 0.18543208837509156\n",
      "Batch 115,  loss: 0.14958897083997727\n",
      "Batch 120,  loss: 0.18874933272600175\n",
      "Batch 125,  loss: 0.16213344931602477\n",
      "Batch 130,  loss: 0.18928064107894899\n",
      "Batch 135,  loss: 0.15995312333106995\n",
      "Batch 140,  loss: 0.14980930536985398\n",
      "Batch 145,  loss: 0.14527403116226195\n",
      "Batch 150,  loss: 0.13378934562206268\n",
      "Batch 155,  loss: 0.17891880571842195\n",
      "Batch 160,  loss: 0.15918296873569487\n",
      "Batch 165,  loss: 0.15773844867944717\n",
      "Batch 170,  loss: 0.1820855215191841\n",
      "Batch 175,  loss: 0.14676751494407653\n",
      "Batch 180,  loss: 0.12795080989599228\n",
      "Batch 185,  loss: 0.13801429867744447\n",
      "Batch 190,  loss: 0.19030428528785706\n",
      "Batch 195,  loss: 0.1362406462430954\n",
      "Batch 200,  loss: 0.1476437509059906\n",
      "Batch 205,  loss: 0.12951172590255738\n",
      "Batch 210,  loss: 0.18661189675331116\n",
      "Batch 215,  loss: 0.1662597358226776\n",
      "Batch 220,  loss: 0.13198091834783554\n",
      "Batch 225,  loss: 0.18209806233644485\n",
      "Batch 230,  loss: 0.12697036266326905\n",
      "Batch 235,  loss: 0.18589783310890198\n",
      "Batch 240,  loss: 0.16000907868146896\n",
      "Batch 245,  loss: 0.1306251496076584\n",
      "Batch 250,  loss: 0.14759207665920257\n",
      "Batch 255,  loss: 0.1613402023911476\n",
      "Batch 260,  loss: 0.1956593871116638\n",
      "Batch 265,  loss: 0.16946979761123657\n",
      "Batch 270,  loss: 0.1604140967130661\n",
      "Batch 275,  loss: 0.15054422616958618\n",
      "Batch 280,  loss: 0.18666351735591888\n",
      "Batch 285,  loss: 0.17813067138195038\n",
      "Batch 290,  loss: 0.11711575984954833\n",
      "Batch 295,  loss: 0.1717316433787346\n",
      "Batch 300,  loss: 0.15578248500823974\n",
      "Batch 305,  loss: 0.1481969326734543\n",
      "Batch 310,  loss: 0.14150677174329757\n",
      "Batch 315,  loss: 0.17516329288482665\n",
      "Batch 320,  loss: 0.14331470131874086\n",
      "Batch 325,  loss: 0.12651172876358033\n",
      "Batch 330,  loss: 0.13784110844135283\n",
      "Batch 335,  loss: 0.1602483168244362\n",
      "Batch 340,  loss: 0.16798268258571625\n",
      "Batch 345,  loss: 0.16197967231273652\n",
      "Batch 350,  loss: 0.2052377313375473\n",
      "Batch 355,  loss: 0.178785540163517\n",
      "Batch 360,  loss: 0.1491948038339615\n",
      "Batch 365,  loss: 0.16743602454662324\n",
      "Batch 370,  loss: 0.13744545578956605\n",
      "Batch 375,  loss: 0.14712317734956742\n",
      "Batch 380,  loss: 0.15797896981239318\n",
      "Batch 385,  loss: 0.15986100435256959\n",
      "Batch 390,  loss: 0.17622023373842238\n",
      "Batch 395,  loss: 0.1473682254552841\n",
      "Batch 400,  loss: 0.12655889242887497\n",
      "Batch 405,  loss: 0.12493218928575515\n",
      "Batch 410,  loss: 0.17063290774822235\n",
      "Batch 415,  loss: 0.14058943688869477\n",
      "Batch 420,  loss: 0.15761343091726304\n",
      "Batch 425,  loss: 0.16571159064769744\n",
      "Batch 430,  loss: 0.14007470905780792\n",
      "Batch 435,  loss: 0.15781862437725067\n",
      "Batch 440,  loss: 0.12256145179271698\n",
      "Batch 445,  loss: 0.14237080812454223\n",
      "Batch 450,  loss: 0.15259688049554826\n",
      "Batch 455,  loss: 0.1492159903049469\n",
      "Batch 460,  loss: 0.19783565998077393\n",
      "Batch 465,  loss: 0.13722476959228516\n",
      "Batch 470,  loss: 0.16130899786949157\n",
      "Batch 475,  loss: 0.15643220245838166\n",
      "Batch 480,  loss: 0.14793335795402526\n",
      "Batch 485,  loss: 0.1766657203435898\n",
      "Batch 490,  loss: 0.15689400732517242\n",
      "Batch 495,  loss: 0.147935351729393\n",
      "Batch 500,  loss: 0.15213607549667357\n",
      "Batch 505,  loss: 0.16543346345424653\n",
      "Batch 510,  loss: 0.1629917249083519\n",
      "Batch 515,  loss: 0.15192176401615143\n",
      "Batch 520,  loss: 0.1182060569524765\n",
      "Batch 525,  loss: 0.14518932476639748\n",
      "Batch 530,  loss: 0.125642991065979\n",
      "Batch 535,  loss: 0.1595051795244217\n",
      "Batch 540,  loss: 0.20332043170928954\n",
      "Batch 545,  loss: 0.16508932709693908\n",
      "Batch 550,  loss: 0.14363088607788085\n",
      "Batch 555,  loss: 0.14030139446258544\n",
      "Batch 560,  loss: 0.17569499760866164\n",
      "Batch 565,  loss: 0.21661683470010756\n",
      "Batch 570,  loss: 0.16187747120857238\n",
      "Batch 575,  loss: 0.1478413686156273\n",
      "Batch 580,  loss: 0.1933419018983841\n",
      "Batch 585,  loss: 0.1780497059226036\n",
      "Batch 590,  loss: 0.16009128391742705\n",
      "Batch 595,  loss: 0.13092330396175383\n",
      "Batch 600,  loss: 0.14960925728082658\n",
      "Batch 605,  loss: 0.15977562069892884\n",
      "Batch 610,  loss: 0.14311860352754593\n",
      "Batch 615,  loss: 0.19919937252998351\n",
      "Batch 620,  loss: 0.17744970917701722\n",
      "Batch 625,  loss: 0.1512504041194916\n",
      "Batch 630,  loss: 0.12721725255250932\n",
      "Batch 635,  loss: 0.1708927720785141\n",
      "Batch 640,  loss: 0.09525807052850724\n",
      "Batch 645,  loss: 0.12571038156747819\n",
      "Batch 650,  loss: 0.15327973365783693\n",
      "Batch 655,  loss: 0.14809723049402237\n",
      "Batch 660,  loss: 0.12874321043491363\n",
      "Batch 665,  loss: 0.14980393648147583\n",
      "Batch 670,  loss: 0.16682902127504348\n",
      "Batch 675,  loss: 0.14709459543228148\n",
      "Batch 680,  loss: 0.12433153688907624\n",
      "Batch 685,  loss: 0.13220276832580566\n",
      "Batch 690,  loss: 0.15874166190624237\n",
      "Batch 695,  loss: 0.17782674133777618\n",
      "Batch 700,  loss: 0.15128764808177947\n",
      "Batch 705,  loss: 0.1549401253461838\n",
      "Batch 710,  loss: 0.1651916652917862\n",
      "Batch 715,  loss: 0.1321209579706192\n",
      "Batch 720,  loss: 0.15617390722036362\n",
      "Batch 725,  loss: 0.17626227736473082\n",
      "Batch 730,  loss: 0.22200888991355897\n",
      "Batch 735,  loss: 0.16798312962055206\n",
      "Batch 740,  loss: 0.1449967071413994\n",
      "Batch 745,  loss: 0.15838827490806578\n",
      "Batch 750,  loss: 0.14066549837589265\n",
      "Batch 755,  loss: 0.1453544020652771\n",
      "Batch 760,  loss: 0.14907684028148652\n",
      "Batch 765,  loss: 0.16155730038881302\n",
      "Batch 770,  loss: 0.11860632002353669\n",
      "Batch 775,  loss: 0.12417968213558198\n",
      "Batch 780,  loss: 0.13613695055246353\n",
      "Batch 785,  loss: 0.15087039023637772\n",
      "Batch 790,  loss: 0.15798551291227342\n",
      "Batch 795,  loss: 0.12943312227725984\n",
      "Batch 800,  loss: 0.18183111548423767\n",
      "Batch 805,  loss: 0.14376128166913987\n",
      "Batch 810,  loss: 0.17848998308181763\n",
      "Batch 815,  loss: 0.16155896037817002\n",
      "Batch 820,  loss: 0.1413252606987953\n",
      "Batch 825,  loss: 0.14627160429954528\n",
      "Batch 830,  loss: 0.1859963893890381\n",
      "Batch 835,  loss: 0.1566380351781845\n",
      "Batch 840,  loss: 0.1864677682518959\n",
      "Batch 845,  loss: 0.19344357550144195\n",
      "Batch 850,  loss: 0.14746440351009368\n",
      "Batch 855,  loss: 0.2030322164297104\n",
      "Batch 860,  loss: 0.16336729526519775\n",
      "Batch 865,  loss: 0.15995443016290664\n",
      "Batch 870,  loss: 0.17713226974010468\n",
      "Batch 875,  loss: 0.12892968952655792\n",
      "Batch 880,  loss: 0.15139820128679277\n",
      "Batch 885,  loss: 0.14556571394205092\n",
      "Batch 890,  loss: 0.15269221663475036\n",
      "Batch 895,  loss: 0.15731675326824188\n",
      "Batch 900,  loss: 0.15077369213104247\n",
      "Batch 905,  loss: 0.12145818322896958\n",
      "Batch 910,  loss: 0.13826603442430496\n",
      "Batch 915,  loss: 0.1481798380613327\n",
      "Batch 920,  loss: 0.13849216252565383\n",
      "Batch 925,  loss: 0.14822231829166413\n",
      "Batch 930,  loss: 0.16579810678958892\n",
      "Batch 935,  loss: 0.12560190856456757\n",
      "Batch 940,  loss: 0.15213453471660615\n",
      "Batch 945,  loss: 0.16032882034778595\n",
      "Batch 950,  loss: 0.13738629668951036\n",
      "Batch 955,  loss: 0.16039334386587142\n",
      "Batch 960,  loss: 0.17844638228416443\n",
      "Batch 965,  loss: 0.13231087923049928\n",
      "Batch 970,  loss: 0.1581595093011856\n",
      "Batch 975,  loss: 0.17603918612003328\n",
      "Batch 980,  loss: 0.17750293612480164\n",
      "Batch 985,  loss: 0.19038718044757844\n",
      "Batch 990,  loss: 0.1569521903991699\n",
      "Batch 995,  loss: 0.15599890947341918\n",
      "Batch 1000,  loss: 0.12601238042116164\n",
      "Batch 1005,  loss: 0.17283634096384048\n",
      "Batch 1010,  loss: 0.13062823563814163\n",
      "Batch 1015,  loss: 0.15001194179058075\n",
      "Batch 1020,  loss: 0.1855919986963272\n",
      "Batch 1025,  loss: 0.1926687628030777\n",
      "Batch 1030,  loss: 0.14691314995288848\n",
      "Batch 1035,  loss: 0.1607048362493515\n",
      "Batch 1040,  loss: 0.14829058647155763\n",
      "Batch 1045,  loss: 0.11017771810293198\n",
      "Batch 1050,  loss: 0.128391270339489\n",
      "Batch 1055,  loss: 0.14010832607746124\n",
      "Batch 1060,  loss: 0.1548537939786911\n",
      "Batch 1065,  loss: 0.15287965089082717\n",
      "Batch 1070,  loss: 0.15290805995464324\n",
      "Batch 1075,  loss: 0.14823404848575591\n",
      "Batch 1080,  loss: 0.14937234818935394\n",
      "Batch 1085,  loss: 0.1760228008031845\n",
      "Batch 1090,  loss: 0.17864039689302444\n",
      "Batch 1095,  loss: 0.2044781357049942\n",
      "Batch 1100,  loss: 0.1512109413743019\n",
      "Batch 1105,  loss: 0.13702286183834075\n",
      "Batch 1110,  loss: 0.1566717267036438\n",
      "Batch 1115,  loss: 0.1466805964708328\n",
      "Batch 1120,  loss: 0.1816523179411888\n",
      "Batch 1125,  loss: 0.14335816502571105\n",
      "Batch 1130,  loss: 0.17514219433069228\n",
      "Batch 1135,  loss: 0.14004585891962051\n",
      "Batch 1140,  loss: 0.12154729664325714\n",
      "Batch 1145,  loss: 0.14339906871318817\n",
      "Batch 1150,  loss: 0.15528711378574372\n",
      "Batch 1155,  loss: 0.1660676807165146\n",
      "Batch 1160,  loss: 0.1523241400718689\n",
      "Batch 1165,  loss: 0.1736026108264923\n",
      "Batch 1170,  loss: 0.1416349157691002\n",
      "Batch 1175,  loss: 0.16796006113290787\n",
      "Batch 1180,  loss: 0.1634833887219429\n",
      "Batch 1185,  loss: 0.12474213540554047\n",
      "Batch 1190,  loss: 0.15088758617639542\n",
      "Batch 1195,  loss: 0.1740845501422882\n",
      "Batch 1200,  loss: 0.133803591132164\n",
      "Batch 1205,  loss: 0.19841268658638\n",
      "Batch 1210,  loss: 0.16600445210933684\n",
      "Batch 1215,  loss: 0.1402744844555855\n",
      "Batch 1220,  loss: 0.1497936725616455\n",
      "Batch 1225,  loss: 0.1512441396713257\n",
      "Batch 1230,  loss: 0.1564249187707901\n",
      "Batch 1235,  loss: 0.19714971780776977\n",
      "Batch 1240,  loss: 0.17576855719089507\n",
      "Batch 1245,  loss: 0.14797410666942595\n",
      "Batch 1250,  loss: 0.14980277866125108\n",
      "Batch 1255,  loss: 0.16065900325775145\n",
      "Batch 1260,  loss: 0.13539600968360901\n",
      "Batch 1265,  loss: 0.16461119949817657\n",
      "Batch 1270,  loss: 0.12468886375427246\n",
      "Batch 1275,  loss: 0.13247755020856858\n",
      "Batch 1280,  loss: 0.11077830493450165\n",
      "Batch 1285,  loss: 0.15141446590423585\n",
      "Batch 1290,  loss: 0.1994113564491272\n",
      "Batch 1295,  loss: 0.12975646555423737\n",
      "Batch 1300,  loss: 0.20501414835453033\n",
      "Batch 1305,  loss: 0.13195324689149857\n",
      "Batch 1310,  loss: 0.14657307267189026\n",
      "Batch 1315,  loss: 0.15911280810832978\n",
      "Batch 1320,  loss: 0.14295584261417388\n",
      "Batch 1325,  loss: 0.1334975078701973\n",
      "Batch 1330,  loss: 0.17308066934347152\n",
      "Batch 1335,  loss: 0.1348673552274704\n",
      "Batch 1340,  loss: 0.16534489691257476\n",
      "Batch 1345,  loss: 0.12240298390388489\n",
      "Batch 1350,  loss: 0.16790159344673156\n",
      "Batch 1355,  loss: 0.14842143654823303\n",
      "Batch 1360,  loss: 0.20160720348358155\n",
      "Batch 1365,  loss: 0.17460320442914962\n",
      "Batch 1370,  loss: 0.13728729486465455\n",
      "Batch 1375,  loss: 0.12343568652868271\n",
      "Batch 1380,  loss: 0.13066856265068055\n",
      "Batch 1385,  loss: 0.14109715521335603\n",
      "Batch 1390,  loss: 0.14839878231287001\n",
      "Batch 1395,  loss: 0.14256237745285033\n",
      "Batch 1400,  loss: 0.16983798444271087\n",
      "Batch 1405,  loss: 0.16261359304189682\n",
      "Batch 1410,  loss: 0.17873303592205048\n",
      "Batch 1415,  loss: 0.1567109301686287\n",
      "Batch 1420,  loss: 0.13430979251861572\n",
      "Batch 1425,  loss: 0.14184186160564421\n",
      "Batch 1430,  loss: 0.13308918327093125\n",
      "Batch 1435,  loss: 0.14498542845249177\n",
      "Batch 1440,  loss: 0.13453063666820525\n",
      "Batch 1445,  loss: 0.18534295856952668\n",
      "Batch 1450,  loss: 0.20259106457233428\n",
      "Batch 1455,  loss: 0.2057807430624962\n",
      "Batch 1460,  loss: 0.16954683363437653\n",
      "Batch 1465,  loss: 0.1467018097639084\n",
      "Batch 1470,  loss: 0.18635242879390718\n",
      "Batch 1475,  loss: 0.15236155688762665\n",
      "Batch 1480,  loss: 0.14857203960418702\n",
      "Batch 1485,  loss: 0.17070505321025847\n",
      "Batch 1490,  loss: 0.17906972467899324\n",
      "Batch 1495,  loss: 0.15947567522525788\n",
      "Batch 1500,  loss: 0.18664263784885407\n",
      "Batch 1505,  loss: 0.14929635524749757\n",
      "Batch 1510,  loss: 0.1079159438610077\n",
      "Batch 1515,  loss: 0.1302665501832962\n",
      "Batch 1520,  loss: 0.149126860499382\n",
      "Batch 1525,  loss: 0.22631645500659942\n",
      "Batch 1530,  loss: 0.13731372058391572\n",
      "Batch 1535,  loss: 0.13064482063055038\n",
      "Batch 1540,  loss: 0.16666794717311859\n",
      "Batch 1545,  loss: 0.12971563637256622\n",
      "Batch 1550,  loss: 0.14720165133476257\n",
      "Batch 1555,  loss: 0.20013906806707382\n",
      "Batch 1560,  loss: 0.1483552113175392\n",
      "Batch 1565,  loss: 0.15654847621917725\n",
      "Batch 1570,  loss: 0.14761976152658463\n",
      "Batch 1575,  loss: 0.1874660521745682\n",
      "Batch 1580,  loss: 0.15808204412460328\n",
      "Batch 1585,  loss: 0.125174380838871\n",
      "Batch 1590,  loss: 0.13964105844497682\n",
      "Batch 1595,  loss: 0.22146698385477065\n",
      "Batch 1600,  loss: 0.13253756016492843\n",
      "Batch 1605,  loss: 0.16223247945308686\n",
      "Batch 1610,  loss: 0.1466321051120758\n",
      "Batch 1615,  loss: 0.19874955117702484\n",
      "Batch 1620,  loss: 0.20209358930587767\n",
      "Batch 1625,  loss: 0.15889452695846557\n",
      "Batch 1630,  loss: 0.1298561066389084\n",
      "Batch 1635,  loss: 0.16376266181468963\n",
      "Batch 1640,  loss: 0.16522195041179658\n",
      "Batch 1645,  loss: 0.13709326088428497\n",
      "Batch 1650,  loss: 0.15914406776428222\n",
      "Batch 1655,  loss: 0.13281320333480834\n",
      "Batch 1660,  loss: 0.164131823182106\n",
      "Batch 1665,  loss: 0.13777753859758377\n",
      "Batch 1670,  loss: 0.17322748601436616\n",
      "Batch 1675,  loss: 0.16525859087705613\n",
      "Batch 1680,  loss: 0.18321261703968048\n",
      "Batch 1685,  loss: 0.17233159244060517\n",
      "Batch 1690,  loss: 0.15063175559043884\n",
      "Batch 1695,  loss: 0.22913554906845093\n",
      "Batch 1700,  loss: 0.16560961902141572\n",
      "Batch 1705,  loss: 0.1345532014966011\n",
      "Batch 1710,  loss: 0.2051306188106537\n",
      "Batch 1715,  loss: 0.1616503491997719\n",
      "Batch 1720,  loss: 0.16343131363391877\n",
      "Batch 1725,  loss: 0.13061303943395614\n",
      "Batch 1730,  loss: 0.13436552584171296\n",
      "Batch 1735,  loss: 0.14153911024332047\n",
      "Batch 1740,  loss: 0.2007492169737816\n",
      "Batch 1745,  loss: 0.19992218613624574\n",
      "Batch 1750,  loss: 0.1564478322863579\n",
      "Batch 1755,  loss: 0.17398373782634735\n",
      "Batch 1760,  loss: 0.14837009310722352\n",
      "Batch 1765,  loss: 0.14693304896354675\n",
      "Batch 1770,  loss: 0.16856958270072936\n",
      "Batch 1775,  loss: 0.15973639488220215\n",
      "Batch 1780,  loss: 0.1773258164525032\n",
      "Batch 1785,  loss: 0.16836825311183928\n",
      "Batch 1790,  loss: 0.2015211060643196\n",
      "Batch 1795,  loss: 0.17046672850847244\n",
      "Batch 1800,  loss: 0.16473113298416137\n",
      "Batch 1805,  loss: 0.1328444793820381\n",
      "Batch 1810,  loss: 0.17344387173652648\n",
      "Batch 1815,  loss: 0.19672889709472657\n",
      "Batch 1820,  loss: 0.13368573039770126\n",
      "Batch 1825,  loss: 0.15705947279930116\n",
      "Batch 1830,  loss: 0.15143582373857498\n",
      "Batch 1835,  loss: 0.15707084238529206\n",
      "Batch 1840,  loss: 0.16562239527702333\n",
      "Batch 1845,  loss: 0.17602312564849854\n",
      "Batch 1850,  loss: 0.1233403816819191\n",
      "Batch 1855,  loss: 0.14839541912078857\n",
      "Batch 1860,  loss: 0.15745594799518586\n",
      "Batch 1865,  loss: 0.1660597950220108\n",
      "Batch 1870,  loss: 0.14600725769996642\n",
      "Batch 1875,  loss: 0.20072880387306213\n",
      "Batch 1880,  loss: 0.15160893499851227\n",
      "Batch 1885,  loss: 0.20524609684944153\n",
      "Batch 1890,  loss: 0.1528903767466545\n",
      "Batch 1895,  loss: 0.1699132114648819\n",
      "Batch 1900,  loss: 0.15506219863891602\n",
      "Batch 1905,  loss: 0.1383189469575882\n",
      "Batch 1910,  loss: 0.14750014543533324\n",
      "Batch 1915,  loss: 0.13157923072576522\n",
      "Batch 1920,  loss: 0.171828306466341\n",
      "Batch 1925,  loss: 0.17275296598672868\n",
      "Batch 1930,  loss: 0.13941770941019058\n",
      "Batch 1935,  loss: 0.15242891311645507\n",
      "Batch 1940,  loss: 0.14217758625745774\n",
      "Batch 1945,  loss: 0.20502415895462037\n",
      "Batch 1950,  loss: 0.16688051223754882\n",
      "Batch 1955,  loss: 0.11098262071609497\n",
      "Batch 1960,  loss: 0.17679790556430816\n",
      "Batch 1965,  loss: 0.134522046148777\n",
      "Batch 1970,  loss: 0.1669043555855751\n",
      "Batch 1975,  loss: 0.15730517208576203\n",
      "Batch 1980,  loss: 0.15272445678710939\n",
      "Batch 1985,  loss: 0.20495954155921936\n",
      "Batch 1990,  loss: 0.16225491166114808\n",
      "Batch 1995,  loss: 0.1545871764421463\n",
      "Batch 2000,  loss: 0.1242924153804779\n",
      "Batch 2005,  loss: 0.13295189589262008\n",
      "Batch 2010,  loss: 0.14432235807180405\n",
      "Batch 2015,  loss: 0.13841435313224792\n",
      "Batch 2020,  loss: 0.13780505508184432\n",
      "Batch 2025,  loss: 0.12483132034540176\n",
      "Batch 2030,  loss: 0.13209258168935775\n",
      "Batch 2035,  loss: 0.1443568080663681\n",
      "Batch 2040,  loss: 0.126181760430336\n",
      "Batch 2045,  loss: 0.12751782238483428\n",
      "Batch 2050,  loss: 0.1815263882279396\n",
      "Batch 2055,  loss: 0.14087122082710266\n",
      "Batch 2060,  loss: 0.17737317979335784\n",
      "Batch 2065,  loss: 0.1767133057117462\n",
      "Batch 2070,  loss: 0.1685984402894974\n",
      "Batch 2075,  loss: 0.1406084656715393\n",
      "Batch 2080,  loss: 0.201983742415905\n",
      "Batch 2085,  loss: 0.17028959840536118\n",
      "Batch 2090,  loss: 0.173088338971138\n",
      "Batch 2095,  loss: 0.16433459818363189\n",
      "Batch 2100,  loss: 0.15516539812088012\n",
      "Batch 2105,  loss: 0.16782166957855224\n",
      "Batch 2110,  loss: 0.15446123629808425\n",
      "Batch 2115,  loss: 0.18703921139240265\n",
      "Batch 2120,  loss: 0.1390219435095787\n",
      "Batch 2125,  loss: 0.15002057403326036\n",
      "Batch 2130,  loss: 0.14536184072494507\n",
      "Batch 2135,  loss: 0.13658064156770705\n",
      "Batch 2140,  loss: 0.15009822696447372\n",
      "Batch 2145,  loss: 0.12601445019245147\n",
      "Batch 2150,  loss: 0.13164322078227997\n",
      "Batch 2155,  loss: 0.14861032962799073\n",
      "Batch 2160,  loss: 0.13909029960632324\n",
      "Batch 2165,  loss: 0.16676209568977357\n",
      "Batch 2170,  loss: 0.15964501202106476\n",
      "Batch 2175,  loss: 0.15439153611660003\n",
      "Batch 2180,  loss: 0.15590303540229797\n",
      "Batch 2185,  loss: 0.1482846111059189\n",
      "Batch 2190,  loss: 0.14468051344156266\n",
      "Batch 2195,  loss: 0.1378640741109848\n",
      "Batch 2200,  loss: 0.12362280488014221\n",
      "Batch 2205,  loss: 0.17359479069709777\n",
      "Batch 2210,  loss: 0.12612420916557313\n",
      "Batch 2215,  loss: 0.1429789513349533\n",
      "Batch 2220,  loss: 0.12207086086273193\n",
      "Batch 2225,  loss: 0.19451125860214233\n",
      "Batch 2230,  loss: 0.17912767231464385\n",
      "Batch 2235,  loss: 0.15916720926761627\n",
      "Batch 2240,  loss: 0.18229911625385284\n",
      "Batch 2245,  loss: 0.12771695852279663\n",
      "Batch 2250,  loss: 0.13994120359420775\n",
      "Batch 2255,  loss: 0.17996265292167662\n",
      "Batch 2260,  loss: 0.14551912546157836\n",
      "Batch 2265,  loss: 0.2107001394033432\n",
      "Batch 2270,  loss: 0.1502198502421379\n",
      "Batch 2275,  loss: 0.15170108079910277\n",
      "Batch 2280,  loss: 0.1385296732187271\n",
      "Batch 2285,  loss: 0.15920832753181458\n",
      "Batch 2290,  loss: 0.13899337202310563\n",
      "Batch 2295,  loss: 0.16558323055505753\n",
      "Batch 2300,  loss: 0.14314317107200622\n",
      "Batch 2305,  loss: 0.1658739537000656\n",
      "Batch 2310,  loss: 0.1352759540081024\n",
      "Batch 2315,  loss: 0.1879439115524292\n",
      "Batch 2320,  loss: 0.16974764913320542\n",
      "Batch 2325,  loss: 0.14482865780591964\n",
      "Batch 2330,  loss: 0.18937866687774657\n",
      "Batch 2335,  loss: 0.14525515139102935\n",
      "Batch 2340,  loss: 0.22540394365787506\n",
      "Batch 2345,  loss: 0.16545311808586122\n",
      "Batch 2350,  loss: 0.12922860831022262\n",
      "Batch 2355,  loss: 0.15122085064649582\n",
      "Batch 2360,  loss: 0.14535121917724608\n",
      "Batch 2365,  loss: 0.13967296183109285\n",
      "Batch 2370,  loss: 0.14620354622602463\n",
      "Batch 2375,  loss: 0.14696659445762633\n",
      "Batch 2380,  loss: 0.1724056988954544\n",
      "Batch 2385,  loss: 0.18667976707220077\n",
      "Batch 2390,  loss: 0.12702007442712784\n",
      "Batch 2395,  loss: 0.17538756132125854\n",
      "Batch 2400,  loss: 0.13836637735366822\n",
      "Batch 2405,  loss: 0.19998337626457213\n",
      "Batch 2410,  loss: 0.16435196846723557\n",
      "Batch 2415,  loss: 0.1563747465610504\n",
      "Batch 2420,  loss: 0.15319960713386535\n",
      "Batch 2425,  loss: 0.15760716199874877\n",
      "Batch 2430,  loss: 0.20775128602981568\n",
      "Batch 2435,  loss: 0.15482377409934997\n",
      "Batch 2440,  loss: 0.17386675179004668\n",
      "Batch 2445,  loss: 0.17644067406654357\n",
      "Batch 2450,  loss: 0.18130452036857606\n",
      "Batch 2455,  loss: 0.157028990983963\n",
      "Batch 2460,  loss: 0.122964408993721\n",
      "Batch 2465,  loss: 0.13158533722162247\n",
      "Batch 2470,  loss: 0.1453690305352211\n",
      "Batch 2475,  loss: 0.14562325328588485\n",
      "Batch 2480,  loss: 0.1939936637878418\n",
      "Batch 2485,  loss: 0.17660207450389862\n",
      "Batch 2490,  loss: 0.1763759583234787\n",
      "Batch 2495,  loss: 0.17014990895986556\n",
      "Batch 2500,  loss: 0.12329177558422089\n",
      "Batch 2505,  loss: 0.14397492855787278\n",
      "Batch 2510,  loss: 0.15956039130687713\n",
      "Batch 2515,  loss: 0.18567592948675155\n",
      "Batch 2520,  loss: 0.15690559446811675\n",
      "Batch 2525,  loss: 0.17729068398475648\n",
      "Batch 2530,  loss: 0.11961715966463089\n",
      "Batch 2535,  loss: 0.15253930389881135\n",
      "Batch 2540,  loss: 0.15192077606916427\n",
      "Batch 2545,  loss: 0.15509187281131745\n",
      "Batch 2550,  loss: 0.13059299886226655\n",
      "Batch 2555,  loss: 0.13160160630941392\n",
      "Batch 2560,  loss: 0.20783617794513704\n",
      "Batch 2565,  loss: 0.20073527693748475\n",
      "Batch 2570,  loss: 0.16068611145019532\n",
      "Batch 2575,  loss: 0.16599673330783843\n",
      "Batch 2580,  loss: 0.16482563614845275\n",
      "Batch 2585,  loss: 0.15100868344306945\n",
      "Batch 2590,  loss: 0.1168480709195137\n",
      "Batch 2595,  loss: 0.1524350970983505\n",
      "Batch 2600,  loss: 0.1871297687292099\n",
      "Batch 2605,  loss: 0.1500143975019455\n",
      "Batch 2610,  loss: 0.17121600210666657\n",
      "Batch 2615,  loss: 0.15022043287754058\n",
      "Batch 2620,  loss: 0.18135039806365966\n",
      "Batch 2625,  loss: 0.12934913635253906\n",
      "Batch 2630,  loss: 0.16835179328918456\n",
      "Batch 2635,  loss: 0.13354431092739105\n",
      "Batch 2640,  loss: 0.1629854291677475\n",
      "Batch 2645,  loss: 0.1633240431547165\n",
      "Batch 2650,  loss: 0.14436898231506348\n",
      "Batch 2655,  loss: 0.1591002196073532\n",
      "Batch 2660,  loss: 0.17147893458604813\n",
      "Batch 2665,  loss: 0.16220933347940444\n",
      "Batch 2670,  loss: 0.14904115200042725\n",
      "Batch 2675,  loss: 0.13262933641672134\n",
      "Batch 2680,  loss: 0.1380276009440422\n",
      "Batch 2685,  loss: 0.16661663353443146\n",
      "Batch 2690,  loss: 0.15679909586906432\n",
      "Batch 2695,  loss: 0.14546194821596145\n",
      "Batch 2700,  loss: 0.15674792528152465\n",
      "Batch 2705,  loss: 0.17170552909374237\n",
      "Batch 2710,  loss: 0.12208440899848938\n",
      "Batch 2715,  loss: 0.13856100291013718\n",
      "Batch 2720,  loss: 0.1625932812690735\n",
      "Batch 2725,  loss: 0.15399927645921707\n",
      "Batch 2730,  loss: 0.14939747303724288\n",
      "Batch 2735,  loss: 0.14463768899440765\n",
      "Batch 2740,  loss: 0.13932324349880218\n",
      "Batch 2745,  loss: 0.1952619209885597\n",
      "Batch 2750,  loss: 0.13506039083003998\n",
      "Batch 2755,  loss: 0.14254911243915558\n",
      "Batch 2760,  loss: 0.14853475689888002\n",
      "Batch 2765,  loss: 0.13741156160831453\n",
      "Batch 2770,  loss: 0.15647502839565278\n",
      "LOSS train 0.15647502839565278. Validation loss: 0.16074681762278217 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 34:\n",
      "Batch 5,  loss: 0.12015933692455291\n",
      "Batch 10,  loss: 0.13518698513507843\n",
      "Batch 15,  loss: 0.12488629668951035\n",
      "Batch 20,  loss: 0.16194804906845092\n",
      "Batch 25,  loss: 0.15497737973928452\n",
      "Batch 30,  loss: 0.16614652127027513\n",
      "Batch 35,  loss: 0.1587606132030487\n",
      "Batch 40,  loss: 0.09449977278709412\n",
      "Batch 45,  loss: 0.16725340783596038\n",
      "Batch 50,  loss: 0.20031230449676513\n",
      "Batch 55,  loss: 0.16556058824062347\n",
      "Batch 60,  loss: 0.17188360393047333\n",
      "Batch 65,  loss: 0.14908038675785065\n",
      "Batch 70,  loss: 0.13878773003816605\n",
      "Batch 75,  loss: 0.16238949894905091\n",
      "Batch 80,  loss: 0.1463263988494873\n",
      "Batch 85,  loss: 0.13288744688034057\n",
      "Batch 90,  loss: 0.1877492696046829\n",
      "Batch 95,  loss: 0.1310456782579422\n",
      "Batch 100,  loss: 0.15564825236797333\n",
      "Batch 105,  loss: 0.15718014389276505\n",
      "Batch 110,  loss: 0.1629203513264656\n",
      "Batch 115,  loss: 0.20479902923107146\n",
      "Batch 120,  loss: 0.13588259667158126\n",
      "Batch 125,  loss: 0.160169580578804\n",
      "Batch 130,  loss: 0.19136218428611756\n",
      "Batch 135,  loss: 0.15537335127592086\n",
      "Batch 140,  loss: 0.17948818504810332\n",
      "Batch 145,  loss: 0.1794047474861145\n",
      "Batch 150,  loss: 0.12198761701583863\n",
      "Batch 155,  loss: 0.1269899368286133\n",
      "Batch 160,  loss: 0.15662521719932557\n",
      "Batch 165,  loss: 0.19559262394905091\n",
      "Batch 170,  loss: 0.1543103963136673\n",
      "Batch 175,  loss: 0.1893083408474922\n",
      "Batch 180,  loss: 0.11662943214178086\n",
      "Batch 185,  loss: 0.19133222997188568\n",
      "Batch 190,  loss: 0.13064954578876495\n",
      "Batch 195,  loss: 0.13866256177425385\n",
      "Batch 200,  loss: 0.14555469602346421\n",
      "Batch 205,  loss: 0.13402161747217178\n",
      "Batch 210,  loss: 0.13458978682756423\n",
      "Batch 215,  loss: 0.12723225653171538\n",
      "Batch 220,  loss: 0.14830098748207093\n",
      "Batch 225,  loss: 0.1438399702310562\n",
      "Batch 230,  loss: 0.1688486158847809\n",
      "Batch 235,  loss: 0.15579112023115158\n",
      "Batch 240,  loss: 0.11548141837120056\n",
      "Batch 245,  loss: 0.16209086924791336\n",
      "Batch 250,  loss: 0.15554630309343337\n",
      "Batch 255,  loss: 0.16221333146095276\n",
      "Batch 260,  loss: 0.14337154775857924\n",
      "Batch 265,  loss: 0.1622902810573578\n",
      "Batch 270,  loss: 0.15187308192253113\n",
      "Batch 275,  loss: 0.1439918264746666\n",
      "Batch 280,  loss: 0.16452390551567078\n",
      "Batch 285,  loss: 0.1538261130452156\n",
      "Batch 290,  loss: 0.16768191754817963\n",
      "Batch 295,  loss: 0.15283406525850296\n",
      "Batch 300,  loss: 0.131265689432621\n",
      "Batch 305,  loss: 0.13927221149206162\n",
      "Batch 310,  loss: 0.1488781303167343\n",
      "Batch 315,  loss: 0.1432219460606575\n",
      "Batch 320,  loss: 0.17131960093975068\n",
      "Batch 325,  loss: 0.1799651265144348\n",
      "Batch 330,  loss: 0.12068658918142319\n",
      "Batch 335,  loss: 0.13206490874290466\n",
      "Batch 340,  loss: 0.1748819500207901\n",
      "Batch 345,  loss: 0.218739116191864\n",
      "Batch 350,  loss: 0.12838856130838394\n",
      "Batch 355,  loss: 0.17121981233358383\n",
      "Batch 360,  loss: 0.13033100962638855\n",
      "Batch 365,  loss: 0.18325527310371398\n",
      "Batch 370,  loss: 0.22968676090240478\n",
      "Batch 375,  loss: 0.1607826292514801\n",
      "Batch 380,  loss: 0.14231493920087815\n",
      "Batch 385,  loss: 0.14354390501976014\n",
      "Batch 390,  loss: 0.1550484701991081\n",
      "Batch 395,  loss: 0.14278167486190796\n",
      "Batch 400,  loss: 0.16688382923603057\n",
      "Batch 405,  loss: 0.1886477917432785\n",
      "Batch 410,  loss: 0.12719945907592772\n",
      "Batch 415,  loss: 0.2179548665881157\n",
      "Batch 420,  loss: 0.15033417344093322\n",
      "Batch 425,  loss: 0.14653777778148652\n",
      "Batch 430,  loss: 0.1609778270125389\n",
      "Batch 435,  loss: 0.1517568290233612\n",
      "Batch 440,  loss: 0.17697847485542298\n",
      "Batch 445,  loss: 0.17698225975036622\n",
      "Batch 450,  loss: 0.19917544573545456\n",
      "Batch 455,  loss: 0.1367709219455719\n",
      "Batch 460,  loss: 0.13558909744024278\n",
      "Batch 465,  loss: 0.12896305322647095\n",
      "Batch 470,  loss: 0.18397383391857147\n",
      "Batch 475,  loss: 0.18137950599193572\n",
      "Batch 480,  loss: 0.11973713040351867\n",
      "Batch 485,  loss: 0.16817718744277954\n",
      "Batch 490,  loss: 0.1680009514093399\n",
      "Batch 495,  loss: 0.1830889254808426\n",
      "Batch 500,  loss: 0.15274540185928345\n",
      "Batch 505,  loss: 0.14759716093540193\n",
      "Batch 510,  loss: 0.1460874170064926\n",
      "Batch 515,  loss: 0.1655656725168228\n",
      "Batch 520,  loss: 0.11114681363105774\n",
      "Batch 525,  loss: 0.1471614196896553\n",
      "Batch 530,  loss: 0.1635841727256775\n",
      "Batch 535,  loss: 0.20998568832874298\n",
      "Batch 540,  loss: 0.120431786775589\n",
      "Batch 545,  loss: 0.2078186884522438\n",
      "Batch 550,  loss: 0.1739623188972473\n",
      "Batch 555,  loss: 0.18186736702919007\n",
      "Batch 560,  loss: 0.15138148069381713\n",
      "Batch 565,  loss: 0.1538865715265274\n",
      "Batch 570,  loss: 0.17749978899955748\n",
      "Batch 575,  loss: 0.21133359670639038\n",
      "Batch 580,  loss: 0.142489992082119\n",
      "Batch 585,  loss: 0.15857930183410646\n",
      "Batch 590,  loss: 0.12934571206569673\n",
      "Batch 595,  loss: 0.21479108333587646\n",
      "Batch 600,  loss: 0.130749648809433\n",
      "Batch 605,  loss: 0.16308596283197402\n",
      "Batch 610,  loss: 0.16153264045715332\n",
      "Batch 615,  loss: 0.16094348430633545\n",
      "Batch 620,  loss: 0.17408015727996826\n",
      "Batch 625,  loss: 0.17223235666751863\n",
      "Batch 630,  loss: 0.17276761382818223\n",
      "Batch 635,  loss: 0.14362738728523256\n",
      "Batch 640,  loss: 0.19309925884008408\n",
      "Batch 645,  loss: 0.14462930262088775\n",
      "Batch 650,  loss: 0.16410184502601624\n",
      "Batch 655,  loss: 0.13989257514476777\n",
      "Batch 660,  loss: 0.12817926853895187\n",
      "Batch 665,  loss: 0.17311177551746368\n",
      "Batch 670,  loss: 0.14454809874296187\n",
      "Batch 675,  loss: 0.15277787148952485\n",
      "Batch 680,  loss: 0.15463331639766692\n",
      "Batch 685,  loss: 0.19447854161262512\n",
      "Batch 690,  loss: 0.1628438115119934\n",
      "Batch 695,  loss: 0.15616254210472108\n",
      "Batch 700,  loss: 0.1321197420358658\n",
      "Batch 705,  loss: 0.14752342998981477\n",
      "Batch 710,  loss: 0.16584513187408448\n",
      "Batch 715,  loss: 0.1528892546892166\n",
      "Batch 720,  loss: 0.14515646398067475\n",
      "Batch 725,  loss: 0.12486661374568939\n",
      "Batch 730,  loss: 0.13059847801923752\n",
      "Batch 735,  loss: 0.14615865051746368\n",
      "Batch 740,  loss: 0.1775974377989769\n",
      "Batch 745,  loss: 0.12255733609199523\n",
      "Batch 750,  loss: 0.15236794501543044\n",
      "Batch 755,  loss: 0.16943511366844177\n",
      "Batch 760,  loss: 0.1369388297200203\n",
      "Batch 765,  loss: 0.13934800326824187\n",
      "Batch 770,  loss: 0.16729169636964797\n",
      "Batch 775,  loss: 0.16281156241893768\n",
      "Batch 780,  loss: 0.1409958451986313\n",
      "Batch 785,  loss: 0.14666853845119476\n",
      "Batch 790,  loss: 0.1388944521546364\n",
      "Batch 795,  loss: 0.1478068396449089\n",
      "Batch 800,  loss: 0.12593794018030166\n",
      "Batch 805,  loss: 0.1770928233861923\n",
      "Batch 810,  loss: 0.11954840570688248\n",
      "Batch 815,  loss: 0.17662953585386276\n",
      "Batch 820,  loss: 0.13381375521421432\n",
      "Batch 825,  loss: 0.14702401757240297\n",
      "Batch 830,  loss: 0.13722627609968185\n",
      "Batch 835,  loss: 0.1353629931807518\n",
      "Batch 840,  loss: 0.18642616271972656\n",
      "Batch 845,  loss: 0.1310530796647072\n",
      "Batch 850,  loss: 0.13505351394414902\n",
      "Batch 855,  loss: 0.13050644993782043\n",
      "Batch 860,  loss: 0.1260431468486786\n",
      "Batch 865,  loss: 0.16859167218208312\n",
      "Batch 870,  loss: 0.12832153141498565\n",
      "Batch 875,  loss: 0.17953720688819885\n",
      "Batch 880,  loss: 0.17587977051734924\n",
      "Batch 885,  loss: 0.12600552141666413\n",
      "Batch 890,  loss: 0.14612467139959334\n",
      "Batch 895,  loss: 0.13648664206266403\n",
      "Batch 900,  loss: 0.1207184299826622\n",
      "Batch 905,  loss: 0.16344584822654723\n",
      "Batch 910,  loss: 0.15651503652334214\n",
      "Batch 915,  loss: 0.15667356550693512\n",
      "Batch 920,  loss: 0.1187216356396675\n",
      "Batch 925,  loss: 0.1397384524345398\n",
      "Batch 930,  loss: 0.1874847173690796\n",
      "Batch 935,  loss: 0.12177511006593704\n",
      "Batch 940,  loss: 0.1469767138361931\n",
      "Batch 945,  loss: 0.13943883776664734\n",
      "Batch 950,  loss: 0.14810101091861724\n",
      "Batch 955,  loss: 0.16244093626737593\n",
      "Batch 960,  loss: 0.15250960737466812\n",
      "Batch 965,  loss: 0.17481975257396698\n",
      "Batch 970,  loss: 0.17018310427665712\n",
      "Batch 975,  loss: 0.12140088230371475\n",
      "Batch 980,  loss: 0.14507387429475785\n",
      "Batch 985,  loss: 0.16596315950155258\n",
      "Batch 990,  loss: 0.15968976616859437\n",
      "Batch 995,  loss: 0.12931535691022872\n",
      "Batch 1000,  loss: 0.17238494455814363\n",
      "Batch 1005,  loss: 0.13510637283325194\n",
      "Batch 1010,  loss: 0.18352218270301818\n",
      "Batch 1015,  loss: 0.14773131608963014\n",
      "Batch 1020,  loss: 0.1578901916742325\n",
      "Batch 1025,  loss: 0.14384786337614058\n",
      "Batch 1030,  loss: 0.16234640181064605\n",
      "Batch 1035,  loss: 0.16025284230709075\n",
      "Batch 1040,  loss: 0.18381270170211791\n",
      "Batch 1045,  loss: 0.16344041824340821\n",
      "Batch 1050,  loss: 0.15933674126863479\n",
      "Batch 1055,  loss: 0.2397064223885536\n",
      "Batch 1060,  loss: 0.1661510944366455\n",
      "Batch 1065,  loss: 0.16883810758590698\n",
      "Batch 1070,  loss: 0.13967961817979813\n",
      "Batch 1075,  loss: 0.16254455596208572\n",
      "Batch 1080,  loss: 0.1402554526925087\n",
      "Batch 1085,  loss: 0.16379058957099915\n",
      "Batch 1090,  loss: 0.13190269321203232\n",
      "Batch 1095,  loss: 0.19465598165988923\n",
      "Batch 1100,  loss: 0.14695097804069518\n",
      "Batch 1105,  loss: 0.14894362688064575\n",
      "Batch 1110,  loss: 0.18428705632686615\n",
      "Batch 1115,  loss: 0.14747161269187928\n",
      "Batch 1120,  loss: 0.15431772619485856\n",
      "Batch 1125,  loss: 0.1322360411286354\n",
      "Batch 1130,  loss: 0.1566319763660431\n",
      "Batch 1135,  loss: 0.15924028754234315\n",
      "Batch 1140,  loss: 0.14663928747177124\n",
      "Batch 1145,  loss: 0.14705708026885986\n",
      "Batch 1150,  loss: 0.14431408941745758\n",
      "Batch 1155,  loss: 0.15285757035017014\n",
      "Batch 1160,  loss: 0.1358687847852707\n",
      "Batch 1165,  loss: 0.19661751091480256\n",
      "Batch 1170,  loss: 0.11729935556650162\n",
      "Batch 1175,  loss: 0.19201156497001648\n",
      "Batch 1180,  loss: 0.1883345663547516\n",
      "Batch 1185,  loss: 0.1497282028198242\n",
      "Batch 1190,  loss: 0.1419741690158844\n",
      "Batch 1195,  loss: 0.15939773619174957\n",
      "Batch 1200,  loss: 0.16130640655755996\n",
      "Batch 1205,  loss: 0.17819317132234574\n",
      "Batch 1210,  loss: 0.17416554987430571\n",
      "Batch 1215,  loss: 0.11897173374891282\n",
      "Batch 1220,  loss: 0.16746018826961517\n",
      "Batch 1225,  loss: 0.1662220239639282\n",
      "Batch 1230,  loss: 0.15117633193731309\n",
      "Batch 1235,  loss: 0.15463992804288865\n",
      "Batch 1240,  loss: 0.1457352429628372\n",
      "Batch 1245,  loss: 0.14613883644342424\n",
      "Batch 1250,  loss: 0.1497095614671707\n",
      "Batch 1255,  loss: 0.14552755951881408\n",
      "Batch 1260,  loss: 0.16660993099212645\n",
      "Batch 1265,  loss: 0.09575606286525726\n",
      "Batch 1270,  loss: 0.14499359130859374\n",
      "Batch 1275,  loss: 0.15559904873371125\n",
      "Batch 1280,  loss: 0.14510132670402526\n",
      "Batch 1285,  loss: 0.1961542397737503\n",
      "Batch 1290,  loss: 0.16937711387872695\n",
      "Batch 1295,  loss: 0.1426825687289238\n",
      "Batch 1300,  loss: 0.13419016152620317\n",
      "Batch 1305,  loss: 0.16416550576686859\n",
      "Batch 1310,  loss: 0.19738771319389342\n",
      "Batch 1315,  loss: 0.1686822846531868\n",
      "Batch 1320,  loss: 0.16034443974494933\n",
      "Batch 1325,  loss: 0.15344279408454894\n",
      "Batch 1330,  loss: 0.15433957427740097\n",
      "Batch 1335,  loss: 0.12220496535301209\n",
      "Batch 1340,  loss: 0.15950092822313308\n",
      "Batch 1345,  loss: 0.1661994069814682\n",
      "Batch 1350,  loss: 0.125779327750206\n",
      "Batch 1355,  loss: 0.1503814145922661\n",
      "Batch 1360,  loss: 0.18600288331508635\n",
      "Batch 1365,  loss: 0.1281568169593811\n",
      "Batch 1370,  loss: 0.1635693907737732\n",
      "Batch 1375,  loss: 0.15774141550064086\n",
      "Batch 1380,  loss: 0.14919177889823915\n",
      "Batch 1385,  loss: 0.21745225489139558\n",
      "Batch 1390,  loss: 0.18965207636356354\n",
      "Batch 1395,  loss: 0.15490223467350006\n",
      "Batch 1400,  loss: 0.17614631354808807\n",
      "Batch 1405,  loss: 0.17719661593437194\n",
      "Batch 1410,  loss: 0.20885988771915437\n",
      "Batch 1415,  loss: 0.11599483639001847\n",
      "Batch 1420,  loss: 0.1634223610162735\n",
      "Batch 1425,  loss: 0.15366664826869963\n",
      "Batch 1430,  loss: 0.15871039777994156\n",
      "Batch 1435,  loss: 0.13693761825561523\n",
      "Batch 1440,  loss: 0.14121008217334746\n",
      "Batch 1445,  loss: 0.13925631046295167\n",
      "Batch 1450,  loss: 0.14593796133995057\n",
      "Batch 1455,  loss: 0.14006620794534683\n",
      "Batch 1460,  loss: 0.1575810953974724\n",
      "Batch 1465,  loss: 0.14566873759031296\n",
      "Batch 1470,  loss: 0.1522965520620346\n",
      "Batch 1475,  loss: 0.1571672558784485\n",
      "Batch 1480,  loss: 0.16176507472991944\n",
      "Batch 1485,  loss: 0.1612121880054474\n",
      "Batch 1490,  loss: 0.1604280114173889\n",
      "Batch 1495,  loss: 0.1552253007888794\n",
      "Batch 1500,  loss: 0.1846732795238495\n",
      "Batch 1505,  loss: 0.15681918561458588\n",
      "Batch 1510,  loss: 0.18126822263002396\n",
      "Batch 1515,  loss: 0.13474837243556975\n",
      "Batch 1520,  loss: 0.13006542772054672\n",
      "Batch 1525,  loss: 0.16258905082941055\n",
      "Batch 1530,  loss: 0.150843146443367\n",
      "Batch 1535,  loss: 0.13185027837753296\n",
      "Batch 1540,  loss: 0.1320279523730278\n",
      "Batch 1545,  loss: 0.12790519446134568\n",
      "Batch 1550,  loss: 0.15863550305366517\n",
      "Batch 1555,  loss: 0.14020437151193618\n",
      "Batch 1560,  loss: 0.11610091924667358\n",
      "Batch 1565,  loss: 0.1596752494573593\n",
      "Batch 1570,  loss: 0.20675992220640182\n",
      "Batch 1575,  loss: 0.1782232016324997\n",
      "Batch 1580,  loss: 0.13280270844697953\n",
      "Batch 1585,  loss: 0.17216574847698213\n",
      "Batch 1590,  loss: 0.16178009212017058\n",
      "Batch 1595,  loss: 0.1722120463848114\n",
      "Batch 1600,  loss: 0.15312440395355226\n",
      "Batch 1605,  loss: 0.1767822712659836\n",
      "Batch 1610,  loss: 0.17983103394508362\n",
      "Batch 1615,  loss: 0.1634691596031189\n",
      "Batch 1620,  loss: 0.21769038438796998\n",
      "Batch 1625,  loss: 0.1763877809047699\n",
      "Batch 1630,  loss: 0.1522191971540451\n",
      "Batch 1635,  loss: 0.1767515182495117\n",
      "Batch 1640,  loss: 0.22316633462905883\n",
      "Batch 1645,  loss: 0.16746560633182525\n",
      "Batch 1650,  loss: 0.17588340640068054\n",
      "Batch 1655,  loss: 0.1616791933774948\n",
      "Batch 1660,  loss: 0.16751072108745574\n",
      "Batch 1665,  loss: 0.17406168580055237\n",
      "Batch 1670,  loss: 0.13930745273828507\n",
      "Batch 1675,  loss: 0.1394958898425102\n",
      "Batch 1680,  loss: 0.17309648990631105\n",
      "Batch 1685,  loss: 0.15434718877077103\n",
      "Batch 1690,  loss: 0.15441389381885529\n",
      "Batch 1695,  loss: 0.20450825691223146\n",
      "Batch 1700,  loss: 0.16094791889190674\n",
      "Batch 1705,  loss: 0.12958396673202516\n",
      "Batch 1710,  loss: 0.13113835006952285\n",
      "Batch 1715,  loss: 0.1672057181596756\n",
      "Batch 1720,  loss: 0.1592449277639389\n",
      "Batch 1725,  loss: 0.16117168366909027\n",
      "Batch 1730,  loss: 0.15081390738487244\n",
      "Batch 1735,  loss: 0.19054914712905885\n",
      "Batch 1740,  loss: 0.13585658520460128\n",
      "Batch 1745,  loss: 0.1335553675889969\n",
      "Batch 1750,  loss: 0.15490662455558776\n",
      "Batch 1755,  loss: 0.1749449700117111\n",
      "Batch 1760,  loss: 0.18628838211297988\n",
      "Batch 1765,  loss: 0.1863050103187561\n",
      "Batch 1770,  loss: 0.15564090460538865\n",
      "Batch 1775,  loss: 0.14793019145727157\n",
      "Batch 1780,  loss: 0.16676761507987975\n",
      "Batch 1785,  loss: 0.13993780314922333\n",
      "Batch 1790,  loss: 0.15537335872650146\n",
      "Batch 1795,  loss: 0.14543091803789138\n",
      "Batch 1800,  loss: 0.16484047770500182\n",
      "Batch 1805,  loss: 0.16175104677677155\n",
      "Batch 1810,  loss: 0.14385681450366974\n",
      "Batch 1815,  loss: 0.13163311183452606\n",
      "Batch 1820,  loss: 0.15650517791509627\n",
      "Batch 1825,  loss: 0.1549850046634674\n",
      "Batch 1830,  loss: 0.18438044786453248\n",
      "Batch 1835,  loss: 0.17561526149511336\n",
      "Batch 1840,  loss: 0.1686749428510666\n",
      "Batch 1845,  loss: 0.15246680676937102\n",
      "Batch 1850,  loss: 0.1134895697236061\n",
      "Batch 1855,  loss: 0.15532545894384384\n",
      "Batch 1860,  loss: 0.20235477685928344\n",
      "Batch 1865,  loss: 0.14950976967811586\n",
      "Batch 1870,  loss: 0.1655008986592293\n",
      "Batch 1875,  loss: 0.15845493525266646\n",
      "Batch 1880,  loss: 0.1523815095424652\n",
      "Batch 1885,  loss: 0.15642514824867249\n",
      "Batch 1890,  loss: 0.12101018130779266\n",
      "Batch 1895,  loss: 0.16192401051521302\n",
      "Batch 1900,  loss: 0.1481043964624405\n",
      "Batch 1905,  loss: 0.14233216941356658\n",
      "Batch 1910,  loss: 0.11485550850629807\n",
      "Batch 1915,  loss: 0.15414245426654816\n",
      "Batch 1920,  loss: 0.11371046304702759\n",
      "Batch 1925,  loss: 0.20823386013507844\n",
      "Batch 1930,  loss: 0.14774016290903091\n",
      "Batch 1935,  loss: 0.16832152605056763\n",
      "Batch 1940,  loss: 0.17840893864631652\n",
      "Batch 1945,  loss: 0.20018174648284912\n",
      "Batch 1950,  loss: 0.18681861758232116\n",
      "Batch 1955,  loss: 0.15515264123678207\n",
      "Batch 1960,  loss: 0.13165842443704606\n",
      "Batch 1965,  loss: 0.16442127674818038\n",
      "Batch 1970,  loss: 0.16148505061864854\n",
      "Batch 1975,  loss: 0.11805014312267303\n",
      "Batch 1980,  loss: 0.181860613822937\n",
      "Batch 1985,  loss: 0.15593950897455217\n",
      "Batch 1990,  loss: 0.1419993057847023\n",
      "Batch 1995,  loss: 0.15691051185131072\n",
      "Batch 2000,  loss: 0.15450655221939086\n",
      "Batch 2005,  loss: 0.1404434472322464\n",
      "Batch 2010,  loss: 0.1355978235602379\n",
      "Batch 2015,  loss: 0.15754982233047485\n",
      "Batch 2020,  loss: 0.16923071295022965\n",
      "Batch 2025,  loss: 0.1966879963874817\n",
      "Batch 2030,  loss: 0.16063312888145448\n",
      "Batch 2035,  loss: 0.1351967930793762\n",
      "Batch 2040,  loss: 0.1420602649450302\n",
      "Batch 2045,  loss: 0.18420595824718475\n",
      "Batch 2050,  loss: 0.16225126385688782\n",
      "Batch 2055,  loss: 0.18253106772899627\n",
      "Batch 2060,  loss: 0.16990925520658492\n",
      "Batch 2065,  loss: 0.18966183811426163\n",
      "Batch 2070,  loss: 0.16770956814289092\n",
      "Batch 2075,  loss: 0.12145874947309494\n",
      "Batch 2080,  loss: 0.16550211608409882\n",
      "Batch 2085,  loss: 0.10780082494020463\n",
      "Batch 2090,  loss: 0.15208935737609863\n",
      "Batch 2095,  loss: 0.18174329698085784\n",
      "Batch 2100,  loss: 0.1685555249452591\n",
      "Batch 2105,  loss: 0.12611485570669173\n",
      "Batch 2110,  loss: 0.16414326578378677\n",
      "Batch 2115,  loss: 0.15921266973018647\n",
      "Batch 2120,  loss: 0.13103647232055665\n",
      "Batch 2125,  loss: 0.15046483874320984\n",
      "Batch 2130,  loss: 0.1979344055056572\n",
      "Batch 2135,  loss: 0.1674307703971863\n",
      "Batch 2140,  loss: 0.1403422772884369\n",
      "Batch 2145,  loss: 0.13981789350509644\n",
      "Batch 2150,  loss: 0.14957084357738495\n",
      "Batch 2155,  loss: 0.1519756317138672\n",
      "Batch 2160,  loss: 0.1815386086702347\n",
      "Batch 2165,  loss: 0.17987691164016723\n",
      "Batch 2170,  loss: 0.15802280455827714\n",
      "Batch 2175,  loss: 0.12893011271953583\n",
      "Batch 2180,  loss: 0.14591338634490966\n",
      "Batch 2185,  loss: 0.15196703523397445\n",
      "Batch 2190,  loss: 0.1478360339999199\n",
      "Batch 2195,  loss: 0.16691911071538926\n",
      "Batch 2200,  loss: 0.18109166920185088\n",
      "Batch 2205,  loss: 0.15733546018600464\n",
      "Batch 2210,  loss: 0.14923729598522187\n",
      "Batch 2215,  loss: 0.13501180708408356\n",
      "Batch 2220,  loss: 0.1519190788269043\n",
      "Batch 2225,  loss: 0.14830079376697541\n",
      "Batch 2230,  loss: 0.12456400841474533\n",
      "Batch 2235,  loss: 0.1663312315940857\n",
      "Batch 2240,  loss: 0.17850657403469086\n",
      "Batch 2245,  loss: 0.15427899360656738\n",
      "Batch 2250,  loss: 0.1416783720254898\n",
      "Batch 2255,  loss: 0.138905131816864\n",
      "Batch 2260,  loss: 0.13033667504787444\n",
      "Batch 2265,  loss: 0.1630487859249115\n",
      "Batch 2270,  loss: 0.12498946785926819\n",
      "Batch 2275,  loss: 0.14000222980976104\n",
      "Batch 2280,  loss: 0.14957622885704042\n",
      "Batch 2285,  loss: 0.20276024341583251\n",
      "Batch 2290,  loss: 0.1646600365638733\n",
      "Batch 2295,  loss: 0.14976991713047028\n",
      "Batch 2300,  loss: 0.1437650889158249\n",
      "Batch 2305,  loss: 0.21210498809814454\n",
      "Batch 2310,  loss: 0.14380932599306107\n",
      "Batch 2315,  loss: 0.1449253737926483\n",
      "Batch 2320,  loss: 0.11290768682956695\n",
      "Batch 2325,  loss: 0.13201503455638885\n",
      "Batch 2330,  loss: 0.15661906749010085\n",
      "Batch 2335,  loss: 0.15712771713733673\n",
      "Batch 2340,  loss: 0.13650397956371307\n",
      "Batch 2345,  loss: 0.18047652244567872\n",
      "Batch 2350,  loss: 0.15215740501880645\n",
      "Batch 2355,  loss: 0.16993710696697234\n",
      "Batch 2360,  loss: 0.1311400443315506\n",
      "Batch 2365,  loss: 0.10536524802446365\n",
      "Batch 2370,  loss: 0.18629867434501649\n",
      "Batch 2375,  loss: 0.13970580846071243\n",
      "Batch 2380,  loss: 0.11212310940027237\n",
      "Batch 2385,  loss: 0.16200078129768372\n",
      "Batch 2390,  loss: 0.15047181248664857\n",
      "Batch 2395,  loss: 0.15598748177289962\n",
      "Batch 2400,  loss: 0.17785740792751312\n",
      "Batch 2405,  loss: 0.17149470150470733\n",
      "Batch 2410,  loss: 0.14032432734966277\n",
      "Batch 2415,  loss: 0.12701280415058136\n",
      "Batch 2420,  loss: 0.16312529295682907\n",
      "Batch 2425,  loss: 0.16346472799777984\n",
      "Batch 2430,  loss: 0.18841318786144257\n",
      "Batch 2435,  loss: 0.23614716529846191\n",
      "Batch 2440,  loss: 0.12005313783884049\n",
      "Batch 2445,  loss: 0.12261815667152405\n",
      "Batch 2450,  loss: 0.15357818454504013\n",
      "Batch 2455,  loss: 0.14837354868650438\n",
      "Batch 2460,  loss: 0.14555672705173492\n",
      "Batch 2465,  loss: 0.1403859093785286\n",
      "Batch 2470,  loss: 0.12460508048534394\n",
      "Batch 2475,  loss: 0.11682942062616349\n",
      "Batch 2480,  loss: 0.14913036525249482\n",
      "Batch 2485,  loss: 0.17110126316547394\n",
      "Batch 2490,  loss: 0.13116155862808226\n",
      "Batch 2495,  loss: 0.1607479691505432\n",
      "Batch 2500,  loss: 0.17565647065639495\n",
      "Batch 2505,  loss: 0.17133838534355164\n",
      "Batch 2510,  loss: 0.14063482284545897\n",
      "Batch 2515,  loss: 0.1184114933013916\n",
      "Batch 2520,  loss: 0.16403605937957763\n",
      "Batch 2525,  loss: 0.15034815967082976\n",
      "Batch 2530,  loss: 0.1770767956972122\n",
      "Batch 2535,  loss: 0.12873297333717346\n",
      "Batch 2540,  loss: 0.1476619005203247\n",
      "Batch 2545,  loss: 0.17359925359487532\n",
      "Batch 2550,  loss: 0.16187611669301988\n",
      "Batch 2555,  loss: 0.15449115335941316\n",
      "Batch 2560,  loss: 0.2457680583000183\n",
      "Batch 2565,  loss: 0.15032685399055482\n",
      "Batch 2570,  loss: 0.14891639351844788\n",
      "Batch 2575,  loss: 0.14020849019289017\n",
      "Batch 2580,  loss: 0.14727852791547774\n",
      "Batch 2585,  loss: 0.17007655501365662\n",
      "Batch 2590,  loss: 0.14651235491037368\n",
      "Batch 2595,  loss: 0.13047315031290055\n",
      "Batch 2600,  loss: 0.18246536403894426\n",
      "Batch 2605,  loss: 0.1299416020512581\n",
      "Batch 2610,  loss: 0.17179224491119385\n",
      "Batch 2615,  loss: 0.1357377752661705\n",
      "Batch 2620,  loss: 0.1405043423175812\n",
      "Batch 2625,  loss: 0.13348369896411896\n",
      "Batch 2630,  loss: 0.17136374413967131\n",
      "Batch 2635,  loss: 0.18870698511600495\n",
      "Batch 2640,  loss: 0.145029217004776\n",
      "Batch 2645,  loss: 0.15732677578926085\n",
      "Batch 2650,  loss: 0.14040845334529878\n",
      "Batch 2655,  loss: 0.1923751175403595\n",
      "Batch 2660,  loss: 0.20410817861557007\n",
      "Batch 2665,  loss: 0.1442233771085739\n",
      "Batch 2670,  loss: 0.1332106977701187\n",
      "Batch 2675,  loss: 0.14118724912405015\n",
      "Batch 2680,  loss: 0.14567734003067018\n",
      "Batch 2685,  loss: 0.1515726014971733\n",
      "Batch 2690,  loss: 0.1441172793507576\n",
      "Batch 2695,  loss: 0.156953889131546\n",
      "Batch 2700,  loss: 0.13519271910190583\n",
      "Batch 2705,  loss: 0.17952836453914642\n",
      "Batch 2710,  loss: 0.20822449326515197\n",
      "Batch 2715,  loss: 0.13894351422786713\n",
      "Batch 2720,  loss: 0.16414294689893721\n",
      "Batch 2725,  loss: 0.13125717639923096\n",
      "Batch 2730,  loss: 0.15928743183612823\n",
      "Batch 2735,  loss: 0.12514689266681672\n",
      "Batch 2740,  loss: 0.12457561194896698\n",
      "Batch 2745,  loss: 0.16397807002067566\n",
      "Batch 2750,  loss: 0.1395028442144394\n",
      "Batch 2755,  loss: 0.14064578711986542\n",
      "Batch 2760,  loss: 0.1543429434299469\n",
      "Batch 2765,  loss: 0.15603554248809814\n",
      "Batch 2770,  loss: 0.15924755334854127\n",
      "LOSS train 0.15924755334854127. Validation loss: 0.1564180444233999 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 35:\n",
      "Batch 5,  loss: 0.16817966401576995\n",
      "Batch 10,  loss: 0.12486739754676819\n",
      "Batch 15,  loss: 0.14308889210224152\n",
      "Batch 20,  loss: 0.15006707608699799\n",
      "Batch 25,  loss: 0.13809402734041215\n",
      "Batch 30,  loss: 0.1618478327989578\n",
      "Batch 35,  loss: 0.1540326625108719\n",
      "Batch 40,  loss: 0.1852987140417099\n",
      "Batch 45,  loss: 0.16966152489185332\n",
      "Batch 50,  loss: 0.14097397178411483\n",
      "Batch 55,  loss: 0.14408615380525588\n",
      "Batch 60,  loss: 0.1435069888830185\n",
      "Batch 65,  loss: 0.21501764953136443\n",
      "Batch 70,  loss: 0.15179707258939742\n",
      "Batch 75,  loss: 0.13889136761426926\n",
      "Batch 80,  loss: 0.15127330720424653\n",
      "Batch 85,  loss: 0.14470457136631013\n",
      "Batch 90,  loss: 0.1787226215004921\n",
      "Batch 95,  loss: 0.13440648913383485\n",
      "Batch 100,  loss: 0.14952879399061203\n",
      "Batch 105,  loss: 0.17366446405649186\n",
      "Batch 110,  loss: 0.1298600196838379\n",
      "Batch 115,  loss: 0.15185140669345856\n",
      "Batch 120,  loss: 0.17103011310100555\n",
      "Batch 125,  loss: 0.203615902364254\n",
      "Batch 130,  loss: 0.15808158069849015\n",
      "Batch 135,  loss: 0.1360226094722748\n",
      "Batch 140,  loss: 0.1309374213218689\n",
      "Batch 145,  loss: 0.20154154002666474\n",
      "Batch 150,  loss: 0.16013250201940538\n",
      "Batch 155,  loss: 0.12787872552871704\n",
      "Batch 160,  loss: 0.14489016234874724\n",
      "Batch 165,  loss: 0.13195195496082307\n",
      "Batch 170,  loss: 0.16877453327178954\n",
      "Batch 175,  loss: 0.12017694860696793\n",
      "Batch 180,  loss: 0.2054920956492424\n",
      "Batch 185,  loss: 0.15297293663024902\n",
      "Batch 190,  loss: 0.17911145836114883\n",
      "Batch 195,  loss: 0.15966204106807708\n",
      "Batch 200,  loss: 0.16996304988861083\n",
      "Batch 205,  loss: 0.1399855747818947\n",
      "Batch 210,  loss: 0.1478567212820053\n",
      "Batch 215,  loss: 0.11263150721788406\n",
      "Batch 220,  loss: 0.1685186058282852\n",
      "Batch 225,  loss: 0.1549731433391571\n",
      "Batch 230,  loss: 0.18074471056461333\n",
      "Batch 235,  loss: 0.1446889415383339\n",
      "Batch 240,  loss: 0.14776805341243743\n",
      "Batch 245,  loss: 0.17355302572250367\n",
      "Batch 250,  loss: 0.12791746556758882\n",
      "Batch 255,  loss: 0.16809764504432678\n",
      "Batch 260,  loss: 0.18825463354587554\n",
      "Batch 265,  loss: 0.16770167052745819\n",
      "Batch 270,  loss: 0.1653105229139328\n",
      "Batch 275,  loss: 0.17763794362545013\n",
      "Batch 280,  loss: 0.17540788054466247\n",
      "Batch 285,  loss: 0.13877232372760773\n",
      "Batch 290,  loss: 0.15777106285095216\n",
      "Batch 295,  loss: 0.16210819780826569\n",
      "Batch 300,  loss: 0.14244226217269898\n",
      "Batch 305,  loss: 0.13999768495559692\n",
      "Batch 310,  loss: 0.14787604212760924\n",
      "Batch 315,  loss: 0.11658142507076263\n",
      "Batch 320,  loss: 0.1338802009820938\n",
      "Batch 325,  loss: 0.17168448269367217\n",
      "Batch 330,  loss: 0.13106558173894883\n",
      "Batch 335,  loss: 0.1528788462281227\n",
      "Batch 340,  loss: 0.18269370198249818\n",
      "Batch 345,  loss: 0.13028403073549272\n",
      "Batch 350,  loss: 0.2653424710035324\n",
      "Batch 355,  loss: 0.15514105558395386\n",
      "Batch 360,  loss: 0.20884034782648087\n",
      "Batch 365,  loss: 0.1828321933746338\n",
      "Batch 370,  loss: 0.10680548697710038\n",
      "Batch 375,  loss: 0.1216466099023819\n",
      "Batch 380,  loss: 0.18344777524471284\n",
      "Batch 385,  loss: 0.12160945385694504\n",
      "Batch 390,  loss: 0.17326113283634187\n",
      "Batch 395,  loss: 0.16997012495994568\n",
      "Batch 400,  loss: 0.16717723309993743\n",
      "Batch 405,  loss: 0.1241185948252678\n",
      "Batch 410,  loss: 0.19838381111621856\n",
      "Batch 415,  loss: 0.12724249362945556\n",
      "Batch 420,  loss: 0.18303917348384857\n",
      "Batch 425,  loss: 0.14512057453393937\n",
      "Batch 430,  loss: 0.12211508303880692\n",
      "Batch 435,  loss: 0.16023982167243958\n",
      "Batch 440,  loss: 0.14028331488370896\n",
      "Batch 445,  loss: 0.15929133892059327\n",
      "Batch 450,  loss: 0.15905836522579192\n",
      "Batch 455,  loss: 0.15012420117855071\n",
      "Batch 460,  loss: 0.15533455908298494\n",
      "Batch 465,  loss: 0.1450596883893013\n",
      "Batch 470,  loss: 0.18205812573432922\n",
      "Batch 475,  loss: 0.1900070309638977\n",
      "Batch 480,  loss: 0.16847746074199677\n",
      "Batch 485,  loss: 0.13951144814491273\n",
      "Batch 490,  loss: 0.12263981699943542\n",
      "Batch 495,  loss: 0.1795766144990921\n",
      "Batch 500,  loss: 0.17204601168632508\n",
      "Batch 505,  loss: 0.17525866627693176\n",
      "Batch 510,  loss: 0.14812456965446472\n",
      "Batch 515,  loss: 0.17846251428127288\n",
      "Batch 520,  loss: 0.19790729582309724\n",
      "Batch 525,  loss: 0.1654570907354355\n",
      "Batch 530,  loss: 0.15584920048713685\n",
      "Batch 535,  loss: 0.18793835937976838\n",
      "Batch 540,  loss: 0.15143848657608033\n",
      "Batch 545,  loss: 0.12429972887039184\n",
      "Batch 550,  loss: 0.14193424135446547\n",
      "Batch 555,  loss: 0.13281429260969163\n",
      "Batch 560,  loss: 0.1679416000843048\n",
      "Batch 565,  loss: 0.1596684515476227\n",
      "Batch 570,  loss: 0.1491420090198517\n",
      "Batch 575,  loss: 0.1869669884443283\n",
      "Batch 580,  loss: 0.19580218344926834\n",
      "Batch 585,  loss: 0.14624003171920777\n",
      "Batch 590,  loss: 0.1548309162259102\n",
      "Batch 595,  loss: 0.15545371919870377\n",
      "Batch 600,  loss: 0.1621868222951889\n",
      "Batch 605,  loss: 0.1519977182149887\n",
      "Batch 610,  loss: 0.1216501384973526\n",
      "Batch 615,  loss: 0.197959366440773\n",
      "Batch 620,  loss: 0.1323714405298233\n",
      "Batch 625,  loss: 0.1545902818441391\n",
      "Batch 630,  loss: 0.15015922784805297\n",
      "Batch 635,  loss: 0.18759662061929702\n",
      "Batch 640,  loss: 0.14720083326101302\n",
      "Batch 645,  loss: 0.1801472157239914\n",
      "Batch 650,  loss: 0.13124799430370332\n",
      "Batch 655,  loss: 0.16067034900188445\n",
      "Batch 660,  loss: 0.12787131369113922\n",
      "Batch 665,  loss: 0.16407542377710344\n",
      "Batch 670,  loss: 0.12322577834129333\n",
      "Batch 675,  loss: 0.1472103476524353\n",
      "Batch 680,  loss: 0.14008525460958482\n",
      "Batch 685,  loss: 0.17586093842983247\n",
      "Batch 690,  loss: 0.13242821395397186\n",
      "Batch 695,  loss: 0.14700105488300325\n",
      "Batch 700,  loss: 0.1396706745028496\n",
      "Batch 705,  loss: 0.19877234399318694\n",
      "Batch 710,  loss: 0.14974080324172973\n",
      "Batch 715,  loss: 0.15395515859127046\n",
      "Batch 720,  loss: 0.16721184998750688\n",
      "Batch 725,  loss: 0.17516766339540482\n",
      "Batch 730,  loss: 0.14160434454679488\n",
      "Batch 735,  loss: 0.22998882830142975\n",
      "Batch 740,  loss: 0.14898520708084106\n",
      "Batch 745,  loss: 0.13587713241577148\n",
      "Batch 750,  loss: 0.12876155227422714\n",
      "Batch 755,  loss: 0.1673145353794098\n",
      "Batch 760,  loss: 0.11182929426431656\n",
      "Batch 765,  loss: 0.25010141134262087\n",
      "Batch 770,  loss: 0.16688631772994994\n",
      "Batch 775,  loss: 0.1299392968416214\n",
      "Batch 780,  loss: 0.1418968603014946\n",
      "Batch 785,  loss: 0.16747473180294037\n",
      "Batch 790,  loss: 0.1476125657558441\n",
      "Batch 795,  loss: 0.2338479772210121\n",
      "Batch 800,  loss: 0.14028401374816896\n",
      "Batch 805,  loss: 0.18082341998815538\n",
      "Batch 810,  loss: 0.1401522070169449\n",
      "Batch 815,  loss: 0.1501092568039894\n",
      "Batch 820,  loss: 0.22650428414344786\n",
      "Batch 825,  loss: 0.1438310921192169\n",
      "Batch 830,  loss: 0.15482079982757568\n",
      "Batch 835,  loss: 0.14272412061691284\n",
      "Batch 840,  loss: 0.1554710865020752\n",
      "Batch 845,  loss: 0.1451659008860588\n",
      "Batch 850,  loss: 0.19643850475549698\n",
      "Batch 855,  loss: 0.1645822376012802\n",
      "Batch 860,  loss: 0.12011526674032211\n",
      "Batch 865,  loss: 0.14505296796560288\n",
      "Batch 870,  loss: 0.14728541374206544\n",
      "Batch 875,  loss: 0.1553933635354042\n",
      "Batch 880,  loss: 0.17261431813240052\n",
      "Batch 885,  loss: 0.1589006170630455\n",
      "Batch 890,  loss: 0.1505380243062973\n",
      "Batch 895,  loss: 0.17056456804275513\n",
      "Batch 900,  loss: 0.2106516182422638\n",
      "Batch 905,  loss: 0.10555951595306397\n",
      "Batch 910,  loss: 0.1380079910159111\n",
      "Batch 915,  loss: 0.15910786092281343\n",
      "Batch 920,  loss: 0.16474772691726686\n",
      "Batch 925,  loss: 0.1640922874212265\n",
      "Batch 930,  loss: 0.10801454186439514\n",
      "Batch 935,  loss: 0.15934713184833527\n",
      "Batch 940,  loss: 0.16310964673757553\n",
      "Batch 945,  loss: 0.15389769971370698\n",
      "Batch 950,  loss: 0.18820179700851442\n",
      "Batch 955,  loss: 0.146701081097126\n",
      "Batch 960,  loss: 0.1406106948852539\n",
      "Batch 965,  loss: 0.16628921031951904\n",
      "Batch 970,  loss: 0.16021281927824021\n",
      "Batch 975,  loss: 0.1362119972705841\n",
      "Batch 980,  loss: 0.14521438032388687\n",
      "Batch 985,  loss: 0.16046757996082306\n",
      "Batch 990,  loss: 0.11762752383947372\n",
      "Batch 995,  loss: 0.1634344130754471\n",
      "Batch 1000,  loss: 0.14482647329568862\n",
      "Batch 1005,  loss: 0.1328663244843483\n",
      "Batch 1010,  loss: 0.14761215150356294\n",
      "Batch 1015,  loss: 0.1961446911096573\n",
      "Batch 1020,  loss: 0.13120120614767075\n",
      "Batch 1025,  loss: 0.20695706009864806\n",
      "Batch 1030,  loss: 0.15686900913715363\n",
      "Batch 1035,  loss: 0.15596893131732942\n",
      "Batch 1040,  loss: 0.1429701939225197\n",
      "Batch 1045,  loss: 0.14524613618850707\n",
      "Batch 1050,  loss: 0.16954046338796616\n",
      "Batch 1055,  loss: 0.1692959576845169\n",
      "Batch 1060,  loss: 0.1335597366094589\n",
      "Batch 1065,  loss: 0.18467190712690354\n",
      "Batch 1070,  loss: 0.13835522830486296\n",
      "Batch 1075,  loss: 0.15135439336299897\n",
      "Batch 1080,  loss: 0.11353464424610138\n",
      "Batch 1085,  loss: 0.14688963145017625\n",
      "Batch 1090,  loss: 0.14740775823593139\n",
      "Batch 1095,  loss: 0.11419765949249268\n",
      "Batch 1100,  loss: 0.1429123744368553\n",
      "Batch 1105,  loss: 0.14165668338537216\n",
      "Batch 1110,  loss: 0.2023361712694168\n",
      "Batch 1115,  loss: 0.22035953849554063\n",
      "Batch 1120,  loss: 0.16387032121419906\n",
      "Batch 1125,  loss: 0.14797601997852325\n",
      "Batch 1130,  loss: 0.17600672245025634\n",
      "Batch 1135,  loss: 0.12902391254901885\n",
      "Batch 1140,  loss: 0.1253563329577446\n",
      "Batch 1145,  loss: 0.11906232535839081\n",
      "Batch 1150,  loss: 0.1328165203332901\n",
      "Batch 1155,  loss: 0.1354486107826233\n",
      "Batch 1160,  loss: 0.24264632165431976\n",
      "Batch 1165,  loss: 0.22275611758232117\n",
      "Batch 1170,  loss: 0.1588992953300476\n",
      "Batch 1175,  loss: 0.13384602963924408\n",
      "Batch 1180,  loss: 0.13527488857507705\n",
      "Batch 1185,  loss: 0.15205639004707336\n",
      "Batch 1190,  loss: 0.18944062292575836\n",
      "Batch 1195,  loss: 0.15674727261066437\n",
      "Batch 1200,  loss: 0.12951367646455764\n",
      "Batch 1205,  loss: 0.14410220682621003\n",
      "Batch 1210,  loss: 0.12819414138793944\n",
      "Batch 1215,  loss: 0.17399258762598038\n",
      "Batch 1220,  loss: 0.15465041100978852\n",
      "Batch 1225,  loss: 0.2315798819065094\n",
      "Batch 1230,  loss: 0.13420868664979935\n",
      "Batch 1235,  loss: 0.1612066626548767\n",
      "Batch 1240,  loss: 0.20588848292827605\n",
      "Batch 1245,  loss: 0.15361073315143586\n",
      "Batch 1250,  loss: 0.16371163129806518\n",
      "Batch 1255,  loss: 0.11150044649839401\n",
      "Batch 1260,  loss: 0.16526009887456894\n",
      "Batch 1265,  loss: 0.1743557095527649\n",
      "Batch 1270,  loss: 0.20587146580219268\n",
      "Batch 1275,  loss: 0.14184872508049012\n",
      "Batch 1280,  loss: 0.14232607185840607\n",
      "Batch 1285,  loss: 0.1765278935432434\n",
      "Batch 1290,  loss: 0.1802324742078781\n",
      "Batch 1295,  loss: 0.18251187205314637\n",
      "Batch 1300,  loss: 0.14372240006923676\n",
      "Batch 1305,  loss: 0.1561887502670288\n",
      "Batch 1310,  loss: 0.2063998818397522\n",
      "Batch 1315,  loss: 0.15586257129907607\n",
      "Batch 1320,  loss: 0.14699916541576385\n",
      "Batch 1325,  loss: 0.1670341044664383\n",
      "Batch 1330,  loss: 0.15108002126216888\n",
      "Batch 1335,  loss: 0.11199156045913697\n",
      "Batch 1340,  loss: 0.13326288461685182\n",
      "Batch 1345,  loss: 0.17448894530534745\n",
      "Batch 1350,  loss: 0.14122649431228637\n",
      "Batch 1355,  loss: 0.14354688823223113\n",
      "Batch 1360,  loss: 0.165931898355484\n",
      "Batch 1365,  loss: 0.15735839158296586\n",
      "Batch 1370,  loss: 0.1405331537127495\n",
      "Batch 1375,  loss: 0.12716359347105027\n",
      "Batch 1380,  loss: 0.1315561294555664\n",
      "Batch 1385,  loss: 0.11441912949085235\n",
      "Batch 1390,  loss: 0.11014559864997864\n",
      "Batch 1395,  loss: 0.17430042922496797\n",
      "Batch 1400,  loss: 0.14255593121051788\n",
      "Batch 1405,  loss: 0.13093709647655488\n",
      "Batch 1410,  loss: 0.17865756303071975\n",
      "Batch 1415,  loss: 0.15539961606264113\n",
      "Batch 1420,  loss: 0.1260760933160782\n",
      "Batch 1425,  loss: 0.17724574506282806\n",
      "Batch 1430,  loss: 0.1588920533657074\n",
      "Batch 1435,  loss: 0.16413257718086244\n",
      "Batch 1440,  loss: 0.11153891235589981\n",
      "Batch 1445,  loss: 0.1265353873372078\n",
      "Batch 1450,  loss: 0.1415909692645073\n",
      "Batch 1455,  loss: 0.16231019794940948\n",
      "Batch 1460,  loss: 0.17614511549472808\n",
      "Batch 1465,  loss: 0.13280845284461976\n",
      "Batch 1470,  loss: 0.1748769462108612\n",
      "Batch 1475,  loss: 0.15258179008960723\n",
      "Batch 1480,  loss: 0.14549646377563477\n",
      "Batch 1485,  loss: 0.15733584761619568\n",
      "Batch 1490,  loss: 0.1554158478975296\n",
      "Batch 1495,  loss: 0.17994122505187987\n",
      "Batch 1500,  loss: 0.16157208383083344\n",
      "Batch 1505,  loss: 0.17836283147335052\n",
      "Batch 1510,  loss: 0.16724216639995576\n",
      "Batch 1515,  loss: 0.1645130842924118\n",
      "Batch 1520,  loss: 0.15644681453704834\n",
      "Batch 1525,  loss: 0.1956612527370453\n",
      "Batch 1530,  loss: 0.1286541238427162\n",
      "Batch 1535,  loss: 0.16273098289966584\n",
      "Batch 1540,  loss: 0.15253255367279053\n",
      "Batch 1545,  loss: 0.12454327046871186\n",
      "Batch 1550,  loss: 0.14609816521406174\n",
      "Batch 1555,  loss: 0.23176852166652678\n",
      "Batch 1560,  loss: 0.14274962544441222\n",
      "Batch 1565,  loss: 0.15416975021362306\n",
      "Batch 1570,  loss: 0.13781367391347885\n",
      "Batch 1575,  loss: 0.15971110463142396\n",
      "Batch 1580,  loss: 0.1449883311986923\n",
      "Batch 1585,  loss: 0.1721781700849533\n",
      "Batch 1590,  loss: 0.19056826531887056\n",
      "Batch 1595,  loss: 0.1543092280626297\n",
      "Batch 1600,  loss: 0.1730307251214981\n",
      "Batch 1605,  loss: 0.16692433953285218\n",
      "Batch 1610,  loss: 0.1353593572974205\n",
      "Batch 1615,  loss: 0.14214399456977844\n",
      "Batch 1620,  loss: 0.1906949907541275\n",
      "Batch 1625,  loss: 0.15114780515432358\n",
      "Batch 1630,  loss: 0.16645417213439942\n",
      "Batch 1635,  loss: 0.14732723832130432\n",
      "Batch 1640,  loss: 0.16140743494033813\n",
      "Batch 1645,  loss: 0.12177116125822067\n",
      "Batch 1650,  loss: 0.14656480848789216\n",
      "Batch 1655,  loss: 0.18373236954212188\n",
      "Batch 1660,  loss: 0.21383758187294005\n",
      "Batch 1665,  loss: 0.17460237592458724\n",
      "Batch 1670,  loss: 0.16740760058164597\n",
      "Batch 1675,  loss: 0.1793040841817856\n",
      "Batch 1680,  loss: 0.17135713249444962\n",
      "Batch 1685,  loss: 0.13054510056972504\n",
      "Batch 1690,  loss: 0.13986558914184571\n",
      "Batch 1695,  loss: 0.11824607104063034\n",
      "Batch 1700,  loss: 0.22291696965694427\n",
      "Batch 1705,  loss: 0.1503866583108902\n",
      "Batch 1710,  loss: 0.13126181364059447\n",
      "Batch 1715,  loss: 0.11592376977205276\n",
      "Batch 1720,  loss: 0.13497902005910872\n",
      "Batch 1725,  loss: 0.17408572435379027\n",
      "Batch 1730,  loss: 0.13865918815135955\n",
      "Batch 1735,  loss: 0.16915159821510314\n",
      "Batch 1740,  loss: 0.16341125220060349\n",
      "Batch 1745,  loss: 0.14422518014907837\n",
      "Batch 1750,  loss: 0.11772196143865585\n",
      "Batch 1755,  loss: 0.1366393133997917\n",
      "Batch 1760,  loss: 0.1618685841560364\n",
      "Batch 1765,  loss: 0.19120772331953048\n",
      "Batch 1770,  loss: 0.14644801169633864\n",
      "Batch 1775,  loss: 0.149984148144722\n",
      "Batch 1780,  loss: 0.16343035250902177\n",
      "Batch 1785,  loss: 0.1485328644514084\n",
      "Batch 1790,  loss: 0.1334426149725914\n",
      "Batch 1795,  loss: 0.13852670937776565\n",
      "Batch 1800,  loss: 0.18364419937133789\n",
      "Batch 1805,  loss: 0.10325941145420074\n",
      "Batch 1810,  loss: 0.16449193358421327\n",
      "Batch 1815,  loss: 0.162450310587883\n",
      "Batch 1820,  loss: 0.1731542393565178\n",
      "Batch 1825,  loss: 0.14405962377786635\n",
      "Batch 1830,  loss: 0.1669256269931793\n",
      "Batch 1835,  loss: 0.12506600916385652\n",
      "Batch 1840,  loss: 0.19822439402341843\n",
      "Batch 1845,  loss: 0.09812771528959274\n",
      "Batch 1850,  loss: 0.15186217427253723\n",
      "Batch 1855,  loss: 0.12823027968406678\n",
      "Batch 1860,  loss: 0.1337404265999794\n",
      "Batch 1865,  loss: 0.159069786965847\n",
      "Batch 1870,  loss: 0.1599866822361946\n",
      "Batch 1875,  loss: 0.14702233970165252\n",
      "Batch 1880,  loss: 0.13771518617868422\n",
      "Batch 1885,  loss: 0.1856235906481743\n",
      "Batch 1890,  loss: 0.19678284227848053\n",
      "Batch 1895,  loss: 0.2203299030661583\n",
      "Batch 1900,  loss: 0.149711412191391\n",
      "Batch 1905,  loss: 0.1615147203207016\n",
      "Batch 1910,  loss: 0.14425214231014252\n",
      "Batch 1915,  loss: 0.1563969224691391\n",
      "Batch 1920,  loss: 0.15479169338941573\n",
      "Batch 1925,  loss: 0.15719307363033294\n",
      "Batch 1930,  loss: 0.22277561128139495\n",
      "Batch 1935,  loss: 0.15001380443572998\n",
      "Batch 1940,  loss: 0.13923247158527374\n",
      "Batch 1945,  loss: 0.12155932784080506\n",
      "Batch 1950,  loss: 0.1460070863366127\n",
      "Batch 1955,  loss: 0.1509526938199997\n",
      "Batch 1960,  loss: 0.13508853912353516\n",
      "Batch 1965,  loss: 0.19067946970462799\n",
      "Batch 1970,  loss: 0.1395134910941124\n",
      "Batch 1975,  loss: 0.1489827573299408\n",
      "Batch 1980,  loss: 0.16756395101547242\n",
      "Batch 1985,  loss: 0.19079710841178893\n",
      "Batch 1990,  loss: 0.1601144939661026\n",
      "Batch 1995,  loss: 0.13025198578834535\n",
      "Batch 2000,  loss: 0.1168290689587593\n",
      "Batch 2005,  loss: 0.17818839550018312\n",
      "Batch 2010,  loss: 0.14007543474435807\n",
      "Batch 2015,  loss: 0.15013450682163237\n",
      "Batch 2020,  loss: 0.14061595350503922\n",
      "Batch 2025,  loss: 0.11052061021327972\n",
      "Batch 2030,  loss: 0.14104476869106292\n",
      "Batch 2035,  loss: 0.15022866129875184\n",
      "Batch 2040,  loss: 0.17003659456968306\n",
      "Batch 2045,  loss: 0.13107791692018508\n",
      "Batch 2050,  loss: 0.14812055826187134\n",
      "Batch 2055,  loss: 0.1395686849951744\n",
      "Batch 2060,  loss: 0.17181594371795655\n",
      "Batch 2065,  loss: 0.18512448370456697\n",
      "Batch 2070,  loss: 0.15296145379543305\n",
      "Batch 2075,  loss: 0.18511246740818024\n",
      "Batch 2080,  loss: 0.16469525843858718\n",
      "Batch 2085,  loss: 0.14871849864721298\n",
      "Batch 2090,  loss: 0.16303539276123047\n",
      "Batch 2095,  loss: 0.17400577664375305\n",
      "Batch 2100,  loss: 0.14750345796346664\n",
      "Batch 2105,  loss: 0.1768868088722229\n",
      "Batch 2110,  loss: 0.17769968807697295\n",
      "Batch 2115,  loss: 0.14211430549621581\n",
      "Batch 2120,  loss: 0.14585374146699906\n",
      "Batch 2125,  loss: 0.15612819641828538\n",
      "Batch 2130,  loss: 0.17305703461170197\n",
      "Batch 2135,  loss: 0.1444553017616272\n",
      "Batch 2140,  loss: 0.213214647769928\n",
      "Batch 2145,  loss: 0.1309744358062744\n",
      "Batch 2150,  loss: 0.14913236498832702\n",
      "Batch 2155,  loss: 0.13061688244342803\n",
      "Batch 2160,  loss: 0.15597169548273088\n",
      "Batch 2165,  loss: 0.16029015183448792\n",
      "Batch 2170,  loss: 0.1279527187347412\n",
      "Batch 2175,  loss: 0.14636408239603044\n",
      "Batch 2180,  loss: 0.10897444784641266\n",
      "Batch 2185,  loss: 0.14208033680915833\n",
      "Batch 2190,  loss: 0.15415880382061004\n",
      "Batch 2195,  loss: 0.16201341897249222\n",
      "Batch 2200,  loss: 0.13332917243242265\n",
      "Batch 2205,  loss: 0.12571886479854583\n",
      "Batch 2210,  loss: 0.15821085423231124\n",
      "Batch 2215,  loss: 0.13281581699848174\n",
      "Batch 2220,  loss: 0.18770992159843444\n",
      "Batch 2225,  loss: 0.14238484799861909\n",
      "Batch 2230,  loss: 0.14766082167625427\n",
      "Batch 2235,  loss: 0.1774354547262192\n",
      "Batch 2240,  loss: 0.1418507516384125\n",
      "Batch 2245,  loss: 0.12099749147891999\n",
      "Batch 2250,  loss: 0.12538690567016603\n",
      "Batch 2255,  loss: 0.13731621950864792\n",
      "Batch 2260,  loss: 0.11231020241975784\n",
      "Batch 2265,  loss: 0.15547359585762024\n",
      "Batch 2270,  loss: 0.14885865151882172\n",
      "Batch 2275,  loss: 0.12702541947364807\n",
      "Batch 2280,  loss: 0.18779578804969788\n",
      "Batch 2285,  loss: 0.11472990289330483\n",
      "Batch 2290,  loss: 0.1302702993154526\n",
      "Batch 2295,  loss: 0.15563707202672958\n",
      "Batch 2300,  loss: 0.14030816853046418\n",
      "Batch 2305,  loss: 0.1840302050113678\n",
      "Batch 2310,  loss: 0.2245419591665268\n",
      "Batch 2315,  loss: 0.1601100742816925\n",
      "Batch 2320,  loss: 0.15880005359649657\n",
      "Batch 2325,  loss: 0.13867638558149337\n",
      "Batch 2330,  loss: 0.11223469227552414\n",
      "Batch 2335,  loss: 0.1831631690263748\n",
      "Batch 2340,  loss: 0.20780476033687592\n",
      "Batch 2345,  loss: 0.15541805028915406\n",
      "Batch 2350,  loss: 0.12522374093532562\n",
      "Batch 2355,  loss: 0.14705245345830917\n",
      "Batch 2360,  loss: 0.16035968959331512\n",
      "Batch 2365,  loss: 0.1347777545452118\n",
      "Batch 2370,  loss: 0.1434454709291458\n",
      "Batch 2375,  loss: 0.11947465240955353\n",
      "Batch 2380,  loss: 0.1905403643846512\n",
      "Batch 2385,  loss: 0.17610130906105043\n",
      "Batch 2390,  loss: 0.1254831373691559\n",
      "Batch 2395,  loss: 0.11182639822363853\n",
      "Batch 2400,  loss: 0.17462149262428284\n",
      "Batch 2405,  loss: 0.1703124687075615\n",
      "Batch 2410,  loss: 0.15745755434036254\n",
      "Batch 2415,  loss: 0.15780653655529023\n",
      "Batch 2420,  loss: 0.1095343604683876\n",
      "Batch 2425,  loss: 0.1225309669971466\n",
      "Batch 2430,  loss: 0.13688816428184508\n",
      "Batch 2435,  loss: 0.17904664278030397\n",
      "Batch 2440,  loss: 0.14951657950878144\n",
      "Batch 2445,  loss: 0.13335202634334564\n",
      "Batch 2450,  loss: 0.15030004680156708\n",
      "Batch 2455,  loss: 0.12924933731555938\n",
      "Batch 2460,  loss: 0.11974476277828217\n",
      "Batch 2465,  loss: 0.20156630724668503\n",
      "Batch 2470,  loss: 0.1508609101176262\n",
      "Batch 2475,  loss: 0.13675512224435807\n",
      "Batch 2480,  loss: 0.15191410183906556\n",
      "Batch 2485,  loss: 0.15624327957630157\n",
      "Batch 2490,  loss: 0.15369067788124086\n",
      "Batch 2495,  loss: 0.14904478937387466\n",
      "Batch 2500,  loss: 0.20853906571865083\n",
      "Batch 2505,  loss: 0.1587689757347107\n",
      "Batch 2510,  loss: 0.13564275354146957\n",
      "Batch 2515,  loss: 0.170158189535141\n",
      "Batch 2520,  loss: 0.19906087219715118\n",
      "Batch 2525,  loss: 0.18847995847463608\n",
      "Batch 2530,  loss: 0.1351381078362465\n",
      "Batch 2535,  loss: 0.12076605707406998\n",
      "Batch 2540,  loss: 0.12661920934915544\n",
      "Batch 2545,  loss: 0.1654950350522995\n",
      "Batch 2550,  loss: 0.1511451154947281\n",
      "Batch 2555,  loss: 0.14944048523902892\n",
      "Batch 2560,  loss: 0.16605211198329925\n",
      "Batch 2565,  loss: 0.12990706115961076\n",
      "Batch 2570,  loss: 0.13989318460226058\n",
      "Batch 2575,  loss: 0.14873540997505189\n",
      "Batch 2580,  loss: 0.13294478058815\n",
      "Batch 2585,  loss: 0.1428835541009903\n",
      "Batch 2590,  loss: 0.16473675966262818\n",
      "Batch 2595,  loss: 0.16973329484462737\n",
      "Batch 2600,  loss: 0.12703977227211\n",
      "Batch 2605,  loss: 0.16774574518203736\n",
      "Batch 2610,  loss: 0.17507635951042175\n",
      "Batch 2615,  loss: 0.17484960854053497\n",
      "Batch 2620,  loss: 0.18461355268955232\n",
      "Batch 2625,  loss: 0.12925977408885955\n",
      "Batch 2630,  loss: 0.12272746413946152\n",
      "Batch 2635,  loss: 0.16951867938041687\n",
      "Batch 2640,  loss: 0.1548624187707901\n",
      "Batch 2645,  loss: 0.1780906856060028\n",
      "Batch 2650,  loss: 0.16963998079299927\n",
      "Batch 2655,  loss: 0.1681654006242752\n",
      "Batch 2660,  loss: 0.12930001318454742\n",
      "Batch 2665,  loss: 0.17131200730800628\n",
      "Batch 2670,  loss: 0.16171747893095018\n",
      "Batch 2675,  loss: 0.14495860040187836\n",
      "Batch 2680,  loss: 0.1197610467672348\n",
      "Batch 2685,  loss: 0.11250935941934585\n",
      "Batch 2690,  loss: 0.1665162593126297\n",
      "Batch 2695,  loss: 0.12675483673810958\n",
      "Batch 2700,  loss: 0.1803113639354706\n",
      "Batch 2705,  loss: 0.16511475145816804\n",
      "Batch 2710,  loss: 0.15669088512659074\n",
      "Batch 2715,  loss: 0.13890151232481002\n",
      "Batch 2720,  loss: 0.13905419409275055\n",
      "Batch 2725,  loss: 0.1511233389377594\n",
      "Batch 2730,  loss: 0.17366783022880555\n",
      "Batch 2735,  loss: 0.17580169290304185\n",
      "Batch 2740,  loss: 0.15235248804092408\n",
      "Batch 2745,  loss: 0.14126404374837875\n",
      "Batch 2750,  loss: 0.15694373548030854\n",
      "Batch 2755,  loss: 0.11657135486602783\n",
      "Batch 2760,  loss: 0.16222124099731444\n",
      "Batch 2765,  loss: 0.2025647521018982\n",
      "Batch 2770,  loss: 0.1680553063750267\n",
      "LOSS train 0.1680553063750267. Validation loss: 0.16185772891686712 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 36:\n",
      "Batch 5,  loss: 0.21092820167541504\n",
      "Batch 10,  loss: 0.13891217410564421\n",
      "Batch 15,  loss: 0.1817065954208374\n",
      "Batch 20,  loss: 0.13398451060056688\n",
      "Batch 25,  loss: 0.17641837596893312\n",
      "Batch 30,  loss: 0.15313013643026352\n",
      "Batch 35,  loss: 0.13735802173614503\n",
      "Batch 40,  loss: 0.18787437081336975\n",
      "Batch 45,  loss: 0.15271546095609664\n",
      "Batch 50,  loss: 0.13802431672811508\n",
      "Batch 55,  loss: 0.13846754431724548\n",
      "Batch 60,  loss: 0.1456412523984909\n",
      "Batch 65,  loss: 0.14117036312818526\n",
      "Batch 70,  loss: 0.1537390947341919\n",
      "Batch 75,  loss: 0.15701212286949157\n",
      "Batch 80,  loss: 0.12762522101402282\n",
      "Batch 85,  loss: 0.1956907629966736\n",
      "Batch 90,  loss: 0.1518104776740074\n",
      "Batch 95,  loss: 0.11578930169343948\n",
      "Batch 100,  loss: 0.14896763414144515\n",
      "Batch 105,  loss: 0.14486926794052124\n",
      "Batch 110,  loss: 0.11931860446929932\n",
      "Batch 115,  loss: 0.14022523835301398\n",
      "Batch 120,  loss: 0.12474224418401718\n",
      "Batch 125,  loss: 0.19024796187877654\n",
      "Batch 130,  loss: 0.13175061643123626\n",
      "Batch 135,  loss: 0.12861147075891494\n",
      "Batch 140,  loss: 0.12585878223180771\n",
      "Batch 145,  loss: 0.16694681942462922\n",
      "Batch 150,  loss: 0.21230096220970154\n",
      "Batch 155,  loss: 0.16022456884384156\n",
      "Batch 160,  loss: 0.159384061396122\n",
      "Batch 165,  loss: 0.21491180509328842\n",
      "Batch 170,  loss: 0.16222417950630189\n",
      "Batch 175,  loss: 0.17410067319869996\n",
      "Batch 180,  loss: 0.168352372944355\n",
      "Batch 185,  loss: 0.17783772945404053\n",
      "Batch 190,  loss: 0.169287870824337\n",
      "Batch 195,  loss: 0.1783005028963089\n",
      "Batch 200,  loss: 0.15916701257228852\n",
      "Batch 205,  loss: 0.18402274399995805\n",
      "Batch 210,  loss: 0.1736304745078087\n",
      "Batch 215,  loss: 0.1467434585094452\n",
      "Batch 220,  loss: 0.1718225046992302\n",
      "Batch 225,  loss: 0.15182926505804062\n",
      "Batch 230,  loss: 0.19272429943084718\n",
      "Batch 235,  loss: 0.17588359713554383\n",
      "Batch 240,  loss: 0.15838461816310884\n",
      "Batch 245,  loss: 0.1319736808538437\n",
      "Batch 250,  loss: 0.14753259271383284\n",
      "Batch 255,  loss: 0.13556017130613326\n",
      "Batch 260,  loss: 0.188310906291008\n",
      "Batch 265,  loss: 0.14748533368110656\n",
      "Batch 270,  loss: 0.1735231176018715\n",
      "Batch 275,  loss: 0.17899129986763002\n",
      "Batch 280,  loss: 0.1537560224533081\n",
      "Batch 285,  loss: 0.15150863379240037\n",
      "Batch 290,  loss: 0.14173560887575148\n",
      "Batch 295,  loss: 0.16558105051517485\n",
      "Batch 300,  loss: 0.14319296181201935\n",
      "Batch 305,  loss: 0.15967138409614562\n",
      "Batch 310,  loss: 0.1424569845199585\n",
      "Batch 315,  loss: 0.1430202305316925\n",
      "Batch 320,  loss: 0.17142414599657058\n",
      "Batch 325,  loss: 0.1679979145526886\n",
      "Batch 330,  loss: 0.1717121794819832\n",
      "Batch 335,  loss: 0.19812623858451844\n",
      "Batch 340,  loss: 0.13102261126041412\n",
      "Batch 345,  loss: 0.1699424058198929\n",
      "Batch 350,  loss: 0.1504112511873245\n",
      "Batch 355,  loss: 0.16514486968517303\n",
      "Batch 360,  loss: 0.15066486299037934\n",
      "Batch 365,  loss: 0.11788085252046585\n",
      "Batch 370,  loss: 0.12954790741205216\n",
      "Batch 375,  loss: 0.13959699720144272\n",
      "Batch 380,  loss: 0.16321564614772796\n",
      "Batch 385,  loss: 0.21698273122310638\n",
      "Batch 390,  loss: 0.11585159450769425\n",
      "Batch 395,  loss: 0.15867879986763\n",
      "Batch 400,  loss: 0.14949288666248323\n",
      "Batch 405,  loss: 0.1623307168483734\n",
      "Batch 410,  loss: 0.12964136004447938\n",
      "Batch 415,  loss: 0.17665061801671983\n",
      "Batch 420,  loss: 0.14320162534713746\n",
      "Batch 425,  loss: 0.1877521812915802\n",
      "Batch 430,  loss: 0.16870748698711396\n",
      "Batch 435,  loss: 0.1723699152469635\n",
      "Batch 440,  loss: 0.13738112300634384\n",
      "Batch 445,  loss: 0.17739651799201966\n",
      "Batch 450,  loss: 0.19700490832328796\n",
      "Batch 455,  loss: 0.15598334223031998\n",
      "Batch 460,  loss: 0.14205265790224075\n",
      "Batch 465,  loss: 0.14982766211032866\n",
      "Batch 470,  loss: 0.16665646880865098\n",
      "Batch 475,  loss: 0.1294129654765129\n",
      "Batch 480,  loss: 0.19380417168140412\n",
      "Batch 485,  loss: 0.18367928117513657\n",
      "Batch 490,  loss: 0.15497941076755523\n",
      "Batch 495,  loss: 0.17476112246513367\n",
      "Batch 500,  loss: 0.13808539360761643\n",
      "Batch 505,  loss: 0.16307185888290404\n",
      "Batch 510,  loss: 0.15810564309358596\n",
      "Batch 515,  loss: 0.13928329795598984\n",
      "Batch 520,  loss: 0.11187053471803665\n",
      "Batch 525,  loss: 0.17868997305631637\n",
      "Batch 530,  loss: 0.10418056398630142\n",
      "Batch 535,  loss: 0.1583130642771721\n",
      "Batch 540,  loss: 0.16132535189390182\n",
      "Batch 545,  loss: 0.1935710459947586\n",
      "Batch 550,  loss: 0.1306033357977867\n",
      "Batch 555,  loss: 0.16127687692642212\n",
      "Batch 560,  loss: 0.15923241078853606\n",
      "Batch 565,  loss: 0.1563305824995041\n",
      "Batch 570,  loss: 0.1373436212539673\n",
      "Batch 575,  loss: 0.18081849813461304\n",
      "Batch 580,  loss: 0.11046783030033111\n",
      "Batch 585,  loss: 0.13207513689994813\n",
      "Batch 590,  loss: 0.11209979802370071\n",
      "Batch 595,  loss: 0.14760884642601013\n",
      "Batch 600,  loss: 0.14632510244846345\n",
      "Batch 605,  loss: 0.13791156709194183\n",
      "Batch 610,  loss: 0.13484717756509781\n",
      "Batch 615,  loss: 0.1529046818614006\n",
      "Batch 620,  loss: 0.16102130562067032\n",
      "Batch 625,  loss: 0.1562124341726303\n",
      "Batch 630,  loss: 0.19954512119293213\n",
      "Batch 635,  loss: 0.1740071952342987\n",
      "Batch 640,  loss: 0.17238312363624572\n",
      "Batch 645,  loss: 0.1285800576210022\n",
      "Batch 650,  loss: 0.17210357785224914\n",
      "Batch 655,  loss: 0.12303033620119094\n",
      "Batch 660,  loss: 0.16222160905599595\n",
      "Batch 665,  loss: 0.19357356131076814\n",
      "Batch 670,  loss: 0.13589209765195848\n",
      "Batch 675,  loss: 0.13693043887615203\n",
      "Batch 680,  loss: 0.13047880828380584\n",
      "Batch 685,  loss: 0.16624967455863954\n",
      "Batch 690,  loss: 0.15209577679634095\n",
      "Batch 695,  loss: 0.15813453644514083\n",
      "Batch 700,  loss: 0.13756389021873475\n",
      "Batch 705,  loss: 0.1530910164117813\n",
      "Batch 710,  loss: 0.11891510039567947\n",
      "Batch 715,  loss: 0.1271569937467575\n",
      "Batch 720,  loss: 0.12912842631340027\n",
      "Batch 725,  loss: 0.13810285180807114\n",
      "Batch 730,  loss: 0.14025402218103408\n",
      "Batch 735,  loss: 0.14411208629608155\n",
      "Batch 740,  loss: 0.16816388070583344\n",
      "Batch 745,  loss: 0.11656560599803925\n",
      "Batch 750,  loss: 0.1464008793234825\n",
      "Batch 755,  loss: 0.1278468906879425\n",
      "Batch 760,  loss: 0.12001911401748658\n",
      "Batch 765,  loss: 0.15457699596881866\n",
      "Batch 770,  loss: 0.12718190103769303\n",
      "Batch 775,  loss: 0.17680896818637848\n",
      "Batch 780,  loss: 0.16548702120780945\n",
      "Batch 785,  loss: 0.1562130868434906\n",
      "Batch 790,  loss: 0.12591811567544936\n",
      "Batch 795,  loss: 0.1236216515302658\n",
      "Batch 800,  loss: 0.19077275395393373\n",
      "Batch 805,  loss: 0.10975341200828552\n",
      "Batch 810,  loss: 0.15232348144054414\n",
      "Batch 815,  loss: 0.12212422043085099\n",
      "Batch 820,  loss: 0.1267133355140686\n",
      "Batch 825,  loss: 0.16998020708560943\n",
      "Batch 830,  loss: 0.19125455915927886\n",
      "Batch 835,  loss: 0.15513975918293\n",
      "Batch 840,  loss: 0.18346474915742875\n",
      "Batch 845,  loss: 0.1440495729446411\n",
      "Batch 850,  loss: 0.153946390748024\n",
      "Batch 855,  loss: 0.14245258569717406\n",
      "Batch 860,  loss: 0.14951065927743912\n",
      "Batch 865,  loss: 0.17535172551870346\n",
      "Batch 870,  loss: 0.1442200869321823\n",
      "Batch 875,  loss: 0.13336945176124573\n",
      "Batch 880,  loss: 0.17377457320690154\n",
      "Batch 885,  loss: 0.18957799971103667\n",
      "Batch 890,  loss: 0.14737311601638795\n",
      "Batch 895,  loss: 0.1538861244916916\n",
      "Batch 900,  loss: 0.14321373403072357\n",
      "Batch 905,  loss: 0.13144374042749404\n",
      "Batch 910,  loss: 0.14305505752563477\n",
      "Batch 915,  loss: 0.12460346221923828\n",
      "Batch 920,  loss: 0.13044628053903579\n",
      "Batch 925,  loss: 0.15037849247455598\n",
      "Batch 930,  loss: 0.13371863663196565\n",
      "Batch 935,  loss: 0.24743758141994476\n",
      "Batch 940,  loss: 0.16505545377731323\n",
      "Batch 945,  loss: 0.12752166837453843\n",
      "Batch 950,  loss: 0.14706904739141463\n",
      "Batch 955,  loss: 0.14852493703365327\n",
      "Batch 960,  loss: 0.1313746988773346\n",
      "Batch 965,  loss: 0.14440605640411378\n",
      "Batch 970,  loss: 0.1474658578634262\n",
      "Batch 975,  loss: 0.15875197052955628\n",
      "Batch 980,  loss: 0.19654930382966995\n",
      "Batch 985,  loss: 0.1424722582101822\n",
      "Batch 990,  loss: 0.1440170466899872\n",
      "Batch 995,  loss: 0.12872074395418168\n",
      "Batch 1000,  loss: 0.16096565425395964\n",
      "Batch 1005,  loss: 0.2343842089176178\n",
      "Batch 1010,  loss: 0.13365524709224702\n",
      "Batch 1015,  loss: 0.1363792598247528\n",
      "Batch 1020,  loss: 0.14754748195409775\n",
      "Batch 1025,  loss: 0.22797817438840867\n",
      "Batch 1030,  loss: 0.15299418270587922\n",
      "Batch 1035,  loss: 0.1732697755098343\n",
      "Batch 1040,  loss: 0.1365552932024002\n",
      "Batch 1045,  loss: 0.15933557450771332\n",
      "Batch 1050,  loss: 0.18076917827129363\n",
      "Batch 1055,  loss: 0.19103107750415801\n",
      "Batch 1060,  loss: 0.15548733174800872\n",
      "Batch 1065,  loss: 0.13165486752986907\n",
      "Batch 1070,  loss: 0.13896378576755525\n",
      "Batch 1075,  loss: 0.17776034772396088\n",
      "Batch 1080,  loss: 0.14392219930887223\n",
      "Batch 1085,  loss: 0.19562953412532808\n",
      "Batch 1090,  loss: 0.11736573949456215\n",
      "Batch 1095,  loss: 0.13955378234386445\n",
      "Batch 1100,  loss: 0.13223352432250976\n",
      "Batch 1105,  loss: 0.1701188027858734\n",
      "Batch 1110,  loss: 0.14726412296295166\n",
      "Batch 1115,  loss: 0.14390785992145538\n",
      "Batch 1120,  loss: 0.10392056554555892\n",
      "Batch 1125,  loss: 0.1824827492237091\n",
      "Batch 1130,  loss: 0.13833443820476532\n",
      "Batch 1135,  loss: 0.17333131432533264\n",
      "Batch 1140,  loss: 0.16748193502426148\n",
      "Batch 1145,  loss: 0.14809622317552568\n",
      "Batch 1150,  loss: 0.13875086903572081\n",
      "Batch 1155,  loss: 0.12277866154909134\n",
      "Batch 1160,  loss: 0.1312964603304863\n",
      "Batch 1165,  loss: 0.16273657679557801\n",
      "Batch 1170,  loss: 0.21023266911506652\n",
      "Batch 1175,  loss: 0.14999019354581833\n",
      "Batch 1180,  loss: 0.1270752117037773\n",
      "Batch 1185,  loss: 0.15510938316583633\n",
      "Batch 1190,  loss: 0.21590871512889862\n",
      "Batch 1195,  loss: 0.15845755487680435\n",
      "Batch 1200,  loss: 0.09739111363887787\n",
      "Batch 1205,  loss: 0.1868852913379669\n",
      "Batch 1210,  loss: 0.15287539213895798\n",
      "Batch 1215,  loss: 0.178939288854599\n",
      "Batch 1220,  loss: 0.1441103458404541\n",
      "Batch 1225,  loss: 0.15518682301044465\n",
      "Batch 1230,  loss: 0.13871840089559556\n",
      "Batch 1235,  loss: 0.15827991366386412\n",
      "Batch 1240,  loss: 0.1432155042886734\n",
      "Batch 1245,  loss: 0.13568764328956603\n",
      "Batch 1250,  loss: 0.1635059505701065\n",
      "Batch 1255,  loss: 0.14764803051948547\n",
      "Batch 1260,  loss: 0.1412674218416214\n",
      "Batch 1265,  loss: 0.12674191892147063\n",
      "Batch 1270,  loss: 0.1698308289051056\n",
      "Batch 1275,  loss: 0.13481532633304597\n",
      "Batch 1280,  loss: 0.16061227023601532\n",
      "Batch 1285,  loss: 0.17460627853870392\n",
      "Batch 1290,  loss: 0.15482196360826492\n",
      "Batch 1295,  loss: 0.1842047691345215\n",
      "Batch 1300,  loss: 0.15128428339958191\n",
      "Batch 1305,  loss: 0.1486540824174881\n",
      "Batch 1310,  loss: 0.1297403872013092\n",
      "Batch 1315,  loss: 0.12350287735462188\n",
      "Batch 1320,  loss: 0.17954381108283995\n",
      "Batch 1325,  loss: 0.11598240435123444\n",
      "Batch 1330,  loss: 0.1381824091076851\n",
      "Batch 1335,  loss: 0.1805551156401634\n",
      "Batch 1340,  loss: 0.11961425244808196\n",
      "Batch 1345,  loss: 0.1465231940150261\n",
      "Batch 1350,  loss: 0.20395007431507112\n",
      "Batch 1355,  loss: 0.15320526659488679\n",
      "Batch 1360,  loss: 0.1669736087322235\n",
      "Batch 1365,  loss: 0.14008497446775436\n",
      "Batch 1370,  loss: 0.16065532416105271\n",
      "Batch 1375,  loss: 0.15379371047019957\n",
      "Batch 1380,  loss: 0.18877825886011124\n",
      "Batch 1385,  loss: 0.15946765393018722\n",
      "Batch 1390,  loss: 0.1799868479371071\n",
      "Batch 1395,  loss: 0.1774657279253006\n",
      "Batch 1400,  loss: 0.1465732589364052\n",
      "Batch 1405,  loss: 0.17060696631669997\n",
      "Batch 1410,  loss: 0.145403853058815\n",
      "Batch 1415,  loss: 0.1420191615819931\n",
      "Batch 1420,  loss: 0.17184939235448837\n",
      "Batch 1425,  loss: 0.18605992048978806\n",
      "Batch 1430,  loss: 0.18746402263641357\n",
      "Batch 1435,  loss: 0.1482728362083435\n",
      "Batch 1440,  loss: 0.11912010908126831\n",
      "Batch 1445,  loss: 0.1494284301996231\n",
      "Batch 1450,  loss: 0.15839521884918212\n",
      "Batch 1455,  loss: 0.1634694129228592\n",
      "Batch 1460,  loss: 0.15900227725505828\n",
      "Batch 1465,  loss: 0.1788749188184738\n",
      "Batch 1470,  loss: 0.16727739572525024\n",
      "Batch 1475,  loss: 0.12209681123495102\n",
      "Batch 1480,  loss: 0.11250428110361099\n",
      "Batch 1485,  loss: 0.14009339064359666\n",
      "Batch 1490,  loss: 0.187808820605278\n",
      "Batch 1495,  loss: 0.12897082716226577\n",
      "Batch 1500,  loss: 0.13201084733009338\n",
      "Batch 1505,  loss: 0.15438081175088883\n",
      "Batch 1510,  loss: 0.13317518532276154\n",
      "Batch 1515,  loss: 0.15910435914993287\n",
      "Batch 1520,  loss: 0.13798949718475342\n",
      "Batch 1525,  loss: 0.14742286503314972\n",
      "Batch 1530,  loss: 0.16111937314271926\n",
      "Batch 1535,  loss: 0.20957286804914474\n",
      "Batch 1540,  loss: 0.18089652955532073\n",
      "Batch 1545,  loss: 0.1148587629199028\n",
      "Batch 1550,  loss: 0.16577809303998947\n",
      "Batch 1555,  loss: 0.15357474684715272\n",
      "Batch 1560,  loss: 0.14385305047035218\n",
      "Batch 1565,  loss: 0.12884052991867065\n",
      "Batch 1570,  loss: 0.1474884644150734\n",
      "Batch 1575,  loss: 0.16148031651973724\n",
      "Batch 1580,  loss: 0.12633845806121827\n",
      "Batch 1585,  loss: 0.12578936517238617\n",
      "Batch 1590,  loss: 0.1351752132177353\n",
      "Batch 1595,  loss: 0.11649293154478073\n",
      "Batch 1600,  loss: 0.1737240195274353\n",
      "Batch 1605,  loss: 0.16379960924386977\n",
      "Batch 1610,  loss: 0.15013235360383986\n",
      "Batch 1615,  loss: 0.14550426006317138\n",
      "Batch 1620,  loss: 0.1550917237997055\n",
      "Batch 1625,  loss: 0.13888685703277587\n",
      "Batch 1630,  loss: 0.18096815347671508\n",
      "Batch 1635,  loss: 0.159882615506649\n",
      "Batch 1640,  loss: 0.1425023302435875\n",
      "Batch 1645,  loss: 0.159614634513855\n",
      "Batch 1650,  loss: 0.151181423664093\n",
      "Batch 1655,  loss: 0.12273575961589814\n",
      "Batch 1660,  loss: 0.15906649827957153\n",
      "Batch 1665,  loss: 0.1453234925866127\n",
      "Batch 1670,  loss: 0.17465944290161134\n",
      "Batch 1675,  loss: 0.13984735012054444\n",
      "Batch 1680,  loss: 0.16194151639938353\n",
      "Batch 1685,  loss: 0.13988162726163864\n",
      "Batch 1690,  loss: 0.13038294166326522\n",
      "Batch 1695,  loss: 0.17471929639577866\n",
      "Batch 1700,  loss: 0.10883741974830627\n",
      "Batch 1705,  loss: 0.13607947677373886\n",
      "Batch 1710,  loss: 0.19461721628904344\n",
      "Batch 1715,  loss: 0.14805988669395448\n",
      "Batch 1720,  loss: 0.15047553479671477\n",
      "Batch 1725,  loss: 0.11664393544197083\n",
      "Batch 1730,  loss: 0.16356527656316758\n",
      "Batch 1735,  loss: 0.12410537898540497\n",
      "Batch 1740,  loss: 0.13050063699483871\n",
      "Batch 1745,  loss: 0.11673569679260254\n",
      "Batch 1750,  loss: 0.16963951587677\n",
      "Batch 1755,  loss: 0.12626676857471467\n",
      "Batch 1760,  loss: 0.1580294191837311\n",
      "Batch 1765,  loss: 0.1775900900363922\n",
      "Batch 1770,  loss: 0.12136069536209107\n",
      "Batch 1775,  loss: 0.14936222434043883\n",
      "Batch 1780,  loss: 0.14679495394229888\n",
      "Batch 1785,  loss: 0.12031488567590713\n",
      "Batch 1790,  loss: 0.14984855353832244\n",
      "Batch 1795,  loss: 0.17738765776157378\n",
      "Batch 1800,  loss: 0.17524999678134917\n",
      "Batch 1805,  loss: 0.1513426348567009\n",
      "Batch 1810,  loss: 0.18642410039901733\n",
      "Batch 1815,  loss: 0.1516025796532631\n",
      "Batch 1820,  loss: 0.15074120163917543\n",
      "Batch 1825,  loss: 0.16168953180313111\n",
      "Batch 1830,  loss: 0.11413670927286149\n",
      "Batch 1835,  loss: 0.1120668351650238\n",
      "Batch 1840,  loss: 0.13843855261802673\n",
      "Batch 1845,  loss: 0.18276892304420472\n",
      "Batch 1850,  loss: 0.20249491035938263\n",
      "Batch 1855,  loss: 0.1546971693634987\n",
      "Batch 1860,  loss: 0.12666726410388945\n",
      "Batch 1865,  loss: 0.15179068148136138\n",
      "Batch 1870,  loss: 0.12362896502017975\n",
      "Batch 1875,  loss: 0.17312362939119338\n",
      "Batch 1880,  loss: 0.12035868316888809\n",
      "Batch 1885,  loss: 0.16026541888713836\n",
      "Batch 1890,  loss: 0.1829995959997177\n",
      "Batch 1895,  loss: 0.14751904904842378\n",
      "Batch 1900,  loss: 0.18625883460044862\n",
      "Batch 1905,  loss: 0.14376533776521683\n",
      "Batch 1910,  loss: 0.17587636709213256\n",
      "Batch 1915,  loss: 0.12787538170814514\n",
      "Batch 1920,  loss: 0.10737030804157258\n",
      "Batch 1925,  loss: 0.11612668856978417\n",
      "Batch 1930,  loss: 0.17365418672561644\n",
      "Batch 1935,  loss: 0.14475447237491607\n",
      "Batch 1940,  loss: 0.1826471596956253\n",
      "Batch 1945,  loss: 0.14419471025466918\n",
      "Batch 1950,  loss: 0.15191522240638733\n",
      "Batch 1955,  loss: 0.1776268646121025\n",
      "Batch 1960,  loss: 0.13444843590259553\n",
      "Batch 1965,  loss: 0.15167434215545655\n",
      "Batch 1970,  loss: 0.13395054191350936\n",
      "Batch 1975,  loss: 0.11545385420322418\n",
      "Batch 1980,  loss: 0.16718848198652267\n",
      "Batch 1985,  loss: 0.1282591849565506\n",
      "Batch 1990,  loss: 0.1524086281657219\n",
      "Batch 1995,  loss: 0.17664956748485566\n",
      "Batch 2000,  loss: 0.20331239700317383\n",
      "Batch 2005,  loss: 0.17377234548330306\n",
      "Batch 2010,  loss: 0.13432036489248275\n",
      "Batch 2015,  loss: 0.18926115781068803\n",
      "Batch 2020,  loss: 0.1635735422372818\n",
      "Batch 2025,  loss: 0.13081613481044768\n",
      "Batch 2030,  loss: 0.15699237287044526\n",
      "Batch 2035,  loss: 0.15356968194246293\n",
      "Batch 2040,  loss: 0.1874976560473442\n",
      "Batch 2045,  loss: 0.1537150949239731\n",
      "Batch 2050,  loss: 0.21020530462265014\n",
      "Batch 2055,  loss: 0.16551837027072908\n",
      "Batch 2060,  loss: 0.16667310297489166\n",
      "Batch 2065,  loss: 0.17000181674957277\n",
      "Batch 2070,  loss: 0.17689837217330934\n",
      "Batch 2075,  loss: 0.09328626692295075\n",
      "Batch 2080,  loss: 0.15410128384828567\n",
      "Batch 2085,  loss: 0.16250001788139343\n",
      "Batch 2090,  loss: 0.1560672253370285\n",
      "Batch 2095,  loss: 0.13992732167243957\n",
      "Batch 2100,  loss: 0.1821165382862091\n",
      "Batch 2105,  loss: 0.15112655162811278\n",
      "Batch 2110,  loss: 0.1565806359052658\n",
      "Batch 2115,  loss: 0.18969237059354782\n",
      "Batch 2120,  loss: 0.185181125998497\n",
      "Batch 2125,  loss: 0.16613612174987794\n",
      "Batch 2130,  loss: 0.16628870069980622\n",
      "Batch 2135,  loss: 0.16574442982673646\n",
      "Batch 2140,  loss: 0.17503172159194946\n",
      "Batch 2145,  loss: 0.1512753501534462\n",
      "Batch 2150,  loss: 0.1839693680405617\n",
      "Batch 2155,  loss: 0.16635024696588516\n",
      "Batch 2160,  loss: 0.18785350918769836\n",
      "Batch 2165,  loss: 0.12916401028633118\n",
      "Batch 2170,  loss: 0.198050057888031\n",
      "Batch 2175,  loss: 0.18208237886428832\n",
      "Batch 2180,  loss: 0.18360845744609833\n",
      "Batch 2185,  loss: 0.15077531933784485\n",
      "Batch 2190,  loss: 0.13541779220104216\n",
      "Batch 2195,  loss: 0.12040490210056305\n",
      "Batch 2200,  loss: 0.16255168318748475\n",
      "Batch 2205,  loss: 0.18481389284133912\n",
      "Batch 2210,  loss: 0.1419343337416649\n",
      "Batch 2215,  loss: 0.11823880970478058\n",
      "Batch 2220,  loss: 0.1325859010219574\n",
      "Batch 2225,  loss: 0.16722458899021148\n",
      "Batch 2230,  loss: 0.192672099173069\n",
      "Batch 2235,  loss: 0.18089614808559418\n",
      "Batch 2240,  loss: 0.19781705737113953\n",
      "Batch 2245,  loss: 0.1267578899860382\n",
      "Batch 2250,  loss: 0.14218878000974655\n",
      "Batch 2255,  loss: 0.14446500092744827\n",
      "Batch 2260,  loss: 0.1586373895406723\n",
      "Batch 2265,  loss: 0.10984977781772613\n",
      "Batch 2270,  loss: 0.13973433375358582\n",
      "Batch 2275,  loss: 0.1986408144235611\n",
      "Batch 2280,  loss: 0.13557335436344148\n",
      "Batch 2285,  loss: 0.1674772471189499\n",
      "Batch 2290,  loss: 0.2073694258928299\n",
      "Batch 2295,  loss: 0.16699555218219758\n",
      "Batch 2300,  loss: 0.18600911796092987\n",
      "Batch 2305,  loss: 0.14257802367210387\n",
      "Batch 2310,  loss: 0.14055576920509338\n",
      "Batch 2315,  loss: 0.14130499884486197\n",
      "Batch 2320,  loss: 0.12955324947834015\n",
      "Batch 2325,  loss: 0.17089115381240844\n",
      "Batch 2330,  loss: 0.15210456848144532\n",
      "Batch 2335,  loss: 0.1367010399699211\n",
      "Batch 2340,  loss: 0.12125272303819656\n",
      "Batch 2345,  loss: 0.17515967637300492\n",
      "Batch 2350,  loss: 0.16545091569423676\n",
      "Batch 2355,  loss: 0.14839982837438584\n",
      "Batch 2360,  loss: 0.176940393447876\n",
      "Batch 2365,  loss: 0.17493833601474762\n",
      "Batch 2370,  loss: 0.14909272640943527\n",
      "Batch 2375,  loss: 0.14935752749443054\n",
      "Batch 2380,  loss: 0.14452601969242096\n",
      "Batch 2385,  loss: 0.17435875833034514\n",
      "Batch 2390,  loss: 0.14343886077404022\n",
      "Batch 2395,  loss: 0.1249188631772995\n",
      "Batch 2400,  loss: 0.12384146302938462\n",
      "Batch 2405,  loss: 0.14128498882055282\n",
      "Batch 2410,  loss: 0.1503968358039856\n",
      "Batch 2415,  loss: 0.16129446625709534\n",
      "Batch 2420,  loss: 0.13379526883363724\n",
      "Batch 2425,  loss: 0.15740495324134826\n",
      "Batch 2430,  loss: 0.1875357985496521\n",
      "Batch 2435,  loss: 0.13595229387283325\n",
      "Batch 2440,  loss: 0.14948974847793578\n",
      "Batch 2445,  loss: 0.16918356120586395\n",
      "Batch 2450,  loss: 0.14986614286899566\n",
      "Batch 2455,  loss: 0.1123454213142395\n",
      "Batch 2460,  loss: 0.19331910610198974\n",
      "Batch 2465,  loss: 0.12732911854982376\n",
      "Batch 2470,  loss: 0.1392727494239807\n",
      "Batch 2475,  loss: 0.14544790536165236\n",
      "Batch 2480,  loss: 0.12454084306955338\n",
      "Batch 2485,  loss: 0.16195772886276244\n",
      "Batch 2490,  loss: 0.14255935102701187\n",
      "Batch 2495,  loss: 0.15548278093338014\n",
      "Batch 2500,  loss: 0.1303676962852478\n",
      "Batch 2505,  loss: 0.15223726630210876\n",
      "Batch 2510,  loss: 0.17035876512527465\n",
      "Batch 2515,  loss: 0.17070178389549256\n",
      "Batch 2520,  loss: 0.14817681014537812\n",
      "Batch 2525,  loss: 0.1997278317809105\n",
      "Batch 2530,  loss: 0.16689741015434265\n",
      "Batch 2535,  loss: 0.20224273800849915\n",
      "Batch 2540,  loss: 0.19379384070634842\n",
      "Batch 2545,  loss: 0.13031123578548431\n",
      "Batch 2550,  loss: 0.14962464570999146\n",
      "Batch 2555,  loss: 0.20520274788141252\n",
      "Batch 2560,  loss: 0.15128026008605958\n",
      "Batch 2565,  loss: 0.1212193250656128\n",
      "Batch 2570,  loss: 0.15818977057933808\n",
      "Batch 2575,  loss: 0.15325917601585387\n",
      "Batch 2580,  loss: 0.15154800415039063\n",
      "Batch 2585,  loss: 0.12304173558950424\n",
      "Batch 2590,  loss: 0.14854640066623687\n",
      "Batch 2595,  loss: 0.14191187024116517\n",
      "Batch 2600,  loss: 0.11830300539731979\n",
      "Batch 2605,  loss: 0.14248729646205902\n",
      "Batch 2610,  loss: 0.12627544850111008\n",
      "Batch 2615,  loss: 0.1194100022315979\n",
      "Batch 2620,  loss: 0.09904499351978302\n",
      "Batch 2625,  loss: 0.13849826604127885\n",
      "Batch 2630,  loss: 0.1777281492948532\n",
      "Batch 2635,  loss: 0.16498003602027894\n",
      "Batch 2640,  loss: 0.1768060326576233\n",
      "Batch 2645,  loss: 0.16677992641925812\n",
      "Batch 2650,  loss: 0.13074260354042053\n",
      "Batch 2655,  loss: 0.18929552435874938\n",
      "Batch 2660,  loss: 0.15773691684007646\n",
      "Batch 2665,  loss: 0.1288309931755066\n",
      "Batch 2670,  loss: 0.17333462685346604\n",
      "Batch 2675,  loss: 0.17696283012628555\n",
      "Batch 2680,  loss: 0.1694069817662239\n",
      "Batch 2685,  loss: 0.14906848222017288\n",
      "Batch 2690,  loss: 0.1979136884212494\n",
      "Batch 2695,  loss: 0.11665249615907669\n",
      "Batch 2700,  loss: 0.11429879069328308\n",
      "Batch 2705,  loss: 0.1258791521191597\n",
      "Batch 2710,  loss: 0.17962645888328552\n",
      "Batch 2715,  loss: 0.149718177318573\n",
      "Batch 2720,  loss: 0.17948747277259827\n",
      "Batch 2725,  loss: 0.19244093596935272\n",
      "Batch 2730,  loss: 0.19223442375659944\n",
      "Batch 2735,  loss: 0.15209754109382628\n",
      "Batch 2740,  loss: 0.15135367959737778\n",
      "Batch 2745,  loss: 0.1652388259768486\n",
      "Batch 2750,  loss: 0.14177613258361815\n",
      "Batch 2755,  loss: 0.14768750220537186\n",
      "Batch 2760,  loss: 0.11950687766075134\n",
      "Batch 2765,  loss: 0.16645456701517106\n",
      "Batch 2770,  loss: 0.18296141922473907\n",
      "LOSS train 0.18296141922473907. Validation loss: 0.15860628021160933 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 37:\n",
      "Batch 5,  loss: 0.15082208812236786\n",
      "Batch 10,  loss: 0.14555617719888686\n",
      "Batch 15,  loss: 0.14143401831388475\n",
      "Batch 20,  loss: 0.16363125443458557\n",
      "Batch 25,  loss: 0.1991940438747406\n",
      "Batch 30,  loss: 0.15273385494947433\n",
      "Batch 35,  loss: 0.17710267007350922\n",
      "Batch 40,  loss: 0.15954282283782958\n",
      "Batch 45,  loss: 0.1619822636246681\n",
      "Batch 50,  loss: 0.18424314260482788\n",
      "Batch 55,  loss: 0.1187290295958519\n",
      "Batch 60,  loss: 0.19435883760452272\n",
      "Batch 65,  loss: 0.18376713693141938\n",
      "Batch 70,  loss: 0.15212711691856384\n",
      "Batch 75,  loss: 0.149402391910553\n",
      "Batch 80,  loss: 0.16229295432567598\n",
      "Batch 85,  loss: 0.13220561146736146\n",
      "Batch 90,  loss: 0.12124031335115433\n",
      "Batch 95,  loss: 0.13007766306400298\n",
      "Batch 100,  loss: 0.14031557440757753\n",
      "Batch 105,  loss: 0.13844832628965378\n",
      "Batch 110,  loss: 0.16287405788898468\n",
      "Batch 115,  loss: 0.16896208822727204\n",
      "Batch 120,  loss: 0.16300345063209534\n",
      "Batch 125,  loss: 0.161515474319458\n",
      "Batch 130,  loss: 0.14989768266677855\n",
      "Batch 135,  loss: 0.19498279243707656\n",
      "Batch 140,  loss: 0.1483402818441391\n",
      "Batch 145,  loss: 0.15941892564296722\n",
      "Batch 150,  loss: 0.15273726880550384\n",
      "Batch 155,  loss: 0.20495792627334594\n",
      "Batch 160,  loss: 0.1511922299861908\n",
      "Batch 165,  loss: 0.13413965851068496\n",
      "Batch 170,  loss: 0.16842854470014573\n",
      "Batch 175,  loss: 0.17664606273174285\n",
      "Batch 180,  loss: 0.17026882916688918\n",
      "Batch 185,  loss: 0.1703483998775482\n",
      "Batch 190,  loss: 0.13124872744083405\n",
      "Batch 195,  loss: 0.23345713913440705\n",
      "Batch 200,  loss: 0.1822750449180603\n",
      "Batch 205,  loss: 0.14816063791513442\n",
      "Batch 210,  loss: 0.18429666757583618\n",
      "Batch 215,  loss: 0.1716722533106804\n",
      "Batch 220,  loss: 0.16197026371955872\n",
      "Batch 225,  loss: 0.20605808198451997\n",
      "Batch 230,  loss: 0.14612189084291458\n",
      "Batch 235,  loss: 0.15802156925201416\n",
      "Batch 240,  loss: 0.14676715731620787\n",
      "Batch 245,  loss: 0.16590776443481445\n",
      "Batch 250,  loss: 0.1391989067196846\n",
      "Batch 255,  loss: 0.1431774377822876\n",
      "Batch 260,  loss: 0.11130996942520141\n",
      "Batch 265,  loss: 0.19095027297735215\n",
      "Batch 270,  loss: 0.17236139476299286\n",
      "Batch 275,  loss: 0.1386070117354393\n",
      "Batch 280,  loss: 0.1564680367708206\n",
      "Batch 285,  loss: 0.12737835347652435\n",
      "Batch 290,  loss: 0.16700002402067185\n",
      "Batch 295,  loss: 0.13975990638136865\n",
      "Batch 300,  loss: 0.1453528583049774\n",
      "Batch 305,  loss: 0.1659001260995865\n",
      "Batch 310,  loss: 0.1170089989900589\n",
      "Batch 315,  loss: 0.18363523483276367\n",
      "Batch 320,  loss: 0.15868645608425141\n",
      "Batch 325,  loss: 0.13580364882946014\n",
      "Batch 330,  loss: 0.10550532788038254\n",
      "Batch 335,  loss: 0.19435253739356995\n",
      "Batch 340,  loss: 0.152571439743042\n",
      "Batch 345,  loss: 0.1732283726334572\n",
      "Batch 350,  loss: 0.15627267509698867\n",
      "Batch 355,  loss: 0.14028827100992203\n",
      "Batch 360,  loss: 0.11864659190177917\n",
      "Batch 365,  loss: 0.14160394668579102\n",
      "Batch 370,  loss: 0.15809261798858643\n",
      "Batch 375,  loss: 0.1412744253873825\n",
      "Batch 380,  loss: 0.13864309936761857\n",
      "Batch 385,  loss: 0.1774304687976837\n",
      "Batch 390,  loss: 0.1373159557580948\n",
      "Batch 395,  loss: 0.13583218008279802\n",
      "Batch 400,  loss: 0.1870933398604393\n",
      "Batch 405,  loss: 0.17382905930280684\n",
      "Batch 410,  loss: 0.15974953919649124\n",
      "Batch 415,  loss: 0.10459752380847931\n",
      "Batch 420,  loss: 0.09577396959066391\n",
      "Batch 425,  loss: 0.14601702839136124\n",
      "Batch 430,  loss: 0.14252082705497743\n",
      "Batch 435,  loss: 0.14716030061244964\n",
      "Batch 440,  loss: 0.18566677272319793\n",
      "Batch 445,  loss: 0.1801814019680023\n",
      "Batch 450,  loss: 0.12494999766349793\n",
      "Batch 455,  loss: 0.14418014883995056\n",
      "Batch 460,  loss: 0.12805320024490358\n",
      "Batch 465,  loss: 0.14080297499895095\n",
      "Batch 470,  loss: 0.11617862433195114\n",
      "Batch 475,  loss: 0.1377902254462242\n",
      "Batch 480,  loss: 0.14604739844799042\n",
      "Batch 485,  loss: 0.17522129714488982\n",
      "Batch 490,  loss: 0.12086474299430847\n",
      "Batch 495,  loss: 0.1503448635339737\n",
      "Batch 500,  loss: 0.16980083286762238\n",
      "Batch 505,  loss: 0.16217565834522246\n",
      "Batch 510,  loss: 0.19836386740207673\n",
      "Batch 515,  loss: 0.13551077544689177\n",
      "Batch 520,  loss: 0.17406090199947358\n",
      "Batch 525,  loss: 0.16825876533985137\n",
      "Batch 530,  loss: 0.1619196876883507\n",
      "Batch 535,  loss: 0.14189591109752656\n",
      "Batch 540,  loss: 0.1875951647758484\n",
      "Batch 545,  loss: 0.1954881027340889\n",
      "Batch 550,  loss: 0.13052455335855484\n",
      "Batch 555,  loss: 0.1401481419801712\n",
      "Batch 560,  loss: 0.13184603303670883\n",
      "Batch 565,  loss: 0.12947789579629898\n",
      "Batch 570,  loss: 0.15530411899089813\n",
      "Batch 575,  loss: 0.1701631009578705\n",
      "Batch 580,  loss: 0.1330938771367073\n",
      "Batch 585,  loss: 0.16350301802158357\n",
      "Batch 590,  loss: 0.13499566316604614\n",
      "Batch 595,  loss: 0.20318046808242798\n",
      "Batch 600,  loss: 0.17868863940238952\n",
      "Batch 605,  loss: 0.147652967274189\n",
      "Batch 610,  loss: 0.1346321076154709\n",
      "Batch 615,  loss: 0.14775421023368834\n",
      "Batch 620,  loss: 0.1351697713136673\n",
      "Batch 625,  loss: 0.1565944567322731\n",
      "Batch 630,  loss: 0.13764778524637222\n",
      "Batch 635,  loss: 0.10942639857530594\n",
      "Batch 640,  loss: 0.15799373686313628\n",
      "Batch 645,  loss: 0.1700507342815399\n",
      "Batch 650,  loss: 0.12123018950223922\n",
      "Batch 655,  loss: 0.1752953752875328\n",
      "Batch 660,  loss: 0.1333349645137787\n",
      "Batch 665,  loss: 0.12887948602437974\n",
      "Batch 670,  loss: 0.14673479795455932\n",
      "Batch 675,  loss: 0.16533978283405304\n",
      "Batch 680,  loss: 0.15447438061237334\n",
      "Batch 685,  loss: 0.15736507326364518\n",
      "Batch 690,  loss: 0.16779577136039733\n",
      "Batch 695,  loss: 0.17669082880020143\n",
      "Batch 700,  loss: 0.14613159894943237\n",
      "Batch 705,  loss: 0.11280809938907624\n",
      "Batch 710,  loss: 0.17063629627227783\n",
      "Batch 715,  loss: 0.13448438048362732\n",
      "Batch 720,  loss: 0.11453819870948792\n",
      "Batch 725,  loss: 0.16144518852233886\n",
      "Batch 730,  loss: 0.18681789934635162\n",
      "Batch 735,  loss: 0.16877260208129882\n",
      "Batch 740,  loss: 0.1274419456720352\n",
      "Batch 745,  loss: 0.14082894772291182\n",
      "Batch 750,  loss: 0.16957816779613494\n",
      "Batch 755,  loss: 0.14514823704957963\n",
      "Batch 760,  loss: 0.14187490046024323\n",
      "Batch 765,  loss: 0.1490565448999405\n",
      "Batch 770,  loss: 0.12939064502716063\n",
      "Batch 775,  loss: 0.12536165118217468\n",
      "Batch 780,  loss: 0.17854213416576387\n",
      "Batch 785,  loss: 0.15613662153482438\n",
      "Batch 790,  loss: 0.16154709458351135\n",
      "Batch 795,  loss: 0.15752755105495453\n",
      "Batch 800,  loss: 0.15775904655456544\n",
      "Batch 805,  loss: 0.14055881649255753\n",
      "Batch 810,  loss: 0.1357592910528183\n",
      "Batch 815,  loss: 0.13926775753498077\n",
      "Batch 820,  loss: 0.1663832873106003\n",
      "Batch 825,  loss: 0.17940135300159454\n",
      "Batch 830,  loss: 0.1482705906033516\n",
      "Batch 835,  loss: 0.1755793534219265\n",
      "Batch 840,  loss: 0.14893145859241486\n",
      "Batch 845,  loss: 0.1348790556192398\n",
      "Batch 850,  loss: 0.17559100091457366\n",
      "Batch 855,  loss: 0.14789851903915405\n",
      "Batch 860,  loss: 0.18461707532405852\n",
      "Batch 865,  loss: 0.1555580586194992\n",
      "Batch 870,  loss: 0.2155643731355667\n",
      "Batch 875,  loss: 0.1562056541442871\n",
      "Batch 880,  loss: 0.15530613362789153\n",
      "Batch 885,  loss: 0.15037221014499663\n",
      "Batch 890,  loss: 0.11061065793037414\n",
      "Batch 895,  loss: 0.16776643693447113\n",
      "Batch 900,  loss: 0.12488242089748383\n",
      "Batch 905,  loss: 0.18865661472082138\n",
      "Batch 910,  loss: 0.12696458101272584\n",
      "Batch 915,  loss: 0.1348007172346115\n",
      "Batch 920,  loss: 0.13165332078933717\n",
      "Batch 925,  loss: 0.1277313306927681\n",
      "Batch 930,  loss: 0.17600295543670655\n",
      "Batch 935,  loss: 0.15197941064834594\n",
      "Batch 940,  loss: 0.1510200172662735\n",
      "Batch 945,  loss: 0.16412641555070878\n",
      "Batch 950,  loss: 0.1305539309978485\n",
      "Batch 955,  loss: 0.1623194545507431\n",
      "Batch 960,  loss: 0.14338900595903398\n",
      "Batch 965,  loss: 0.17559422552585602\n",
      "Batch 970,  loss: 0.13961080312728882\n",
      "Batch 975,  loss: 0.14196364879608153\n",
      "Batch 980,  loss: 0.2189558655023575\n",
      "Batch 985,  loss: 0.1550688311457634\n",
      "Batch 990,  loss: 0.14698386490345\n",
      "Batch 995,  loss: 0.16820521354675294\n",
      "Batch 1000,  loss: 0.12251796871423722\n",
      "Batch 1005,  loss: 0.10300826728343963\n",
      "Batch 1010,  loss: 0.19118909835815429\n",
      "Batch 1015,  loss: 0.1586976408958435\n",
      "Batch 1020,  loss: 0.13355595171451567\n",
      "Batch 1025,  loss: 0.18270822018384933\n",
      "Batch 1030,  loss: 0.16391365826129914\n",
      "Batch 1035,  loss: 0.14538349956274033\n",
      "Batch 1040,  loss: 0.15720993429422378\n",
      "Batch 1045,  loss: 0.14844364523887635\n",
      "Batch 1050,  loss: 0.14760535657405854\n",
      "Batch 1055,  loss: 0.14756311029195784\n",
      "Batch 1060,  loss: 0.1503615438938141\n",
      "Batch 1065,  loss: 0.16929637640714645\n",
      "Batch 1070,  loss: 0.1286918729543686\n",
      "Batch 1075,  loss: 0.1449503242969513\n",
      "Batch 1080,  loss: 0.16543884128332137\n",
      "Batch 1085,  loss: 0.11418720185756684\n",
      "Batch 1090,  loss: 0.13416160196065902\n",
      "Batch 1095,  loss: 0.13593906164169312\n",
      "Batch 1100,  loss: 0.12345603629946708\n",
      "Batch 1105,  loss: 0.13988128751516343\n",
      "Batch 1110,  loss: 0.17765183448791505\n",
      "Batch 1115,  loss: 0.15957803279161453\n",
      "Batch 1120,  loss: 0.1466837614774704\n",
      "Batch 1125,  loss: 0.16219161152839662\n",
      "Batch 1130,  loss: 0.14467914402484894\n",
      "Batch 1135,  loss: 0.18145302832126617\n",
      "Batch 1140,  loss: 0.14769688695669175\n",
      "Batch 1145,  loss: 0.12187008857727051\n",
      "Batch 1150,  loss: 0.20962367951869965\n",
      "Batch 1155,  loss: 0.1594096153974533\n",
      "Batch 1160,  loss: 0.19201599359512328\n",
      "Batch 1165,  loss: 0.1800525516271591\n",
      "Batch 1170,  loss: 0.1682564675807953\n",
      "Batch 1175,  loss: 0.17425173819065093\n",
      "Batch 1180,  loss: 0.14928207099437713\n",
      "Batch 1185,  loss: 0.13393479883670806\n",
      "Batch 1190,  loss: 0.15126580148935317\n",
      "Batch 1195,  loss: 0.18185649514198304\n",
      "Batch 1200,  loss: 0.18259811997413636\n",
      "Batch 1205,  loss: 0.13439298272132874\n",
      "Batch 1210,  loss: 0.16070658564567566\n",
      "Batch 1215,  loss: 0.14592189490795135\n",
      "Batch 1220,  loss: 0.14712908565998079\n",
      "Batch 1225,  loss: 0.15606008768081664\n",
      "Batch 1230,  loss: 0.1670605570077896\n",
      "Batch 1235,  loss: 0.1897263616323471\n",
      "Batch 1240,  loss: 0.13612762540578843\n",
      "Batch 1245,  loss: 0.16812679022550583\n",
      "Batch 1250,  loss: 0.1288771688938141\n",
      "Batch 1255,  loss: 0.13001115918159484\n",
      "Batch 1260,  loss: 0.13897329717874526\n",
      "Batch 1265,  loss: 0.13701976239681243\n",
      "Batch 1270,  loss: 0.17477435022592544\n",
      "Batch 1275,  loss: 0.1278425633907318\n",
      "Batch 1280,  loss: 0.1962552011013031\n",
      "Batch 1285,  loss: 0.16873908340930938\n",
      "Batch 1290,  loss: 0.13094569742679596\n",
      "Batch 1295,  loss: 0.13756762444972992\n",
      "Batch 1300,  loss: 0.13403483629226684\n",
      "Batch 1305,  loss: 0.1352567195892334\n",
      "Batch 1310,  loss: 0.16280475109815598\n",
      "Batch 1315,  loss: 0.13749325573444365\n",
      "Batch 1320,  loss: 0.1327102765440941\n",
      "Batch 1325,  loss: 0.13782575577497483\n",
      "Batch 1330,  loss: 0.14431795477867126\n",
      "Batch 1335,  loss: 0.18138370513916016\n",
      "Batch 1340,  loss: 0.13128784596920012\n",
      "Batch 1345,  loss: 0.1562581866979599\n",
      "Batch 1350,  loss: 0.1371693342924118\n",
      "Batch 1355,  loss: 0.13351740837097167\n",
      "Batch 1360,  loss: 0.1505252778530121\n",
      "Batch 1365,  loss: 0.12099578380584716\n",
      "Batch 1370,  loss: 0.13750336170196534\n",
      "Batch 1375,  loss: 0.16482032537460328\n",
      "Batch 1380,  loss: 0.1602616235613823\n",
      "Batch 1385,  loss: 0.16797493398189545\n",
      "Batch 1390,  loss: 0.1427125722169876\n",
      "Batch 1395,  loss: 0.11954554617404937\n",
      "Batch 1400,  loss: 0.18776791095733641\n",
      "Batch 1405,  loss: 0.16456590294837953\n",
      "Batch 1410,  loss: 0.19128865897655487\n",
      "Batch 1415,  loss: 0.1471366599202156\n",
      "Batch 1420,  loss: 0.1647695928812027\n",
      "Batch 1425,  loss: 0.14709734171628952\n",
      "Batch 1430,  loss: 0.15036823600530624\n",
      "Batch 1435,  loss: 0.11115373224020005\n",
      "Batch 1440,  loss: 0.13250481933355332\n",
      "Batch 1445,  loss: 0.16529205441474915\n",
      "Batch 1450,  loss: 0.09332777857780457\n",
      "Batch 1455,  loss: 0.1826122894883156\n",
      "Batch 1460,  loss: 0.14115188717842103\n",
      "Batch 1465,  loss: 0.1305921792984009\n",
      "Batch 1470,  loss: 0.1794659376144409\n",
      "Batch 1475,  loss: 0.17460786998271943\n",
      "Batch 1480,  loss: 0.17773703038692473\n",
      "Batch 1485,  loss: 0.1885412871837616\n",
      "Batch 1490,  loss: 0.13795063495635987\n",
      "Batch 1495,  loss: 0.15363505482673645\n",
      "Batch 1500,  loss: 0.1377769887447357\n",
      "Batch 1505,  loss: 0.1729829028248787\n",
      "Batch 1510,  loss: 0.1621582567691803\n",
      "Batch 1515,  loss: 0.16939731687307358\n",
      "Batch 1520,  loss: 0.16814300119876863\n",
      "Batch 1525,  loss: 0.18284132331609726\n",
      "Batch 1530,  loss: 0.14495365619659423\n",
      "Batch 1535,  loss: 0.16643237918615342\n",
      "Batch 1540,  loss: 0.1319744199514389\n",
      "Batch 1545,  loss: 0.15104035139083863\n",
      "Batch 1550,  loss: 0.1465095192193985\n",
      "Batch 1555,  loss: 0.1305329754948616\n",
      "Batch 1560,  loss: 0.13503677248954774\n",
      "Batch 1565,  loss: 0.159987610578537\n",
      "Batch 1570,  loss: 0.1914393723011017\n",
      "Batch 1575,  loss: 0.14950725734233855\n",
      "Batch 1580,  loss: 0.13510280549526216\n",
      "Batch 1585,  loss: 0.1631614089012146\n",
      "Batch 1590,  loss: 0.11773053854703903\n",
      "Batch 1595,  loss: 0.16072792261838914\n",
      "Batch 1600,  loss: 0.16879510283470153\n",
      "Batch 1605,  loss: 0.21777985692024232\n",
      "Batch 1610,  loss: 0.13925250470638276\n",
      "Batch 1615,  loss: 0.17344858646392822\n",
      "Batch 1620,  loss: 0.16007125079631807\n",
      "Batch 1625,  loss: 0.1408179521560669\n",
      "Batch 1630,  loss: 0.1651968002319336\n",
      "Batch 1635,  loss: 0.15671315491199495\n",
      "Batch 1640,  loss: 0.19482656717300414\n",
      "Batch 1645,  loss: 0.16520560085773467\n",
      "Batch 1650,  loss: 0.16781596839427948\n",
      "Batch 1655,  loss: 0.15295569151639937\n",
      "Batch 1660,  loss: 0.11889739930629731\n",
      "Batch 1665,  loss: 0.18539945185184478\n",
      "Batch 1670,  loss: 0.18535228967666625\n",
      "Batch 1675,  loss: 0.18334588706493377\n",
      "Batch 1680,  loss: 0.13945538997650148\n",
      "Batch 1685,  loss: 0.1717733010649681\n",
      "Batch 1690,  loss: 0.1660341128706932\n",
      "Batch 1695,  loss: 0.16606590449810027\n",
      "Batch 1700,  loss: 0.17808046638965608\n",
      "Batch 1705,  loss: 0.11452359557151795\n",
      "Batch 1710,  loss: 0.1423929139971733\n",
      "Batch 1715,  loss: 0.1116951510310173\n",
      "Batch 1720,  loss: 0.11897572875022888\n",
      "Batch 1725,  loss: 0.1323175087571144\n",
      "Batch 1730,  loss: 0.15320875644683837\n",
      "Batch 1735,  loss: 0.12413406074047088\n",
      "Batch 1740,  loss: 0.16609182059764863\n",
      "Batch 1745,  loss: 0.14717853367328643\n",
      "Batch 1750,  loss: 0.16246262490749358\n",
      "Batch 1755,  loss: 0.14344601333141327\n",
      "Batch 1760,  loss: 0.19421883225440978\n",
      "Batch 1765,  loss: 0.15047759115695952\n",
      "Batch 1770,  loss: 0.17515220791101455\n",
      "Batch 1775,  loss: 0.1473260298371315\n",
      "Batch 1780,  loss: 0.17618536651134492\n",
      "Batch 1785,  loss: 0.15435187220573426\n",
      "Batch 1790,  loss: 0.14232734590768814\n",
      "Batch 1795,  loss: 0.21591303050518035\n",
      "Batch 1800,  loss: 0.1976200371980667\n",
      "Batch 1805,  loss: 0.12427497655153275\n",
      "Batch 1810,  loss: 0.16912791430950164\n",
      "Batch 1815,  loss: 0.1940453678369522\n",
      "Batch 1820,  loss: 0.15406844317913054\n",
      "Batch 1825,  loss: 0.18493853360414506\n",
      "Batch 1830,  loss: 0.13642029762268065\n",
      "Batch 1835,  loss: 0.19508866220712662\n",
      "Batch 1840,  loss: 0.12556437999010087\n",
      "Batch 1845,  loss: 0.16818174421787263\n",
      "Batch 1850,  loss: 0.12006648778915405\n",
      "Batch 1855,  loss: 0.15685043334960938\n",
      "Batch 1860,  loss: 0.15666570663452148\n",
      "Batch 1865,  loss: 0.1317168027162552\n",
      "Batch 1870,  loss: 0.12490954548120499\n",
      "Batch 1875,  loss: 0.16780945807695388\n",
      "Batch 1880,  loss: 0.16619031727313996\n",
      "Batch 1885,  loss: 0.14511257410049438\n",
      "Batch 1890,  loss: 0.18153416514396667\n",
      "Batch 1895,  loss: 0.15383272767066955\n",
      "Batch 1900,  loss: 0.14951060861349105\n",
      "Batch 1905,  loss: 0.17909675240516662\n",
      "Batch 1910,  loss: 0.12035802155733108\n",
      "Batch 1915,  loss: 0.13284632116556166\n",
      "Batch 1920,  loss: 0.15704767853021623\n",
      "Batch 1925,  loss: 0.14790519177913666\n",
      "Batch 1930,  loss: 0.166285203397274\n",
      "Batch 1935,  loss: 0.13932585418224336\n",
      "Batch 1940,  loss: 0.175589719414711\n",
      "Batch 1945,  loss: 0.13536677211523057\n",
      "Batch 1950,  loss: 0.16714882254600524\n",
      "Batch 1955,  loss: 0.17500695288181306\n",
      "Batch 1960,  loss: 0.13161203116178513\n",
      "Batch 1965,  loss: 0.16341999769210816\n",
      "Batch 1970,  loss: 0.14051304161548614\n",
      "Batch 1975,  loss: 0.1666141003370285\n",
      "Batch 1980,  loss: 0.18826558589935302\n",
      "Batch 1985,  loss: 0.17521024942398072\n",
      "Batch 1990,  loss: 0.13957521468400955\n",
      "Batch 1995,  loss: 0.1434984862804413\n",
      "Batch 2000,  loss: 0.17452990561723708\n",
      "Batch 2005,  loss: 0.168813955783844\n",
      "Batch 2010,  loss: 0.16882196962833404\n",
      "Batch 2015,  loss: 0.19871222972869873\n",
      "Batch 2020,  loss: 0.16999388188123704\n",
      "Batch 2025,  loss: 0.15403154939413072\n",
      "Batch 2030,  loss: 0.14391453564167023\n",
      "Batch 2035,  loss: 0.14899314641952516\n",
      "Batch 2040,  loss: 0.1271341472864151\n",
      "Batch 2045,  loss: 0.15849509537220002\n",
      "Batch 2050,  loss: 0.15166522860527037\n",
      "Batch 2055,  loss: 0.15135841816663742\n",
      "Batch 2060,  loss: 0.14291612058877945\n",
      "Batch 2065,  loss: 0.13398888111114501\n",
      "Batch 2070,  loss: 0.1569267764687538\n",
      "Batch 2075,  loss: 0.1669515311717987\n",
      "Batch 2080,  loss: 0.1519697606563568\n",
      "Batch 2085,  loss: 0.15160343945026397\n",
      "Batch 2090,  loss: 0.14120753407478331\n",
      "Batch 2095,  loss: 0.1955104202032089\n",
      "Batch 2100,  loss: 0.11042827665805817\n",
      "Batch 2105,  loss: 0.15873880982398986\n",
      "Batch 2110,  loss: 0.17767381072044372\n",
      "Batch 2115,  loss: 0.13791582584381104\n",
      "Batch 2120,  loss: 0.12115730792284012\n",
      "Batch 2125,  loss: 0.1608324319124222\n",
      "Batch 2130,  loss: 0.20296267569065093\n",
      "Batch 2135,  loss: 0.1717853620648384\n",
      "Batch 2140,  loss: 0.22133129835128784\n",
      "Batch 2145,  loss: 0.17082267701625825\n",
      "Batch 2150,  loss: 0.15408112108707428\n",
      "Batch 2155,  loss: 0.1393811136484146\n",
      "Batch 2160,  loss: 0.1791410282254219\n",
      "Batch 2165,  loss: 0.14343833774328232\n",
      "Batch 2170,  loss: 0.1738235116004944\n",
      "Batch 2175,  loss: 0.15094820857048036\n",
      "Batch 2180,  loss: 0.1312088117003441\n",
      "Batch 2185,  loss: 0.13181910812854766\n",
      "Batch 2190,  loss: 0.17737643271684647\n",
      "Batch 2195,  loss: 0.14666095674037932\n",
      "Batch 2200,  loss: 0.1831235870718956\n",
      "Batch 2205,  loss: 0.15329328179359436\n",
      "Batch 2210,  loss: 0.15991264283657075\n",
      "Batch 2215,  loss: 0.13997898548841475\n",
      "Batch 2220,  loss: 0.1916399359703064\n",
      "Batch 2225,  loss: 0.14771068394184111\n",
      "Batch 2230,  loss: 0.17372800707817077\n",
      "Batch 2235,  loss: 0.1381869435310364\n",
      "Batch 2240,  loss: 0.15086518675088884\n",
      "Batch 2245,  loss: 0.13138856291770934\n",
      "Batch 2250,  loss: 0.18890522420406342\n",
      "Batch 2255,  loss: 0.13892284035682678\n",
      "Batch 2260,  loss: 0.15109768211841584\n",
      "Batch 2265,  loss: 0.15196045935153962\n",
      "Batch 2270,  loss: 0.15976752787828447\n",
      "Batch 2275,  loss: 0.1129738599061966\n",
      "Batch 2280,  loss: 0.19669705778360366\n",
      "Batch 2285,  loss: 0.1453163966536522\n",
      "Batch 2290,  loss: 0.1452543705701828\n",
      "Batch 2295,  loss: 0.19230591356754304\n",
      "Batch 2300,  loss: 0.14945898503065108\n",
      "Batch 2305,  loss: 0.12206478118896484\n",
      "Batch 2310,  loss: 0.1429353415966034\n",
      "Batch 2315,  loss: 0.14064638167619706\n",
      "Batch 2320,  loss: 0.1428682893514633\n",
      "Batch 2325,  loss: 0.16021588742733\n",
      "Batch 2330,  loss: 0.1213289588689804\n",
      "Batch 2335,  loss: 0.12436294257640838\n",
      "Batch 2340,  loss: 0.1807595133781433\n",
      "Batch 2345,  loss: 0.17890080511569978\n",
      "Batch 2350,  loss: 0.16041892766952515\n",
      "Batch 2355,  loss: 0.11421302706003189\n",
      "Batch 2360,  loss: 0.14765020608901977\n",
      "Batch 2365,  loss: 0.17817932069301606\n",
      "Batch 2370,  loss: 0.142314213514328\n",
      "Batch 2375,  loss: 0.14673812687397003\n",
      "Batch 2380,  loss: 0.14584555625915527\n",
      "Batch 2385,  loss: 0.15984531491994858\n",
      "Batch 2390,  loss: 0.14233496487140657\n",
      "Batch 2395,  loss: 0.142099791765213\n",
      "Batch 2400,  loss: 0.1716705486178398\n",
      "Batch 2405,  loss: 0.14489801824092866\n",
      "Batch 2410,  loss: 0.17540376931428908\n",
      "Batch 2415,  loss: 0.11600856631994247\n",
      "Batch 2420,  loss: 0.17189146280288697\n",
      "Batch 2425,  loss: 0.12880779802799225\n",
      "Batch 2430,  loss: 0.14955786913633345\n",
      "Batch 2435,  loss: 0.1729801446199417\n",
      "Batch 2440,  loss: 0.15421863198280333\n",
      "Batch 2445,  loss: 0.14074800163507462\n",
      "Batch 2450,  loss: 0.16753760278224944\n",
      "Batch 2455,  loss: 0.12810097634792328\n",
      "Batch 2460,  loss: 0.15794498175382615\n",
      "Batch 2465,  loss: 0.13726084530353547\n",
      "Batch 2470,  loss: 0.152612142264843\n",
      "Batch 2475,  loss: 0.13444450497627258\n",
      "Batch 2480,  loss: 0.19258923977613449\n",
      "Batch 2485,  loss: 0.1525409683585167\n",
      "Batch 2490,  loss: 0.11923069208860397\n",
      "Batch 2495,  loss: 0.14956599473953247\n",
      "Batch 2500,  loss: 0.14086963832378388\n",
      "Batch 2505,  loss: 0.156149323284626\n",
      "Batch 2510,  loss: 0.16564341485500336\n",
      "Batch 2515,  loss: 0.1287257432937622\n",
      "Batch 2520,  loss: 0.15047101378440858\n",
      "Batch 2525,  loss: 0.13380494117736816\n",
      "Batch 2530,  loss: 0.14762382507324218\n",
      "Batch 2535,  loss: 0.15112422853708268\n",
      "Batch 2540,  loss: 0.15436893105506896\n",
      "Batch 2545,  loss: 0.1635049104690552\n",
      "Batch 2550,  loss: 0.16440313756465913\n",
      "Batch 2555,  loss: 0.17430113703012468\n",
      "Batch 2560,  loss: 0.16420890688896178\n",
      "Batch 2565,  loss: 0.1303025797009468\n",
      "Batch 2570,  loss: 0.16917505264282226\n",
      "Batch 2575,  loss: 0.13455491214990617\n",
      "Batch 2580,  loss: 0.15492229014635087\n",
      "Batch 2585,  loss: 0.15510017275810242\n",
      "Batch 2590,  loss: 0.13976545333862306\n",
      "Batch 2595,  loss: 0.15413669049739837\n",
      "Batch 2600,  loss: 0.1568652480840683\n",
      "Batch 2605,  loss: 0.11574612706899642\n",
      "Batch 2610,  loss: 0.15378548055887223\n",
      "Batch 2615,  loss: 0.15168868154287338\n",
      "Batch 2620,  loss: 0.14508447647094727\n",
      "Batch 2625,  loss: 0.10476494878530503\n",
      "Batch 2630,  loss: 0.1686438351869583\n",
      "Batch 2635,  loss: 0.11699586361646652\n",
      "Batch 2640,  loss: 0.16356497555971145\n",
      "Batch 2645,  loss: 0.1392981618642807\n",
      "Batch 2650,  loss: 0.13628885596990586\n",
      "Batch 2655,  loss: 0.12352541387081147\n",
      "Batch 2660,  loss: 0.1485271006822586\n",
      "Batch 2665,  loss: 0.19537972509860993\n",
      "Batch 2670,  loss: 0.1215696930885315\n",
      "Batch 2675,  loss: 0.1551322251558304\n",
      "Batch 2680,  loss: 0.12486298084259033\n",
      "Batch 2685,  loss: 0.13470574617385864\n",
      "Batch 2690,  loss: 0.18684479147195815\n",
      "Batch 2695,  loss: 0.14701399505138396\n",
      "Batch 2700,  loss: 0.16418282240629195\n",
      "Batch 2705,  loss: 0.11020801514387131\n",
      "Batch 2710,  loss: 0.15233332067728042\n",
      "Batch 2715,  loss: 0.1708947539329529\n",
      "Batch 2720,  loss: 0.2188155919313431\n",
      "Batch 2725,  loss: 0.15603932440280915\n",
      "Batch 2730,  loss: 0.0975335881114006\n",
      "Batch 2735,  loss: 0.13061106503009795\n",
      "Batch 2740,  loss: 0.13307858407497405\n",
      "Batch 2745,  loss: 0.16533902287483215\n",
      "Batch 2750,  loss: 0.14504386484622955\n",
      "Batch 2755,  loss: 0.15380796641111374\n",
      "Batch 2760,  loss: 0.13482091724872589\n",
      "Batch 2765,  loss: 0.13358435332775115\n",
      "Batch 2770,  loss: 0.13015505522489548\n",
      "LOSS train 0.13015505522489548. Validation loss: 0.16109324512093465 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 38:\n",
      "Batch 5,  loss: 0.13958171308040618\n",
      "Batch 10,  loss: 0.19401610195636748\n",
      "Batch 15,  loss: 0.15535401552915573\n",
      "Batch 20,  loss: 0.14204992353916168\n",
      "Batch 25,  loss: 0.20483445525169372\n",
      "Batch 30,  loss: 0.14599253833293915\n",
      "Batch 35,  loss: 0.17958993315696717\n",
      "Batch 40,  loss: 0.14289180040359498\n",
      "Batch 45,  loss: 0.18433864116668702\n",
      "Batch 50,  loss: 0.14615027606487274\n",
      "Batch 55,  loss: 0.12339968532323838\n",
      "Batch 60,  loss: 0.15258309096097947\n",
      "Batch 65,  loss: 0.12757232189178466\n",
      "Batch 70,  loss: 0.12115386128425598\n",
      "Batch 75,  loss: 0.1426377847790718\n",
      "Batch 80,  loss: 0.16312599629163743\n",
      "Batch 85,  loss: 0.1572983980178833\n",
      "Batch 90,  loss: 0.12091023176908493\n",
      "Batch 95,  loss: 0.13626506179571152\n",
      "Batch 100,  loss: 0.14659236520528793\n",
      "Batch 105,  loss: 0.17861805558204652\n",
      "Batch 110,  loss: 0.16411097645759581\n",
      "Batch 115,  loss: 0.14068531095981598\n",
      "Batch 120,  loss: 0.1541624590754509\n",
      "Batch 125,  loss: 0.1459801450371742\n",
      "Batch 130,  loss: 0.12846454977989197\n",
      "Batch 135,  loss: 0.14389150440692902\n",
      "Batch 140,  loss: 0.13533306121826172\n",
      "Batch 145,  loss: 0.16968763768672943\n",
      "Batch 150,  loss: 0.13980348855257035\n",
      "Batch 155,  loss: 0.12876440733671188\n",
      "Batch 160,  loss: 0.1412049874663353\n",
      "Batch 165,  loss: 0.1401484102010727\n",
      "Batch 170,  loss: 0.16956997215747832\n",
      "Batch 175,  loss: 0.18304456472396852\n",
      "Batch 180,  loss: 0.16376646757125854\n",
      "Batch 185,  loss: 0.2115139842033386\n",
      "Batch 190,  loss: 0.1344701439142227\n",
      "Batch 195,  loss: 0.13211924433708191\n",
      "Batch 200,  loss: 0.13738439977169037\n",
      "Batch 205,  loss: 0.1613099068403244\n",
      "Batch 210,  loss: 0.19022861421108245\n",
      "Batch 215,  loss: 0.18554239571094513\n",
      "Batch 220,  loss: 0.15325332581996917\n",
      "Batch 225,  loss: 0.16057752966880798\n",
      "Batch 230,  loss: 0.13934683054685593\n",
      "Batch 235,  loss: 0.17098130881786347\n",
      "Batch 240,  loss: 0.12595492452383042\n",
      "Batch 245,  loss: 0.17615867555141448\n",
      "Batch 250,  loss: 0.1903579980134964\n",
      "Batch 255,  loss: 0.15522349774837493\n",
      "Batch 260,  loss: 0.16926783919334412\n",
      "Batch 265,  loss: 0.18719049096107482\n",
      "Batch 270,  loss: 0.1689007967710495\n",
      "Batch 275,  loss: 0.14788669794797898\n",
      "Batch 280,  loss: 0.18145282864570617\n",
      "Batch 285,  loss: 0.13050310909748078\n",
      "Batch 290,  loss: 0.11990066468715668\n",
      "Batch 295,  loss: 0.13346643894910812\n",
      "Batch 300,  loss: 0.14882866591215133\n",
      "Batch 305,  loss: 0.13747615814208985\n",
      "Batch 310,  loss: 0.13809207528829576\n",
      "Batch 315,  loss: 0.14110767096281052\n",
      "Batch 320,  loss: 0.1389879122376442\n",
      "Batch 325,  loss: 0.1489448145031929\n",
      "Batch 330,  loss: 0.15026772171258926\n",
      "Batch 335,  loss: 0.17623288333415985\n",
      "Batch 340,  loss: 0.21159506738185882\n",
      "Batch 345,  loss: 0.15156940072774888\n",
      "Batch 350,  loss: 0.1854657083749771\n",
      "Batch 355,  loss: 0.13305610418319702\n",
      "Batch 360,  loss: 0.18453845977783204\n",
      "Batch 365,  loss: 0.16639766097068787\n",
      "Batch 370,  loss: 0.15091615319252014\n",
      "Batch 375,  loss: 0.14573273360729216\n",
      "Batch 380,  loss: 0.13598939776420593\n",
      "Batch 385,  loss: 0.1405422419309616\n",
      "Batch 390,  loss: 0.18225424587726594\n",
      "Batch 395,  loss: 0.132286037504673\n",
      "Batch 400,  loss: 0.14635797441005707\n",
      "Batch 405,  loss: 0.18842041194438935\n",
      "Batch 410,  loss: 0.16120876520872116\n",
      "Batch 415,  loss: 0.18128071427345277\n",
      "Batch 420,  loss: 0.16883844435214995\n",
      "Batch 425,  loss: 0.1753397822380066\n",
      "Batch 430,  loss: 0.16477348506450654\n",
      "Batch 435,  loss: 0.13554183542728424\n",
      "Batch 440,  loss: 0.14405957162380217\n",
      "Batch 445,  loss: 0.1319480210542679\n",
      "Batch 450,  loss: 0.16755963414907454\n",
      "Batch 455,  loss: 0.13398424834012984\n",
      "Batch 460,  loss: 0.14352112412452697\n",
      "Batch 465,  loss: 0.15534157305955887\n",
      "Batch 470,  loss: 0.12201760411262512\n",
      "Batch 475,  loss: 0.10912410914897919\n",
      "Batch 480,  loss: 0.18180216550827027\n",
      "Batch 485,  loss: 0.1287854418158531\n",
      "Batch 490,  loss: 0.17333774268627167\n",
      "Batch 495,  loss: 0.14585701525211334\n",
      "Batch 500,  loss: 0.15066296011209487\n",
      "Batch 505,  loss: 0.12699708789587022\n",
      "Batch 510,  loss: 0.13530879765748977\n",
      "Batch 515,  loss: 0.1451645702123642\n",
      "Batch 520,  loss: 0.1520679175853729\n",
      "Batch 525,  loss: 0.17627834975719453\n",
      "Batch 530,  loss: 0.16486517786979676\n",
      "Batch 535,  loss: 0.14626936614513397\n",
      "Batch 540,  loss: 0.17746252715587615\n",
      "Batch 545,  loss: 0.1475977525115013\n",
      "Batch 550,  loss: 0.2023319810628891\n",
      "Batch 555,  loss: 0.15664791762828828\n",
      "Batch 560,  loss: 0.134330877661705\n",
      "Batch 565,  loss: 0.13483891189098357\n",
      "Batch 570,  loss: 0.16473141312599182\n",
      "Batch 575,  loss: 0.23073343336582183\n",
      "Batch 580,  loss: 0.1550268143415451\n",
      "Batch 585,  loss: 0.1656881734728813\n",
      "Batch 590,  loss: 0.18807302713394164\n",
      "Batch 595,  loss: 0.12362022846937179\n",
      "Batch 600,  loss: 0.1533025473356247\n",
      "Batch 605,  loss: 0.14735810756683348\n",
      "Batch 610,  loss: 0.1614953249692917\n",
      "Batch 615,  loss: 0.12562584578990937\n",
      "Batch 620,  loss: 0.1453813537955284\n",
      "Batch 625,  loss: 0.125589120388031\n",
      "Batch 630,  loss: 0.15528603494167328\n",
      "Batch 635,  loss: 0.1474546492099762\n",
      "Batch 640,  loss: 0.14569484442472458\n",
      "Batch 645,  loss: 0.13054089546203612\n",
      "Batch 650,  loss: 0.1294449746608734\n",
      "Batch 655,  loss: 0.12609810531139373\n",
      "Batch 660,  loss: 0.14441837668418883\n",
      "Batch 665,  loss: 0.0993658185005188\n",
      "Batch 670,  loss: 0.14719596058130263\n",
      "Batch 675,  loss: 0.11493179053068162\n",
      "Batch 680,  loss: 0.11947569400072097\n",
      "Batch 685,  loss: 0.1610153242945671\n",
      "Batch 690,  loss: 0.1526661366224289\n",
      "Batch 695,  loss: 0.14545727968215943\n",
      "Batch 700,  loss: 0.1501099020242691\n",
      "Batch 705,  loss: 0.1534176364541054\n",
      "Batch 710,  loss: 0.1712473839521408\n",
      "Batch 715,  loss: 0.14164679497480392\n",
      "Batch 720,  loss: 0.16955046951770783\n",
      "Batch 725,  loss: 0.1526731491088867\n",
      "Batch 730,  loss: 0.13897632658481598\n",
      "Batch 735,  loss: 0.1639494389295578\n",
      "Batch 740,  loss: 0.11506124287843704\n",
      "Batch 745,  loss: 0.15511322319507598\n",
      "Batch 750,  loss: 0.13726111948490144\n",
      "Batch 755,  loss: 0.1469946324825287\n",
      "Batch 760,  loss: 0.15340567678213118\n",
      "Batch 765,  loss: 0.09975641667842865\n",
      "Batch 770,  loss: 0.1344209834933281\n",
      "Batch 775,  loss: 0.1377205729484558\n",
      "Batch 780,  loss: 0.1601983681321144\n",
      "Batch 785,  loss: 0.14958339929580688\n",
      "Batch 790,  loss: 0.14227678179740905\n",
      "Batch 795,  loss: 0.12999796569347383\n",
      "Batch 800,  loss: 0.11788853704929352\n",
      "Batch 805,  loss: 0.15794988125562667\n",
      "Batch 810,  loss: 0.13899244070053102\n",
      "Batch 815,  loss: 0.15551405996084214\n",
      "Batch 820,  loss: 0.13796844333410263\n",
      "Batch 825,  loss: 0.1674555003643036\n",
      "Batch 830,  loss: 0.1807541936635971\n",
      "Batch 835,  loss: 0.17529526203870774\n",
      "Batch 840,  loss: 0.1374343067407608\n",
      "Batch 845,  loss: 0.1684776872396469\n",
      "Batch 850,  loss: 0.19386773705482482\n",
      "Batch 855,  loss: 0.14098059833049775\n",
      "Batch 860,  loss: 0.12053562700748444\n",
      "Batch 865,  loss: 0.14495832622051238\n",
      "Batch 870,  loss: 0.18639659881591797\n",
      "Batch 875,  loss: 0.14372530430555344\n",
      "Batch 880,  loss: 0.15241894572973252\n",
      "Batch 885,  loss: 0.19985525608062743\n",
      "Batch 890,  loss: 0.17532298266887664\n",
      "Batch 895,  loss: 0.14423550367355348\n",
      "Batch 900,  loss: 0.15567118525505066\n",
      "Batch 905,  loss: 0.14023631811141968\n",
      "Batch 910,  loss: 0.15208839774131774\n",
      "Batch 915,  loss: 0.15138992965221404\n",
      "Batch 920,  loss: 0.1884866327047348\n",
      "Batch 925,  loss: 0.10537920445203781\n",
      "Batch 930,  loss: 0.1741297125816345\n",
      "Batch 935,  loss: 0.12847145646810532\n",
      "Batch 940,  loss: 0.14119261354207993\n",
      "Batch 945,  loss: 0.14799119681119918\n",
      "Batch 950,  loss: 0.11198155730962753\n",
      "Batch 955,  loss: 0.148678757250309\n",
      "Batch 960,  loss: 0.1308133900165558\n",
      "Batch 965,  loss: 0.17904249727725982\n",
      "Batch 970,  loss: 0.18228038251399994\n",
      "Batch 975,  loss: 0.2098070964217186\n",
      "Batch 980,  loss: 0.13874508291482926\n",
      "Batch 985,  loss: 0.1155312716960907\n",
      "Batch 990,  loss: 0.17221126854419708\n",
      "Batch 995,  loss: 0.13159552216529846\n",
      "Batch 1000,  loss: 0.16368117928504944\n",
      "Batch 1005,  loss: 0.14860550910234452\n",
      "Batch 1010,  loss: 0.16723456382751464\n",
      "Batch 1015,  loss: 0.1520940363407135\n",
      "Batch 1020,  loss: 0.17351745069026947\n",
      "Batch 1025,  loss: 0.1798877716064453\n",
      "Batch 1030,  loss: 0.16556397676467896\n",
      "Batch 1035,  loss: 0.14324989020824433\n",
      "Batch 1040,  loss: 0.14449025988578795\n",
      "Batch 1045,  loss: 0.13692417442798616\n",
      "Batch 1050,  loss: 0.14767484217882157\n",
      "Batch 1055,  loss: 0.14308375418186187\n",
      "Batch 1060,  loss: 0.12729927003383637\n",
      "Batch 1065,  loss: 0.13212397545576096\n",
      "Batch 1070,  loss: 0.14098592102527618\n",
      "Batch 1075,  loss: 0.1635952264070511\n",
      "Batch 1080,  loss: 0.16186058670282363\n",
      "Batch 1085,  loss: 0.18221451044082643\n",
      "Batch 1090,  loss: 0.1661708414554596\n",
      "Batch 1095,  loss: 0.16759936213493348\n",
      "Batch 1100,  loss: 0.14767440259456635\n",
      "Batch 1105,  loss: 0.1390606701374054\n",
      "Batch 1110,  loss: 0.14540453255176544\n",
      "Batch 1115,  loss: 0.18527056276798248\n",
      "Batch 1120,  loss: 0.17672666162252426\n",
      "Batch 1125,  loss: 0.1467474266886711\n",
      "Batch 1130,  loss: 0.1444011777639389\n",
      "Batch 1135,  loss: 0.1481591761112213\n",
      "Batch 1140,  loss: 0.13905299156904222\n",
      "Batch 1145,  loss: 0.11098812371492386\n",
      "Batch 1150,  loss: 0.1283898025751114\n",
      "Batch 1155,  loss: 0.14901764690876007\n",
      "Batch 1160,  loss: 0.12734686434268952\n",
      "Batch 1165,  loss: 0.14159819781780242\n",
      "Batch 1170,  loss: 0.12381598502397537\n",
      "Batch 1175,  loss: 0.14089131504297256\n",
      "Batch 1180,  loss: 0.1685076266527176\n",
      "Batch 1185,  loss: 0.1588904082775116\n",
      "Batch 1190,  loss: 0.1466379940509796\n",
      "Batch 1195,  loss: 0.15385626256465912\n",
      "Batch 1200,  loss: 0.19954260289669037\n",
      "Batch 1205,  loss: 0.12725138813257217\n",
      "Batch 1210,  loss: 0.1357835814356804\n",
      "Batch 1215,  loss: 0.1382807195186615\n",
      "Batch 1220,  loss: 0.17093000411987305\n",
      "Batch 1225,  loss: 0.16477787494659424\n",
      "Batch 1230,  loss: 0.14521269798278807\n",
      "Batch 1235,  loss: 0.1531824678182602\n",
      "Batch 1240,  loss: 0.19019393920898436\n",
      "Batch 1245,  loss: 0.14195264726877213\n",
      "Batch 1250,  loss: 0.12765239477157592\n",
      "Batch 1255,  loss: 0.1684963196516037\n",
      "Batch 1260,  loss: 0.10515022948384285\n",
      "Batch 1265,  loss: 0.14862740486860276\n",
      "Batch 1270,  loss: 0.1980031669139862\n",
      "Batch 1275,  loss: 0.12064732611179352\n",
      "Batch 1280,  loss: 0.135499507188797\n",
      "Batch 1285,  loss: 0.15683993101119995\n",
      "Batch 1290,  loss: 0.17647769004106523\n",
      "Batch 1295,  loss: 0.13398896157741547\n",
      "Batch 1300,  loss: 0.17339909076690674\n",
      "Batch 1305,  loss: 0.1308389976620674\n",
      "Batch 1310,  loss: 0.15907257199287414\n",
      "Batch 1315,  loss: 0.1601777642965317\n",
      "Batch 1320,  loss: 0.13994208574295045\n",
      "Batch 1325,  loss: 0.16595232635736465\n",
      "Batch 1330,  loss: 0.12904921025037766\n",
      "Batch 1335,  loss: 0.1557909369468689\n",
      "Batch 1340,  loss: 0.1253686413168907\n",
      "Batch 1345,  loss: 0.12496319860219955\n",
      "Batch 1350,  loss: 0.118357053399086\n",
      "Batch 1355,  loss: 0.16058528423309326\n",
      "Batch 1360,  loss: 0.14456990659236907\n",
      "Batch 1365,  loss: 0.14641538113355637\n",
      "Batch 1370,  loss: 0.1439812883734703\n",
      "Batch 1375,  loss: 0.1451560899615288\n",
      "Batch 1380,  loss: 0.14748426973819734\n",
      "Batch 1385,  loss: 0.1768777623772621\n",
      "Batch 1390,  loss: 0.17642543613910674\n",
      "Batch 1395,  loss: 0.14809415638446807\n",
      "Batch 1400,  loss: 0.1798236846923828\n",
      "Batch 1405,  loss: 0.17260278463363649\n",
      "Batch 1410,  loss: 0.1317719876766205\n",
      "Batch 1415,  loss: 0.1621455132961273\n",
      "Batch 1420,  loss: 0.1974879503250122\n",
      "Batch 1425,  loss: 0.13507331907749176\n",
      "Batch 1430,  loss: 0.16963830292224885\n",
      "Batch 1435,  loss: 0.13567788004875184\n",
      "Batch 1440,  loss: 0.17950724363327025\n",
      "Batch 1445,  loss: 0.14371342808008195\n",
      "Batch 1450,  loss: 0.13129210323095322\n",
      "Batch 1455,  loss: 0.12891251891851424\n",
      "Batch 1460,  loss: 0.15041331946849823\n",
      "Batch 1465,  loss: 0.1421514168381691\n",
      "Batch 1470,  loss: 0.1325526475906372\n",
      "Batch 1475,  loss: 0.14328991174697875\n",
      "Batch 1480,  loss: 0.14501641541719437\n",
      "Batch 1485,  loss: 0.14189580231904983\n",
      "Batch 1490,  loss: 0.16728214919567108\n",
      "Batch 1495,  loss: 0.14343910813331603\n",
      "Batch 1500,  loss: 0.1302243322134018\n",
      "Batch 1505,  loss: 0.150920470058918\n",
      "Batch 1510,  loss: 0.14492566734552384\n",
      "Batch 1515,  loss: 0.13392787724733352\n",
      "Batch 1520,  loss: 0.15244610607624054\n",
      "Batch 1525,  loss: 0.17335654348134993\n",
      "Batch 1530,  loss: 0.13625762462615967\n",
      "Batch 1535,  loss: 0.15268862694501878\n",
      "Batch 1540,  loss: 0.14570870846509934\n",
      "Batch 1545,  loss: 0.16214549243450166\n",
      "Batch 1550,  loss: 0.1552113652229309\n",
      "Batch 1555,  loss: 0.14959791600704192\n",
      "Batch 1560,  loss: 0.17909365892410278\n",
      "Batch 1565,  loss: 0.1392335459589958\n",
      "Batch 1570,  loss: 0.14636631458997726\n",
      "Batch 1575,  loss: 0.1747000187635422\n",
      "Batch 1580,  loss: 0.16742730736732483\n",
      "Batch 1585,  loss: 0.1418689265847206\n",
      "Batch 1590,  loss: 0.14209832549095153\n",
      "Batch 1595,  loss: 0.13677975684404373\n",
      "Batch 1600,  loss: 0.17217533886432648\n",
      "Batch 1605,  loss: 0.14432535767555238\n",
      "Batch 1610,  loss: 0.17854368090629577\n",
      "Batch 1615,  loss: 0.162845641374588\n",
      "Batch 1620,  loss: 0.1294381469488144\n",
      "Batch 1625,  loss: 0.1564267784357071\n",
      "Batch 1630,  loss: 0.16406705379486083\n",
      "Batch 1635,  loss: 0.15108869969844818\n",
      "Batch 1640,  loss: 0.156014883518219\n",
      "Batch 1645,  loss: 0.13485439717769623\n",
      "Batch 1650,  loss: 0.17110686600208283\n",
      "Batch 1655,  loss: 0.15335919260978698\n",
      "Batch 1660,  loss: 0.17326073050498964\n",
      "Batch 1665,  loss: 0.11758758425712586\n",
      "Batch 1670,  loss: 0.1511580154299736\n",
      "Batch 1675,  loss: 0.15568314641714096\n",
      "Batch 1680,  loss: 0.16695559918880462\n",
      "Batch 1685,  loss: 0.183802130818367\n",
      "Batch 1690,  loss: 0.1401352494955063\n",
      "Batch 1695,  loss: 0.16283517628908156\n",
      "Batch 1700,  loss: 0.15478508919477463\n",
      "Batch 1705,  loss: 0.16479449719190598\n",
      "Batch 1710,  loss: 0.17678703367710114\n",
      "Batch 1715,  loss: 0.15244614481925964\n",
      "Batch 1720,  loss: 0.18740050494670868\n",
      "Batch 1725,  loss: 0.16287906765937804\n",
      "Batch 1730,  loss: 0.14183972924947738\n",
      "Batch 1735,  loss: 0.14357029944658278\n",
      "Batch 1740,  loss: 0.18621968179941178\n",
      "Batch 1745,  loss: 0.1828610599040985\n",
      "Batch 1750,  loss: 0.14824926853179932\n",
      "Batch 1755,  loss: 0.1585151493549347\n",
      "Batch 1760,  loss: 0.1597035676240921\n",
      "Batch 1765,  loss: 0.14882172495126725\n",
      "Batch 1770,  loss: 0.15554484128952026\n",
      "Batch 1775,  loss: 0.14273761212825775\n",
      "Batch 1780,  loss: 0.16095678210258485\n",
      "Batch 1785,  loss: 0.19678743928670883\n",
      "Batch 1790,  loss: 0.13412274271249772\n",
      "Batch 1795,  loss: 0.1118907243013382\n",
      "Batch 1800,  loss: 0.11487952768802642\n",
      "Batch 1805,  loss: 0.16074878722429276\n",
      "Batch 1810,  loss: 0.17010027319192886\n",
      "Batch 1815,  loss: 0.1415933519601822\n",
      "Batch 1820,  loss: 0.13949381709098815\n",
      "Batch 1825,  loss: 0.1712538942694664\n",
      "Batch 1830,  loss: 0.17452820539474487\n",
      "Batch 1835,  loss: 0.155104561150074\n",
      "Batch 1840,  loss: 0.139365354180336\n",
      "Batch 1845,  loss: 0.14041958898305892\n",
      "Batch 1850,  loss: 0.17196730077266692\n",
      "Batch 1855,  loss: 0.18551959097385406\n",
      "Batch 1860,  loss: 0.17652529776096343\n",
      "Batch 1865,  loss: 0.12815276086330413\n",
      "Batch 1870,  loss: 0.14889784306287765\n",
      "Batch 1875,  loss: 0.1670530378818512\n",
      "Batch 1880,  loss: 0.13257711827754975\n",
      "Batch 1885,  loss: 0.1615786075592041\n",
      "Batch 1890,  loss: 0.13589273244142533\n",
      "Batch 1895,  loss: 0.19744884669780732\n",
      "Batch 1900,  loss: 0.17893688678741454\n",
      "Batch 1905,  loss: 0.16249490678310394\n",
      "Batch 1910,  loss: 0.1605695217847824\n",
      "Batch 1915,  loss: 0.17730662673711778\n",
      "Batch 1920,  loss: 0.14628140330314637\n",
      "Batch 1925,  loss: 0.13918622881174086\n",
      "Batch 1930,  loss: 0.18930143862962723\n",
      "Batch 1935,  loss: 0.1332587018609047\n",
      "Batch 1940,  loss: 0.13993716537952422\n",
      "Batch 1945,  loss: 0.15805931836366655\n",
      "Batch 1950,  loss: 0.10761941522359848\n",
      "Batch 1955,  loss: 0.1267337292432785\n",
      "Batch 1960,  loss: 0.16175865530967712\n",
      "Batch 1965,  loss: 0.1814475581049919\n",
      "Batch 1970,  loss: 0.13878287822008134\n",
      "Batch 1975,  loss: 0.1207932934165001\n",
      "Batch 1980,  loss: 0.15498052090406417\n",
      "Batch 1985,  loss: 0.12824442684650422\n",
      "Batch 1990,  loss: 0.1200764536857605\n",
      "Batch 1995,  loss: 0.12225541174411773\n",
      "Batch 2000,  loss: 0.1537041112780571\n",
      "Batch 2005,  loss: 0.143940207362175\n",
      "Batch 2010,  loss: 0.21172435879707335\n",
      "Batch 2015,  loss: 0.12949572652578353\n",
      "Batch 2020,  loss: 0.13925250470638276\n",
      "Batch 2025,  loss: 0.1605047643184662\n",
      "Batch 2030,  loss: 0.1828676402568817\n",
      "Batch 2035,  loss: 0.12500491738319397\n",
      "Batch 2040,  loss: 0.18035933375358582\n",
      "Batch 2045,  loss: 0.14173202961683273\n",
      "Batch 2050,  loss: 0.15520561784505843\n",
      "Batch 2055,  loss: 0.15088959485292436\n",
      "Batch 2060,  loss: 0.15399064123630524\n",
      "Batch 2065,  loss: 0.13720016330480575\n",
      "Batch 2070,  loss: 0.1260756254196167\n",
      "Batch 2075,  loss: 0.18240060806274414\n",
      "Batch 2080,  loss: 0.1936097577214241\n",
      "Batch 2085,  loss: 0.17234549522399903\n",
      "Batch 2090,  loss: 0.14968299567699433\n",
      "Batch 2095,  loss: 0.19256190657615663\n",
      "Batch 2100,  loss: 0.16961918771266937\n",
      "Batch 2105,  loss: 0.15181582868099214\n",
      "Batch 2110,  loss: 0.18598839938640593\n",
      "Batch 2115,  loss: 0.15353199243545532\n",
      "Batch 2120,  loss: 0.13039071708917618\n",
      "Batch 2125,  loss: 0.18246854543685914\n",
      "Batch 2130,  loss: 0.16439638733863832\n",
      "Batch 2135,  loss: 0.17058189809322358\n",
      "Batch 2140,  loss: 0.14131570011377334\n",
      "Batch 2145,  loss: 0.15364394187927247\n",
      "Batch 2150,  loss: 0.1699440985918045\n",
      "Batch 2155,  loss: 0.20662920773029328\n",
      "Batch 2160,  loss: 0.12005289494991303\n",
      "Batch 2165,  loss: 0.12864920794963836\n",
      "Batch 2170,  loss: 0.14384564459323884\n",
      "Batch 2175,  loss: 0.13829867243766786\n",
      "Batch 2180,  loss: 0.13666577339172364\n",
      "Batch 2185,  loss: 0.16712208986282348\n",
      "Batch 2190,  loss: 0.135534805059433\n",
      "Batch 2195,  loss: 0.14983559995889664\n",
      "Batch 2200,  loss: 0.1376143753528595\n",
      "Batch 2205,  loss: 0.1136360839009285\n",
      "Batch 2210,  loss: 0.19153867959976195\n",
      "Batch 2215,  loss: 0.14038592875003814\n",
      "Batch 2220,  loss: 0.13659582287073135\n",
      "Batch 2225,  loss: 0.16273051053285598\n",
      "Batch 2230,  loss: 0.1559426635503769\n",
      "Batch 2235,  loss: 0.12793149948120117\n",
      "Batch 2240,  loss: 0.18110439479351043\n",
      "Batch 2245,  loss: 0.16054149866104125\n",
      "Batch 2250,  loss: 0.144281505048275\n",
      "Batch 2255,  loss: 0.16005673706531526\n",
      "Batch 2260,  loss: 0.17423800826072694\n",
      "Batch 2265,  loss: 0.13804954588413237\n",
      "Batch 2270,  loss: 0.12645473331212997\n",
      "Batch 2275,  loss: 0.15730874836444855\n",
      "Batch 2280,  loss: 0.15392565727233887\n",
      "Batch 2285,  loss: 0.19770589470863342\n",
      "Batch 2290,  loss: 0.1585357666015625\n",
      "Batch 2295,  loss: 0.17146559357643126\n",
      "Batch 2300,  loss: 0.15212026238441467\n",
      "Batch 2305,  loss: 0.1219197615981102\n",
      "Batch 2310,  loss: 0.1563032701611519\n",
      "Batch 2315,  loss: 0.1157236248254776\n",
      "Batch 2320,  loss: 0.21423912942409515\n",
      "Batch 2325,  loss: 0.1632412225008011\n",
      "Batch 2330,  loss: 0.12480778843164445\n",
      "Batch 2335,  loss: 0.12519109398126602\n",
      "Batch 2340,  loss: 0.15940169990062714\n",
      "Batch 2345,  loss: 0.17936048805713653\n",
      "Batch 2350,  loss: 0.17170937955379487\n",
      "Batch 2355,  loss: 0.1260170266032219\n",
      "Batch 2360,  loss: 0.1408993721008301\n",
      "Batch 2365,  loss: 0.11651269346475601\n",
      "Batch 2370,  loss: 0.17638648748397828\n",
      "Batch 2375,  loss: 0.16294626593589784\n",
      "Batch 2380,  loss: 0.1489086151123047\n",
      "Batch 2385,  loss: 0.11465106308460235\n",
      "Batch 2390,  loss: 0.17263096570968628\n",
      "Batch 2395,  loss: 0.16366900503635406\n",
      "Batch 2400,  loss: 0.14958032667636872\n",
      "Batch 2405,  loss: 0.16856761276721954\n",
      "Batch 2410,  loss: 0.13875729888677596\n",
      "Batch 2415,  loss: 0.12648022472858428\n",
      "Batch 2420,  loss: 0.15725500881671906\n",
      "Batch 2425,  loss: 0.15553065836429597\n",
      "Batch 2430,  loss: 0.13567852228879929\n",
      "Batch 2435,  loss: 0.11728151142597198\n",
      "Batch 2440,  loss: 0.13453900516033174\n",
      "Batch 2445,  loss: 0.16681303232908248\n",
      "Batch 2450,  loss: 0.14282914996147156\n",
      "Batch 2455,  loss: 0.1778499513864517\n",
      "Batch 2460,  loss: 0.1276380106806755\n",
      "Batch 2465,  loss: 0.11565477848052978\n",
      "Batch 2470,  loss: 0.14738129079341888\n",
      "Batch 2475,  loss: 0.13637935221195222\n",
      "Batch 2480,  loss: 0.16124703288078307\n",
      "Batch 2485,  loss: 0.16506873965263366\n",
      "Batch 2490,  loss: 0.17442722022533416\n",
      "Batch 2495,  loss: 0.16142286956310273\n",
      "Batch 2500,  loss: 0.18989252895116807\n",
      "Batch 2505,  loss: 0.13671241998672484\n",
      "Batch 2510,  loss: 0.1366299122571945\n",
      "Batch 2515,  loss: 0.16575783491134644\n",
      "Batch 2520,  loss: 0.1403934806585312\n",
      "Batch 2525,  loss: 0.1492968827486038\n",
      "Batch 2530,  loss: 0.18917267471551896\n",
      "Batch 2535,  loss: 0.14808496385812758\n",
      "Batch 2540,  loss: 0.15503610521554947\n",
      "Batch 2545,  loss: 0.16911210268735885\n",
      "Batch 2550,  loss: 0.1377721443772316\n",
      "Batch 2555,  loss: 0.16940443515777587\n",
      "Batch 2560,  loss: 0.1331912100315094\n",
      "Batch 2565,  loss: 0.14025425165891647\n",
      "Batch 2570,  loss: 0.1956814169883728\n",
      "Batch 2575,  loss: 0.1513825088739395\n",
      "Batch 2580,  loss: 0.13243529200553894\n",
      "Batch 2585,  loss: 0.18907833993434905\n",
      "Batch 2590,  loss: 0.15343200862407685\n",
      "Batch 2595,  loss: 0.12778163701295853\n",
      "Batch 2600,  loss: 0.19858552515506744\n",
      "Batch 2605,  loss: 0.14731414020061492\n",
      "Batch 2610,  loss: 0.17182212471961975\n",
      "Batch 2615,  loss: 0.14823889434337617\n",
      "Batch 2620,  loss: 0.15555374771356584\n",
      "Batch 2625,  loss: 0.14730284810066224\n",
      "Batch 2630,  loss: 0.15830033868551255\n",
      "Batch 2635,  loss: 0.1573179066181183\n",
      "Batch 2640,  loss: 0.15325480103492736\n",
      "Batch 2645,  loss: 0.11416135728359222\n",
      "Batch 2650,  loss: 0.18222611546516418\n",
      "Batch 2655,  loss: 0.17219598442316056\n",
      "Batch 2660,  loss: 0.15430230498313904\n",
      "Batch 2665,  loss: 0.15751794427633287\n",
      "Batch 2670,  loss: 0.13747799694538115\n",
      "Batch 2675,  loss: 0.1237385168671608\n",
      "Batch 2680,  loss: 0.16397936940193175\n",
      "Batch 2685,  loss: 0.1282278910279274\n",
      "Batch 2690,  loss: 0.15236064195632934\n",
      "Batch 2695,  loss: 0.13728299140930175\n",
      "Batch 2700,  loss: 0.1664416342973709\n",
      "Batch 2705,  loss: 0.12989216297864914\n",
      "Batch 2710,  loss: 0.17018245160579681\n",
      "Batch 2715,  loss: 0.14287049472332\n",
      "Batch 2720,  loss: 0.1612422287464142\n",
      "Batch 2725,  loss: 0.13614097833633423\n",
      "Batch 2730,  loss: 0.192696975171566\n",
      "Batch 2735,  loss: 0.12863655984401703\n",
      "Batch 2740,  loss: 0.20817560255527495\n",
      "Batch 2745,  loss: 0.15031934678554534\n",
      "Batch 2750,  loss: 0.13709720969200134\n",
      "Batch 2755,  loss: 0.18056555986404418\n",
      "Batch 2760,  loss: 0.14400814473628998\n",
      "Batch 2765,  loss: 0.15125960856676102\n",
      "Batch 2770,  loss: 0.16617588251829146\n",
      "LOSS train 0.16617588251829146. Validation loss: 0.15620710605677837 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 39:\n",
      "Batch 5,  loss: 0.15322035551071167\n",
      "Batch 10,  loss: 0.19819285869598388\n",
      "Batch 15,  loss: 0.1516677737236023\n",
      "Batch 20,  loss: 0.1559920445084572\n",
      "Batch 25,  loss: 0.16331277489662172\n",
      "Batch 30,  loss: 0.1331132620573044\n",
      "Batch 35,  loss: 0.18109593838453292\n",
      "Batch 40,  loss: 0.1533827468752861\n",
      "Batch 45,  loss: 0.17845417112112044\n",
      "Batch 50,  loss: 0.15863660126924514\n",
      "Batch 55,  loss: 0.15525768399238588\n",
      "Batch 60,  loss: 0.14193966537714003\n",
      "Batch 65,  loss: 0.1713038221001625\n",
      "Batch 70,  loss: 0.1463841527700424\n",
      "Batch 75,  loss: 0.13086214065551757\n",
      "Batch 80,  loss: 0.13657915443181992\n",
      "Batch 85,  loss: 0.16379625499248504\n",
      "Batch 90,  loss: 0.16728343367576598\n",
      "Batch 95,  loss: 0.20870810598134995\n",
      "Batch 100,  loss: 0.155232572555542\n",
      "Batch 105,  loss: 0.16662534475326538\n",
      "Batch 110,  loss: 0.1513407915830612\n",
      "Batch 115,  loss: 0.1720710054039955\n",
      "Batch 120,  loss: 0.16130655258893967\n",
      "Batch 125,  loss: 0.11433168798685074\n",
      "Batch 130,  loss: 0.14825932830572128\n",
      "Batch 135,  loss: 0.15312064439058304\n",
      "Batch 140,  loss: 0.17758091688156127\n",
      "Batch 145,  loss: 0.12666418254375458\n",
      "Batch 150,  loss: 0.1442586213350296\n",
      "Batch 155,  loss: 0.12454394698143005\n",
      "Batch 160,  loss: 0.1954585760831833\n",
      "Batch 165,  loss: 0.15322847962379454\n",
      "Batch 170,  loss: 0.15466474890708923\n",
      "Batch 175,  loss: 0.19907770305871964\n",
      "Batch 180,  loss: 0.16334736347198486\n",
      "Batch 185,  loss: 0.18303419649600983\n",
      "Batch 190,  loss: 0.1372064620256424\n",
      "Batch 195,  loss: 0.19259132742881774\n",
      "Batch 200,  loss: 0.12656980007886887\n",
      "Batch 205,  loss: 0.16837905943393708\n",
      "Batch 210,  loss: 0.11548338085412979\n",
      "Batch 215,  loss: 0.15619765669107438\n",
      "Batch 220,  loss: 0.19525771737098693\n",
      "Batch 225,  loss: 0.1534735679626465\n",
      "Batch 230,  loss: 0.1537626400589943\n",
      "Batch 235,  loss: 0.12133118659257888\n",
      "Batch 240,  loss: 0.16187724769115447\n",
      "Batch 245,  loss: 0.18813293874263765\n",
      "Batch 250,  loss: 0.13653543293476106\n",
      "Batch 255,  loss: 0.14203065186738967\n",
      "Batch 260,  loss: 0.14470710158348082\n",
      "Batch 265,  loss: 0.15474578440189363\n",
      "Batch 270,  loss: 0.14624509513378142\n",
      "Batch 275,  loss: 0.14311525821685792\n",
      "Batch 280,  loss: 0.15265271365642546\n",
      "Batch 285,  loss: 0.14274297654628754\n",
      "Batch 290,  loss: 0.16378948390483855\n",
      "Batch 295,  loss: 0.15833114832639694\n",
      "Batch 300,  loss: 0.14130332469940185\n",
      "Batch 305,  loss: 0.13011764287948607\n",
      "Batch 310,  loss: 0.10287261754274368\n",
      "Batch 315,  loss: 0.14179012030363083\n",
      "Batch 320,  loss: 0.18165442049503328\n",
      "Batch 325,  loss: 0.11544050127267838\n",
      "Batch 330,  loss: 0.14892951250076295\n",
      "Batch 335,  loss: 0.14144318103790282\n",
      "Batch 340,  loss: 0.15810444355010986\n",
      "Batch 345,  loss: 0.14856359362602234\n",
      "Batch 350,  loss: 0.14150164574384688\n",
      "Batch 355,  loss: 0.17416988611221312\n",
      "Batch 360,  loss: 0.14895596504211425\n",
      "Batch 365,  loss: 0.1770571857690811\n",
      "Batch 370,  loss: 0.1526026025414467\n",
      "Batch 375,  loss: 0.1062072366476059\n",
      "Batch 380,  loss: 0.14634059369564056\n",
      "Batch 385,  loss: 0.16672639846801757\n",
      "Batch 390,  loss: 0.11674668043851852\n",
      "Batch 395,  loss: 0.11853730827569961\n",
      "Batch 400,  loss: 0.15357329249382018\n",
      "Batch 405,  loss: 0.1607631504535675\n",
      "Batch 410,  loss: 0.16668194085359572\n",
      "Batch 415,  loss: 0.1627463787794113\n",
      "Batch 420,  loss: 0.16730999201536179\n",
      "Batch 425,  loss: 0.1423800468444824\n",
      "Batch 430,  loss: 0.1552497535943985\n",
      "Batch 435,  loss: 0.1592813804745674\n",
      "Batch 440,  loss: 0.12946684062480926\n",
      "Batch 445,  loss: 0.15277481377124785\n",
      "Batch 450,  loss: 0.15968478620052337\n",
      "Batch 455,  loss: 0.15757239758968353\n",
      "Batch 460,  loss: 0.14693943709135054\n",
      "Batch 465,  loss: 0.1543363317847252\n",
      "Batch 470,  loss: 0.16067762672901154\n",
      "Batch 475,  loss: 0.12773074507713317\n",
      "Batch 480,  loss: 0.14655857980251313\n",
      "Batch 485,  loss: 0.12142129987478256\n",
      "Batch 490,  loss: 0.12699804455041885\n",
      "Batch 495,  loss: 0.17666410207748412\n",
      "Batch 500,  loss: 0.17121710628271103\n",
      "Batch 505,  loss: 0.17770621478557586\n",
      "Batch 510,  loss: 0.19853201508522034\n",
      "Batch 515,  loss: 0.1851409375667572\n",
      "Batch 520,  loss: 0.14597749412059785\n",
      "Batch 525,  loss: 0.15646037459373474\n",
      "Batch 530,  loss: 0.1349451497197151\n",
      "Batch 535,  loss: 0.1214702695608139\n",
      "Batch 540,  loss: 0.23685533106327056\n",
      "Batch 545,  loss: 0.08867874667048455\n",
      "Batch 550,  loss: 0.15044816434383393\n",
      "Batch 555,  loss: 0.15633596628904342\n",
      "Batch 560,  loss: 0.17314043939113616\n",
      "Batch 565,  loss: 0.14927507042884827\n",
      "Batch 570,  loss: 0.1725027471780777\n",
      "Batch 575,  loss: 0.14994511306285857\n",
      "Batch 580,  loss: 0.16088509559631348\n",
      "Batch 585,  loss: 0.14314378499984742\n",
      "Batch 590,  loss: 0.13991924822330476\n",
      "Batch 595,  loss: 0.13214033395051955\n",
      "Batch 600,  loss: 0.14195275604724883\n",
      "Batch 605,  loss: 0.1653476744890213\n",
      "Batch 610,  loss: 0.1246115043759346\n",
      "Batch 615,  loss: 0.158049476146698\n",
      "Batch 620,  loss: 0.11885576248168946\n",
      "Batch 625,  loss: 0.13837240040302276\n",
      "Batch 630,  loss: 0.15402788519859315\n",
      "Batch 635,  loss: 0.17643040120601655\n",
      "Batch 640,  loss: 0.13004864305257796\n",
      "Batch 645,  loss: 0.1719123125076294\n",
      "Batch 650,  loss: 0.14960538148880004\n",
      "Batch 655,  loss: 0.1514866203069687\n",
      "Batch 660,  loss: 0.1323198914527893\n",
      "Batch 665,  loss: 0.13043152540922165\n",
      "Batch 670,  loss: 0.17133368849754332\n",
      "Batch 675,  loss: 0.11490057408809662\n",
      "Batch 680,  loss: 0.17459320574998854\n",
      "Batch 685,  loss: 0.14508845508098603\n",
      "Batch 690,  loss: 0.11984932273626328\n",
      "Batch 695,  loss: 0.16248080059885978\n",
      "Batch 700,  loss: 0.16145668774843216\n",
      "Batch 705,  loss: 0.15274364054203032\n",
      "Batch 710,  loss: 0.18047606348991393\n",
      "Batch 715,  loss: 0.15479353368282317\n",
      "Batch 720,  loss: 0.1477796897292137\n",
      "Batch 725,  loss: 0.16560235470533372\n",
      "Batch 730,  loss: 0.11945107132196427\n",
      "Batch 735,  loss: 0.12575924396514893\n",
      "Batch 740,  loss: 0.13201235681772233\n",
      "Batch 745,  loss: 0.15179824233055114\n",
      "Batch 750,  loss: 0.1215271919965744\n",
      "Batch 755,  loss: 0.1240757867693901\n",
      "Batch 760,  loss: 0.12736764103174208\n",
      "Batch 765,  loss: 0.1466629222035408\n",
      "Batch 770,  loss: 0.14428520500659942\n",
      "Batch 775,  loss: 0.19330861568450927\n",
      "Batch 780,  loss: 0.13868874311447144\n",
      "Batch 785,  loss: 0.17789994776248932\n",
      "Batch 790,  loss: 0.09732793718576431\n",
      "Batch 795,  loss: 0.1429525211453438\n",
      "Batch 800,  loss: 0.13310966193675994\n",
      "Batch 805,  loss: 0.14920699149370192\n",
      "Batch 810,  loss: 0.19106482565402985\n",
      "Batch 815,  loss: 0.13721139281988143\n",
      "Batch 820,  loss: 0.13144964575767518\n",
      "Batch 825,  loss: 0.1282566413283348\n",
      "Batch 830,  loss: 0.13734696060419083\n",
      "Batch 835,  loss: 0.15952907800674437\n",
      "Batch 840,  loss: 0.12778452634811402\n",
      "Batch 845,  loss: 0.11268222033977508\n",
      "Batch 850,  loss: 0.16335409581661225\n",
      "Batch 855,  loss: 0.12362175583839416\n",
      "Batch 860,  loss: 0.16795251071453093\n",
      "Batch 865,  loss: 0.12615555226802827\n",
      "Batch 870,  loss: 0.14989722073078154\n",
      "Batch 875,  loss: 0.1511440932750702\n",
      "Batch 880,  loss: 0.12534078657627107\n",
      "Batch 885,  loss: 0.15083948373794556\n",
      "Batch 890,  loss: 0.13113031089305877\n",
      "Batch 895,  loss: 0.19938333332538605\n",
      "Batch 900,  loss: 0.1921876847743988\n",
      "Batch 905,  loss: 0.1579672798514366\n",
      "Batch 910,  loss: 0.18386483788490296\n",
      "Batch 915,  loss: 0.15636544823646545\n",
      "Batch 920,  loss: 0.1261692985892296\n",
      "Batch 925,  loss: 0.1490822285413742\n",
      "Batch 930,  loss: 0.1482323706150055\n",
      "Batch 935,  loss: 0.1717415452003479\n",
      "Batch 940,  loss: 0.14581997096538543\n",
      "Batch 945,  loss: 0.19204055666923522\n",
      "Batch 950,  loss: 0.1432512328028679\n",
      "Batch 955,  loss: 0.17792018055915831\n",
      "Batch 960,  loss: 0.15453650802373886\n",
      "Batch 965,  loss: 0.1322582855820656\n",
      "Batch 970,  loss: 0.1507428139448166\n",
      "Batch 975,  loss: 0.15541620254516603\n",
      "Batch 980,  loss: 0.16872571259737015\n",
      "Batch 985,  loss: 0.11492290794849395\n",
      "Batch 990,  loss: 0.1126867562532425\n",
      "Batch 995,  loss: 0.16731189489364623\n",
      "Batch 1000,  loss: 0.1302679806947708\n",
      "Batch 1005,  loss: 0.13895869702100755\n",
      "Batch 1010,  loss: 0.17727120518684386\n",
      "Batch 1015,  loss: 0.13315982222557068\n",
      "Batch 1020,  loss: 0.17509259581565856\n",
      "Batch 1025,  loss: 0.1256520316004753\n",
      "Batch 1030,  loss: 0.13284811973571778\n",
      "Batch 1035,  loss: 0.1613483101129532\n",
      "Batch 1040,  loss: 0.16748503148555755\n",
      "Batch 1045,  loss: 0.09867056012153626\n",
      "Batch 1050,  loss: 0.1761261612176895\n",
      "Batch 1055,  loss: 0.18318056166172028\n",
      "Batch 1060,  loss: 0.13038334399461746\n",
      "Batch 1065,  loss: 0.14476961493492127\n",
      "Batch 1070,  loss: 0.14520856589078904\n",
      "Batch 1075,  loss: 0.1457514762878418\n",
      "Batch 1080,  loss: 0.150345678627491\n",
      "Batch 1085,  loss: 0.15590894520282744\n",
      "Batch 1090,  loss: 0.1611922264099121\n",
      "Batch 1095,  loss: 0.14697252511978148\n",
      "Batch 1100,  loss: 0.15410380959510803\n",
      "Batch 1105,  loss: 0.11722234040498733\n",
      "Batch 1110,  loss: 0.1766261175274849\n",
      "Batch 1115,  loss: 0.20533646047115325\n",
      "Batch 1120,  loss: 0.1496559724211693\n",
      "Batch 1125,  loss: 0.13031223118305207\n",
      "Batch 1130,  loss: 0.1347016677260399\n",
      "Batch 1135,  loss: 0.16501401588320733\n",
      "Batch 1140,  loss: 0.12296458780765533\n",
      "Batch 1145,  loss: 0.12167541086673736\n",
      "Batch 1150,  loss: 0.1488186687231064\n",
      "Batch 1155,  loss: 0.15819506198167801\n",
      "Batch 1160,  loss: 0.13407759219408036\n",
      "Batch 1165,  loss: 0.1918616086244583\n",
      "Batch 1170,  loss: 0.17040727734565736\n",
      "Batch 1175,  loss: 0.15214286595582963\n",
      "Batch 1180,  loss: 0.15983828902244568\n",
      "Batch 1185,  loss: 0.15506224632263182\n",
      "Batch 1190,  loss: 0.15354605317115783\n",
      "Batch 1195,  loss: 0.1689550071954727\n",
      "Batch 1200,  loss: 0.18376898169517517\n",
      "Batch 1205,  loss: 0.13545227646827698\n",
      "Batch 1210,  loss: 0.11777876764535904\n",
      "Batch 1215,  loss: 0.12592659294605255\n",
      "Batch 1220,  loss: 0.15170268714427948\n",
      "Batch 1225,  loss: 0.18414820730686188\n",
      "Batch 1230,  loss: 0.23112038671970367\n",
      "Batch 1235,  loss: 0.18313049674034118\n",
      "Batch 1240,  loss: 0.17095450162887574\n",
      "Batch 1245,  loss: 0.12717981040477752\n",
      "Batch 1250,  loss: 0.1466273471713066\n",
      "Batch 1255,  loss: 0.12050955891609191\n",
      "Batch 1260,  loss: 0.145063054561615\n",
      "Batch 1265,  loss: 0.13866646140813826\n",
      "Batch 1270,  loss: 0.14730284065008165\n",
      "Batch 1275,  loss: 0.12956006824970245\n",
      "Batch 1280,  loss: 0.1764679193496704\n",
      "Batch 1285,  loss: 0.21070185899734498\n",
      "Batch 1290,  loss: 0.137855364382267\n",
      "Batch 1295,  loss: 0.17562837153673172\n",
      "Batch 1300,  loss: 0.1733851909637451\n",
      "Batch 1305,  loss: 0.17908854484558107\n",
      "Batch 1310,  loss: 0.13463018238544464\n",
      "Batch 1315,  loss: 0.12959813177585602\n",
      "Batch 1320,  loss: 0.13309505432844163\n",
      "Batch 1325,  loss: 0.13918664902448655\n",
      "Batch 1330,  loss: 0.15660687536001205\n",
      "Batch 1335,  loss: 0.1344030350446701\n",
      "Batch 1340,  loss: 0.15232328772544862\n",
      "Batch 1345,  loss: 0.13383661359548568\n",
      "Batch 1350,  loss: 0.20916977524757385\n",
      "Batch 1355,  loss: 0.17351772785186767\n",
      "Batch 1360,  loss: 0.16016317456960677\n",
      "Batch 1365,  loss: 0.1677270621061325\n",
      "Batch 1370,  loss: 0.1502804011106491\n",
      "Batch 1375,  loss: 0.12380507290363311\n",
      "Batch 1380,  loss: 0.15389218926429749\n",
      "Batch 1385,  loss: 0.1357082337141037\n",
      "Batch 1390,  loss: 0.15177435278892518\n",
      "Batch 1395,  loss: 0.17325072586536408\n",
      "Batch 1400,  loss: 0.16271608769893647\n",
      "Batch 1405,  loss: 0.1442284345626831\n",
      "Batch 1410,  loss: 0.1463124632835388\n",
      "Batch 1415,  loss: 0.18864176869392396\n",
      "Batch 1420,  loss: 0.12036645710468293\n",
      "Batch 1425,  loss: 0.16386643648147584\n",
      "Batch 1430,  loss: 0.1420815646648407\n",
      "Batch 1435,  loss: 0.17619068324565887\n",
      "Batch 1440,  loss: 0.14181963205337525\n",
      "Batch 1445,  loss: 0.1495974063873291\n",
      "Batch 1450,  loss: 0.17233605682849884\n",
      "Batch 1455,  loss: 0.167128387093544\n",
      "Batch 1460,  loss: 0.1327202320098877\n",
      "Batch 1465,  loss: 0.16495091319084168\n",
      "Batch 1470,  loss: 0.15922445356845855\n",
      "Batch 1475,  loss: 0.1852664977312088\n",
      "Batch 1480,  loss: 0.10448853373527527\n",
      "Batch 1485,  loss: 0.13971515893936157\n",
      "Batch 1490,  loss: 0.11159790605306626\n",
      "Batch 1495,  loss: 0.15628067553043365\n",
      "Batch 1500,  loss: 0.12207695990800857\n",
      "Batch 1505,  loss: 0.11894571930170059\n",
      "Batch 1510,  loss: 0.16604520678520202\n",
      "Batch 1515,  loss: 0.12911297082901002\n",
      "Batch 1520,  loss: 0.12708296477794648\n",
      "Batch 1525,  loss: 0.1804804801940918\n",
      "Batch 1530,  loss: 0.14521547257900239\n",
      "Batch 1535,  loss: 0.12993728071451188\n",
      "Batch 1540,  loss: 0.15949898362159728\n",
      "Batch 1545,  loss: 0.13939069509506224\n",
      "Batch 1550,  loss: 0.15827592015266417\n",
      "Batch 1555,  loss: 0.15804599821567536\n",
      "Batch 1560,  loss: 0.1511203318834305\n",
      "Batch 1565,  loss: 0.13161929249763488\n",
      "Batch 1570,  loss: 0.126858951151371\n",
      "Batch 1575,  loss: 0.145573490858078\n",
      "Batch 1580,  loss: 0.1603839725255966\n",
      "Batch 1585,  loss: 0.1583499789237976\n",
      "Batch 1590,  loss: 0.13982420265674592\n",
      "Batch 1595,  loss: 0.13871704488992692\n",
      "Batch 1600,  loss: 0.1639588236808777\n",
      "Batch 1605,  loss: 0.14634196907281877\n",
      "Batch 1610,  loss: 0.15360898077487944\n",
      "Batch 1615,  loss: 0.16218232810497285\n",
      "Batch 1620,  loss: 0.1322208173573017\n",
      "Batch 1625,  loss: 0.1627151131629944\n",
      "Batch 1630,  loss: 0.14235134273767472\n",
      "Batch 1635,  loss: 0.14583479464054108\n",
      "Batch 1640,  loss: 0.16481797099113465\n",
      "Batch 1645,  loss: 0.10977579206228257\n",
      "Batch 1650,  loss: 0.15983688831329346\n",
      "Batch 1655,  loss: 0.1570087641477585\n",
      "Batch 1660,  loss: 0.15385302454233168\n",
      "Batch 1665,  loss: 0.143966506421566\n",
      "Batch 1670,  loss: 0.17565467804670334\n",
      "Batch 1675,  loss: 0.12313574552536011\n",
      "Batch 1680,  loss: 0.18717312812805176\n",
      "Batch 1685,  loss: 0.1413260743021965\n",
      "Batch 1690,  loss: 0.17260572016239167\n",
      "Batch 1695,  loss: 0.1312137573957443\n",
      "Batch 1700,  loss: 0.19493283927440644\n",
      "Batch 1705,  loss: 0.1548092171549797\n",
      "Batch 1710,  loss: 0.11328984498977661\n",
      "Batch 1715,  loss: 0.10060901790857316\n",
      "Batch 1720,  loss: 0.13165313005447388\n",
      "Batch 1725,  loss: 0.1911926254630089\n",
      "Batch 1730,  loss: 0.16604293882846832\n",
      "Batch 1735,  loss: 0.17258232533931733\n",
      "Batch 1740,  loss: 0.17669961452484131\n",
      "Batch 1745,  loss: 0.12574099898338317\n",
      "Batch 1750,  loss: 0.17889748513698578\n",
      "Batch 1755,  loss: 0.17165352255105973\n",
      "Batch 1760,  loss: 0.14633672535419465\n",
      "Batch 1765,  loss: 0.12767883092164994\n",
      "Batch 1770,  loss: 0.13989644050598143\n",
      "Batch 1775,  loss: 0.1392248570919037\n",
      "Batch 1780,  loss: 0.15170178711414337\n",
      "Batch 1785,  loss: 0.12364660054445267\n",
      "Batch 1790,  loss: 0.16383790075778962\n",
      "Batch 1795,  loss: 0.17946236729621887\n",
      "Batch 1800,  loss: 0.12131251096725464\n",
      "Batch 1805,  loss: 0.16404610574245454\n",
      "Batch 1810,  loss: 0.14481954723596574\n",
      "Batch 1815,  loss: 0.1334790602326393\n",
      "Batch 1820,  loss: 0.1498036041855812\n",
      "Batch 1825,  loss: 0.13786203861236573\n",
      "Batch 1830,  loss: 0.11001429855823516\n",
      "Batch 1835,  loss: 0.17864592373371124\n",
      "Batch 1840,  loss: 0.14809362292289735\n",
      "Batch 1845,  loss: 0.16670043170452117\n",
      "Batch 1850,  loss: 0.11434819996356964\n",
      "Batch 1855,  loss: 0.16065863519906998\n",
      "Batch 1860,  loss: 0.1875217780470848\n",
      "Batch 1865,  loss: 0.17951060980558395\n",
      "Batch 1870,  loss: 0.14064414501190187\n",
      "Batch 1875,  loss: 0.12321242243051529\n",
      "Batch 1880,  loss: 0.14258598983287812\n",
      "Batch 1885,  loss: 0.15069472789764404\n",
      "Batch 1890,  loss: 0.15527513474225998\n",
      "Batch 1895,  loss: 0.18321870863437653\n",
      "Batch 1900,  loss: 0.13085898160934448\n",
      "Batch 1905,  loss: 0.16328332126140593\n",
      "Batch 1910,  loss: 0.17098288387060165\n",
      "Batch 1915,  loss: 0.17448963671922685\n",
      "Batch 1920,  loss: 0.14542972892522812\n",
      "Batch 1925,  loss: 0.16037742793560028\n",
      "Batch 1930,  loss: 0.16354503631591796\n",
      "Batch 1935,  loss: 0.14257907420396804\n",
      "Batch 1940,  loss: 0.20375203788280488\n",
      "Batch 1945,  loss: 0.1753267377614975\n",
      "Batch 1950,  loss: 0.14154698252677916\n",
      "Batch 1955,  loss: 0.14669927954673767\n",
      "Batch 1960,  loss: 0.18836058676242828\n",
      "Batch 1965,  loss: 0.17373281419277192\n",
      "Batch 1970,  loss: 0.13720498681068422\n",
      "Batch 1975,  loss: 0.14001762568950654\n",
      "Batch 1980,  loss: 0.14821946024894714\n",
      "Batch 1985,  loss: 0.1388204053044319\n",
      "Batch 1990,  loss: 0.20013653635978698\n",
      "Batch 1995,  loss: 0.14448907673358918\n",
      "Batch 2000,  loss: 0.1688014581799507\n",
      "Batch 2005,  loss: 0.12340306043624878\n",
      "Batch 2010,  loss: 0.10935867130756378\n",
      "Batch 2015,  loss: 0.1640839010477066\n",
      "Batch 2020,  loss: 0.14009508043527602\n",
      "Batch 2025,  loss: 0.16950645446777343\n",
      "Batch 2030,  loss: 0.15770622789859773\n",
      "Batch 2035,  loss: 0.1648143246769905\n",
      "Batch 2040,  loss: 0.15846165120601655\n",
      "Batch 2045,  loss: 0.1414901167154312\n",
      "Batch 2050,  loss: 0.14490749537944794\n",
      "Batch 2055,  loss: 0.11376027762889862\n",
      "Batch 2060,  loss: 0.14662000983953477\n",
      "Batch 2065,  loss: 0.1429428145289421\n",
      "Batch 2070,  loss: 0.14401354938745498\n",
      "Batch 2075,  loss: 0.1410412922501564\n",
      "Batch 2080,  loss: 0.12847872078418732\n",
      "Batch 2085,  loss: 0.19172978401184082\n",
      "Batch 2090,  loss: 0.15786542296409606\n",
      "Batch 2095,  loss: 0.2187545120716095\n",
      "Batch 2100,  loss: 0.15632917881011962\n",
      "Batch 2105,  loss: 0.1156270943582058\n",
      "Batch 2110,  loss: 0.17202697396278382\n",
      "Batch 2115,  loss: 0.13341481536626815\n",
      "Batch 2120,  loss: 0.174787238240242\n",
      "Batch 2125,  loss: 0.16406678259372712\n",
      "Batch 2130,  loss: 0.1369434729218483\n",
      "Batch 2135,  loss: 0.15720051229000093\n",
      "Batch 2140,  loss: 0.124873086810112\n",
      "Batch 2145,  loss: 0.19569954872131348\n",
      "Batch 2150,  loss: 0.15921563804149627\n",
      "Batch 2155,  loss: 0.1293524533510208\n",
      "Batch 2160,  loss: 0.13131386786699295\n",
      "Batch 2165,  loss: 0.19967693090438843\n",
      "Batch 2170,  loss: 0.16223546862602234\n",
      "Batch 2175,  loss: 0.1710483103990555\n",
      "Batch 2180,  loss: 0.16560887396335602\n",
      "Batch 2185,  loss: 0.21113407909870147\n",
      "Batch 2190,  loss: 0.17241963744163513\n",
      "Batch 2195,  loss: 0.12377313524484634\n",
      "Batch 2200,  loss: 0.14424936175346376\n",
      "Batch 2205,  loss: 0.13734611570835115\n",
      "Batch 2210,  loss: 0.15650354325771332\n",
      "Batch 2215,  loss: 0.16187501102685928\n",
      "Batch 2220,  loss: 0.12903812080621718\n",
      "Batch 2225,  loss: 0.15301872938871383\n",
      "Batch 2230,  loss: 0.16011648923158645\n",
      "Batch 2235,  loss: 0.17826902121305466\n",
      "Batch 2240,  loss: 0.15917102992534637\n",
      "Batch 2245,  loss: 0.13798487931489944\n",
      "Batch 2250,  loss: 0.1284312129020691\n",
      "Batch 2255,  loss: 0.16731816828250884\n",
      "Batch 2260,  loss: 0.13883586823940278\n",
      "Batch 2265,  loss: 0.14551265984773637\n",
      "Batch 2270,  loss: 0.1324844941496849\n",
      "Batch 2275,  loss: 0.14049891382455826\n",
      "Batch 2280,  loss: 0.17346638441085815\n",
      "Batch 2285,  loss: 0.17256415784358978\n",
      "Batch 2290,  loss: 0.15402128100395202\n",
      "Batch 2295,  loss: 0.11920263022184371\n",
      "Batch 2300,  loss: 0.20065792500972748\n",
      "Batch 2305,  loss: 0.13954397141933442\n",
      "Batch 2310,  loss: 0.1543491631746292\n",
      "Batch 2315,  loss: 0.14585791528224945\n",
      "Batch 2320,  loss: 0.15967451483011247\n",
      "Batch 2325,  loss: 0.14297928661108017\n",
      "Batch 2330,  loss: 0.13639850169420242\n",
      "Batch 2335,  loss: 0.14966845512390137\n",
      "Batch 2340,  loss: 0.17556674182415008\n",
      "Batch 2345,  loss: 0.20288486033678055\n",
      "Batch 2350,  loss: 0.20432493686676026\n",
      "Batch 2355,  loss: 0.1748729467391968\n",
      "Batch 2360,  loss: 0.12956365048885346\n",
      "Batch 2365,  loss: 0.1615046888589859\n",
      "Batch 2370,  loss: 0.12451093196868897\n",
      "Batch 2375,  loss: 0.1650667041540146\n",
      "Batch 2380,  loss: 0.16525938659906386\n",
      "Batch 2385,  loss: 0.18747758567333223\n",
      "Batch 2390,  loss: 0.1620379388332367\n",
      "Batch 2395,  loss: 0.1654825210571289\n",
      "Batch 2400,  loss: 0.1363633990287781\n",
      "Batch 2405,  loss: 0.15467047989368438\n",
      "Batch 2410,  loss: 0.18001129925251008\n",
      "Batch 2415,  loss: 0.1764695778489113\n",
      "Batch 2420,  loss: 0.14281417280435563\n",
      "Batch 2425,  loss: 0.13188712745904924\n",
      "Batch 2430,  loss: 0.128291580080986\n",
      "Batch 2435,  loss: 0.12743207961320877\n",
      "Batch 2440,  loss: 0.14771300852298735\n",
      "Batch 2445,  loss: 0.16934478878974915\n",
      "Batch 2450,  loss: 0.1432679995894432\n",
      "Batch 2455,  loss: 0.14937167167663573\n",
      "Batch 2460,  loss: 0.19517397582530976\n",
      "Batch 2465,  loss: 0.1524294674396515\n",
      "Batch 2470,  loss: 0.18013506829738618\n",
      "Batch 2475,  loss: 0.15372365564107895\n",
      "Batch 2480,  loss: 0.12548476234078407\n",
      "Batch 2485,  loss: 0.14314210414886475\n",
      "Batch 2490,  loss: 0.14624880701303483\n",
      "Batch 2495,  loss: 0.17746580094099046\n",
      "Batch 2500,  loss: 0.12034492343664169\n",
      "Batch 2505,  loss: 0.1310085326433182\n",
      "Batch 2510,  loss: 0.13701607286930084\n",
      "Batch 2515,  loss: 0.1952153503894806\n",
      "Batch 2520,  loss: 0.13660146296024323\n",
      "Batch 2525,  loss: 0.16964383721351622\n",
      "Batch 2530,  loss: 0.13711478561162949\n",
      "Batch 2535,  loss: 0.16377794444561006\n",
      "Batch 2540,  loss: 0.18122447431087493\n",
      "Batch 2545,  loss: 0.14684989005327226\n",
      "Batch 2550,  loss: 0.18157244622707366\n",
      "Batch 2555,  loss: 0.15721855610609053\n",
      "Batch 2560,  loss: 0.16934548318386078\n",
      "Batch 2565,  loss: 0.13329233527183532\n",
      "Batch 2570,  loss: 0.1153150662779808\n",
      "Batch 2575,  loss: 0.12526484578847885\n",
      "Batch 2580,  loss: 0.15383903980255126\n",
      "Batch 2585,  loss: 0.15973826944828035\n",
      "Batch 2590,  loss: 0.16587206870317459\n",
      "Batch 2595,  loss: 0.163390052318573\n",
      "Batch 2600,  loss: 0.14120383858680724\n",
      "Batch 2605,  loss: 0.16238927245140075\n",
      "Batch 2610,  loss: 0.12193523049354553\n",
      "Batch 2615,  loss: 0.17470284551382065\n",
      "Batch 2620,  loss: 0.13399850577116013\n",
      "Batch 2625,  loss: 0.13216962963342666\n",
      "Batch 2630,  loss: 0.1417330801486969\n",
      "Batch 2635,  loss: 0.14384903609752656\n",
      "Batch 2640,  loss: 0.22107300460338591\n",
      "Batch 2645,  loss: 0.15474313944578172\n",
      "Batch 2650,  loss: 0.14174718260765076\n",
      "Batch 2655,  loss: 0.1236041471362114\n",
      "Batch 2660,  loss: 0.15487573444843292\n",
      "Batch 2665,  loss: 0.15982354432344437\n",
      "Batch 2670,  loss: 0.15229947566986085\n",
      "Batch 2675,  loss: 0.15706775337457657\n",
      "Batch 2680,  loss: 0.15346712470054627\n",
      "Batch 2685,  loss: 0.12030547261238098\n",
      "Batch 2690,  loss: 0.12063625007867813\n",
      "Batch 2695,  loss: 0.17629062980413437\n",
      "Batch 2700,  loss: 0.1606011986732483\n",
      "Batch 2705,  loss: 0.17649225890636444\n",
      "Batch 2710,  loss: 0.11793249994516372\n",
      "Batch 2715,  loss: 0.15738218575716018\n",
      "Batch 2720,  loss: 0.13897731602191926\n",
      "Batch 2725,  loss: 0.1579759955406189\n",
      "Batch 2730,  loss: 0.17116708308458328\n",
      "Batch 2735,  loss: 0.12837455570697784\n",
      "Batch 2740,  loss: 0.1329222247004509\n",
      "Batch 2745,  loss: 0.16757464706897734\n",
      "Batch 2750,  loss: 0.17903993129730225\n",
      "Batch 2755,  loss: 0.16566303223371506\n",
      "Batch 2760,  loss: 0.111135932803154\n",
      "Batch 2765,  loss: 0.1343556597828865\n",
      "Batch 2770,  loss: 0.19175124764442444\n",
      "LOSS train 0.19175124764442444. Validation loss: 0.16189024362980423 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 40:\n",
      "Batch 5,  loss: 0.1229256808757782\n",
      "Batch 10,  loss: 0.18680784106254578\n",
      "Batch 15,  loss: 0.1723179966211319\n",
      "Batch 20,  loss: 0.16001911759376525\n",
      "Batch 25,  loss: 0.13705867230892183\n",
      "Batch 30,  loss: 0.12480572313070297\n",
      "Batch 35,  loss: 0.11158133745193481\n",
      "Batch 40,  loss: 0.13415737748146056\n",
      "Batch 45,  loss: 0.13558256924152373\n",
      "Batch 50,  loss: 0.20038062930107117\n",
      "Batch 55,  loss: 0.1740909367799759\n",
      "Batch 60,  loss: 0.1304927200078964\n",
      "Batch 65,  loss: 0.14722641110420226\n",
      "Batch 70,  loss: 0.17512938976287842\n",
      "Batch 75,  loss: 0.12221080213785171\n",
      "Batch 80,  loss: 0.12806549668312073\n",
      "Batch 85,  loss: 0.14567986875772476\n",
      "Batch 90,  loss: 0.15320996642112733\n",
      "Batch 95,  loss: 0.13022879064083098\n",
      "Batch 100,  loss: 0.13252903074026107\n",
      "Batch 105,  loss: 0.1326851725578308\n",
      "Batch 110,  loss: 0.19901693910360335\n",
      "Batch 115,  loss: 0.16138482391834258\n",
      "Batch 120,  loss: 0.16954231560230254\n",
      "Batch 125,  loss: 0.16523042917251587\n",
      "Batch 130,  loss: 0.14295440763235093\n",
      "Batch 135,  loss: 0.14221033602952957\n",
      "Batch 140,  loss: 0.15232389718294143\n",
      "Batch 145,  loss: 0.13725588321685792\n",
      "Batch 150,  loss: 0.15155018568038942\n",
      "Batch 155,  loss: 0.1245529904961586\n",
      "Batch 160,  loss: 0.1638893559575081\n",
      "Batch 165,  loss: 0.17322923690080644\n",
      "Batch 170,  loss: 0.1813356727361679\n",
      "Batch 175,  loss: 0.15078184902668\n",
      "Batch 180,  loss: 0.12018900215625763\n",
      "Batch 185,  loss: 0.14492183029651642\n",
      "Batch 190,  loss: 0.13401115387678147\n",
      "Batch 195,  loss: 0.1259312629699707\n",
      "Batch 200,  loss: 0.15593272149562837\n",
      "Batch 205,  loss: 0.14769534766674042\n",
      "Batch 210,  loss: 0.15143815875053407\n",
      "Batch 215,  loss: 0.13497559279203414\n",
      "Batch 220,  loss: 0.17977074682712554\n",
      "Batch 225,  loss: 0.1457649290561676\n",
      "Batch 230,  loss: 0.16753159761428832\n",
      "Batch 235,  loss: 0.11909072995185851\n",
      "Batch 240,  loss: 0.1438615143299103\n",
      "Batch 245,  loss: 0.16647091805934905\n",
      "Batch 250,  loss: 0.14220000803470612\n",
      "Batch 255,  loss: 0.1874002754688263\n",
      "Batch 260,  loss: 0.15351834744215012\n",
      "Batch 265,  loss: 0.20946090221405028\n",
      "Batch 270,  loss: 0.1589970886707306\n",
      "Batch 275,  loss: 0.15886944234371186\n",
      "Batch 280,  loss: 0.12254826426506042\n",
      "Batch 285,  loss: 0.1689528539776802\n",
      "Batch 290,  loss: 0.15439475029706956\n",
      "Batch 295,  loss: 0.1491589739918709\n",
      "Batch 300,  loss: 0.1350501835346222\n",
      "Batch 305,  loss: 0.16510022878646852\n",
      "Batch 310,  loss: 0.1423662468791008\n",
      "Batch 315,  loss: 0.1660238742828369\n",
      "Batch 320,  loss: 0.11373919844627381\n",
      "Batch 325,  loss: 0.14812033176422118\n",
      "Batch 330,  loss: 0.156847719848156\n",
      "Batch 335,  loss: 0.19469308108091354\n",
      "Batch 340,  loss: 0.1797672063112259\n",
      "Batch 345,  loss: 0.15078025162220002\n",
      "Batch 350,  loss: 0.16649326235055922\n",
      "Batch 355,  loss: 0.1795840561389923\n",
      "Batch 360,  loss: 0.17553378343582154\n",
      "Batch 365,  loss: 0.1630113497376442\n",
      "Batch 370,  loss: 0.1391468495130539\n",
      "Batch 375,  loss: 0.12463625967502594\n",
      "Batch 380,  loss: 0.1194943681359291\n",
      "Batch 385,  loss: 0.168707737326622\n",
      "Batch 390,  loss: 0.1557870775461197\n",
      "Batch 395,  loss: 0.12878738790750505\n",
      "Batch 400,  loss: 0.14217390716075898\n",
      "Batch 405,  loss: 0.13657139092683793\n",
      "Batch 410,  loss: 0.17926883399486543\n",
      "Batch 415,  loss: 0.15778450965881347\n",
      "Batch 420,  loss: 0.15495319068431854\n",
      "Batch 425,  loss: 0.17742218375205993\n",
      "Batch 430,  loss: 0.1549047827720642\n",
      "Batch 435,  loss: 0.15739607214927673\n",
      "Batch 440,  loss: 0.1339342027902603\n",
      "Batch 445,  loss: 0.18467775583267212\n",
      "Batch 450,  loss: 0.11200348734855652\n",
      "Batch 455,  loss: 0.13806762397289277\n",
      "Batch 460,  loss: 0.12475725710391998\n",
      "Batch 465,  loss: 0.16481804847717285\n",
      "Batch 470,  loss: 0.16971013247966765\n",
      "Batch 475,  loss: 0.13063956797122955\n",
      "Batch 480,  loss: 0.14935864508152008\n",
      "Batch 485,  loss: 0.14947063773870467\n",
      "Batch 490,  loss: 0.18584374189376832\n",
      "Batch 495,  loss: 0.1405497670173645\n",
      "Batch 500,  loss: 0.14669786691665648\n",
      "Batch 505,  loss: 0.14073545336723328\n",
      "Batch 510,  loss: 0.17957701086997985\n",
      "Batch 515,  loss: 0.16709007918834687\n",
      "Batch 520,  loss: 0.11344325244426727\n",
      "Batch 525,  loss: 0.16371719539165497\n",
      "Batch 530,  loss: 0.13863971531391145\n",
      "Batch 535,  loss: 0.12437188029289245\n",
      "Batch 540,  loss: 0.14711340963840486\n",
      "Batch 545,  loss: 0.16608363687992095\n",
      "Batch 550,  loss: 0.1441188186407089\n",
      "Batch 555,  loss: 0.12652973532676698\n",
      "Batch 560,  loss: 0.1449194148182869\n",
      "Batch 565,  loss: 0.1460941031575203\n",
      "Batch 570,  loss: 0.11111681908369064\n",
      "Batch 575,  loss: 0.14073319733142853\n",
      "Batch 580,  loss: 0.12721900939941405\n",
      "Batch 585,  loss: 0.1597042351961136\n",
      "Batch 590,  loss: 0.13105686753988266\n",
      "Batch 595,  loss: 0.17357743084430693\n",
      "Batch 600,  loss: 0.09777128100395202\n",
      "Batch 605,  loss: 0.1465396985411644\n",
      "Batch 610,  loss: 0.15799225270748138\n",
      "Batch 615,  loss: 0.19460418820381165\n",
      "Batch 620,  loss: 0.13681299090385438\n",
      "Batch 625,  loss: 0.14924634248018265\n",
      "Batch 630,  loss: 0.14838161170482636\n",
      "Batch 635,  loss: 0.12303691059350967\n",
      "Batch 640,  loss: 0.13161836713552474\n",
      "Batch 645,  loss: 0.16027465164661409\n",
      "Batch 650,  loss: 0.1586360290646553\n",
      "Batch 655,  loss: 0.13959459811449051\n",
      "Batch 660,  loss: 0.14876831471920013\n",
      "Batch 665,  loss: 0.17054632008075715\n",
      "Batch 670,  loss: 0.19533361494541168\n",
      "Batch 675,  loss: 0.11460094153881073\n",
      "Batch 680,  loss: 0.12864279747009277\n",
      "Batch 685,  loss: 0.15534776151180268\n",
      "Batch 690,  loss: 0.14207714498043061\n",
      "Batch 695,  loss: 0.23704528510570527\n",
      "Batch 700,  loss: 0.13504863530397415\n",
      "Batch 705,  loss: 0.16039620637893676\n",
      "Batch 710,  loss: 0.09906722009181976\n",
      "Batch 715,  loss: 0.14294047206640242\n",
      "Batch 720,  loss: 0.1582693487405777\n",
      "Batch 725,  loss: 0.15585772842168807\n",
      "Batch 730,  loss: 0.13885277658700942\n",
      "Batch 735,  loss: 0.11850321739912033\n",
      "Batch 740,  loss: 0.12908031642436982\n",
      "Batch 745,  loss: 0.1438748300075531\n",
      "Batch 750,  loss: 0.13539355397224426\n",
      "Batch 755,  loss: 0.13899100720882415\n",
      "Batch 760,  loss: 0.18488059043884278\n",
      "Batch 765,  loss: 0.14831716567277908\n",
      "Batch 770,  loss: 0.16132000386714934\n",
      "Batch 775,  loss: 0.1257867231965065\n",
      "Batch 780,  loss: 0.1323118418455124\n",
      "Batch 785,  loss: 0.14154600203037263\n",
      "Batch 790,  loss: 0.15510445535182954\n",
      "Batch 795,  loss: 0.12722202241420746\n",
      "Batch 800,  loss: 0.1433161422610283\n",
      "Batch 805,  loss: 0.1575649306178093\n",
      "Batch 810,  loss: 0.1450176179409027\n",
      "Batch 815,  loss: 0.12885988056659697\n",
      "Batch 820,  loss: 0.21052824854850768\n",
      "Batch 825,  loss: 0.13259842097759247\n",
      "Batch 830,  loss: 0.15533815324306488\n",
      "Batch 835,  loss: 0.1420425668358803\n",
      "Batch 840,  loss: 0.15908033698797225\n",
      "Batch 845,  loss: 0.1450036346912384\n",
      "Batch 850,  loss: 0.12386116981506348\n",
      "Batch 855,  loss: 0.14008820652961732\n",
      "Batch 860,  loss: 0.165540012717247\n",
      "Batch 865,  loss: 0.15256054550409318\n",
      "Batch 870,  loss: 0.17481113374233245\n",
      "Batch 875,  loss: 0.18170518279075623\n",
      "Batch 880,  loss: 0.15969773679971694\n",
      "Batch 885,  loss: 0.19526672810316087\n",
      "Batch 890,  loss: 0.13706248253583908\n",
      "Batch 895,  loss: 0.14866551756858826\n",
      "Batch 900,  loss: 0.1584359437227249\n",
      "Batch 905,  loss: 0.14567463994026184\n",
      "Batch 910,  loss: 0.2073153465986252\n",
      "Batch 915,  loss: 0.142392697930336\n",
      "Batch 920,  loss: 0.13837973177433013\n",
      "Batch 925,  loss: 0.17963330298662186\n",
      "Batch 930,  loss: 0.14559802561998367\n",
      "Batch 935,  loss: 0.16044904589653014\n",
      "Batch 940,  loss: 0.1220853254199028\n",
      "Batch 945,  loss: 0.1602123498916626\n",
      "Batch 950,  loss: 0.16112746447324752\n",
      "Batch 955,  loss: 0.1693140059709549\n",
      "Batch 960,  loss: 0.17919638752937317\n",
      "Batch 965,  loss: 0.1671319365501404\n",
      "Batch 970,  loss: 0.12937289476394653\n",
      "Batch 975,  loss: 0.13115867376327514\n",
      "Batch 980,  loss: 0.17900816798210145\n",
      "Batch 985,  loss: 0.13451934456825257\n",
      "Batch 990,  loss: 0.11305242776870728\n",
      "Batch 995,  loss: 0.17396826595067977\n",
      "Batch 1000,  loss: 0.12883831709623336\n",
      "Batch 1005,  loss: 0.17750698328018188\n",
      "Batch 1010,  loss: 0.17205846458673477\n",
      "Batch 1015,  loss: 0.17328534573316573\n",
      "Batch 1020,  loss: 0.1290434867143631\n",
      "Batch 1025,  loss: 0.1620877668261528\n",
      "Batch 1030,  loss: 0.16116608530282975\n",
      "Batch 1035,  loss: 0.14528398215770721\n",
      "Batch 1040,  loss: 0.11235338672995568\n",
      "Batch 1045,  loss: 0.13099165856838227\n",
      "Batch 1050,  loss: 0.18887115716934205\n",
      "Batch 1055,  loss: 0.163547146320343\n",
      "Batch 1060,  loss: 0.1345999702811241\n",
      "Batch 1065,  loss: 0.15519603192806244\n",
      "Batch 1070,  loss: 0.18948137611150742\n",
      "Batch 1075,  loss: 0.13074939101934432\n",
      "Batch 1080,  loss: 0.15611384809017181\n",
      "Batch 1085,  loss: 0.16252568811178209\n",
      "Batch 1090,  loss: 0.15829383283853532\n",
      "Batch 1095,  loss: 0.12368642687797546\n",
      "Batch 1100,  loss: 0.14779155552387238\n",
      "Batch 1105,  loss: 0.14946953505277633\n",
      "Batch 1110,  loss: 0.15012598037719727\n",
      "Batch 1115,  loss: 0.1548030138015747\n",
      "Batch 1120,  loss: 0.19622565805912018\n",
      "Batch 1125,  loss: 0.14748653173446655\n",
      "Batch 1130,  loss: 0.17613511979579927\n",
      "Batch 1135,  loss: 0.16688764095306396\n",
      "Batch 1140,  loss: 0.1567623347043991\n",
      "Batch 1145,  loss: 0.13293793946504592\n",
      "Batch 1150,  loss: 0.14724554866552353\n",
      "Batch 1155,  loss: 0.16899636387825012\n",
      "Batch 1160,  loss: 0.13599868416786193\n",
      "Batch 1165,  loss: 0.12737499698996543\n",
      "Batch 1170,  loss: 0.12771320343017578\n",
      "Batch 1175,  loss: 0.1842620700597763\n",
      "Batch 1180,  loss: 0.14123959243297576\n",
      "Batch 1185,  loss: 0.1606648802757263\n",
      "Batch 1190,  loss: 0.19520384073257446\n",
      "Batch 1195,  loss: 0.18106956481933595\n",
      "Batch 1200,  loss: 0.13389585614204408\n",
      "Batch 1205,  loss: 0.1345273569226265\n",
      "Batch 1210,  loss: 0.16662745773792267\n",
      "Batch 1215,  loss: 0.14074012041091918\n",
      "Batch 1220,  loss: 0.12618919163942338\n",
      "Batch 1225,  loss: 0.12554990947246553\n",
      "Batch 1230,  loss: 0.11291536092758178\n",
      "Batch 1235,  loss: 0.14869530797004699\n",
      "Batch 1240,  loss: 0.15452329814434052\n",
      "Batch 1245,  loss: 0.15272191166877747\n",
      "Batch 1250,  loss: 0.19467301666736603\n",
      "Batch 1255,  loss: 0.14268795251846314\n",
      "Batch 1260,  loss: 0.14924739599227904\n",
      "Batch 1265,  loss: 0.1470589205622673\n",
      "Batch 1270,  loss: 0.14815928190946578\n",
      "Batch 1275,  loss: 0.1633853644132614\n",
      "Batch 1280,  loss: 0.13651367723941804\n",
      "Batch 1285,  loss: 0.15787580609321594\n",
      "Batch 1290,  loss: 0.12984463274478913\n",
      "Batch 1295,  loss: 0.12105915397405624\n",
      "Batch 1300,  loss: 0.15800873190164566\n",
      "Batch 1305,  loss: 0.15240122526884078\n",
      "Batch 1310,  loss: 0.13678637593984605\n",
      "Batch 1315,  loss: 0.13369042575359344\n",
      "Batch 1320,  loss: 0.11488478183746338\n",
      "Batch 1325,  loss: 0.12734307646751403\n",
      "Batch 1330,  loss: 0.15079791098833084\n",
      "Batch 1335,  loss: 0.11847551763057709\n",
      "Batch 1340,  loss: 0.15277293026447297\n",
      "Batch 1345,  loss: 0.1476701468229294\n",
      "Batch 1350,  loss: 0.19559117257595063\n",
      "Batch 1355,  loss: 0.15294825285673141\n",
      "Batch 1360,  loss: 0.18739698827266693\n",
      "Batch 1365,  loss: 0.13832972645759584\n",
      "Batch 1370,  loss: 0.11144110411405564\n",
      "Batch 1375,  loss: 0.12975217998027802\n",
      "Batch 1380,  loss: 0.16466328650712966\n",
      "Batch 1385,  loss: 0.15231824815273284\n",
      "Batch 1390,  loss: 0.16230740994215012\n",
      "Batch 1395,  loss: 0.15226946622133256\n",
      "Batch 1400,  loss: 0.14673691391944885\n",
      "Batch 1405,  loss: 0.1720645695924759\n",
      "Batch 1410,  loss: 0.14620475023984908\n",
      "Batch 1415,  loss: 0.12646468132734298\n",
      "Batch 1420,  loss: 0.1542919635772705\n",
      "Batch 1425,  loss: 0.10771229714155198\n",
      "Batch 1430,  loss: 0.1752028077840805\n",
      "Batch 1435,  loss: 0.1625851273536682\n",
      "Batch 1440,  loss: 0.14080485999584197\n",
      "Batch 1445,  loss: 0.15520859658718109\n",
      "Batch 1450,  loss: 0.19124044775962828\n",
      "Batch 1455,  loss: 0.14813514947891235\n",
      "Batch 1460,  loss: 0.2032134860754013\n",
      "Batch 1465,  loss: 0.16028716862201692\n",
      "Batch 1470,  loss: 0.1664841428399086\n",
      "Batch 1475,  loss: 0.1624735563993454\n",
      "Batch 1480,  loss: 0.14731554239988326\n",
      "Batch 1485,  loss: 0.148622927069664\n",
      "Batch 1490,  loss: 0.18467679619789124\n",
      "Batch 1495,  loss: 0.18199320137500763\n",
      "Batch 1500,  loss: 0.13943889737129211\n",
      "Batch 1505,  loss: 0.15529497116804122\n",
      "Batch 1510,  loss: 0.15849741846323012\n",
      "Batch 1515,  loss: 0.1594761535525322\n",
      "Batch 1520,  loss: 0.10572642087936401\n",
      "Batch 1525,  loss: 0.14768827557563782\n",
      "Batch 1530,  loss: 0.15077601075172425\n",
      "Batch 1535,  loss: 0.2076009601354599\n",
      "Batch 1540,  loss: 0.145318403840065\n",
      "Batch 1545,  loss: 0.16832436621189117\n",
      "Batch 1550,  loss: 0.13895044326782227\n",
      "Batch 1555,  loss: 0.1141306534409523\n",
      "Batch 1560,  loss: 0.12055080533027648\n",
      "Batch 1565,  loss: 0.14255823493003844\n",
      "Batch 1570,  loss: 0.16821121871471406\n",
      "Batch 1575,  loss: 0.13877657949924468\n",
      "Batch 1580,  loss: 0.14834104031324385\n",
      "Batch 1585,  loss: 0.1454823434352875\n",
      "Batch 1590,  loss: 0.10362442731857299\n",
      "Batch 1595,  loss: 0.1414507582783699\n",
      "Batch 1600,  loss: 0.15508124530315398\n",
      "Batch 1605,  loss: 0.12044027149677276\n",
      "Batch 1610,  loss: 0.12727160453796388\n",
      "Batch 1615,  loss: 0.15688108503818513\n",
      "Batch 1620,  loss: 0.1875409245491028\n",
      "Batch 1625,  loss: 0.1498084545135498\n",
      "Batch 1630,  loss: 0.15195106863975524\n",
      "Batch 1635,  loss: 0.13059065341949463\n",
      "Batch 1640,  loss: 0.1467386305332184\n",
      "Batch 1645,  loss: 0.1590240180492401\n",
      "Batch 1650,  loss: 0.10062972456216812\n",
      "Batch 1655,  loss: 0.17160375714302062\n",
      "Batch 1660,  loss: 0.14223284721374513\n",
      "Batch 1665,  loss: 0.18340915739536284\n",
      "Batch 1670,  loss: 0.1576893597841263\n",
      "Batch 1675,  loss: 0.15989040732383727\n",
      "Batch 1680,  loss: 0.1482929140329361\n",
      "Batch 1685,  loss: 0.18730698227882386\n",
      "Batch 1690,  loss: 0.1748397797346115\n",
      "Batch 1695,  loss: 0.13603233098983764\n",
      "Batch 1700,  loss: 0.1323384389281273\n",
      "Batch 1705,  loss: 0.1946112558245659\n",
      "Batch 1710,  loss: 0.18736976087093354\n",
      "Batch 1715,  loss: 0.12949124872684478\n",
      "Batch 1720,  loss: 0.11673877537250518\n",
      "Batch 1725,  loss: 0.13523892015218736\n",
      "Batch 1730,  loss: 0.15230482816696167\n",
      "Batch 1735,  loss: 0.18087010234594345\n",
      "Batch 1740,  loss: 0.16707159876823424\n",
      "Batch 1745,  loss: 0.1308770164847374\n",
      "Batch 1750,  loss: 0.1570567011833191\n",
      "Batch 1755,  loss: 0.20480309575796127\n",
      "Batch 1760,  loss: 0.15404481589794158\n",
      "Batch 1765,  loss: 0.12468638718128204\n",
      "Batch 1770,  loss: 0.14218531548976898\n",
      "Batch 1775,  loss: 0.15724559426307677\n",
      "Batch 1780,  loss: 0.17813903242349624\n",
      "Batch 1785,  loss: 0.15220560878515244\n",
      "Batch 1790,  loss: 0.14915797114372253\n",
      "Batch 1795,  loss: 0.13302567601203918\n",
      "Batch 1800,  loss: 0.17801617085933685\n",
      "Batch 1805,  loss: 0.15281254649162293\n",
      "Batch 1810,  loss: 0.16963953673839569\n",
      "Batch 1815,  loss: 0.12571932077407838\n",
      "Batch 1820,  loss: 0.14075424820184707\n",
      "Batch 1825,  loss: 0.1629232197999954\n",
      "Batch 1830,  loss: 0.1620299994945526\n",
      "Batch 1835,  loss: 0.1392334908246994\n",
      "Batch 1840,  loss: 0.19022078514099122\n",
      "Batch 1845,  loss: 0.14394954442977906\n",
      "Batch 1850,  loss: 0.13600148856639863\n",
      "Batch 1855,  loss: 0.12224549055099487\n",
      "Batch 1860,  loss: 0.1404401659965515\n",
      "Batch 1865,  loss: 0.1973988175392151\n",
      "Batch 1870,  loss: 0.15526011288166047\n",
      "Batch 1875,  loss: 0.17825879156589508\n",
      "Batch 1880,  loss: 0.15022704005241394\n",
      "Batch 1885,  loss: 0.16196133941411972\n",
      "Batch 1890,  loss: 0.15892120748758315\n",
      "Batch 1895,  loss: 0.13743898421525955\n",
      "Batch 1900,  loss: 0.14634424448013306\n",
      "Batch 1905,  loss: 0.13863516449928284\n",
      "Batch 1910,  loss: 0.18236251771450043\n",
      "Batch 1915,  loss: 0.16519102156162263\n",
      "Batch 1920,  loss: 0.17955169975757598\n",
      "Batch 1925,  loss: 0.20683881342411042\n",
      "Batch 1930,  loss: 0.12726352065801622\n",
      "Batch 1935,  loss: 0.1453005313873291\n",
      "Batch 1940,  loss: 0.19267081171274186\n",
      "Batch 1945,  loss: 0.14805188179016113\n",
      "Batch 1950,  loss: 0.17597987353801728\n",
      "Batch 1955,  loss: 0.15065570771694184\n",
      "Batch 1960,  loss: 0.15150531530380248\n",
      "Batch 1965,  loss: 0.1665506809949875\n",
      "Batch 1970,  loss: 0.1294373333454132\n",
      "Batch 1975,  loss: 0.1449307844042778\n",
      "Batch 1980,  loss: 0.13317286372184753\n",
      "Batch 1985,  loss: 0.14062462300062178\n",
      "Batch 1990,  loss: 0.1642818346619606\n",
      "Batch 1995,  loss: 0.1534661903977394\n",
      "Batch 2000,  loss: 0.1252674326300621\n",
      "Batch 2005,  loss: 0.13725047409534455\n",
      "Batch 2010,  loss: 0.15224725306034087\n",
      "Batch 2015,  loss: 0.14165447205305098\n",
      "Batch 2020,  loss: 0.18253486156463622\n",
      "Batch 2025,  loss: 0.11477579474449158\n",
      "Batch 2030,  loss: 0.14704444259405136\n",
      "Batch 2035,  loss: 0.14684492647647857\n",
      "Batch 2040,  loss: 0.15725163072347642\n",
      "Batch 2045,  loss: 0.1471804015338421\n",
      "Batch 2050,  loss: 0.13865313827991485\n",
      "Batch 2055,  loss: 0.20338858366012574\n",
      "Batch 2060,  loss: 0.15794210731983185\n",
      "Batch 2065,  loss: 0.12425381243228913\n",
      "Batch 2070,  loss: 0.19816013872623445\n",
      "Batch 2075,  loss: 0.17174462378025054\n",
      "Batch 2080,  loss: 0.13140759766101837\n",
      "Batch 2085,  loss: 0.14518491327762603\n",
      "Batch 2090,  loss: 0.12786190956830978\n",
      "Batch 2095,  loss: 0.15364086925983428\n",
      "Batch 2100,  loss: 0.16468294560909272\n",
      "Batch 2105,  loss: 0.14465390145778656\n",
      "Batch 2110,  loss: 0.1303125277161598\n",
      "Batch 2115,  loss: 0.1638554096221924\n",
      "Batch 2120,  loss: 0.15817603468894958\n",
      "Batch 2125,  loss: 0.13626841455698013\n",
      "Batch 2130,  loss: 0.16082009375095369\n",
      "Batch 2135,  loss: 0.18275611102581024\n",
      "Batch 2140,  loss: 0.13184292167425155\n",
      "Batch 2145,  loss: 0.16596138030290603\n",
      "Batch 2150,  loss: 0.16678370237350465\n",
      "Batch 2155,  loss: 0.15031006932258606\n",
      "Batch 2160,  loss: 0.1978114902973175\n",
      "Batch 2165,  loss: 0.14062294363975525\n",
      "Batch 2170,  loss: 0.1610370934009552\n",
      "Batch 2175,  loss: 0.17685059309005738\n",
      "Batch 2180,  loss: 0.1371798262000084\n",
      "Batch 2185,  loss: 0.12497504502534866\n",
      "Batch 2190,  loss: 0.16430428326129914\n",
      "Batch 2195,  loss: 0.1433876097202301\n",
      "Batch 2200,  loss: 0.13124201595783233\n",
      "Batch 2205,  loss: 0.1708155930042267\n",
      "Batch 2210,  loss: 0.1747717887163162\n",
      "Batch 2215,  loss: 0.1973835051059723\n",
      "Batch 2220,  loss: 0.14606156200170517\n",
      "Batch 2225,  loss: 0.11894621998071671\n",
      "Batch 2230,  loss: 0.15299323946237564\n",
      "Batch 2235,  loss: 0.13427530229091644\n",
      "Batch 2240,  loss: 0.15355872511863708\n",
      "Batch 2245,  loss: 0.14006809145212173\n",
      "Batch 2250,  loss: 0.14466360658407212\n",
      "Batch 2255,  loss: 0.17024290710687637\n",
      "Batch 2260,  loss: 0.12566972225904466\n",
      "Batch 2265,  loss: 0.12956713140010834\n",
      "Batch 2270,  loss: 0.13004793524742125\n",
      "Batch 2275,  loss: 0.15656574666500092\n",
      "Batch 2280,  loss: 0.11652692407369614\n",
      "Batch 2285,  loss: 0.14763746857643129\n",
      "Batch 2290,  loss: 0.13575129956007004\n",
      "Batch 2295,  loss: 0.165864697098732\n",
      "Batch 2300,  loss: 0.1392895758152008\n",
      "Batch 2305,  loss: 0.16251160800457\n",
      "Batch 2310,  loss: 0.14825642257928848\n",
      "Batch 2315,  loss: 0.1329058051109314\n",
      "Batch 2320,  loss: 0.14820316731929778\n",
      "Batch 2325,  loss: 0.17389672100543976\n",
      "Batch 2330,  loss: 0.12966150939464569\n",
      "Batch 2335,  loss: 0.16163255423307418\n",
      "Batch 2340,  loss: 0.17408105880022048\n",
      "Batch 2345,  loss: 0.11721841543912888\n",
      "Batch 2350,  loss: 0.15982022881507874\n",
      "Batch 2355,  loss: 0.18064444363117219\n",
      "Batch 2360,  loss: 0.1344030514359474\n",
      "Batch 2365,  loss: 0.13775767087936402\n",
      "Batch 2370,  loss: 0.1375470757484436\n",
      "Batch 2375,  loss: 0.13288096189498902\n",
      "Batch 2380,  loss: 0.12139482498168945\n",
      "Batch 2385,  loss: 0.15096423476934434\n",
      "Batch 2390,  loss: 0.158447702229023\n",
      "Batch 2395,  loss: 0.1932334005832672\n",
      "Batch 2400,  loss: 0.13326660245656968\n",
      "Batch 2405,  loss: 0.1715720608830452\n",
      "Batch 2410,  loss: 0.14862145781517028\n",
      "Batch 2415,  loss: 0.17867682874202728\n",
      "Batch 2420,  loss: 0.22144376039505004\n",
      "Batch 2425,  loss: 0.1344834566116333\n",
      "Batch 2430,  loss: 0.17422018349170684\n",
      "Batch 2435,  loss: 0.15493425726890564\n",
      "Batch 2440,  loss: 0.16622911989688874\n",
      "Batch 2445,  loss: 0.15231414437294005\n",
      "Batch 2450,  loss: 0.18714533746242523\n",
      "Batch 2455,  loss: 0.1692576825618744\n",
      "Batch 2460,  loss: 0.12088166773319245\n",
      "Batch 2465,  loss: 0.1866519644856453\n",
      "Batch 2470,  loss: 0.14824170619249344\n",
      "Batch 2475,  loss: 0.13311593532562255\n",
      "Batch 2480,  loss: 0.15403082370758056\n",
      "Batch 2485,  loss: 0.15563394129276276\n",
      "Batch 2490,  loss: 0.14199063032865525\n",
      "Batch 2495,  loss: 0.1162227600812912\n",
      "Batch 2500,  loss: 0.1420233964920044\n",
      "Batch 2505,  loss: 0.12833266258239745\n",
      "Batch 2510,  loss: 0.13433367013931274\n",
      "Batch 2515,  loss: 0.17235779762268066\n",
      "Batch 2520,  loss: 0.14381250739097595\n",
      "Batch 2525,  loss: 0.14411498308181764\n",
      "Batch 2530,  loss: 0.17594327330589293\n",
      "Batch 2535,  loss: 0.14494551569223404\n",
      "Batch 2540,  loss: 0.16966886520385743\n",
      "Batch 2545,  loss: 0.16157826036214828\n",
      "Batch 2550,  loss: 0.1415732443332672\n",
      "Batch 2555,  loss: 0.1678583025932312\n",
      "Batch 2560,  loss: 0.10732843428850174\n",
      "Batch 2565,  loss: 0.13111587464809418\n",
      "Batch 2570,  loss: 0.18039461672306062\n",
      "Batch 2575,  loss: 0.1671195238828659\n",
      "Batch 2580,  loss: 0.11403778344392776\n",
      "Batch 2585,  loss: 0.17563365697860717\n",
      "Batch 2590,  loss: 0.15787541270256042\n",
      "Batch 2595,  loss: 0.18449575006961821\n",
      "Batch 2600,  loss: 0.14202272444963454\n",
      "Batch 2605,  loss: 0.15206832587718963\n",
      "Batch 2610,  loss: 0.13993921428918837\n",
      "Batch 2615,  loss: 0.14394054412841797\n",
      "Batch 2620,  loss: 0.17321811020374298\n",
      "Batch 2625,  loss: 0.1523198664188385\n",
      "Batch 2630,  loss: 0.1284798264503479\n",
      "Batch 2635,  loss: 0.13600014448165892\n",
      "Batch 2640,  loss: 0.16523980647325515\n",
      "Batch 2645,  loss: 0.12387745976448059\n",
      "Batch 2650,  loss: 0.1708766460418701\n",
      "Batch 2655,  loss: 0.2001663252711296\n",
      "Batch 2660,  loss: 0.16821051836013795\n",
      "Batch 2665,  loss: 0.17507156133651733\n",
      "Batch 2670,  loss: 0.16329458355903625\n",
      "Batch 2675,  loss: 0.167245352268219\n",
      "Batch 2680,  loss: 0.11405036002397537\n",
      "Batch 2685,  loss: 0.1836972564458847\n",
      "Batch 2690,  loss: 0.17285242825746536\n",
      "Batch 2695,  loss: 0.13220632672309876\n",
      "Batch 2700,  loss: 0.1342517465353012\n",
      "Batch 2705,  loss: 0.1929943382740021\n",
      "Batch 2710,  loss: 0.1562781423330307\n",
      "Batch 2715,  loss: 0.16414344012737275\n",
      "Batch 2720,  loss: 0.1275849461555481\n",
      "Batch 2725,  loss: 0.12409465461969375\n",
      "Batch 2730,  loss: 0.14624251574277877\n",
      "Batch 2735,  loss: 0.1061777040362358\n",
      "Batch 2740,  loss: 0.15517198890447617\n",
      "Batch 2745,  loss: 0.11517967581748963\n",
      "Batch 2750,  loss: 0.16154195815324784\n",
      "Batch 2755,  loss: 0.11845404803752899\n",
      "Batch 2760,  loss: 0.16271539330482482\n",
      "Batch 2765,  loss: 0.12634943425655365\n",
      "Batch 2770,  loss: 0.1316457659006119\n",
      "LOSS train 0.1316457659006119. Validation loss: 0.16338582242088806 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 41:\n",
      "Batch 5,  loss: 0.13243882954120637\n",
      "Batch 10,  loss: 0.1512112870812416\n",
      "Batch 15,  loss: 0.1650308296084404\n",
      "Batch 20,  loss: 0.1225785717368126\n",
      "Batch 25,  loss: 0.18573097735643387\n",
      "Batch 30,  loss: 0.14593005180358887\n",
      "Batch 35,  loss: 0.13004767000675202\n",
      "Batch 40,  loss: 0.14071473926305772\n",
      "Batch 45,  loss: 0.1891796588897705\n",
      "Batch 50,  loss: 0.17791788876056672\n",
      "Batch 55,  loss: 0.13503384888172149\n",
      "Batch 60,  loss: 0.18582603633403777\n",
      "Batch 65,  loss: 0.14977732300758362\n",
      "Batch 70,  loss: 0.12676302790641786\n",
      "Batch 75,  loss: 0.1330915778875351\n",
      "Batch 80,  loss: 0.15197948813438417\n",
      "Batch 85,  loss: 0.17237681448459624\n",
      "Batch 90,  loss: 0.11689812541007996\n",
      "Batch 95,  loss: 0.180826860666275\n",
      "Batch 100,  loss: 0.14694342166185378\n",
      "Batch 105,  loss: 0.1258266642689705\n",
      "Batch 110,  loss: 0.15398288667201995\n",
      "Batch 115,  loss: 0.1267840340733528\n",
      "Batch 120,  loss: 0.1893552839756012\n",
      "Batch 125,  loss: 0.14235096871852876\n",
      "Batch 130,  loss: 0.17502903044223786\n",
      "Batch 135,  loss: 0.16320309340953826\n",
      "Batch 140,  loss: 0.14258808344602586\n",
      "Batch 145,  loss: 0.22448641061782837\n",
      "Batch 150,  loss: 0.1853749632835388\n",
      "Batch 155,  loss: 0.12409523725509644\n",
      "Batch 160,  loss: 0.16229751110076904\n",
      "Batch 165,  loss: 0.16202419996261597\n",
      "Batch 170,  loss: 0.12455183565616608\n",
      "Batch 175,  loss: 0.1338675394654274\n",
      "Batch 180,  loss: 0.15707629323005676\n",
      "Batch 185,  loss: 0.16022491604089736\n",
      "Batch 190,  loss: 0.15527106523513795\n",
      "Batch 195,  loss: 0.14594854563474655\n",
      "Batch 200,  loss: 0.1240087553858757\n",
      "Batch 205,  loss: 0.1269543156027794\n",
      "Batch 210,  loss: 0.13654575794935225\n",
      "Batch 215,  loss: 0.1446508824825287\n",
      "Batch 220,  loss: 0.1767405867576599\n",
      "Batch 225,  loss: 0.15169432163238525\n",
      "Batch 230,  loss: 0.1750662997364998\n",
      "Batch 235,  loss: 0.14876054972410202\n",
      "Batch 240,  loss: 0.14319367557764054\n",
      "Batch 245,  loss: 0.15644789040088652\n",
      "Batch 250,  loss: 0.1725854307413101\n",
      "Batch 255,  loss: 0.1574741542339325\n",
      "Batch 260,  loss: 0.16318246722221375\n",
      "Batch 265,  loss: 0.11776001453399658\n",
      "Batch 270,  loss: 0.14991410970687866\n",
      "Batch 275,  loss: 0.14256724417209626\n",
      "Batch 280,  loss: 0.17549085319042207\n",
      "Batch 285,  loss: 0.15194410234689712\n",
      "Batch 290,  loss: 0.18398167490959166\n",
      "Batch 295,  loss: 0.18133009523153304\n",
      "Batch 300,  loss: 0.1744733989238739\n",
      "Batch 305,  loss: 0.1608035832643509\n",
      "Batch 310,  loss: 0.14627169966697692\n",
      "Batch 315,  loss: 0.11291791796684265\n",
      "Batch 320,  loss: 0.16807480454444884\n",
      "Batch 325,  loss: 0.14194996654987335\n",
      "Batch 330,  loss: 0.1415774405002594\n",
      "Batch 335,  loss: 0.10662010461091995\n",
      "Batch 340,  loss: 0.1687103971838951\n",
      "Batch 345,  loss: 0.1592629447579384\n",
      "Batch 350,  loss: 0.1419418200850487\n",
      "Batch 355,  loss: 0.12055006474256516\n",
      "Batch 360,  loss: 0.1276002272963524\n",
      "Batch 365,  loss: 0.1743411973118782\n",
      "Batch 370,  loss: 0.12451865077018738\n",
      "Batch 375,  loss: 0.16840129792690278\n",
      "Batch 380,  loss: 0.14566834270954132\n",
      "Batch 385,  loss: 0.15632033050060273\n",
      "Batch 390,  loss: 0.1249102532863617\n",
      "Batch 395,  loss: 0.15619548857212068\n",
      "Batch 400,  loss: 0.15092850774526595\n",
      "Batch 405,  loss: 0.10939060896635056\n",
      "Batch 410,  loss: 0.12106156647205353\n",
      "Batch 415,  loss: 0.16986028999090194\n",
      "Batch 420,  loss: 0.17476637214422225\n",
      "Batch 425,  loss: 0.15640192925930024\n",
      "Batch 430,  loss: 0.13892937004566192\n",
      "Batch 435,  loss: 0.16900945603847503\n",
      "Batch 440,  loss: 0.11095516979694367\n",
      "Batch 445,  loss: 0.15791506916284562\n",
      "Batch 450,  loss: 0.14078418910503387\n",
      "Batch 455,  loss: 0.12794862687587738\n",
      "Batch 460,  loss: 0.11009765863418579\n",
      "Batch 465,  loss: 0.14294610619544984\n",
      "Batch 470,  loss: 0.13984538316726686\n",
      "Batch 475,  loss: 0.10633103996515274\n",
      "Batch 480,  loss: 0.14840811789035796\n",
      "Batch 485,  loss: 0.16609874069690705\n",
      "Batch 490,  loss: 0.11932465434074402\n",
      "Batch 495,  loss: 0.12936188280582428\n",
      "Batch 500,  loss: 0.12275981605052948\n",
      "Batch 505,  loss: 0.15840487629175187\n",
      "Batch 510,  loss: 0.1322336345911026\n",
      "Batch 515,  loss: 0.14794639647006988\n",
      "Batch 520,  loss: 0.13626192063093184\n",
      "Batch 525,  loss: 0.15603770464658737\n",
      "Batch 530,  loss: 0.16430417597293853\n",
      "Batch 535,  loss: 0.13419449776411058\n",
      "Batch 540,  loss: 0.1537398099899292\n",
      "Batch 545,  loss: 0.14197325259447097\n",
      "Batch 550,  loss: 0.1258159637451172\n",
      "Batch 555,  loss: 0.18885864019393922\n",
      "Batch 560,  loss: 0.18242101669311522\n",
      "Batch 565,  loss: 0.14895017296075821\n",
      "Batch 570,  loss: 0.14899277091026306\n",
      "Batch 575,  loss: 0.14822346568107606\n",
      "Batch 580,  loss: 0.1265174686908722\n",
      "Batch 585,  loss: 0.13136616051197053\n",
      "Batch 590,  loss: 0.1911243438720703\n",
      "Batch 595,  loss: 0.1317960187792778\n",
      "Batch 600,  loss: 0.1587177261710167\n",
      "Batch 605,  loss: 0.14139447063207627\n",
      "Batch 610,  loss: 0.17452585995197295\n",
      "Batch 615,  loss: 0.1253628119826317\n",
      "Batch 620,  loss: 0.1646879196166992\n",
      "Batch 625,  loss: 0.13659386038780214\n",
      "Batch 630,  loss: 0.11746112257242203\n",
      "Batch 635,  loss: 0.1757219210267067\n",
      "Batch 640,  loss: 0.15293081402778624\n",
      "Batch 645,  loss: 0.1900382936000824\n",
      "Batch 650,  loss: 0.12950455844402314\n",
      "Batch 655,  loss: 0.18572700321674346\n",
      "Batch 660,  loss: 0.14126190543174744\n",
      "Batch 665,  loss: 0.19715221226215363\n",
      "Batch 670,  loss: 0.14391117691993713\n",
      "Batch 675,  loss: 0.15694486051797868\n",
      "Batch 680,  loss: 0.13876963555812835\n",
      "Batch 685,  loss: 0.13911454230546952\n",
      "Batch 690,  loss: 0.1208145797252655\n",
      "Batch 695,  loss: 0.1616664409637451\n",
      "Batch 700,  loss: 0.14104212522506715\n",
      "Batch 705,  loss: 0.163165819644928\n",
      "Batch 710,  loss: 0.16359579265117646\n",
      "Batch 715,  loss: 0.13736021220684053\n",
      "Batch 720,  loss: 0.1604263812303543\n",
      "Batch 725,  loss: 0.18807352483272552\n",
      "Batch 730,  loss: 0.12825713604688643\n",
      "Batch 735,  loss: 0.11695479601621628\n",
      "Batch 740,  loss: 0.14468391239643097\n",
      "Batch 745,  loss: 0.13283318132162095\n",
      "Batch 750,  loss: 0.15511638522148133\n",
      "Batch 755,  loss: 0.13873643875122071\n",
      "Batch 760,  loss: 0.13398083448410034\n",
      "Batch 765,  loss: 0.14816348254680634\n",
      "Batch 770,  loss: 0.12512438595294953\n",
      "Batch 775,  loss: 0.14392505288124086\n",
      "Batch 780,  loss: 0.14847496151924133\n",
      "Batch 785,  loss: 0.16813351809978486\n",
      "Batch 790,  loss: 0.1299693465232849\n",
      "Batch 795,  loss: 0.14847443103790284\n",
      "Batch 800,  loss: 0.1516236126422882\n",
      "Batch 805,  loss: 0.15177210718393325\n",
      "Batch 810,  loss: 0.1479434624314308\n",
      "Batch 815,  loss: 0.1332456350326538\n",
      "Batch 820,  loss: 0.11665471941232682\n",
      "Batch 825,  loss: 0.13964463770389557\n",
      "Batch 830,  loss: 0.13852461129426957\n",
      "Batch 835,  loss: 0.1154344543814659\n",
      "Batch 840,  loss: 0.19009934067726136\n",
      "Batch 845,  loss: 0.12963388115167618\n",
      "Batch 850,  loss: 0.18004416078329086\n",
      "Batch 855,  loss: 0.1327335149049759\n",
      "Batch 860,  loss: 0.16340242624282836\n",
      "Batch 865,  loss: 0.1653107926249504\n",
      "Batch 870,  loss: 0.1893760919570923\n",
      "Batch 875,  loss: 0.20778857171535492\n",
      "Batch 880,  loss: 0.13653647005558014\n",
      "Batch 885,  loss: 0.12632913887500763\n",
      "Batch 890,  loss: 0.12885575592517853\n",
      "Batch 895,  loss: 0.19814438223838807\n",
      "Batch 900,  loss: 0.1519150361418724\n",
      "Batch 905,  loss: 0.13530807793140412\n",
      "Batch 910,  loss: 0.13578579127788543\n",
      "Batch 915,  loss: 0.1224979504942894\n",
      "Batch 920,  loss: 0.15780213475227356\n",
      "Batch 925,  loss: 0.14257607161998748\n",
      "Batch 930,  loss: 0.14723218381404876\n",
      "Batch 935,  loss: 0.1359000250697136\n",
      "Batch 940,  loss: 0.12919142246246337\n",
      "Batch 945,  loss: 0.168656225502491\n",
      "Batch 950,  loss: 0.15537415742874144\n",
      "Batch 955,  loss: 0.15840371549129487\n",
      "Batch 960,  loss: 0.16300783455371856\n",
      "Batch 965,  loss: 0.1425376147031784\n",
      "Batch 970,  loss: 0.143658247590065\n",
      "Batch 975,  loss: 0.16474314033985138\n",
      "Batch 980,  loss: 0.11620633602142334\n",
      "Batch 985,  loss: 0.15745724439620973\n",
      "Batch 990,  loss: 0.14844907969236373\n",
      "Batch 995,  loss: 0.121687513589859\n",
      "Batch 1000,  loss: 0.1499362826347351\n",
      "Batch 1005,  loss: 0.14256714135408402\n",
      "Batch 1010,  loss: 0.12722497582435607\n",
      "Batch 1015,  loss: 0.14812536239624025\n",
      "Batch 1020,  loss: 0.1507999747991562\n",
      "Batch 1025,  loss: 0.1316442683339119\n",
      "Batch 1030,  loss: 0.19157663285732268\n",
      "Batch 1035,  loss: 0.15473062694072723\n",
      "Batch 1040,  loss: 0.17452220022678375\n",
      "Batch 1045,  loss: 0.17002464234828948\n",
      "Batch 1050,  loss: 0.16104316413402558\n",
      "Batch 1055,  loss: 0.1509724199771881\n",
      "Batch 1060,  loss: 0.12595279961824418\n",
      "Batch 1065,  loss: 0.12997426092624664\n",
      "Batch 1070,  loss: 0.14860868602991104\n",
      "Batch 1075,  loss: 0.17728382349014282\n",
      "Batch 1080,  loss: 0.14545247703790665\n",
      "Batch 1085,  loss: 0.1602319821715355\n",
      "Batch 1090,  loss: 0.11879944056272507\n",
      "Batch 1095,  loss: 0.15773480534553527\n",
      "Batch 1100,  loss: 0.18763229250907898\n",
      "Batch 1105,  loss: 0.19394178092479705\n",
      "Batch 1110,  loss: 0.12338685095310212\n",
      "Batch 1115,  loss: 0.15400229543447494\n",
      "Batch 1120,  loss: 0.18129542768001555\n",
      "Batch 1125,  loss: 0.11892207562923432\n",
      "Batch 1130,  loss: 0.19654931426048278\n",
      "Batch 1135,  loss: 0.15715926438570021\n",
      "Batch 1140,  loss: 0.13039335533976554\n",
      "Batch 1145,  loss: 0.10538887828588486\n",
      "Batch 1150,  loss: 0.14377822428941728\n",
      "Batch 1155,  loss: 0.16586008071899414\n",
      "Batch 1160,  loss: 0.1902247726917267\n",
      "Batch 1165,  loss: 0.12061546444892883\n",
      "Batch 1170,  loss: 0.15148283839225768\n",
      "Batch 1175,  loss: 0.13580408990383147\n",
      "Batch 1180,  loss: 0.12652911245822906\n",
      "Batch 1185,  loss: 0.14730967730283737\n",
      "Batch 1190,  loss: 0.13751656711101531\n",
      "Batch 1195,  loss: 0.15537908673286438\n",
      "Batch 1200,  loss: 0.14072658568620683\n",
      "Batch 1205,  loss: 0.14084667563438416\n",
      "Batch 1210,  loss: 0.11825576275587082\n",
      "Batch 1215,  loss: 0.14599961042404175\n",
      "Batch 1220,  loss: 0.12052924036979676\n",
      "Batch 1225,  loss: 0.1706789791584015\n",
      "Batch 1230,  loss: 0.1309877961874008\n",
      "Batch 1235,  loss: 0.13922150582075118\n",
      "Batch 1240,  loss: 0.15600919723510742\n",
      "Batch 1245,  loss: 0.16161823123693467\n",
      "Batch 1250,  loss: 0.17487830370664598\n",
      "Batch 1255,  loss: 0.13858093917369843\n",
      "Batch 1260,  loss: 0.1494264781475067\n",
      "Batch 1265,  loss: 0.15909181535243988\n",
      "Batch 1270,  loss: 0.1324200600385666\n",
      "Batch 1275,  loss: 0.1410180151462555\n",
      "Batch 1280,  loss: 0.14178506284952164\n",
      "Batch 1285,  loss: 0.17647623270750046\n",
      "Batch 1290,  loss: 0.20211681723594666\n",
      "Batch 1295,  loss: 0.1625428318977356\n",
      "Batch 1300,  loss: 0.13924246281385422\n",
      "Batch 1305,  loss: 0.19334069043397903\n",
      "Batch 1310,  loss: 0.13210979998111724\n",
      "Batch 1315,  loss: 0.1639153018593788\n",
      "Batch 1320,  loss: 0.13516719043254852\n",
      "Batch 1325,  loss: 0.17974563539028168\n",
      "Batch 1330,  loss: 0.14013829827308655\n",
      "Batch 1335,  loss: 0.18545345664024354\n",
      "Batch 1340,  loss: 0.16003954857587815\n",
      "Batch 1345,  loss: 0.1559472054243088\n",
      "Batch 1350,  loss: 0.12964623421430588\n",
      "Batch 1355,  loss: 0.17353858649730683\n",
      "Batch 1360,  loss: 0.12195427268743515\n",
      "Batch 1365,  loss: 0.15897326171398163\n",
      "Batch 1370,  loss: 0.11125806719064713\n",
      "Batch 1375,  loss: 0.15497276782989503\n",
      "Batch 1380,  loss: 0.15174404680728912\n",
      "Batch 1385,  loss: 0.17095265835523604\n",
      "Batch 1390,  loss: 0.16912308484315872\n",
      "Batch 1395,  loss: 0.21510172486305237\n",
      "Batch 1400,  loss: 0.17465859651565552\n",
      "Batch 1405,  loss: 0.17988579869270324\n",
      "Batch 1410,  loss: 0.16446888148784639\n",
      "Batch 1415,  loss: 0.179202201962471\n",
      "Batch 1420,  loss: 0.1354699194431305\n",
      "Batch 1425,  loss: 0.13795493990182878\n",
      "Batch 1430,  loss: 0.1328509584069252\n",
      "Batch 1435,  loss: 0.1397870734333992\n",
      "Batch 1440,  loss: 0.16154634952545166\n",
      "Batch 1445,  loss: 0.165463949739933\n",
      "Batch 1450,  loss: 0.1458156779408455\n",
      "Batch 1455,  loss: 0.16012777537107467\n",
      "Batch 1460,  loss: 0.18555816113948823\n",
      "Batch 1465,  loss: 0.1281404823064804\n",
      "Batch 1470,  loss: 0.14803273379802703\n",
      "Batch 1475,  loss: 0.1510902687907219\n",
      "Batch 1480,  loss: 0.16288386285305023\n",
      "Batch 1485,  loss: 0.13288934230804444\n",
      "Batch 1490,  loss: 0.1428844764828682\n",
      "Batch 1495,  loss: 0.1489790201187134\n",
      "Batch 1500,  loss: 0.14169588387012483\n",
      "Batch 1505,  loss: 0.13660627901554107\n",
      "Batch 1510,  loss: 0.15455033779144287\n",
      "Batch 1515,  loss: 0.1555944487452507\n",
      "Batch 1520,  loss: 0.17326336205005646\n",
      "Batch 1525,  loss: 0.15296862423419952\n",
      "Batch 1530,  loss: 0.13118730038404464\n",
      "Batch 1535,  loss: 0.16600019633769988\n",
      "Batch 1540,  loss: 0.15210107415914537\n",
      "Batch 1545,  loss: 0.1466463714838028\n",
      "Batch 1550,  loss: 0.14151172041893006\n",
      "Batch 1555,  loss: 0.17070406973361968\n",
      "Batch 1560,  loss: 0.14621051847934724\n",
      "Batch 1565,  loss: 0.1514192283153534\n",
      "Batch 1570,  loss: 0.16911077499389648\n",
      "Batch 1575,  loss: 0.1771351009607315\n",
      "Batch 1580,  loss: 0.1410040020942688\n",
      "Batch 1585,  loss: 0.1489049658179283\n",
      "Batch 1590,  loss: 0.2044848918914795\n",
      "Batch 1595,  loss: 0.15384230464696885\n",
      "Batch 1600,  loss: 0.1374239057302475\n",
      "Batch 1605,  loss: 0.15309115052223204\n",
      "Batch 1610,  loss: 0.13998948633670807\n",
      "Batch 1615,  loss: 0.22221313714981078\n",
      "Batch 1620,  loss: 0.1679736331105232\n",
      "Batch 1625,  loss: 0.16794553995132447\n",
      "Batch 1630,  loss: 0.15374114215373993\n",
      "Batch 1635,  loss: 0.15601616501808166\n",
      "Batch 1640,  loss: 0.12586563229560851\n",
      "Batch 1645,  loss: 0.14295390397310256\n",
      "Batch 1650,  loss: 0.1467054843902588\n",
      "Batch 1655,  loss: 0.17387478351593016\n",
      "Batch 1660,  loss: 0.13373504728078842\n",
      "Batch 1665,  loss: 0.13395485281944275\n",
      "Batch 1670,  loss: 0.16196771413087846\n",
      "Batch 1675,  loss: 0.15337458699941636\n",
      "Batch 1680,  loss: 0.11865688264369964\n",
      "Batch 1685,  loss: 0.11764822900295258\n",
      "Batch 1690,  loss: 0.2228594273328781\n",
      "Batch 1695,  loss: 0.1432977169752121\n",
      "Batch 1700,  loss: 0.1887667179107666\n",
      "Batch 1705,  loss: 0.148648764193058\n",
      "Batch 1710,  loss: 0.12878838330507278\n",
      "Batch 1715,  loss: 0.12896752059459687\n",
      "Batch 1720,  loss: 0.1479630082845688\n",
      "Batch 1725,  loss: 0.16172071695327758\n",
      "Batch 1730,  loss: 0.14343306720256804\n",
      "Batch 1735,  loss: 0.19682720303535461\n",
      "Batch 1740,  loss: 0.19642139971256256\n",
      "Batch 1745,  loss: 0.1616850972175598\n",
      "Batch 1750,  loss: 0.15774575024843215\n",
      "Batch 1755,  loss: 0.12267215102910996\n",
      "Batch 1760,  loss: 0.13676296174526215\n",
      "Batch 1765,  loss: 0.1422281250357628\n",
      "Batch 1770,  loss: 0.13814728260040282\n",
      "Batch 1775,  loss: 0.12116282880306244\n",
      "Batch 1780,  loss: 0.18881741762161255\n",
      "Batch 1785,  loss: 0.12496919333934783\n",
      "Batch 1790,  loss: 0.10704419761896133\n",
      "Batch 1795,  loss: 0.12903717458248137\n",
      "Batch 1800,  loss: 0.16098399162292482\n",
      "Batch 1805,  loss: 0.14759337902069092\n",
      "Batch 1810,  loss: 0.1302901476621628\n",
      "Batch 1815,  loss: 0.13733461648225784\n",
      "Batch 1820,  loss: 0.14233885407447816\n",
      "Batch 1825,  loss: 0.14668187946081163\n",
      "Batch 1830,  loss: 0.1468176931142807\n",
      "Batch 1835,  loss: 0.14401555955410003\n",
      "Batch 1840,  loss: 0.14483947455883026\n",
      "Batch 1845,  loss: 0.1261533319950104\n",
      "Batch 1850,  loss: 0.16966316252946853\n",
      "Batch 1855,  loss: 0.19993585348129272\n",
      "Batch 1860,  loss: 0.12520769685506822\n",
      "Batch 1865,  loss: 0.12064107805490494\n",
      "Batch 1870,  loss: 0.16795243322849274\n",
      "Batch 1875,  loss: 0.13335642963647842\n",
      "Batch 1880,  loss: 0.1434713527560234\n",
      "Batch 1885,  loss: 0.17650182992219926\n",
      "Batch 1890,  loss: 0.1642157793045044\n",
      "Batch 1895,  loss: 0.13562095910310745\n",
      "Batch 1900,  loss: 0.13271316587924958\n",
      "Batch 1905,  loss: 0.17078105509281158\n",
      "Batch 1910,  loss: 0.14560654014348984\n",
      "Batch 1915,  loss: 0.132733716070652\n",
      "Batch 1920,  loss: 0.1420600861310959\n",
      "Batch 1925,  loss: 0.1682235836982727\n",
      "Batch 1930,  loss: 0.19354024827480315\n",
      "Batch 1935,  loss: 0.12410826236009598\n",
      "Batch 1940,  loss: 0.18633706569671632\n",
      "Batch 1945,  loss: 0.14547245651483537\n",
      "Batch 1950,  loss: 0.18767263889312744\n",
      "Batch 1955,  loss: 0.142058664560318\n",
      "Batch 1960,  loss: 0.16381338834762574\n",
      "Batch 1965,  loss: 0.14345906376838685\n",
      "Batch 1970,  loss: 0.1604708194732666\n",
      "Batch 1975,  loss: 0.15288203209638596\n",
      "Batch 1980,  loss: 0.1907167762517929\n",
      "Batch 1985,  loss: 0.12121538966894149\n",
      "Batch 1990,  loss: 0.12533831000328063\n",
      "Batch 1995,  loss: 0.13776127696037294\n",
      "Batch 2000,  loss: 0.12593697309494017\n",
      "Batch 2005,  loss: 0.12864052057266234\n",
      "Batch 2010,  loss: 0.15237558037042617\n",
      "Batch 2015,  loss: 0.13109150975942613\n",
      "Batch 2020,  loss: 0.19105581492185592\n",
      "Batch 2025,  loss: 0.11528643816709519\n",
      "Batch 2030,  loss: 0.15249249041080476\n",
      "Batch 2035,  loss: 0.13142494559288026\n",
      "Batch 2040,  loss: 0.12858694791793823\n",
      "Batch 2045,  loss: 0.15241509079933166\n",
      "Batch 2050,  loss: 0.16493353843688965\n",
      "Batch 2055,  loss: 0.1863735795021057\n",
      "Batch 2060,  loss: 0.16460366696119308\n",
      "Batch 2065,  loss: 0.13394456058740617\n",
      "Batch 2070,  loss: 0.17318906188011168\n",
      "Batch 2075,  loss: 0.132315032184124\n",
      "Batch 2080,  loss: 0.17303241193294525\n",
      "Batch 2085,  loss: 0.162473064661026\n",
      "Batch 2090,  loss: 0.168875053524971\n",
      "Batch 2095,  loss: 0.205437071621418\n",
      "Batch 2100,  loss: 0.12858127802610397\n",
      "Batch 2105,  loss: 0.16045252084732056\n",
      "Batch 2110,  loss: 0.11047524809837342\n",
      "Batch 2115,  loss: 0.14409260898828508\n",
      "Batch 2120,  loss: 0.1675892949104309\n",
      "Batch 2125,  loss: 0.17679028511047362\n",
      "Batch 2130,  loss: 0.10996090620756149\n",
      "Batch 2135,  loss: 0.13681062161922455\n",
      "Batch 2140,  loss: 0.15463704019784927\n",
      "Batch 2145,  loss: 0.16370122730731965\n",
      "Batch 2150,  loss: 0.14628102332353593\n",
      "Batch 2155,  loss: 0.16237317025661469\n",
      "Batch 2160,  loss: 0.1821913793683052\n",
      "Batch 2165,  loss: 0.1295660525560379\n",
      "Batch 2170,  loss: 0.13960107862949372\n",
      "Batch 2175,  loss: 0.17408593595027924\n",
      "Batch 2180,  loss: 0.1572086215019226\n",
      "Batch 2185,  loss: 0.14275432080030442\n",
      "Batch 2190,  loss: 0.19004254937171935\n",
      "Batch 2195,  loss: 0.15140107572078704\n",
      "Batch 2200,  loss: 0.10117005109786988\n",
      "Batch 2205,  loss: 0.19414706528186798\n",
      "Batch 2210,  loss: 0.12500782459974288\n",
      "Batch 2215,  loss: 0.14489030241966247\n",
      "Batch 2220,  loss: 0.11943105459213257\n",
      "Batch 2225,  loss: 0.1396879017353058\n",
      "Batch 2230,  loss: 0.1488377183675766\n",
      "Batch 2235,  loss: 0.19033462405204774\n",
      "Batch 2240,  loss: 0.11563181579113006\n",
      "Batch 2245,  loss: 0.14178486913442612\n",
      "Batch 2250,  loss: 0.1330369919538498\n",
      "Batch 2255,  loss: 0.12878822386264802\n",
      "Batch 2260,  loss: 0.1366690218448639\n",
      "Batch 2265,  loss: 0.19232249557971953\n",
      "Batch 2270,  loss: 0.09677633419632911\n",
      "Batch 2275,  loss: 0.13645429760217667\n",
      "Batch 2280,  loss: 0.15776816457509996\n",
      "Batch 2285,  loss: 0.11383927762508392\n",
      "Batch 2290,  loss: 0.17799866944551468\n",
      "Batch 2295,  loss: 0.13051399290561677\n",
      "Batch 2300,  loss: 0.16706079244613647\n",
      "Batch 2305,  loss: 0.12482917606830597\n",
      "Batch 2310,  loss: 0.16768325567245485\n",
      "Batch 2315,  loss: 0.14014752060174943\n",
      "Batch 2320,  loss: 0.1462723821401596\n",
      "Batch 2325,  loss: 0.15712183266878127\n",
      "Batch 2330,  loss: 0.12011828869581223\n",
      "Batch 2335,  loss: 0.13824897408485412\n",
      "Batch 2340,  loss: 0.23469580113887786\n",
      "Batch 2345,  loss: 0.18885619640350343\n",
      "Batch 2350,  loss: 0.15959636569023133\n",
      "Batch 2355,  loss: 0.1318051442503929\n",
      "Batch 2360,  loss: 0.14998048841953276\n",
      "Batch 2365,  loss: 0.1606554552912712\n",
      "Batch 2370,  loss: 0.16578707545995713\n",
      "Batch 2375,  loss: 0.16110460311174393\n",
      "Batch 2380,  loss: 0.14965529441833497\n",
      "Batch 2385,  loss: 0.16495819091796876\n",
      "Batch 2390,  loss: 0.17690603137016297\n",
      "Batch 2395,  loss: 0.1623520225286484\n",
      "Batch 2400,  loss: 0.13635009676218032\n",
      "Batch 2405,  loss: 0.14363868832588195\n",
      "Batch 2410,  loss: 0.1659366726875305\n",
      "Batch 2415,  loss: 0.16197933554649352\n",
      "Batch 2420,  loss: 0.14546036422252656\n",
      "Batch 2425,  loss: 0.16459356546401976\n",
      "Batch 2430,  loss: 0.12520906776189805\n",
      "Batch 2435,  loss: 0.13569700866937637\n",
      "Batch 2440,  loss: 0.10924015343189239\n",
      "Batch 2445,  loss: 0.1368413969874382\n",
      "Batch 2450,  loss: 0.1590229630470276\n",
      "Batch 2455,  loss: 0.1810179889202118\n",
      "Batch 2460,  loss: 0.18492833971977235\n",
      "Batch 2465,  loss: 0.16503354907035828\n",
      "Batch 2470,  loss: 0.23995571136474608\n",
      "Batch 2475,  loss: 0.1939939260482788\n",
      "Batch 2480,  loss: 0.15987602174282073\n",
      "Batch 2485,  loss: 0.14316449761390687\n",
      "Batch 2490,  loss: 0.13196925520896913\n",
      "Batch 2495,  loss: 0.12570232450962066\n",
      "Batch 2500,  loss: 0.13526332825422288\n",
      "Batch 2505,  loss: 0.14614666402339935\n",
      "Batch 2510,  loss: 0.1039227455854416\n",
      "Batch 2515,  loss: 0.1411847472190857\n",
      "Batch 2520,  loss: 0.153413724899292\n",
      "Batch 2525,  loss: 0.13000205308198928\n",
      "Batch 2530,  loss: 0.17855961322784425\n",
      "Batch 2535,  loss: 0.13315172195434571\n",
      "Batch 2540,  loss: 0.13171164691448212\n",
      "Batch 2545,  loss: 0.13575770407915116\n",
      "Batch 2550,  loss: 0.1492616504430771\n",
      "Batch 2555,  loss: 0.1376502811908722\n",
      "Batch 2560,  loss: 0.19416701495647432\n",
      "Batch 2565,  loss: 0.13549405783414842\n",
      "Batch 2570,  loss: 0.1605323612689972\n",
      "Batch 2575,  loss: 0.15043898522853852\n",
      "Batch 2580,  loss: 0.13679789155721664\n",
      "Batch 2585,  loss: 0.15300084352493287\n",
      "Batch 2590,  loss: 0.16266284883022308\n",
      "Batch 2595,  loss: 0.18765512704849244\n",
      "Batch 2600,  loss: 0.1269425094127655\n",
      "Batch 2605,  loss: 0.16690706312656403\n",
      "Batch 2610,  loss: 0.13141636848449706\n",
      "Batch 2615,  loss: 0.1400420993566513\n",
      "Batch 2620,  loss: 0.13710806667804717\n",
      "Batch 2625,  loss: 0.14556857496500014\n",
      "Batch 2630,  loss: 0.12330759465694427\n",
      "Batch 2635,  loss: 0.16063666641712188\n",
      "Batch 2640,  loss: 0.16230812966823577\n",
      "Batch 2645,  loss: 0.16044992208480835\n",
      "Batch 2650,  loss: 0.14793150126934052\n",
      "Batch 2655,  loss: 0.160613551735878\n",
      "Batch 2660,  loss: 0.15614235997200013\n",
      "Batch 2665,  loss: 0.1820369303226471\n",
      "Batch 2670,  loss: 0.13155580759048463\n",
      "Batch 2675,  loss: 0.14537210762500763\n",
      "Batch 2680,  loss: 0.11940149068832398\n",
      "Batch 2685,  loss: 0.10408244580030442\n",
      "Batch 2690,  loss: 0.1206392228603363\n",
      "Batch 2695,  loss: 0.1435908019542694\n",
      "Batch 2700,  loss: 0.18937032520771027\n",
      "Batch 2705,  loss: 0.14843421876430513\n",
      "Batch 2710,  loss: 0.1382325366139412\n",
      "Batch 2715,  loss: 0.1269277364015579\n",
      "Batch 2720,  loss: 0.17060162425041198\n",
      "Batch 2725,  loss: 0.12858231961727143\n",
      "Batch 2730,  loss: 0.16800911724567413\n",
      "Batch 2735,  loss: 0.15848282873630523\n",
      "Batch 2740,  loss: 0.15169876515865327\n",
      "Batch 2745,  loss: 0.1499010995030403\n",
      "Batch 2750,  loss: 0.16790356636047363\n",
      "Batch 2755,  loss: 0.17736180126667023\n",
      "Batch 2760,  loss: 0.15207426249980927\n",
      "Batch 2765,  loss: 0.18867005854845048\n",
      "Batch 2770,  loss: 0.2170988529920578\n",
      "LOSS train 0.2170988529920578. Validation loss: 0.16097836645354552 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 42:\n",
      "Batch 5,  loss: 0.10297659039497375\n",
      "Batch 10,  loss: 0.17333049029111863\n",
      "Batch 15,  loss: 0.15180583894252778\n",
      "Batch 20,  loss: 0.17237506806850433\n",
      "Batch 25,  loss: 0.16237213015556334\n",
      "Batch 30,  loss: 0.10355657041072845\n",
      "Batch 35,  loss: 0.15542727410793306\n",
      "Batch 40,  loss: 0.20160150527954102\n",
      "Batch 45,  loss: 0.1271105468273163\n",
      "Batch 50,  loss: 0.15844699144363403\n",
      "Batch 55,  loss: 0.15907378792762755\n",
      "Batch 60,  loss: 0.18188110291957854\n",
      "Batch 65,  loss: 0.15152909457683564\n",
      "Batch 70,  loss: 0.1204059898853302\n",
      "Batch 75,  loss: 0.11745110601186752\n",
      "Batch 80,  loss: 0.12050359398126602\n",
      "Batch 85,  loss: 0.14326457381248475\n",
      "Batch 90,  loss: 0.11470285505056381\n",
      "Batch 95,  loss: 0.1510641485452652\n",
      "Batch 100,  loss: 0.10506842881441117\n",
      "Batch 105,  loss: 0.14108233153820038\n",
      "Batch 110,  loss: 0.14160320907831192\n",
      "Batch 115,  loss: 0.16183737963438033\n",
      "Batch 120,  loss: 0.16837801188230514\n",
      "Batch 125,  loss: 0.1328907608985901\n",
      "Batch 130,  loss: 0.15256512463092803\n",
      "Batch 135,  loss: 0.13352486193180085\n",
      "Batch 140,  loss: 0.19701534807682036\n",
      "Batch 145,  loss: 0.15794054567813873\n",
      "Batch 150,  loss: 0.1366751715540886\n",
      "Batch 155,  loss: 0.1720501095056534\n",
      "Batch 160,  loss: 0.1182696908712387\n",
      "Batch 165,  loss: 0.18959434181451798\n",
      "Batch 170,  loss: 0.14510627537965776\n",
      "Batch 175,  loss: 0.15666541010141372\n",
      "Batch 180,  loss: 0.16052285432815552\n",
      "Batch 185,  loss: 0.14494216740131377\n",
      "Batch 190,  loss: 0.1725970536470413\n",
      "Batch 195,  loss: 0.12421252802014351\n",
      "Batch 200,  loss: 0.14928050041198732\n",
      "Batch 205,  loss: 0.12452478259801865\n",
      "Batch 210,  loss: 0.16422311961650848\n",
      "Batch 215,  loss: 0.15078116655349733\n",
      "Batch 220,  loss: 0.14195433408021926\n",
      "Batch 225,  loss: 0.11194386556744576\n",
      "Batch 230,  loss: 0.17120886445045472\n",
      "Batch 235,  loss: 0.12119418084621429\n",
      "Batch 240,  loss: 0.14897917509078978\n",
      "Batch 245,  loss: 0.13734789490699767\n",
      "Batch 250,  loss: 0.19768089056015015\n",
      "Batch 255,  loss: 0.19979070723056794\n",
      "Batch 260,  loss: 0.11496507674455643\n",
      "Batch 265,  loss: 0.1879505455493927\n",
      "Batch 270,  loss: 0.13047214597463608\n",
      "Batch 275,  loss: 0.1584228068590164\n",
      "Batch 280,  loss: 0.15675604939460755\n",
      "Batch 285,  loss: 0.13236290514469146\n",
      "Batch 290,  loss: 0.14132936298847198\n",
      "Batch 295,  loss: 0.17075875103473664\n",
      "Batch 300,  loss: 0.1478594109416008\n",
      "Batch 305,  loss: 0.12992182075977327\n",
      "Batch 310,  loss: 0.16167667955160142\n",
      "Batch 315,  loss: 0.1356856107711792\n",
      "Batch 320,  loss: 0.17332041561603545\n",
      "Batch 325,  loss: 0.1375831201672554\n",
      "Batch 330,  loss: 0.11843840330839157\n",
      "Batch 335,  loss: 0.1451694294810295\n",
      "Batch 340,  loss: 0.15226332545280458\n",
      "Batch 345,  loss: 0.1536501333117485\n",
      "Batch 350,  loss: 0.15293530374765396\n",
      "Batch 355,  loss: 0.17138891518115998\n",
      "Batch 360,  loss: 0.15335096716880797\n",
      "Batch 365,  loss: 0.15229974836111068\n",
      "Batch 370,  loss: 0.1232401117682457\n",
      "Batch 375,  loss: 0.14556263089179994\n",
      "Batch 380,  loss: 0.12511941492557527\n",
      "Batch 385,  loss: 0.17695046365261077\n",
      "Batch 390,  loss: 0.1709785670042038\n",
      "Batch 395,  loss: 0.14087304025888442\n",
      "Batch 400,  loss: 0.14878521859645844\n",
      "Batch 405,  loss: 0.16811785995960235\n",
      "Batch 410,  loss: 0.15078928023576738\n",
      "Batch 415,  loss: 0.1500801235437393\n",
      "Batch 420,  loss: 0.16875692307949067\n",
      "Batch 425,  loss: 0.16036808490753174\n",
      "Batch 430,  loss: 0.1228729248046875\n",
      "Batch 435,  loss: 0.1369811162352562\n",
      "Batch 440,  loss: 0.1320883333683014\n",
      "Batch 445,  loss: 0.11589799076318741\n",
      "Batch 450,  loss: 0.19132542610168457\n",
      "Batch 455,  loss: 0.19890623092651366\n",
      "Batch 460,  loss: 0.15673296451568602\n",
      "Batch 465,  loss: 0.16658128201961517\n",
      "Batch 470,  loss: 0.11135441362857819\n",
      "Batch 475,  loss: 0.12854137271642685\n",
      "Batch 480,  loss: 0.18158155977725982\n",
      "Batch 485,  loss: 0.17173270285129547\n",
      "Batch 490,  loss: 0.16814069598913192\n",
      "Batch 495,  loss: 0.15652852058410643\n",
      "Batch 500,  loss: 0.15621635019779206\n",
      "Batch 505,  loss: 0.14968348741531373\n",
      "Batch 510,  loss: 0.1249456062912941\n",
      "Batch 515,  loss: 0.1447410225868225\n",
      "Batch 520,  loss: 0.10833554416894912\n",
      "Batch 525,  loss: 0.12841936647892\n",
      "Batch 530,  loss: 0.14093250781297684\n",
      "Batch 535,  loss: 0.15320729315280915\n",
      "Batch 540,  loss: 0.1346736654639244\n",
      "Batch 545,  loss: 0.15639992654323578\n",
      "Batch 550,  loss: 0.16441508382558823\n",
      "Batch 555,  loss: 0.12707869559526444\n",
      "Batch 560,  loss: 0.16652072966098785\n",
      "Batch 565,  loss: 0.13403685092926027\n",
      "Batch 570,  loss: 0.1662229359149933\n",
      "Batch 575,  loss: 0.10832505971193314\n",
      "Batch 580,  loss: 0.1751793473958969\n",
      "Batch 585,  loss: 0.17488314509391784\n",
      "Batch 590,  loss: 0.11096068769693375\n",
      "Batch 595,  loss: 0.16041910499334336\n",
      "Batch 600,  loss: 0.10006321668624878\n",
      "Batch 605,  loss: 0.12183540165424347\n",
      "Batch 610,  loss: 0.1517387807369232\n",
      "Batch 615,  loss: 0.15526246577501296\n",
      "Batch 620,  loss: 0.156425541639328\n",
      "Batch 625,  loss: 0.1729456067085266\n",
      "Batch 630,  loss: 0.1263205885887146\n",
      "Batch 635,  loss: 0.16909583210945128\n",
      "Batch 640,  loss: 0.14528801739215852\n",
      "Batch 645,  loss: 0.17631046175956727\n",
      "Batch 650,  loss: 0.11292856857180596\n",
      "Batch 655,  loss: 0.13889452517032624\n",
      "Batch 660,  loss: 0.11810653507709504\n",
      "Batch 665,  loss: 0.16542819738388062\n",
      "Batch 670,  loss: 0.161431622505188\n",
      "Batch 675,  loss: 0.13995469212532044\n",
      "Batch 680,  loss: 0.15750019550323485\n",
      "Batch 685,  loss: 0.1633649706840515\n",
      "Batch 690,  loss: 0.120416259765625\n",
      "Batch 695,  loss: 0.14339675158262252\n",
      "Batch 700,  loss: 0.12640575170516968\n",
      "Batch 705,  loss: 0.13581616356968879\n",
      "Batch 710,  loss: 0.16144439578056335\n",
      "Batch 715,  loss: 0.14791721105575562\n",
      "Batch 720,  loss: 0.13413863778114318\n",
      "Batch 725,  loss: 0.19967189729213713\n",
      "Batch 730,  loss: 0.18324902057647705\n",
      "Batch 735,  loss: 0.13741334825754165\n",
      "Batch 740,  loss: 0.16839029490947724\n",
      "Batch 745,  loss: 0.13732512891292573\n",
      "Batch 750,  loss: 0.1622774124145508\n",
      "Batch 755,  loss: 0.13876506686210632\n",
      "Batch 760,  loss: 0.1533835142850876\n",
      "Batch 765,  loss: 0.18134316504001619\n",
      "Batch 770,  loss: 0.12440907955169678\n",
      "Batch 775,  loss: 0.15785866230726242\n",
      "Batch 780,  loss: 0.12070033401250839\n",
      "Batch 785,  loss: 0.1369190514087677\n",
      "Batch 790,  loss: 0.18567821383476257\n",
      "Batch 795,  loss: 0.13712715059518815\n",
      "Batch 800,  loss: 0.12792937308549882\n",
      "Batch 805,  loss: 0.15193843245506286\n",
      "Batch 810,  loss: 0.12014924436807632\n",
      "Batch 815,  loss: 0.12922060787677764\n",
      "Batch 820,  loss: 0.16465996205806732\n",
      "Batch 825,  loss: 0.1629898279905319\n",
      "Batch 830,  loss: 0.13586732149124145\n",
      "Batch 835,  loss: 0.1776542067527771\n",
      "Batch 840,  loss: 0.20934394896030425\n",
      "Batch 845,  loss: 0.17559313774108887\n",
      "Batch 850,  loss: 0.1593332350254059\n",
      "Batch 855,  loss: 0.1307542771100998\n",
      "Batch 860,  loss: 0.14569031149148942\n",
      "Batch 865,  loss: 0.15181077420711517\n",
      "Batch 870,  loss: 0.13184393644332887\n",
      "Batch 875,  loss: 0.14553048461675644\n",
      "Batch 880,  loss: 0.1712983876466751\n",
      "Batch 885,  loss: 0.15891184508800507\n",
      "Batch 890,  loss: 0.1295892208814621\n",
      "Batch 895,  loss: 0.11821040958166122\n",
      "Batch 900,  loss: 0.16131202578544618\n",
      "Batch 905,  loss: 0.15250416100025177\n",
      "Batch 910,  loss: 0.15119597762823106\n",
      "Batch 915,  loss: 0.1309519112110138\n",
      "Batch 920,  loss: 0.18893858790397644\n",
      "Batch 925,  loss: 0.12316103428602218\n",
      "Batch 930,  loss: 0.14992679357528688\n",
      "Batch 935,  loss: 0.14581867754459382\n",
      "Batch 940,  loss: 0.1240533247590065\n",
      "Batch 945,  loss: 0.15527827590703963\n",
      "Batch 950,  loss: 0.19075399041175842\n",
      "Batch 955,  loss: 0.1349862337112427\n",
      "Batch 960,  loss: 0.213338503241539\n",
      "Batch 965,  loss: 0.19830142259597777\n",
      "Batch 970,  loss: 0.1468081772327423\n",
      "Batch 975,  loss: 0.1189872071146965\n",
      "Batch 980,  loss: 0.13310027867555618\n",
      "Batch 985,  loss: 0.12865990549325942\n",
      "Batch 990,  loss: 0.11946412473917008\n",
      "Batch 995,  loss: 0.16241244971752167\n",
      "Batch 1000,  loss: 0.15612429678440093\n",
      "Batch 1005,  loss: 0.13713111728429794\n",
      "Batch 1010,  loss: 0.14046345353126527\n",
      "Batch 1015,  loss: 0.1594051256775856\n",
      "Batch 1020,  loss: 0.20062620043754578\n",
      "Batch 1025,  loss: 0.15243290662765502\n",
      "Batch 1030,  loss: 0.17605337500572205\n",
      "Batch 1035,  loss: 0.20839080214500427\n",
      "Batch 1040,  loss: 0.1501491129398346\n",
      "Batch 1045,  loss: 0.14661115258932114\n",
      "Batch 1050,  loss: 0.1462862193584442\n",
      "Batch 1055,  loss: 0.12393070012331009\n",
      "Batch 1060,  loss: 0.139654678106308\n",
      "Batch 1065,  loss: 0.15658801794052124\n",
      "Batch 1070,  loss: 0.17236594706773758\n",
      "Batch 1075,  loss: 0.11362802386283874\n",
      "Batch 1080,  loss: 0.13373991549015046\n",
      "Batch 1085,  loss: 0.15520424097776414\n",
      "Batch 1090,  loss: 0.10039705485105514\n",
      "Batch 1095,  loss: 0.147535040974617\n",
      "Batch 1100,  loss: 0.12924589663743974\n",
      "Batch 1105,  loss: 0.17555971443653107\n",
      "Batch 1110,  loss: 0.16840340793132783\n",
      "Batch 1115,  loss: 0.1290760427713394\n",
      "Batch 1120,  loss: 0.18313951194286346\n",
      "Batch 1125,  loss: 0.15124175548553467\n",
      "Batch 1130,  loss: 0.14058509171009065\n",
      "Batch 1135,  loss: 0.1771328017115593\n",
      "Batch 1140,  loss: 0.20013836920261383\n",
      "Batch 1145,  loss: 0.1366448998451233\n",
      "Batch 1150,  loss: 0.12922858893871308\n",
      "Batch 1155,  loss: 0.1711200311779976\n",
      "Batch 1160,  loss: 0.1336958661675453\n",
      "Batch 1165,  loss: 0.18220310509204865\n",
      "Batch 1170,  loss: 0.16166123151779174\n",
      "Batch 1175,  loss: 0.12047280073165893\n",
      "Batch 1180,  loss: 0.15745118856430054\n",
      "Batch 1185,  loss: 0.15502611249685289\n",
      "Batch 1190,  loss: 0.15048927068710327\n",
      "Batch 1195,  loss: 0.12752708792686462\n",
      "Batch 1200,  loss: 0.18320650458335877\n",
      "Batch 1205,  loss: 0.16790851354598998\n",
      "Batch 1210,  loss: 0.11428743302822113\n",
      "Batch 1215,  loss: 0.13473245799541472\n",
      "Batch 1220,  loss: 0.150026735663414\n",
      "Batch 1225,  loss: 0.16208093464374543\n",
      "Batch 1230,  loss: 0.12901902496814727\n",
      "Batch 1235,  loss: 0.13851684033870698\n",
      "Batch 1240,  loss: 0.1736701637506485\n",
      "Batch 1245,  loss: 0.16318436414003373\n",
      "Batch 1250,  loss: 0.191432449221611\n",
      "Batch 1255,  loss: 0.1191648229956627\n",
      "Batch 1260,  loss: 0.1552022874355316\n",
      "Batch 1265,  loss: 0.19637580513954161\n",
      "Batch 1270,  loss: 0.16126203536987305\n",
      "Batch 1275,  loss: 0.14582396000623704\n",
      "Batch 1280,  loss: 0.1256100282073021\n",
      "Batch 1285,  loss: 0.14109827876091002\n",
      "Batch 1290,  loss: 0.20861616134643554\n",
      "Batch 1295,  loss: 0.17994709610939025\n",
      "Batch 1300,  loss: 0.18264067620038987\n",
      "Batch 1305,  loss: 0.13867875784635544\n",
      "Batch 1310,  loss: 0.14959028661251067\n",
      "Batch 1315,  loss: 0.15640670359134673\n",
      "Batch 1320,  loss: 0.14380088299512864\n",
      "Batch 1325,  loss: 0.13461124897003174\n",
      "Batch 1330,  loss: 0.13892262130975724\n",
      "Batch 1335,  loss: 0.14570561945438384\n",
      "Batch 1340,  loss: 0.1932250201702118\n",
      "Batch 1345,  loss: 0.12207514643669129\n",
      "Batch 1350,  loss: 0.1766158163547516\n",
      "Batch 1355,  loss: 0.12412886470556259\n",
      "Batch 1360,  loss: 0.15669678449630736\n",
      "Batch 1365,  loss: 0.13398303538560868\n",
      "Batch 1370,  loss: 0.1145267829298973\n",
      "Batch 1375,  loss: 0.16701502501964569\n",
      "Batch 1380,  loss: 0.1623775005340576\n",
      "Batch 1385,  loss: 0.15328637957572938\n",
      "Batch 1390,  loss: 0.15144435316324234\n",
      "Batch 1395,  loss: 0.18228862285614014\n",
      "Batch 1400,  loss: 0.15772015899419783\n",
      "Batch 1405,  loss: 0.16500564217567443\n",
      "Batch 1410,  loss: 0.17223475724458695\n",
      "Batch 1415,  loss: 0.13312678933143615\n",
      "Batch 1420,  loss: 0.12691145688295363\n",
      "Batch 1425,  loss: 0.14713994562625884\n",
      "Batch 1430,  loss: 0.1623162031173706\n",
      "Batch 1435,  loss: 0.1465119257569313\n",
      "Batch 1440,  loss: 0.17820754051208496\n",
      "Batch 1445,  loss: 0.14289451986551285\n",
      "Batch 1450,  loss: 0.15285181403160095\n",
      "Batch 1455,  loss: 0.09623024612665176\n",
      "Batch 1460,  loss: 0.12779302895069122\n",
      "Batch 1465,  loss: 0.13482502549886705\n",
      "Batch 1470,  loss: 0.14118954241275788\n",
      "Batch 1475,  loss: 0.14153488278388976\n",
      "Batch 1480,  loss: 0.1264267936348915\n",
      "Batch 1485,  loss: 0.13494288176298141\n",
      "Batch 1490,  loss: 0.18744920939207077\n",
      "Batch 1495,  loss: 0.17711909860372543\n",
      "Batch 1500,  loss: 0.13312728554010392\n",
      "Batch 1505,  loss: 0.19082735180854798\n",
      "Batch 1510,  loss: 0.18476683497428895\n",
      "Batch 1515,  loss: 0.16438551098108292\n",
      "Batch 1520,  loss: 0.14350917488336562\n",
      "Batch 1525,  loss: 0.13603645861148833\n",
      "Batch 1530,  loss: 0.1337484523653984\n",
      "Batch 1535,  loss: 0.12215717881917953\n",
      "Batch 1540,  loss: 0.17041051983833314\n",
      "Batch 1545,  loss: 0.1508299320936203\n",
      "Batch 1550,  loss: 0.159511199593544\n",
      "Batch 1555,  loss: 0.14472436308860778\n",
      "Batch 1560,  loss: 0.20164006054401398\n",
      "Batch 1565,  loss: 0.14396308064460756\n",
      "Batch 1570,  loss: 0.11937633752822877\n",
      "Batch 1575,  loss: 0.11014533042907715\n",
      "Batch 1580,  loss: 0.1515936091542244\n",
      "Batch 1585,  loss: 0.13528710305690766\n",
      "Batch 1590,  loss: 0.1195020318031311\n",
      "Batch 1595,  loss: 0.11454353481531143\n",
      "Batch 1600,  loss: 0.15781815052032472\n",
      "Batch 1605,  loss: 0.12632123231887818\n",
      "Batch 1610,  loss: 0.10773113369941711\n",
      "Batch 1615,  loss: 0.12642304897308348\n",
      "Batch 1620,  loss: 0.12361662685871125\n",
      "Batch 1625,  loss: 0.12472545951604844\n",
      "Batch 1630,  loss: 0.13323751986026763\n",
      "Batch 1635,  loss: 0.13682647198438644\n",
      "Batch 1640,  loss: 0.13155877888202666\n",
      "Batch 1645,  loss: 0.17482202798128127\n",
      "Batch 1650,  loss: 0.15953464955091476\n",
      "Batch 1655,  loss: 0.1440850868821144\n",
      "Batch 1660,  loss: 0.20220125317573548\n",
      "Batch 1665,  loss: 0.1240448385477066\n",
      "Batch 1670,  loss: 0.13668939769268035\n",
      "Batch 1675,  loss: 0.18306391835212707\n",
      "Batch 1680,  loss: 0.14123515784740448\n",
      "Batch 1685,  loss: 0.14984763860702516\n",
      "Batch 1690,  loss: 0.1259115904569626\n",
      "Batch 1695,  loss: 0.1385531544685364\n",
      "Batch 1700,  loss: 0.1414843112230301\n",
      "Batch 1705,  loss: 0.12119336873292923\n",
      "Batch 1710,  loss: 0.11657824963331223\n",
      "Batch 1715,  loss: 0.15761857479810715\n",
      "Batch 1720,  loss: 0.16437842845916747\n",
      "Batch 1725,  loss: 0.1407826617360115\n",
      "Batch 1730,  loss: 0.13694673031568527\n",
      "Batch 1735,  loss: 0.13318880200386046\n",
      "Batch 1740,  loss: 0.21461663544178008\n",
      "Batch 1745,  loss: 0.1497712627053261\n",
      "Batch 1750,  loss: 0.12457441240549087\n",
      "Batch 1755,  loss: 0.13908182382583617\n",
      "Batch 1760,  loss: 0.13198919892311095\n",
      "Batch 1765,  loss: 0.176686093211174\n",
      "Batch 1770,  loss: 0.1268256798386574\n",
      "Batch 1775,  loss: 0.12420441657304764\n",
      "Batch 1780,  loss: 0.13246096223592757\n",
      "Batch 1785,  loss: 0.14477258175611496\n",
      "Batch 1790,  loss: 0.13006998747587203\n",
      "Batch 1795,  loss: 0.21815480068325996\n",
      "Batch 1800,  loss: 0.12376269698143005\n",
      "Batch 1805,  loss: 0.16213552355766297\n",
      "Batch 1810,  loss: 0.1892203003168106\n",
      "Batch 1815,  loss: 0.18000759184360504\n",
      "Batch 1820,  loss: 0.12399191856384277\n",
      "Batch 1825,  loss: 0.15131026804447173\n",
      "Batch 1830,  loss: 0.1617794930934906\n",
      "Batch 1835,  loss: 0.10776464492082596\n",
      "Batch 1840,  loss: 0.10340616703033448\n",
      "Batch 1845,  loss: 0.1690305233001709\n",
      "Batch 1850,  loss: 0.17303910851478577\n",
      "Batch 1855,  loss: 0.1651250898838043\n",
      "Batch 1860,  loss: 0.1595369338989258\n",
      "Batch 1865,  loss: 0.12527405917644502\n",
      "Batch 1870,  loss: 0.14726903587579726\n",
      "Batch 1875,  loss: 0.20492120385169982\n",
      "Batch 1880,  loss: 0.13811784088611603\n",
      "Batch 1885,  loss: 0.19541148245334625\n",
      "Batch 1890,  loss: 0.14883965402841567\n",
      "Batch 1895,  loss: 0.1856667399406433\n",
      "Batch 1900,  loss: 0.1407965525984764\n",
      "Batch 1905,  loss: 0.14431134164333342\n",
      "Batch 1910,  loss: 0.18590751737356187\n",
      "Batch 1915,  loss: 0.1421441450715065\n",
      "Batch 1920,  loss: 0.14231151938438416\n",
      "Batch 1925,  loss: 0.11579061597585678\n",
      "Batch 1930,  loss: 0.11498219668865203\n",
      "Batch 1935,  loss: 0.12989825308322905\n",
      "Batch 1940,  loss: 0.16376455426216124\n",
      "Batch 1945,  loss: 0.18037433326244354\n",
      "Batch 1950,  loss: 0.14935032725334169\n",
      "Batch 1955,  loss: 0.13262257725000381\n",
      "Batch 1960,  loss: 0.14857919812202453\n",
      "Batch 1965,  loss: 0.1301862582564354\n",
      "Batch 1970,  loss: 0.19222854375839232\n",
      "Batch 1975,  loss: 0.15109896063804626\n",
      "Batch 1980,  loss: 0.13487179577350616\n",
      "Batch 1985,  loss: 0.15347513258457185\n",
      "Batch 1990,  loss: 0.18005163222551346\n",
      "Batch 1995,  loss: 0.15907601714134217\n",
      "Batch 2000,  loss: 0.16417486518621444\n",
      "Batch 2005,  loss: 0.16484134644269943\n",
      "Batch 2010,  loss: 0.17137908339500427\n",
      "Batch 2015,  loss: 0.14526114165782927\n",
      "Batch 2020,  loss: 0.18200194239616393\n",
      "Batch 2025,  loss: 0.16763083636760712\n",
      "Batch 2030,  loss: 0.16353488862514495\n",
      "Batch 2035,  loss: 0.1530034363269806\n",
      "Batch 2040,  loss: 0.17138223052024842\n",
      "Batch 2045,  loss: 0.1468762129545212\n",
      "Batch 2050,  loss: 0.1277625024318695\n",
      "Batch 2055,  loss: 0.1418859302997589\n",
      "Batch 2060,  loss: 0.1564799129962921\n",
      "Batch 2065,  loss: 0.16843605786561966\n",
      "Batch 2070,  loss: 0.16824343502521516\n",
      "Batch 2075,  loss: 0.15964628010988235\n",
      "Batch 2080,  loss: 0.1428353726863861\n",
      "Batch 2085,  loss: 0.1710369184613228\n",
      "Batch 2090,  loss: 0.17782356441020966\n",
      "Batch 2095,  loss: 0.16307516545057296\n",
      "Batch 2100,  loss: 0.15194953680038453\n",
      "Batch 2105,  loss: 0.14816941618919371\n",
      "Batch 2110,  loss: 0.1361383631825447\n",
      "Batch 2115,  loss: 0.18392230272293092\n",
      "Batch 2120,  loss: 0.17146586179733275\n",
      "Batch 2125,  loss: 0.13984819650650024\n",
      "Batch 2130,  loss: 0.1112189844250679\n",
      "Batch 2135,  loss: 0.1377476081252098\n",
      "Batch 2140,  loss: 0.13977766931056976\n",
      "Batch 2145,  loss: 0.12984439134597778\n",
      "Batch 2150,  loss: 0.1665994107723236\n",
      "Batch 2155,  loss: 0.14640957713127137\n",
      "Batch 2160,  loss: 0.17664804309606552\n",
      "Batch 2165,  loss: 0.14485075771808625\n",
      "Batch 2170,  loss: 0.15331932455301284\n",
      "Batch 2175,  loss: 0.13696931153535843\n",
      "Batch 2180,  loss: 0.12584706544876098\n",
      "Batch 2185,  loss: 0.13753733783960342\n",
      "Batch 2190,  loss: 0.17381763458251953\n",
      "Batch 2195,  loss: 0.16702620536088944\n",
      "Batch 2200,  loss: 0.15434717684984206\n",
      "Batch 2205,  loss: 0.14683204889297485\n",
      "Batch 2210,  loss: 0.16945315450429915\n",
      "Batch 2215,  loss: 0.13518985807895662\n",
      "Batch 2220,  loss: 0.1437800869345665\n",
      "Batch 2225,  loss: 0.1589294046163559\n",
      "Batch 2230,  loss: 0.16910508275032043\n",
      "Batch 2235,  loss: 0.14918401539325715\n",
      "Batch 2240,  loss: 0.13843147158622743\n",
      "Batch 2245,  loss: 0.1511397436261177\n",
      "Batch 2250,  loss: 0.15831816494464873\n",
      "Batch 2255,  loss: 0.16762039959430694\n",
      "Batch 2260,  loss: 0.16740530729293823\n",
      "Batch 2265,  loss: 0.11631319224834442\n",
      "Batch 2270,  loss: 0.1619183048605919\n",
      "Batch 2275,  loss: 0.12459406554698944\n",
      "Batch 2280,  loss: 0.18118928968906403\n",
      "Batch 2285,  loss: 0.13231371343135834\n",
      "Batch 2290,  loss: 0.1615358367562294\n",
      "Batch 2295,  loss: 0.13182830661535264\n",
      "Batch 2300,  loss: 0.11276114732027054\n",
      "Batch 2305,  loss: 0.13599236756563188\n",
      "Batch 2310,  loss: 0.15660664439201355\n",
      "Batch 2315,  loss: 0.15104394108057023\n",
      "Batch 2320,  loss: 0.13784285485744477\n",
      "Batch 2325,  loss: 0.15333554595708848\n",
      "Batch 2330,  loss: 0.15347091853618622\n",
      "Batch 2335,  loss: 0.12159292250871659\n",
      "Batch 2340,  loss: 0.15278806090354918\n",
      "Batch 2345,  loss: 0.13414929807186127\n",
      "Batch 2350,  loss: 0.16376665085554123\n",
      "Batch 2355,  loss: 0.15628645122051238\n",
      "Batch 2360,  loss: 0.14233798682689666\n",
      "Batch 2365,  loss: 0.18232206702232362\n",
      "Batch 2370,  loss: 0.135234597325325\n",
      "Batch 2375,  loss: 0.14391644895076752\n",
      "Batch 2380,  loss: 0.14516989290714263\n",
      "Batch 2385,  loss: 0.11331782788038254\n",
      "Batch 2390,  loss: 0.13860457837581636\n",
      "Batch 2395,  loss: 0.16993757486343383\n",
      "Batch 2400,  loss: 0.13231700360774995\n",
      "Batch 2405,  loss: 0.19705601483583451\n",
      "Batch 2410,  loss: 0.21109447181224822\n",
      "Batch 2415,  loss: 0.16266150325536727\n",
      "Batch 2420,  loss: 0.15366147160530091\n",
      "Batch 2425,  loss: 0.14058158099651336\n",
      "Batch 2430,  loss: 0.20467959344387054\n",
      "Batch 2435,  loss: 0.12989981472492218\n",
      "Batch 2440,  loss: 0.14666589945554734\n",
      "Batch 2445,  loss: 0.13323760032653809\n",
      "Batch 2450,  loss: 0.1409366950392723\n",
      "Batch 2455,  loss: 0.1961945354938507\n",
      "Batch 2460,  loss: 0.1201753243803978\n",
      "Batch 2465,  loss: 0.11752069890499114\n",
      "Batch 2470,  loss: 0.12051622718572616\n",
      "Batch 2475,  loss: 0.18839500844478607\n",
      "Batch 2480,  loss: 0.18675428479909897\n",
      "Batch 2485,  loss: 0.17231843173503875\n",
      "Batch 2490,  loss: 0.19136382937431334\n",
      "Batch 2495,  loss: 0.12206526100635529\n",
      "Batch 2500,  loss: 0.13394370377063752\n",
      "Batch 2505,  loss: 0.1371195510029793\n",
      "Batch 2510,  loss: 0.14935481399297715\n",
      "Batch 2515,  loss: 0.12387909591197968\n",
      "Batch 2520,  loss: 0.13227540552616118\n",
      "Batch 2525,  loss: 0.194101382791996\n",
      "Batch 2530,  loss: 0.13131431192159654\n",
      "Batch 2535,  loss: 0.15692034661769866\n",
      "Batch 2540,  loss: 0.14327991008758545\n",
      "Batch 2545,  loss: 0.15989028215408324\n",
      "Batch 2550,  loss: 0.11131962388753891\n",
      "Batch 2555,  loss: 0.14313212633132935\n",
      "Batch 2560,  loss: 0.13620199710130693\n",
      "Batch 2565,  loss: 0.13469166308641434\n",
      "Batch 2570,  loss: 0.14011239111423493\n",
      "Batch 2575,  loss: 0.15103782415390016\n",
      "Batch 2580,  loss: 0.1711459055542946\n",
      "Batch 2585,  loss: 0.14436181932687758\n",
      "Batch 2590,  loss: 0.13428735733032227\n",
      "Batch 2595,  loss: 0.14451996386051177\n",
      "Batch 2600,  loss: 0.172012123465538\n",
      "Batch 2605,  loss: 0.16902529299259186\n",
      "Batch 2610,  loss: 0.14531159549951553\n",
      "Batch 2615,  loss: 0.12542378902435303\n",
      "Batch 2620,  loss: 0.1631111443042755\n",
      "Batch 2625,  loss: 0.12750200033187867\n",
      "Batch 2630,  loss: 0.1485478550195694\n",
      "Batch 2635,  loss: 0.1551717549562454\n",
      "Batch 2640,  loss: 0.1597523123025894\n",
      "Batch 2645,  loss: 0.13303779512643815\n",
      "Batch 2650,  loss: 0.18378988951444625\n",
      "Batch 2655,  loss: 0.1416463479399681\n",
      "Batch 2660,  loss: 0.14158400744199753\n",
      "Batch 2665,  loss: 0.1416419431567192\n",
      "Batch 2670,  loss: 0.09290574640035629\n",
      "Batch 2675,  loss: 0.1193896010518074\n",
      "Batch 2680,  loss: 0.1722844734787941\n",
      "Batch 2685,  loss: 0.2006335288286209\n",
      "Batch 2690,  loss: 0.13355740606784822\n",
      "Batch 2695,  loss: 0.1531782403588295\n",
      "Batch 2700,  loss: 0.15469534397125245\n",
      "Batch 2705,  loss: 0.14777747094631194\n",
      "Batch 2710,  loss: 0.19913438856601715\n",
      "Batch 2715,  loss: 0.15344740748405455\n",
      "Batch 2720,  loss: 0.120365671813488\n",
      "Batch 2725,  loss: 0.13814034312963486\n",
      "Batch 2730,  loss: 0.16026581525802613\n",
      "Batch 2735,  loss: 0.16832973957061767\n",
      "Batch 2740,  loss: 0.16879956871271135\n",
      "Batch 2745,  loss: 0.13943253457546234\n",
      "Batch 2750,  loss: 0.11959774345159531\n",
      "Batch 2755,  loss: 0.18376132547855378\n",
      "Batch 2760,  loss: 0.14684320986270905\n",
      "Batch 2765,  loss: 0.12999215722084045\n",
      "Batch 2770,  loss: 0.15569482892751693\n",
      "LOSS train 0.15569482892751693. Validation loss: 0.16247047516916172 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 43:\n",
      "Batch 5,  loss: 0.19341618120670317\n",
      "Batch 10,  loss: 0.20412186086177825\n",
      "Batch 15,  loss: 0.21128711849451065\n",
      "Batch 20,  loss: 0.1211319088935852\n",
      "Batch 25,  loss: 0.1479732573032379\n",
      "Batch 30,  loss: 0.1620980203151703\n",
      "Batch 35,  loss: 0.16041728854179382\n",
      "Batch 40,  loss: 0.10813120901584625\n",
      "Batch 45,  loss: 0.14295879602432252\n",
      "Batch 50,  loss: 0.13629884868860245\n",
      "Batch 55,  loss: 0.14132970124483107\n",
      "Batch 60,  loss: 0.1464862823486328\n",
      "Batch 65,  loss: 0.165408219397068\n",
      "Batch 70,  loss: 0.13756232261657714\n",
      "Batch 75,  loss: 0.12649467438459397\n",
      "Batch 80,  loss: 0.1946574032306671\n",
      "Batch 85,  loss: 0.13291913866996766\n",
      "Batch 90,  loss: 0.18301919102668762\n",
      "Batch 95,  loss: 0.145601886510849\n",
      "Batch 100,  loss: 0.12765550762414932\n",
      "Batch 105,  loss: 0.14503706246614456\n",
      "Batch 110,  loss: 0.11855427473783493\n",
      "Batch 115,  loss: 0.10712178945541381\n",
      "Batch 120,  loss: 0.1259647935628891\n",
      "Batch 125,  loss: 0.13778281211853027\n",
      "Batch 130,  loss: 0.14090909957885742\n",
      "Batch 135,  loss: 0.1608241617679596\n",
      "Batch 140,  loss: 0.14261790961027146\n",
      "Batch 145,  loss: 0.13963716626167297\n",
      "Batch 150,  loss: 0.1672832652926445\n",
      "Batch 155,  loss: 0.16415682733058928\n",
      "Batch 160,  loss: 0.16970349550247193\n",
      "Batch 165,  loss: 0.14818798005580902\n",
      "Batch 170,  loss: 0.13212718218564987\n",
      "Batch 175,  loss: 0.17152225375175476\n",
      "Batch 180,  loss: 0.18552808463573456\n",
      "Batch 185,  loss: 0.1259697139263153\n",
      "Batch 190,  loss: 0.16276409924030305\n",
      "Batch 195,  loss: 0.14713461697101593\n",
      "Batch 200,  loss: 0.1373253881931305\n",
      "Batch 205,  loss: 0.17895863503217696\n",
      "Batch 210,  loss: 0.1170091912150383\n",
      "Batch 215,  loss: 0.15253387093544007\n",
      "Batch 220,  loss: 0.16977932602167128\n",
      "Batch 225,  loss: 0.1518021434545517\n",
      "Batch 230,  loss: 0.15144227147102357\n",
      "Batch 235,  loss: 0.1587590828537941\n",
      "Batch 240,  loss: 0.1330685183405876\n",
      "Batch 245,  loss: 0.13840023726224898\n",
      "Batch 250,  loss: 0.11282976865768432\n",
      "Batch 255,  loss: 0.16687467992305755\n",
      "Batch 260,  loss: 0.2169891595840454\n",
      "Batch 265,  loss: 0.18961922079324722\n",
      "Batch 270,  loss: 0.18073413670063018\n",
      "Batch 275,  loss: 0.13532626777887344\n",
      "Batch 280,  loss: 0.18161014020442962\n",
      "Batch 285,  loss: 0.1391549825668335\n",
      "Batch 290,  loss: 0.1226592093706131\n",
      "Batch 295,  loss: 0.1460590362548828\n",
      "Batch 300,  loss: 0.15567128658294677\n",
      "Batch 305,  loss: 0.1353805661201477\n",
      "Batch 310,  loss: 0.13332904279232025\n",
      "Batch 315,  loss: 0.12885837852954865\n",
      "Batch 320,  loss: 0.13120318502187728\n",
      "Batch 325,  loss: 0.19810945689678192\n",
      "Batch 330,  loss: 0.15022532939910888\n",
      "Batch 335,  loss: 0.12870247587561606\n",
      "Batch 340,  loss: 0.14820436686277388\n",
      "Batch 345,  loss: 0.12251308560371399\n",
      "Batch 350,  loss: 0.15114016234874725\n",
      "Batch 355,  loss: 0.14503587931394576\n",
      "Batch 360,  loss: 0.13784291446208954\n",
      "Batch 365,  loss: 0.15643302500247955\n",
      "Batch 370,  loss: 0.17303747832775115\n",
      "Batch 375,  loss: 0.14774291217327118\n",
      "Batch 380,  loss: 0.12921350449323654\n",
      "Batch 385,  loss: 0.1383149206638336\n",
      "Batch 390,  loss: 0.1408362239599228\n",
      "Batch 395,  loss: 0.11267361640930176\n",
      "Batch 400,  loss: 0.10668686181306838\n",
      "Batch 405,  loss: 0.2097027361392975\n",
      "Batch 410,  loss: 0.16915139257907869\n",
      "Batch 415,  loss: 0.16725182235240937\n",
      "Batch 420,  loss: 0.12084417194128036\n",
      "Batch 425,  loss: 0.13049396127462387\n",
      "Batch 430,  loss: 0.16843475103378297\n",
      "Batch 435,  loss: 0.19670289158821105\n",
      "Batch 440,  loss: 0.10945556461811065\n",
      "Batch 445,  loss: 0.1396678864955902\n",
      "Batch 450,  loss: 0.10024751424789428\n",
      "Batch 455,  loss: 0.2014746144413948\n",
      "Batch 460,  loss: 0.11598209291696548\n",
      "Batch 465,  loss: 0.13621747344732285\n",
      "Batch 470,  loss: 0.1460792526602745\n",
      "Batch 475,  loss: 0.1646231919527054\n",
      "Batch 480,  loss: 0.16982595324516297\n",
      "Batch 485,  loss: 0.14431968033313752\n",
      "Batch 490,  loss: 0.15445736646652222\n",
      "Batch 495,  loss: 0.1554553985595703\n",
      "Batch 500,  loss: 0.123480623960495\n",
      "Batch 505,  loss: 0.13180367648601532\n",
      "Batch 510,  loss: 0.17460653483867644\n",
      "Batch 515,  loss: 0.14721095710992813\n",
      "Batch 520,  loss: 0.14468338787555696\n",
      "Batch 525,  loss: 0.11837792247533799\n",
      "Batch 530,  loss: 0.15860829800367354\n",
      "Batch 535,  loss: 0.19522058665752412\n",
      "Batch 540,  loss: 0.1535601556301117\n",
      "Batch 545,  loss: 0.1521529257297516\n",
      "Batch 550,  loss: 0.17535628974437714\n",
      "Batch 555,  loss: 0.14440255165100097\n",
      "Batch 560,  loss: 0.11870102286338806\n",
      "Batch 565,  loss: 0.16767174005508423\n",
      "Batch 570,  loss: 0.15453487187623977\n",
      "Batch 575,  loss: 0.1082378402352333\n",
      "Batch 580,  loss: 0.15322511047124862\n",
      "Batch 585,  loss: 0.15841727703809738\n",
      "Batch 590,  loss: 0.10479062348604203\n",
      "Batch 595,  loss: 0.1277095302939415\n",
      "Batch 600,  loss: 0.1669250726699829\n",
      "Batch 605,  loss: 0.15144356042146684\n",
      "Batch 610,  loss: 0.16973941326141356\n",
      "Batch 615,  loss: 0.14134550094604492\n",
      "Batch 620,  loss: 0.12360073775053024\n",
      "Batch 625,  loss: 0.15542514026165008\n",
      "Batch 630,  loss: 0.16866837590932846\n",
      "Batch 635,  loss: 0.12319839298725128\n",
      "Batch 640,  loss: 0.12772307246923448\n",
      "Batch 645,  loss: 0.1437171384692192\n",
      "Batch 650,  loss: 0.14105465412139892\n",
      "Batch 655,  loss: 0.19938139766454696\n",
      "Batch 660,  loss: 0.15620095580816268\n",
      "Batch 665,  loss: 0.16158213019371032\n",
      "Batch 670,  loss: 0.1830656945705414\n",
      "Batch 675,  loss: 0.12484433501958847\n",
      "Batch 680,  loss: 0.1772175759077072\n",
      "Batch 685,  loss: 0.1374893605709076\n",
      "Batch 690,  loss: 0.18762990534305574\n",
      "Batch 695,  loss: 0.1351712316274643\n",
      "Batch 700,  loss: 0.14818840324878693\n",
      "Batch 705,  loss: 0.10464495420455933\n",
      "Batch 710,  loss: 0.1396443173289299\n",
      "Batch 715,  loss: 0.14201992005109787\n",
      "Batch 720,  loss: 0.12184617519378663\n",
      "Batch 725,  loss: 0.1925404727458954\n",
      "Batch 730,  loss: 0.1274300843477249\n",
      "Batch 735,  loss: 0.12089438885450363\n",
      "Batch 740,  loss: 0.1592663988471031\n",
      "Batch 745,  loss: 0.144007870554924\n",
      "Batch 750,  loss: 0.1453191816806793\n",
      "Batch 755,  loss: 0.165465646982193\n",
      "Batch 760,  loss: 0.1362195134162903\n",
      "Batch 765,  loss: 0.14440124183893205\n",
      "Batch 770,  loss: 0.18822377920150757\n",
      "Batch 775,  loss: 0.18314434885978698\n",
      "Batch 780,  loss: 0.12156590074300766\n",
      "Batch 785,  loss: 0.15175793468952178\n",
      "Batch 790,  loss: 0.1496206432580948\n",
      "Batch 795,  loss: 0.10818486958742142\n",
      "Batch 800,  loss: 0.17558628916740418\n",
      "Batch 805,  loss: 0.1358804941177368\n",
      "Batch 810,  loss: 0.13290159851312638\n",
      "Batch 815,  loss: 0.1691894516348839\n",
      "Batch 820,  loss: 0.1403951019048691\n",
      "Batch 825,  loss: 0.16306486576795579\n",
      "Batch 830,  loss: 0.13518877923488617\n",
      "Batch 835,  loss: 0.12429387122392654\n",
      "Batch 840,  loss: 0.109572733938694\n",
      "Batch 845,  loss: 0.1517210453748703\n",
      "Batch 850,  loss: 0.145520381629467\n",
      "Batch 855,  loss: 0.1432813823223114\n",
      "Batch 860,  loss: 0.16115461736917497\n",
      "Batch 865,  loss: 0.15149527043104172\n",
      "Batch 870,  loss: 0.14824991375207902\n",
      "Batch 875,  loss: 0.16256457567214966\n",
      "Batch 880,  loss: 0.1832497924566269\n",
      "Batch 885,  loss: 0.11674388647079467\n",
      "Batch 890,  loss: 0.1296868309378624\n",
      "Batch 895,  loss: 0.12919971346855164\n",
      "Batch 900,  loss: 0.18463194370269775\n",
      "Batch 905,  loss: 0.1532479614019394\n",
      "Batch 910,  loss: 0.13236518055200577\n",
      "Batch 915,  loss: 0.1664291650056839\n",
      "Batch 920,  loss: 0.13112272173166276\n",
      "Batch 925,  loss: 0.16437793374061585\n",
      "Batch 930,  loss: 0.1640627861022949\n",
      "Batch 935,  loss: 0.1291993796825409\n",
      "Batch 940,  loss: 0.19974930584430695\n",
      "Batch 945,  loss: 0.15488114953041077\n",
      "Batch 950,  loss: 0.12587238252162933\n",
      "Batch 955,  loss: 0.1068821296095848\n",
      "Batch 960,  loss: 0.16641043722629548\n",
      "Batch 965,  loss: 0.14536276161670686\n",
      "Batch 970,  loss: 0.13615586757659912\n",
      "Batch 975,  loss: 0.128696009516716\n",
      "Batch 980,  loss: 0.16144218146800995\n",
      "Batch 985,  loss: 0.16510188579559326\n",
      "Batch 990,  loss: 0.13886125683784484\n",
      "Batch 995,  loss: 0.1767396479845047\n",
      "Batch 1000,  loss: 0.16820371747016907\n",
      "Batch 1005,  loss: 0.15383385568857194\n",
      "Batch 1010,  loss: 0.1333793118596077\n",
      "Batch 1015,  loss: 0.1565748155117035\n",
      "Batch 1020,  loss: 0.1443410724401474\n",
      "Batch 1025,  loss: 0.14540508836507798\n",
      "Batch 1030,  loss: 0.14177747964859008\n",
      "Batch 1035,  loss: 0.20446293652057648\n",
      "Batch 1040,  loss: 0.1811917543411255\n",
      "Batch 1045,  loss: 0.1519046813249588\n",
      "Batch 1050,  loss: 0.1885786920785904\n",
      "Batch 1055,  loss: 0.14384086430072784\n",
      "Batch 1060,  loss: 0.11269422471523285\n",
      "Batch 1065,  loss: 0.15136913657188417\n",
      "Batch 1070,  loss: 0.12263497561216355\n",
      "Batch 1075,  loss: 0.12467467039823532\n",
      "Batch 1080,  loss: 0.16672418713569642\n",
      "Batch 1085,  loss: 0.12479169517755509\n",
      "Batch 1090,  loss: 0.17168886661529542\n",
      "Batch 1095,  loss: 0.17635070979595185\n",
      "Batch 1100,  loss: 0.17140489667654038\n",
      "Batch 1105,  loss: 0.14468988180160522\n",
      "Batch 1110,  loss: 0.14050448685884476\n",
      "Batch 1115,  loss: 0.16431330144405365\n",
      "Batch 1120,  loss: 0.1358131468296051\n",
      "Batch 1125,  loss: 0.16788823306560516\n",
      "Batch 1130,  loss: 0.13292571157217026\n",
      "Batch 1135,  loss: 0.13027038425207138\n",
      "Batch 1140,  loss: 0.15687949657440187\n",
      "Batch 1145,  loss: 0.13849808871746064\n",
      "Batch 1150,  loss: 0.15203689634799958\n",
      "Batch 1155,  loss: 0.23048375844955443\n",
      "Batch 1160,  loss: 0.12337407916784286\n",
      "Batch 1165,  loss: 0.1255725808441639\n",
      "Batch 1170,  loss: 0.15231168270111084\n",
      "Batch 1175,  loss: 0.16262170374393464\n",
      "Batch 1180,  loss: 0.18232174813747407\n",
      "Batch 1185,  loss: 0.15828140527009965\n",
      "Batch 1190,  loss: 0.1393290266394615\n",
      "Batch 1195,  loss: 0.13976958394050598\n",
      "Batch 1200,  loss: 0.20962888300418853\n",
      "Batch 1205,  loss: 0.12862384021282197\n",
      "Batch 1210,  loss: 0.1327711522579193\n",
      "Batch 1215,  loss: 0.15400038063526153\n",
      "Batch 1220,  loss: 0.14460608661174773\n",
      "Batch 1225,  loss: 0.17874061763286592\n",
      "Batch 1230,  loss: 0.15642634481191636\n",
      "Batch 1235,  loss: 0.14526954889297486\n",
      "Batch 1240,  loss: 0.1647738367319107\n",
      "Batch 1245,  loss: 0.15610869228839874\n",
      "Batch 1250,  loss: 0.16857865452766418\n",
      "Batch 1255,  loss: 0.16830547004938126\n",
      "Batch 1260,  loss: 0.15905552506446838\n",
      "Batch 1265,  loss: 0.1239863470196724\n",
      "Batch 1270,  loss: 0.1575673595070839\n",
      "Batch 1275,  loss: 0.11579500883817673\n",
      "Batch 1280,  loss: 0.12240211367607116\n",
      "Batch 1285,  loss: 0.13414637744426727\n",
      "Batch 1290,  loss: 0.16424944698810579\n",
      "Batch 1295,  loss: 0.15027114599943162\n",
      "Batch 1300,  loss: 0.14943941831588745\n",
      "Batch 1305,  loss: 0.15234822034835815\n",
      "Batch 1310,  loss: 0.14592089205980302\n",
      "Batch 1315,  loss: 0.12291336804628372\n",
      "Batch 1320,  loss: 0.15215238630771638\n",
      "Batch 1325,  loss: 0.1577544018626213\n",
      "Batch 1330,  loss: 0.15203354358673096\n",
      "Batch 1335,  loss: 0.11916236877441407\n",
      "Batch 1340,  loss: 0.14057856053113937\n",
      "Batch 1345,  loss: 0.13992209434509278\n",
      "Batch 1350,  loss: 0.1792417049407959\n",
      "Batch 1355,  loss: 0.14893578588962555\n",
      "Batch 1360,  loss: 0.14917900562286376\n",
      "Batch 1365,  loss: 0.13646211624145507\n",
      "Batch 1370,  loss: 0.15746572315692903\n",
      "Batch 1375,  loss: 0.16808851361274718\n",
      "Batch 1380,  loss: 0.13436464443802834\n",
      "Batch 1385,  loss: 0.17625916600227357\n",
      "Batch 1390,  loss: 0.17523870021104812\n",
      "Batch 1395,  loss: 0.15771352052688598\n",
      "Batch 1400,  loss: 0.13048043251037597\n",
      "Batch 1405,  loss: 0.2102596193552017\n",
      "Batch 1410,  loss: 0.10974315255880356\n",
      "Batch 1415,  loss: 0.13945868015289306\n",
      "Batch 1420,  loss: 0.13925983309745787\n",
      "Batch 1425,  loss: 0.1491772100329399\n",
      "Batch 1430,  loss: 0.13157032132148744\n",
      "Batch 1435,  loss: 0.18386296927928925\n",
      "Batch 1440,  loss: 0.12818157374858857\n",
      "Batch 1445,  loss: 0.14381826370954515\n",
      "Batch 1450,  loss: 0.1398253932595253\n",
      "Batch 1455,  loss: 0.15446094274520875\n",
      "Batch 1460,  loss: 0.13885942846536636\n",
      "Batch 1465,  loss: 0.14071842432022094\n",
      "Batch 1470,  loss: 0.17663313448429108\n",
      "Batch 1475,  loss: 0.12847811430692674\n",
      "Batch 1480,  loss: 0.14070555567741394\n",
      "Batch 1485,  loss: 0.16077736467123033\n",
      "Batch 1490,  loss: 0.13364221900701523\n",
      "Batch 1495,  loss: 0.1333341896533966\n",
      "Batch 1500,  loss: 0.15112457424402237\n",
      "Batch 1505,  loss: 0.1551770031452179\n",
      "Batch 1510,  loss: 0.11630690693855286\n",
      "Batch 1515,  loss: 0.16806061267852784\n",
      "Batch 1520,  loss: 0.13869195580482482\n",
      "Batch 1525,  loss: 0.1406960591673851\n",
      "Batch 1530,  loss: 0.12266467809677124\n",
      "Batch 1535,  loss: 0.1492567092180252\n",
      "Batch 1540,  loss: 0.1600911170244217\n",
      "Batch 1545,  loss: 0.13918009847402574\n",
      "Batch 1550,  loss: 0.13132769763469695\n",
      "Batch 1555,  loss: 0.1695626363158226\n",
      "Batch 1560,  loss: 0.13672198504209518\n",
      "Batch 1565,  loss: 0.1288791924715042\n",
      "Batch 1570,  loss: 0.15797735899686813\n",
      "Batch 1575,  loss: 0.14511897414922714\n",
      "Batch 1580,  loss: 0.14877238720655442\n",
      "Batch 1585,  loss: 0.14049303084611892\n",
      "Batch 1590,  loss: 0.17703855335712432\n",
      "Batch 1595,  loss: 0.17048536986112595\n",
      "Batch 1600,  loss: 0.18082260489463806\n",
      "Batch 1605,  loss: 0.13761987984180452\n",
      "Batch 1610,  loss: 0.12523460537195205\n",
      "Batch 1615,  loss: 0.13778309524059296\n",
      "Batch 1620,  loss: 0.1521576911211014\n",
      "Batch 1625,  loss: 0.16079437136650085\n",
      "Batch 1630,  loss: 0.1667531967163086\n",
      "Batch 1635,  loss: 0.13604224026203154\n",
      "Batch 1640,  loss: 0.14777666330337524\n",
      "Batch 1645,  loss: 0.13333074748516083\n",
      "Batch 1650,  loss: 0.14793610125780104\n",
      "Batch 1655,  loss: 0.16090595424175264\n",
      "Batch 1660,  loss: 0.1368611514568329\n",
      "Batch 1665,  loss: 0.15497840344905853\n",
      "Batch 1670,  loss: 0.1269926607608795\n",
      "Batch 1675,  loss: 0.1500648319721222\n",
      "Batch 1680,  loss: 0.15089448690414428\n",
      "Batch 1685,  loss: 0.16240991353988649\n",
      "Batch 1690,  loss: 0.16332112103700638\n",
      "Batch 1695,  loss: 0.11728285253047943\n",
      "Batch 1700,  loss: 0.12682509422302246\n",
      "Batch 1705,  loss: 0.16717093884944917\n",
      "Batch 1710,  loss: 0.12653443664312364\n",
      "Batch 1715,  loss: 0.13299233317375184\n",
      "Batch 1720,  loss: 0.11687761396169663\n",
      "Batch 1725,  loss: 0.1342555344104767\n",
      "Batch 1730,  loss: 0.16613587886095046\n",
      "Batch 1735,  loss: 0.1535212516784668\n",
      "Batch 1740,  loss: 0.18218945264816283\n",
      "Batch 1745,  loss: 0.17075612246990204\n",
      "Batch 1750,  loss: 0.1360063999891281\n",
      "Batch 1755,  loss: 0.1254451036453247\n",
      "Batch 1760,  loss: 0.14961435049772262\n",
      "Batch 1765,  loss: 0.20046439468860627\n",
      "Batch 1770,  loss: 0.12274502217769623\n",
      "Batch 1775,  loss: 0.13703655153512956\n",
      "Batch 1780,  loss: 0.1323539987206459\n",
      "Batch 1785,  loss: 0.1309377856552601\n",
      "Batch 1790,  loss: 0.14165357500314713\n",
      "Batch 1795,  loss: 0.17011170983314514\n",
      "Batch 1800,  loss: 0.15036892890930176\n",
      "Batch 1805,  loss: 0.1648847222328186\n",
      "Batch 1810,  loss: 0.14281054586172104\n",
      "Batch 1815,  loss: 0.15562284588813782\n",
      "Batch 1820,  loss: 0.15424996465444565\n",
      "Batch 1825,  loss: 0.12458167225122452\n",
      "Batch 1830,  loss: 0.13474554866552352\n",
      "Batch 1835,  loss: 0.13273201286792755\n",
      "Batch 1840,  loss: 0.16917605698108673\n",
      "Batch 1845,  loss: 0.17464329600334166\n",
      "Batch 1850,  loss: 0.14706524312496186\n",
      "Batch 1855,  loss: 0.15237379372119902\n",
      "Batch 1860,  loss: 0.1620958536863327\n",
      "Batch 1865,  loss: 0.15929518043994903\n",
      "Batch 1870,  loss: 0.16538801193237304\n",
      "Batch 1875,  loss: 0.15302694588899612\n",
      "Batch 1880,  loss: 0.15795703530311583\n",
      "Batch 1885,  loss: 0.14466904401779174\n",
      "Batch 1890,  loss: 0.12310734987258912\n",
      "Batch 1895,  loss: 0.1707489401102066\n",
      "Batch 1900,  loss: 0.16196032166481017\n",
      "Batch 1905,  loss: 0.21047359108924865\n",
      "Batch 1910,  loss: 0.15287707448005677\n",
      "Batch 1915,  loss: 0.1455472633242607\n",
      "Batch 1920,  loss: 0.13012783974409103\n",
      "Batch 1925,  loss: 0.14179248809814454\n",
      "Batch 1930,  loss: 0.14691701531410217\n",
      "Batch 1935,  loss: 0.16635346412658691\n",
      "Batch 1940,  loss: 0.16471898853778838\n",
      "Batch 1945,  loss: 0.1633850008249283\n",
      "Batch 1950,  loss: 0.1678565114736557\n",
      "Batch 1955,  loss: 0.14442773163318634\n",
      "Batch 1960,  loss: 0.15072796046733855\n",
      "Batch 1965,  loss: 0.15060061514377593\n",
      "Batch 1970,  loss: 0.14653403759002687\n",
      "Batch 1975,  loss: 0.12258627563714981\n",
      "Batch 1980,  loss: 0.14258611798286439\n",
      "Batch 1985,  loss: 0.13178983479738235\n",
      "Batch 1990,  loss: 0.12718889862298965\n",
      "Batch 1995,  loss: 0.2170916736125946\n",
      "Batch 2000,  loss: 0.21220659464597702\n",
      "Batch 2005,  loss: 0.11304975152015687\n",
      "Batch 2010,  loss: 0.11436914950609207\n",
      "Batch 2015,  loss: 0.129997418820858\n",
      "Batch 2020,  loss: 0.15800273716449736\n",
      "Batch 2025,  loss: 0.142889341711998\n",
      "Batch 2030,  loss: 0.12355951815843583\n",
      "Batch 2035,  loss: 0.13872462809085845\n",
      "Batch 2040,  loss: 0.17137242406606673\n",
      "Batch 2045,  loss: 0.1475323975086212\n",
      "Batch 2050,  loss: 0.13564651608467101\n",
      "Batch 2055,  loss: 0.21601902693510056\n",
      "Batch 2060,  loss: 0.13463830202817917\n",
      "Batch 2065,  loss: 0.17511222064495086\n",
      "Batch 2070,  loss: 0.14336341321468354\n",
      "Batch 2075,  loss: 0.1708433896303177\n",
      "Batch 2080,  loss: 0.19139849990606309\n",
      "Batch 2085,  loss: 0.14752731919288636\n",
      "Batch 2090,  loss: 0.1420552536845207\n",
      "Batch 2095,  loss: 0.14584796130657196\n",
      "Batch 2100,  loss: 0.14442668855190277\n",
      "Batch 2105,  loss: 0.1307518869638443\n",
      "Batch 2110,  loss: 0.12598110884428024\n",
      "Batch 2115,  loss: 0.16648389399051666\n",
      "Batch 2120,  loss: 0.218425190448761\n",
      "Batch 2125,  loss: 0.1638573557138443\n",
      "Batch 2130,  loss: 0.13219689205288887\n",
      "Batch 2135,  loss: 0.14857889860868453\n",
      "Batch 2140,  loss: 0.14305362850427628\n",
      "Batch 2145,  loss: 0.18371026664972306\n",
      "Batch 2150,  loss: 0.17507082968950272\n",
      "Batch 2155,  loss: 0.1355011582374573\n",
      "Batch 2160,  loss: 0.13122562170028687\n",
      "Batch 2165,  loss: 0.15558436810970305\n",
      "Batch 2170,  loss: 0.1303870052099228\n",
      "Batch 2175,  loss: 0.1628712758421898\n",
      "Batch 2180,  loss: 0.11377651691436767\n",
      "Batch 2185,  loss: 0.16545366644859313\n",
      "Batch 2190,  loss: 0.12315755933523179\n",
      "Batch 2195,  loss: 0.19123481214046478\n",
      "Batch 2200,  loss: 0.14419116526842118\n",
      "Batch 2205,  loss: 0.152872759103775\n",
      "Batch 2210,  loss: 0.15200603306293486\n",
      "Batch 2215,  loss: 0.133002769947052\n",
      "Batch 2220,  loss: 0.14558377489447594\n",
      "Batch 2225,  loss: 0.14168452024459838\n",
      "Batch 2230,  loss: 0.18110275864601136\n",
      "Batch 2235,  loss: 0.12396735548973084\n",
      "Batch 2240,  loss: 0.16122247278690338\n",
      "Batch 2245,  loss: 0.1351623848080635\n",
      "Batch 2250,  loss: 0.17441740036010742\n",
      "Batch 2255,  loss: 0.1000599056482315\n",
      "Batch 2260,  loss: 0.13543779999017716\n",
      "Batch 2265,  loss: 0.14855610430240632\n",
      "Batch 2270,  loss: 0.15887347906827926\n",
      "Batch 2275,  loss: 0.15176254361867905\n",
      "Batch 2280,  loss: 0.15105913281440736\n",
      "Batch 2285,  loss: 0.1214897871017456\n",
      "Batch 2290,  loss: 0.12117051482200622\n",
      "Batch 2295,  loss: 0.1521897554397583\n",
      "Batch 2300,  loss: 0.1469673365354538\n",
      "Batch 2305,  loss: 0.15158578604459763\n",
      "Batch 2310,  loss: 0.1265749454498291\n",
      "Batch 2315,  loss: 0.10774896293878555\n",
      "Batch 2320,  loss: 0.15288200229406357\n",
      "Batch 2325,  loss: 0.17393283247947694\n",
      "Batch 2330,  loss: 0.18135007619857788\n",
      "Batch 2335,  loss: 0.1861371725797653\n",
      "Batch 2340,  loss: 0.1463148444890976\n",
      "Batch 2345,  loss: 0.13597639799118041\n",
      "Batch 2350,  loss: 0.17837003171443938\n",
      "Batch 2355,  loss: 0.12044480741024018\n",
      "Batch 2360,  loss: 0.1728443294763565\n",
      "Batch 2365,  loss: 0.11709642261266709\n",
      "Batch 2370,  loss: 0.14441442489624023\n",
      "Batch 2375,  loss: 0.11432611644268036\n",
      "Batch 2380,  loss: 0.16577337980270385\n",
      "Batch 2385,  loss: 0.2055549681186676\n",
      "Batch 2390,  loss: 0.14388508647680281\n",
      "Batch 2395,  loss: 0.13664192855358123\n",
      "Batch 2400,  loss: 0.1310028091073036\n",
      "Batch 2405,  loss: 0.16682282090187073\n",
      "Batch 2410,  loss: 0.17691294699907303\n",
      "Batch 2415,  loss: 0.14249709397554397\n",
      "Batch 2420,  loss: 0.12645108997821808\n",
      "Batch 2425,  loss: 0.13695215284824372\n",
      "Batch 2430,  loss: 0.17015882730484008\n",
      "Batch 2435,  loss: 0.1401649832725525\n",
      "Batch 2440,  loss: 0.17708585858345033\n",
      "Batch 2445,  loss: 0.11621172130107879\n",
      "Batch 2450,  loss: 0.11373492032289505\n",
      "Batch 2455,  loss: 0.19516703486442566\n",
      "Batch 2460,  loss: 0.16899767220020295\n",
      "Batch 2465,  loss: 0.14919338673353194\n",
      "Batch 2470,  loss: 0.12836784422397612\n",
      "Batch 2475,  loss: 0.1584859549999237\n",
      "Batch 2480,  loss: 0.16858528852462767\n",
      "Batch 2485,  loss: 0.13860836923122405\n",
      "Batch 2490,  loss: 0.12890191078186036\n",
      "Batch 2495,  loss: 0.12703235745429992\n",
      "Batch 2500,  loss: 0.16376144289970399\n",
      "Batch 2505,  loss: 0.18887135684490203\n",
      "Batch 2510,  loss: 0.16848241090774535\n",
      "Batch 2515,  loss: 0.17677499055862428\n",
      "Batch 2520,  loss: 0.1398337483406067\n",
      "Batch 2525,  loss: 0.13377849906682968\n",
      "Batch 2530,  loss: 0.13947091102600098\n",
      "Batch 2535,  loss: 0.13300623148679733\n",
      "Batch 2540,  loss: 0.11708880364894866\n",
      "Batch 2545,  loss: 0.14656831324100494\n",
      "Batch 2550,  loss: 0.17022862136363984\n",
      "Batch 2555,  loss: 0.1349704921245575\n",
      "Batch 2560,  loss: 0.13265435695648192\n",
      "Batch 2565,  loss: 0.1366664469242096\n",
      "Batch 2570,  loss: 0.23161279559135436\n",
      "Batch 2575,  loss: 0.14553594291210176\n",
      "Batch 2580,  loss: 0.13705522567033768\n",
      "Batch 2585,  loss: 0.15667448937892914\n",
      "Batch 2590,  loss: 0.14687673151493072\n",
      "Batch 2595,  loss: 0.1702881410717964\n",
      "Batch 2600,  loss: 0.14926097989082338\n",
      "Batch 2605,  loss: 0.12145131975412368\n",
      "Batch 2610,  loss: 0.12018312215805053\n",
      "Batch 2615,  loss: 0.1620544746518135\n",
      "Batch 2620,  loss: 0.13258480578660964\n",
      "Batch 2625,  loss: 0.1725750297307968\n",
      "Batch 2630,  loss: 0.14942415952682495\n",
      "Batch 2635,  loss: 0.1485880970954895\n",
      "Batch 2640,  loss: 0.18059446215629577\n",
      "Batch 2645,  loss: 0.13982405066490172\n",
      "Batch 2650,  loss: 0.17611112594604492\n",
      "Batch 2655,  loss: 0.1799745038151741\n",
      "Batch 2660,  loss: 0.14787634015083312\n",
      "Batch 2665,  loss: 0.1516965702176094\n",
      "Batch 2670,  loss: 0.15320816040039062\n",
      "Batch 2675,  loss: 0.1498735100030899\n",
      "Batch 2680,  loss: 0.1417829066514969\n",
      "Batch 2685,  loss: 0.13542396128177642\n",
      "Batch 2690,  loss: 0.14095061719417573\n",
      "Batch 2695,  loss: 0.17396143227815627\n",
      "Batch 2700,  loss: 0.12633104324340821\n",
      "Batch 2705,  loss: 0.15473642945289612\n",
      "Batch 2710,  loss: 0.1137327566742897\n",
      "Batch 2715,  loss: 0.14141030311584474\n",
      "Batch 2720,  loss: 0.19751409888267518\n",
      "Batch 2725,  loss: 0.15227723717689515\n",
      "Batch 2730,  loss: 0.1758433997631073\n",
      "Batch 2735,  loss: 0.12805870771408082\n",
      "Batch 2740,  loss: 0.11812242865562439\n",
      "Batch 2745,  loss: 0.15429167300462723\n",
      "Batch 2750,  loss: 0.1581515207886696\n",
      "Batch 2755,  loss: 0.1545954689383507\n",
      "Batch 2760,  loss: 0.1184890478849411\n",
      "Batch 2765,  loss: 0.12263029664754868\n",
      "Batch 2770,  loss: 0.139598485827446\n",
      "LOSS train 0.139598485827446. Validation loss: 0.1624361152471802 \n",
      "\n",
      "\n",
      "\n",
      "EPOCH 44:\n",
      "Batch 5,  loss: 0.11839828044176101\n",
      "Batch 10,  loss: 0.20056939721107483\n",
      "Batch 15,  loss: 0.1508590191602707\n",
      "Batch 20,  loss: 0.17892480045557022\n",
      "Batch 25,  loss: 0.09066525399684906\n",
      "Batch 30,  loss: 0.1562661573290825\n",
      "Batch 35,  loss: 0.15143944323062897\n",
      "Batch 40,  loss: 0.18326846957206727\n",
      "Batch 45,  loss: 0.13580102920532228\n",
      "Batch 50,  loss: 0.11937677264213561\n",
      "Batch 55,  loss: 0.1560459852218628\n",
      "Batch 60,  loss: 0.12664732486009597\n",
      "Batch 65,  loss: 0.13215155750513077\n",
      "Batch 70,  loss: 0.16371754556894302\n",
      "Batch 75,  loss: 0.1481318473815918\n",
      "Batch 80,  loss: 0.15183850824832917\n",
      "Batch 85,  loss: 0.1275331497192383\n",
      "Batch 90,  loss: 0.15505823493003845\n",
      "Batch 95,  loss: 0.11563738882541656\n",
      "Batch 100,  loss: 0.17370422780513764\n",
      "Batch 105,  loss: 0.1371777981519699\n",
      "Batch 110,  loss: 0.1508580729365349\n",
      "Batch 115,  loss: 0.13358407616615295\n",
      "Batch 120,  loss: 0.13841167241334915\n",
      "Batch 125,  loss: 0.12869665920734405\n",
      "Batch 130,  loss: 0.15678867995738982\n",
      "Batch 135,  loss: 0.1649976447224617\n",
      "Batch 140,  loss: 0.15662926733493804\n",
      "Batch 145,  loss: 0.13046272993087768\n",
      "Batch 150,  loss: 0.15798977315425872\n",
      "Batch 155,  loss: 0.13133425861597062\n",
      "Batch 160,  loss: 0.16488623917102813\n",
      "Batch 165,  loss: 0.16759199500083924\n",
      "Batch 170,  loss: 0.1047222524881363\n",
      "Batch 175,  loss: 0.15997515320777894\n",
      "Batch 180,  loss: 0.12473926842212676\n",
      "Batch 185,  loss: 0.1628616511821747\n",
      "Batch 190,  loss: 0.14521819949150086\n",
      "Batch 195,  loss: 0.12198392599821091\n",
      "Batch 200,  loss: 0.1643383949995041\n",
      "Batch 205,  loss: 0.1251322090625763\n",
      "Batch 210,  loss: 0.1438509166240692\n",
      "Batch 215,  loss: 0.15526518672704698\n",
      "Batch 220,  loss: 0.15352340340614318\n",
      "Batch 225,  loss: 0.1554400771856308\n",
      "Batch 230,  loss: 0.12053764164447785\n",
      "Batch 235,  loss: 0.13642240613698958\n",
      "Batch 240,  loss: 0.1511240690946579\n",
      "Batch 245,  loss: 0.19202142655849458\n",
      "Batch 250,  loss: 0.13695337772369384\n",
      "Batch 255,  loss: 0.13223677277565002\n",
      "Batch 260,  loss: 0.10991076678037644\n",
      "Batch 265,  loss: 0.14705553650856018\n",
      "Batch 270,  loss: 0.15543538331985474\n",
      "Batch 275,  loss: 0.15561237931251526\n",
      "Batch 280,  loss: 0.14885272085666656\n",
      "Batch 285,  loss: 0.12633296847343445\n",
      "Batch 290,  loss: 0.1859142005443573\n",
      "Batch 295,  loss: 0.1676482379436493\n",
      "Batch 300,  loss: 0.17695406675338746\n",
      "Batch 305,  loss: 0.15297226309776307\n",
      "Batch 310,  loss: 0.12414119094610214\n",
      "Batch 315,  loss: 0.14439996629953383\n",
      "Batch 320,  loss: 0.17391397655010224\n",
      "Batch 325,  loss: 0.1322989821434021\n",
      "Batch 330,  loss: 0.12124399989843368\n",
      "Batch 335,  loss: 0.11456056535243989\n",
      "Batch 340,  loss: 0.18862313032150269\n",
      "Batch 345,  loss: 0.14929239004850386\n",
      "Batch 350,  loss: 0.1572345107793808\n",
      "Batch 355,  loss: 0.1608706459403038\n",
      "Batch 360,  loss: 0.15193089544773103\n",
      "Batch 365,  loss: 0.1824001342058182\n",
      "Batch 370,  loss: 0.1566703662276268\n",
      "Batch 375,  loss: 0.13488050401210785\n",
      "Batch 380,  loss: 0.1474139451980591\n",
      "Batch 385,  loss: 0.1190810665488243\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, loss_fn, optimizer, device, epochs)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m running_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[14], line 26\u001b[0m, in \u001b[0;36mtrain_one\u001b[1;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 26\u001b[0m running_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m5\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     29\u001b[0m  last_loss \u001b[38;5;241m=\u001b[39m running_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m5\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, loss_fn, optimizer, device, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH+'voicemodelp2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
